{"case_id": "TC-1198", "name": "PCIe SSD: Hotplug in UEFI/HII (negative test)", "status": "Active", "type": "Manual", "description": "Verify system stability when user hotplugs a device while in HII.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nNote: This test is applicable to 15G and earlier only.\r\nInstall at least one PCIe SSD in the system and boot to HII.\r\n\r\n\r\nInput Data", "expected": "Dell PCIe SSD Configuration Utility is displayed."}, {"step": "1", "description": "Description\nNote: This test is applicable to 15G and earlier only.\nInstall at least one PCIe SSD in the system and boot to HII.\n\n\nInput Data", "expected": "Dell PCIe SSD Configuration Utility is displayed."}], "source": ""}
{"case_id": "case-2", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFor AHCI PCIe SSDs: navigate to the PD properties and ensure the device is listed under the PD selection list. Otherwise (for NVMe PCIe SSDs), skip to step 4.\r\n\r\nInput Data", "expected": "PCIe SSD is displayed and accessible."}], "source": ""}
{"case_id": "case-3", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNavigate out to the main configuration menu.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-4", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the PCIe SSD.\r\n\r\nInput Data", "expected": "PCIe SSD main configuration page (for NVMe) may still be displayed, or the PCIe SSD may still be listed under PD properties (for AHCI) with \"invalid\" or stale data; however:\r\n\r\n\r\n1. Verify system is still stable and functional.\r\n\r\n2. Verify user can navigate within HII Configuration Utility."}], "source": ""}
{"case_id": "case-5", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower off the system. Insert one PCIe SSD and boot into HII.\r\n\r\nInput Data", "expected": "Dell PCIe SSD Configuration Utility is displayed."}], "source": ""}
{"case_id": "case-6", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWhile in the main configuration page, hot insert a new PCIe SSD in the system.\r\n\r\nInput Data", "expected": "PCIe SSD may not get displayed (record exact behavior seen in the test results)\r\n\r\n\r\n1. Verify system is still stable and functional.\r\n\r\n2. Verify user can navigate within HII Configuration Utility."}], "source": ""}
{"case_id": "case-7", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nReboot the system and boot into HII.\r\n\r\nInput Data", "expected": "Hot inserted PCIe SSD from step 6 is now displayed properly and is accessible."}], "source": ""}
{"case_id": "TC-1676", "name": "PCIe SSD - Operating Systems - fdisk", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure that the Linux fdisk utility works with the PCIe SSDs.", "precondition": "-", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported Linux operationg system with at least one PCIe SSD in it.\r\n\r\nInput Data", "expected": "The OS sees the device and loads the driver for it."}, {"step": "1", "description": "Description\r\nBoot into a supported Linux operationg system with at least one PCIe SSD in it.\r\n\r\nInput Data", "expected": "The OS sees the device and loads the driver for it."}], "source": ""}
{"case_id": "case-9", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFrom a terminal, run the command, \"fdisk -l\"\r\n\r\nInput Data", "expected": "The PCIe SSD device node is listed"}], "source": ""}
{"case_id": "case-10", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nFrom a terminal, run the command, \"fdisk /dev/DEVICE\" where DEVICE is the PCIe SSD in the system If there are any partitions on the device already, delete them with the \"d\" command and then create a new partition, otherwise just create a new partition as follows: n p 1 w\r\n\r\nInput Data", "expected": "\"cat /proc/partitions\" now shows that the PCIe SSD has a partition on it now"}], "source": ""}
{"case_id": "TC-3565", "name": "Lifecycle Controller(Negative Test Case):  Verify that the System remains stable when user hotinsert / Hot removes the drives in LifeCycle Controller", "status": "Active", "type": "Manual", "description": "Lifecycle Controller(Negative Test Case): Verify that the System remains stable when user hotinsert / Hot removes the drives in LifeCycle Controller", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one PCIe SSD; boot the system and Launch lifecycle controller.\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall at least one PCIe SSD; boot the system and Launch lifecycle controller.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-12", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIn the left pane, click Hardware configuration\r\n\r\nInput Data", "expected": "Option displayed"}], "source": ""}
{"case_id": "case-13", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIn the right pane, click hardware Inventory\r\n\r\nInput Data", "expected": "Option displayed"}], "source": ""}
{"case_id": "case-14", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nClick view Current Inventory and from the listed device inventory look for PCIe SSD.\r\n\r\nInput Data", "expected": "Lifecycle controller displays the Hardware inventory of the selected PCIe SSD."}], "source": ""}
{"case_id": "case-15", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nFollow below step: 1. Hotremove the installed PCie SSD and hot inset the pcie SSD in the same slot 2. Hot remove the SSD again and hot insert in a different slot\r\n\r\nInput Data", "expected": "No kernel panic or Blue screen. system is functional"}], "source": ""}
{"case_id": "case-16", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nReboot the system and boot to OS. Run some IO to the drives\r\n\r\nInput Data", "expected": "Implict. No I/O errors. Drive is fully functional."}], "source": ""}
{"case_id": "TC-3576", "name": "PCIe SSD - Long term: IO and wear leveling stress during power interruption", "status": "Active", "type": "Manual", "description": "Verify device stability and wear leveling runs regardless of power interruption.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall maximum supported PCIe SSDs in the system. Preferably have a mix of device capacities and form factor.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall maximum supported PCIe SSDs in the system. Preferably have a mix of device capacities and form factor.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-18", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nExport the PCIe SSD logs via a supported utility such as OMSS or HII.\r\n\r\nInput Data", "expected": "Logs exported for all devices in the system. Make record of the %life used and spare blocks."}], "source": ""}
{"case_id": "case-19", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup an IO utility to run heavy IO to the PCIe SSD with a high thread count for 1min. \r\n\r\nInput Data", "expected": "IO runs without issues."}], "source": ""}
{"case_id": "case-20", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAfter IO is stopped from step 3, SRSI the PCIe SSD (surprise remove the PCIe SSD followed by a surprise insertion).  \r\n\r\nRepeat steps 3 and 4 10 times if doing manual, or 1000 times if automated (preferred). Wait 1 second in between SR, SI and restarting IO.\r\n\r\n\r\nInput Data", "expected": "No issues during SRSI cycles."}], "source": ""}
{"case_id": "case-21", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nExport the PCIe SSD logs via a supported utility such as OMSS or HII.\r\n\r\nInput Data", "expected": "Logs exported for all devices in the system. %life used and spare blocks have not changed significantly."}], "source": ""}
{"case_id": "case-22", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nReview the SEL, OS logs, and other applicable management logs for any issues or oddities.\r\n\r\nInput Data", "expected": "No issues."}], "source": ""}
{"case_id": "TC-3759", "name": "PCIe SSD: Hot remove a drive while running I/O", "status": "Active", "type": "Manual", "description": "Verify the system remains operational when a PCIe SSD device disappears (ie. removed) while running I/O.", "precondition": "", "steps": [{"step": "1", "description": "Description\nInstall the device under test. If Write Through (WT) mode is applicable to the device, complete steps 1-4 for drives that are in WT mode (write caching disabled).\n\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall the device under test. If Write Through (WT) mode is applicable to the device, complete steps 1-4 for drives that are in WT mode (write caching disabled).\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\r\nBoot to the OS and load the driver for the device. Perform some simple I/O operations on the drive.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\r\nPull the device out.\r\n\r\nInput Data\r\nI/O halted and reported unknown error upon pulling device out\r\nbut system continues to function  without any fatal system error", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}, {"step": "4", "description": "Description\r\nRe-insert the drive. If supported by the I/O utility, verify data integrity (no data loss) when write caching is disabled.\r\n\r\nInput Data", "expected": "Drive is visible and accessible. Data processed prior to the removal is intact. No data loss."}, {"step": "5", "description": "Description\r\nIf applicable to the device, complete steps 1-4 for drives that have write caching enabled (might experience data loss).\r\n\r\nInput Data\r\nno differences  noted with & without windows OS Cache enabled/disabled\r\nsystem continues to function irrespective", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}, {"step": "6", "description": "Description\r\nRepeat steps 2-5 10 times.\r\n\r\nInput Data\r\nresults duplicated every repitition", "expected": "Same results."}, {"step": "1", "description": "Description\r\nInstall the device under test. If Write Through (WT) mode is applicable to the device, complete steps 1-4 for drives that are in WT mode (write caching disabled).\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-24", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS and load the driver for the device. Perform some simple I/O operations on the drive.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-25", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPull the device out.\r\n\r\nInput Data\r\nI/O halted and reported unknown error upon pulling device out\r\nbut system continues to function  without any fatal system error", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}], "source": ""}
{"case_id": "case-26", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the drive. If supported by the I/O utility, verify data integrity (no data loss) when write caching is disabled.\r\n\r\nInput Data", "expected": "Drive is visible and accessible. Data processed prior to the removal is intact. No data loss."}], "source": ""}
{"case_id": "case-27", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf applicable to the device, complete steps 1-4 for drives that have write caching enabled (might experience data loss).\r\n\r\nInput Data\r\nno differences  noted with & without windows OS Cache enabled/disabled\r\nsystem continues to function irrespective", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}], "source": ""}
{"case_id": "case-28", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 2-5 10 times.\r\n\r\nInput Data\r\nresults duplicated every repitition", "expected": "Same results."}], "source": ""}
{"case_id": "TC-4928", "name": "PCIe SSD: Pre-OS hot add [negative test]", "status": "Active", "type": "Manual", "description": "Verify that a hot inserted drive during boot is present and accessible after the OS loads.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot the system and hot insert the device under test before the OS starts to load\r\n\r\nInput Data", "expected": "Device is inserted. System continues to be funcional."}, {"step": "1", "description": "Description\r\nBoot the system and hot insert the device under test before the OS starts to load\r\n\r\nInput Data", "expected": "Device is inserted. System continues to be funcional."}], "source": ""}
{"case_id": "case-30", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS\r\n\r\nInput Data", "expected": "OS loads successfully.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-31", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify that the hot inserted device functions properly (ie. perform some I/O)\r\n\r\nInput Data", "expected": "The PCIe SSD device functions correctly (correct link width and speed). No errors are reported.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "TC-4997", "name": "PCIe SSD: mdadm - Add a Hot-Inserted Drive to an Existing Array", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that a newly hot inserted device can be added to an existing RAID array.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a RAID1\r\n\r\nInput Data", "expected": "The RAID1 array is successfully created"}, {"step": "1", "description": "Description\r\nCreate a RAID1\r\n\r\nInput Data", "expected": "The RAID1 array is successfully created"}], "source": ""}
{"case_id": "case-33", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-34", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID0\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID0"}], "source": ""}
{"case_id": "case-35", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate a RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-36", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-37", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID5\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID5 and resyncs"}], "source": ""}
{"case_id": "TC-11027", "name": "PCIeSSD: BIOS Memory Reservation on Empty Ports", "status": "Active", "type": "Manual", "description": "This test is to ensure that the BIOS always allocates memory for empty root ports/PCIe switch ports to support hot insertion.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS of the system with no NVMe devices installed\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS of the system with no NVMe devices installed\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-39", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDump the PCIe configuration space of the root ports or PCIe switch ports above where the NVMe drives would be\r\n\r\nInput Data", "expected": "The \"Memory Base\" and \"Memory Limit\" registers are both non-zero, and equal to each other."}], "source": ""}
{"case_id": "TC-18261", "name": "PCIeSSD: 4k Sector Size Capacity Check in HII", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, boot into the HII page for the drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}, {"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, boot into the HII page for the drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}], "source": ""}
{"case_id": "case-41", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\r\n\r\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\r\n\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-42", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the HII page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-43", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "TC-19270", "name": "PCIe SSD - Factory WinPE - NVMe inventory (factory util)", "status": "Active", "type": "Manual", "description": "To validate compatibility of NVMe PCIe SSD in WinPE environment. Confirm user is able to retrieve NVMe PCIe SSD properties via the utility used by the factory.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system of each device type and/or form factor.\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system of each device type and/or form factor.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-45", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPull the latest FICore image and boot to it.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-46", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUsing the factory utility, retrieve the NVMe PCIe SSD properties. This step will need to be repeated for every different type of NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Device properties are retrieved successfully. All expected properties are returned and these contain the correct value (also formatted correctly)."}], "source": ""}
{"case_id": "TC-21294", "name": "PCIe SSD ESXi - Hot-Plug of Assigned Datastore (VM Off)", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is off", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Datastore is successfully created"}, {"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Datastore is successfully created"}], "source": ""}
{"case_id": "case-48", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created datastore to a virtual machine\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-49", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWith the VM powered OFF, remove the NVMe drive that has the datastore on it\r\n\r\nInput Data", "expected": "The OS does not crash\r\nThe drive is removed from lspci\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI"}], "source": ""}
{"case_id": "case-50", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the NVMe drive that was removed\r\n\r\nInput Data", "expected": "The device is re-enumerated in lspci\r\nThe device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)"}], "source": ""}
{"case_id": "case-51", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The virtual disks carved from the NVMe datastore is detected within the VM and can successfully complete I/O (run for a minute)"}], "source": ""}
{"case_id": "TC-21854", "name": "PCIeSSD: NVMe MI - Hotplug a device and check the device discovery time", "status": "Active", "type": "Manual", "description": "The device should respond in 1 sec to idrac when idrac talks to its channel after it is hot plugged.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect an I2C Analyzer to the system\r\n\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nConnect an I2C Analyzer to the system\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-53", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the SUT without any NVMe drive into the OS\r\n\r\nNOTE if you must have another NVMe drive installed as the OS, then you will see traffic going to that drive if it's in the same bay as the drive you will be inserting. If this is the case, then consult the I2CTopology.bin file in the iDRAC's root filesystem to view the MUX information to understand when the iDRAC is communicating to the OS drive versus the hotplugged drive.\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-54", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart the I2C trace capture/recording\r\n\r\nInput Data", "expected": "You should not see any communication with I2C address 0xD4 or 0x3A"}], "source": ""}
{"case_id": "case-55", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "Within 10s, in the I2C trace:\r\n1. The FRU of the device will be read from 0xA6 address\r\n2. NVMe-MI traffic to I2C address 0x3A (or 0xD4 if an old device) starts (likely a Read NVme-MI Data Structure command)\r\n\r\nThe order of items #1 and #2 does not matter."}], "source": ""}
{"case_id": "case-56", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove that same drive that was just inserted\r\n\r\nInput Data", "expected": "Within 10s, no more I2C communication with I2C addresses 0xD4 or 0x3A is seen"}], "source": ""}
{"case_id": "TC-24794", "name": "PCIe SSD - UEFI Driver - HII Forms and xUEFI", "status": "Active", "type": "Manual", "description": "Will make sure that HII forms can be processed and that the x-UEFI language is supported", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInsert at least one PCIe SSD in the system and boot to an EFI-bootable USB key\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInsert at least one PCIe SSD in the system and boot to an EFI-bootable USB key\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-58", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nType \"DlpDump.efi\"\r\n\r\nInput Data", "expected": "The FQDD for the PCIe SSD is displayed"}], "source": ""}
{"case_id": "case-59", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nType \"HiiDump.efi -f -d FQDD > tempFile.txt\" where FQDD is the FQDD from step 2\r\n\r\nInput Data", "expected": "In the \"Form Set #1\" section, \"x-UEFI\" is listed as a supported language"}], "source": ""}
{"case_id": "TC-25059", "name": "PCIe SSD: mdadm - Configure Hot Added Drive as a Local Hot Spare", "status": "Active", "type": "Manual", "description": "This test case is used to make sure that a hot inserted NVMe drive can be configured to be configures as a global hot spare for a redundant mdadm RAID array.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a redundant mdadm RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}, {"step": "1", "description": "Description\r\nCreate a redundant mdadm RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}], "source": ""}
{"case_id": "case-61", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert an NVMe drive into the system\r\n\r\nInput Data", "expected": "The NVMe drive is discovered and enumerated by the device driver"}], "source": ""}
{"case_id": "case-62", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nConfigure the hot inserted NVMe drive to be a local hot-spare for the RAID1 array\r\n\r\nInput Data", "expected": "The drive is successfully configured as a local hot-spare for the RAID1 array"}], "source": ""}
{"case_id": "TC-26314", "name": "PCIe SSD: device power measurements", "status": "Active", "type": "Manual", "description": "Verify PCIe SSD power requirements meet Dell specifications.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nPull the latest PCIe SSD device spec and ensure the power requirements meet the Dell requirements. Refer to the Dell RFQ or related document to confirm. Check for the following: - Max/Idle power - Main voltage - Main current - Voltage/Current aux\r\n\r\nInput Data", "expected": "Device specs meet Dell specs."}, {"step": "1", "description": "Description\nPull the latest PCIe SSD device spec and ensure the power requirements meet the Dell requirements. Refer to the Dell RFQ or related document to confirm. Check for the following: - Max/Idle power - Main voltage - Main current - Voltage/Current aux\n\nInput Data", "expected": "Device specs meet Dell specs."}], "source": ""}
{"case_id": "TC-26936", "name": "PCIe SSD: LVM - Configure Hot Added Drive as a Global Hot Spare", "status": "Active", "type": "Manual", "description": "This test case is used to make sure that a hot inserted NVMe drive can be configured to be configures as a global hot spare for a redundant LVM RAID array.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a redundant LVM RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}, {"step": "1", "description": "Description\nCreate a redundant LVM RAID array (like a RAID1)\n\nInput Data", "expected": "The array is created successfully and the background sync completes"}], "source": ""}
{"case_id": "case-65", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert an NVMe drive into the system\r\n\r\nInput Data", "expected": "The NVMe drive is discovered and enumerated by the device driver"}], "source": ""}
{"case_id": "case-66", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nConfigure the hot inserted NVMe drive to be a global hot-spare\r\n\r\nFor example:\r\n\r\nvgextend testvg /dev/nvme8n1\r\n\r\n\r\nInput Data", "expected": "The drive is successfully configured as a global hot-spare"}], "source": ""}
{"case_id": "TC-27143", "name": "PCIeSSD - Hot Insertion : Using Quarch when surprised inserted, the device is available and  unavailable on surprise removal", "status": "Active", "type": "Manual", "description": "Verify MPS is correctly programmed with system booted with device vs. newly added device during runtime using a Quarch", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.\r\n\r\nInput Data", "expected": "Implict"}, {"step": "1", "description": "Description\r\nBoot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-68", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot remove the device using Quarch.\r\n\r\nInput Data", "expected": "Host system continues to run without freeze or hang after the device hot removed and the device is removed from the system."}], "source": ""}
{"case_id": "case-69", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert the device using Quarch and run some I/O\r\n\r\nInput Data", "expected": "The device is detected by the system and I/O runs fine."}], "source": ""}
{"case_id": "case-70", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat step 2 and 3 for 30 minutes\r\n\r\nInput Data", "expected": "Result same as step 2 and 3."}], "source": ""}
{"case_id": "TC-32106", "name": "PCIe SSD ESXi - Hot-Plug of Assigned Datastore (VM On)", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is on", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Datastore is successfully created"}, {"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Datastore is successfully created"}], "source": ""}
{"case_id": "case-72", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created datastore to a virtual machine (1 to Windows and 1 to Linux)\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-73", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive"}], "source": ""}
{"case_id": "case-74", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWith the VM powered ON, remove the NVMe drive that has the datastore on it\r\n\r\nInput Data", "expected": "The hypervisor does not crash\nThe VM OS does not crash\nThe drive is removed from lspci from the hypervisor\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI\nThe virtual disk is removed from the VM OS (you can check \"cat /proc/partitions | grep sd\" in Linux or the Disk Manager in Windows)"}], "source": ""}
{"case_id": "TC-37377", "name": "PCIe SSD: in-rush protection", "status": "Active", "type": "Manual", "description": "Verify that a PCIe SSD device can be hot inserted into a running system and remain operational.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-76", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall the device under test while the OS is running.\r\n\r\nInput Data", "expected": "Verify that the new hardware is added to the system and will configure it if the driver is available. Pull the SMART/Error log from the device."}], "source": ""}
{"case_id": "case-77", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify that the hot inserted device functions properly (ie. perform some I/O)\r\n\r\nInput Data", "expected": "The PCIe SSD device functions correctly after the hot insertion operation. The PCIe SSD default settings are unchanged. Device config space is unchanged.\r\n\r\nSMART/Error log reports 0 errors or abnormalities."}], "source": ""}
{"case_id": "case-78", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2 and 3 at least 10 times.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-79", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUsing Quarch equipment (or other automation method) to perform at least 50 cycles of a PCIe SSD hot insertion with a running system.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "TC-38886", "name": "PCIe SSD: LVM - Rebuild Array after Surprise Removal with Local Hot Spare", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that after a drive is surprise removed from a redundant RAID array, that a rebuild will start with the assigned hot-spare.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a redundant LVM RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}, {"step": "1", "description": "Description\nCreate a redundant LVM RAID array (like a RAID1)\n\nInput Data", "expected": "The array is created successfully and the background sync completes"}], "source": ""}
{"case_id": "case-81", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConfigure another NVMe drive that's not a part of the array to be a local hot-spare\r\n\r\nInput Data", "expected": "The drive is successfully configured as a hot-spare"}], "source": ""}
{"case_id": "case-82", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart I/O to the virtual disk\r\n\r\nInput Data", "expected": "I/O is being handled successfully"}], "source": ""}
{"case_id": "case-83", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove one of the NVMe drives that's a part of the redundant LVM RAID array\r\n\r\nInput Data", "expected": "The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy.\r\n\r\nI/O continues to be processed."}], "source": ""}
{"case_id": "case-84", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStop the I/O stress to allow the resync to finish quicker\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "TC-38896", "name": "PCIe SSD: Power loss during firmware update", "status": "Active", "type": "Manual", "description": "Verify that firmware is not corrupted upon subsequent boot when the PCIe SSD device loses power during firmware flash update.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an environment supported by the firmware flash utility. With a N-1 firmware installed on device, launch firmware update. Keep updating/downgrading firmware in loop. \r\n\r\nInput Data", "expected": "Firmware process upgrade/downgrade starts."}, {"step": "1", "description": "Description\r\nBoot to an environment supported by the firmware flash utility. With a N-1 firmware installed on device, launch firmware update. Keep updating/downgrading firmware in loop. \r\n\r\nInput Data", "expected": "Firmware process upgrade/downgrade starts."}], "source": ""}
{"case_id": "case-86", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDuring execution, pull the AC cable out from the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-87", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRestore power to the system and boot the system into the OS.\r\n\r\nInput Data", "expected": "Device is present and functional."}], "source": ""}
{"case_id": "case-88", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nMake sure the devices are available and repeat the steps 2,3,4 10 times. \r\n\r\nInput Data", "expected": "Make sure that device contains the N-1 firmware as power was pulled during DUP execution."}], "source": ""}
{"case_id": "case-89", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nMake sure device is available at block layer and is accessible. \r\n\r\nInput Data", "expected": "Test completes successfully"}], "source": ""}
{"case_id": "TC-41116", "name": "PCIeSSD: NVMe MI - Device Discovery in idrac GUI", "status": "Active", "type": "Manual", "description": "NVMe MI - Device Discovery in  idrac GUI", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nHookup the I2C Analyzer to the System Back plane to capture the I2C traffic  \r\nNote: D4 is the device I2C address \r\nAs per system get the Channel  I2C mapping to slot\r\n\r\n(This step is not mandatory - But preferred)\r\n\r\n\r\nInput Data", "expected": "NA"}, {"step": "1", "description": "Description\nBoot to the OS with an NVMe device that supports Block Erase and Crypto Erase sanitize. Sanitize erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\n\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\n\n\nIt is recommended to use Linux for its passthru command capabilities.\n\n\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nHookup the I2C Analyzer to the System Back plane to capture the I2C traffic  \r\nNote: D4 is the device I2C address \r\nAs per system get the Channel  I2C mapping to slot\r\n\r\n(This step is not mandatory - But preferred)\r\n\r\n\r\nInput Data", "expected": "NA"}], "source": ""}
{"case_id": "case-91", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the SUT with atleast 1 NVMe SSD\r\n\r\nInput Data", "expected": "NA"}], "source": ""}
{"case_id": "case-92", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the drive is inventoried in idrac.\r\n\r\nInput Data", "expected": "Drive should be detected under storage - physical drives"}], "source": ""}
{"case_id": "TC-44160", "name": "PCIe SSD: mdadm - Arrays Fail at the Right Time when Drives are Removed", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that RAID arrays will transition to the failed state at the right time when drives are removed.\r\n\r\nRAID0 - Fails after 1 drive being removed.\r\nRAID5 - Fails after 2 drives being removed.\r\nRAID6 - Fails after 3 drives being removed.\r\nRAID10 - Fails after 2 drives being removed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a 2-drive RAID0\r\n\r\nInput Data", "expected": "The RAID0 array is created successfully"}, {"step": "1", "description": "Description\r\nCreate a 2-drive RAID0\r\n\r\nInput Data", "expected": "The RAID0 array is created successfully"}], "source": ""}
{"case_id": "case-94", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove one of the drives in the RAID0 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-95", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-96", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove two of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-97", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-98", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove three of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-99", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-100", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nSurprise remove two of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "TC-46577", "name": "PCIe SSD ESXi - Hot-Plug of Assigned Physical RDM (VM Off)", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is off", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a physical RDM on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Physical RDM is successfully created"}, {"step": "1", "description": "Description\r\nCreate a physical RDM on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Physical RDM is successfully created"}], "source": ""}
{"case_id": "case-102", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created Physical RDM to a virtual machine\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-103", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWith the VM powered OFF, remove the NVMe drive that has the Physical RDM on it\r\n\r\nInput Data", "expected": "The OS does not crash\r\nThe drive is removed from lspci\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI"}], "source": ""}
{"case_id": "case-104", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the NVMe drive that was removed\r\n\r\nInput Data", "expected": "The device is re-enumerated in lspci\r\nThe device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)"}], "source": ""}
{"case_id": "case-105", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The virtual disks carved from the NVMe Physical RDM is detected within the VM and can successfully complete I/O (run for a minute)"}], "source": ""}
{"case_id": "TC-49509", "name": "PCIeSSD: 4k Sector Size Capacity Check in iDRAC", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, check the iDRAC page for the drive\r\n\r\nInput Data", "expected": "n the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}, {"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, check the iDRAC page for the drive\r\n\r\nInput Data", "expected": "n the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}], "source": ""}
{"case_id": "case-107", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\r\n\r\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-108", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the iDRAC page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-109", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "TC-51958", "name": "PCIe SSD: mdadm - Redundant Arrays Degrade at the Right Time when Drives are Removed", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that redundant RAID arrays will transition to the degraded state at the right time when drives are removed.\r\n\r\nRAID1 - Degrades after 1 drive being removed.\r\nRAID5 - Degrades after 1 drive being removed.\r\nRAID6 - Degrades after 2 drives being removed.\r\nRAID10 - Degrades after 1 drive being removed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a 2-drive RAID1\r\n\r\nInput Data", "expected": "The RAID1 is created successfully, and the background resync completes"}, {"step": "1", "description": "Description\r\nCreate a 2-drive RAID1\r\n\r\nInput Data", "expected": "The RAID1 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-111", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove one of the drives in the RAID1 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-112", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-113", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove one of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-114", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-115", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove two of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-116", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-117", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nSurprise remove one of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "TC-53188", "name": "PCIe SSD: Generic Full Sweep Performance on Raw Drive", "status": "Active", "type": "Manual", "description": "TestDrive TestCase Objective was not specified.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported Windows or Linux OS with 1 PCIe SSD installed in the system.\r\n\r\nInput Data", "expected": "The system boots and recognizes the PCIe SSD."}, {"step": "1", "description": "Description\r\nBoot to a supported Windows or Linux OS with 1 PCIe SSD installed in the system.\r\n\r\nInput Data", "expected": "The system boots and recognizes the PCIe SSD."}, {"step": "2", "description": "Description\r\nIf using Windows, copy the IOMeter.exe and dynamo.exe files to the system. Else if using Linux, copy the source files to the system and run: 1. touch /usr/include/stropts.h 2. make -f Makefile-Linux.x86_64 dynamo\r\n\r\nInput Data", "expected": "IOMeter is successfully installed on the test system."}, {"step": "3", "description": "Description\r\nEnsure that the PCIe SSD to be tested is not partitioned and does not have a filesystem on it.\r\n\r\nInput Data", "expected": "The drive is raw."}, {"step": "4", "description": "Description\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, you'll need another computer to run a Windows version of IOMeter on it. Then, you'll have to make sure that both the Linux test machine and the Windows computer are on the same network and can ping each other. The firewall on both machines will also have to be disabled ( service iptbales stop for the Linux machine). Once, this is setup, edit the /etc/hosts file on the Linux machine and add an entry for the new IP address of your Linux machine. Last, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\n\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}, {"step": "5", "description": "Description\nDownload the .icf files that are attached to this test case and save them somewhere on the test system if using Windows, or somewhere on the Windows computer if using Linux.\n\nInput Data", "expected": "The .icf files are copied onto the appropriate machine."}, {"step": "6", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the PreCondition.icf file .\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}, {"step": "7", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "8", "description": "Description\r\nFor each worker, remove the \"4kRandWrite4kAlign\" access specification from the \"Access Specifications\" tab.\r\n\r\nInput Data", "expected": "Each worker only has the \"64kSeq..\" test to run."}, {"step": "9", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}, {"step": "10", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = (2 * C) / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to twice over is calculated."}, {"step": "11", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}, {"step": "12", "description": "Description\r\nNow remove the \"64kSeq...\" test from each workers \"Access Specifications\" tab and add the \"4kSeqWrite..\" test in its place.\r\n\r\nInput Data", "expected": "Each worker only has the \"4kSeq..\" test to run."}, {"step": "13", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}, {"step": "14", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = C / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to once is calculated."}, {"step": "15", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}, {"step": "16", "description": "Description\r\nClose the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "17", "description": "Description\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\n\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}, {"step": "18", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Latency.icf file.\r\n\r\nInput Data", "expected": "You see only 1 worker listed now underneath the manager of the test system."}, {"step": "19", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "20", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}, {"step": "21", "description": "Description\r\nOnce the \"Latency\" test is done, close the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "22", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}, {"step": "23", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Run4kA.icf file.\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}, {"step": "24", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "25", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}, {"step": "26", "description": "Description\r\nBoth of the results files should be analyzed.\r\n\r\nInput Data", "expected": ""}, {"step": "1", "description": "Description\r\nBoot to a supported Windows or Linux OS with 1 PCIe SSD installed in the system.\r\n\r\nInput Data", "expected": "The system boots and recognizes the PCIe SSD."}], "source": ""}
{"case_id": "case-119", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf using Windows, copy the IOMeter.exe and dynamo.exe files to the system. Else if using Linux, copy the source files to the system and run: 1. touch /usr/include/stropts.h 2. make -f Makefile-Linux.x86_64 dynamo\r\n\r\nInput Data", "expected": "IOMeter is successfully installed on the test system."}], "source": ""}
{"case_id": "case-120", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nEnsure that the PCIe SSD to be tested is not partitioned and does not have a filesystem on it.\r\n\r\nInput Data", "expected": "The drive is raw."}], "source": ""}
{"case_id": "case-121", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, you'll need another computer to run a Windows version of IOMeter on it. Then, you'll have to make sure that both the Linux test machine and the Windows computer are on the same network and can ping each other. The firewall on both machines will also have to be disabled ( service iptbales stop for the Linux machine). Once, this is setup, edit the /etc/hosts file on the Linux machine and add an entry for the new IP address of your Linux machine. Last, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-122", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDownload the .icf files that are attached to this test case and save them somewhere on the test system if using Windows, or somewhere on the Windows computer if using Linux.\r\n\r\nInput Data", "expected": "The .icf files are copied onto the appropriate machine."}], "source": ""}
{"case_id": "case-123", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the PreCondition.icf file .\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-124", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-125", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFor each worker, remove the \"4kRandWrite4kAlign\" access specification from the \"Access Specifications\" tab.\r\n\r\nInput Data", "expected": "Each worker only has the \"64kSeq..\" test to run."}], "source": ""}
{"case_id": "case-126", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}], "source": ""}
{"case_id": "case-127", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = (2 * C) / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to twice over is calculated."}], "source": ""}
{"case_id": "case-128", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}], "source": ""}
{"case_id": "case-129", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nNow remove the \"64kSeq...\" test from each workers \"Access Specifications\" tab and add the \"4kSeqWrite..\" test in its place.\r\n\r\nInput Data", "expected": "Each worker only has the \"4kSeq..\" test to run."}], "source": ""}
{"case_id": "case-130", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}], "source": ""}
{"case_id": "case-131", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = C / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to once is calculated."}], "source": ""}
{"case_id": "case-132", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "15", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}], "source": ""}
{"case_id": "case-133", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "16", "description": "Description\r\nClose the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-134", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "17", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-135", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "18", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Latency.icf file.\r\n\r\nInput Data", "expected": "You see only 1 worker listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-136", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "19", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-137", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "20", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}], "source": ""}
{"case_id": "case-138", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "21", "description": "Description\r\nOnce the \"Latency\" test is done, close the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-139", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "22", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-140", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "23", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Run4kA.icf file.\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-141", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "24", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-142", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "25", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}], "source": ""}
{"case_id": "case-143", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "26", "description": "Description\r\nBoth of the results files should be analyzed.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-53686", "name": "PCIe SSD: LVM - Arrays Fail at the Right Time when Drives are Removed", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that RAID arrays will transition to the failed state at the right time when drives are removed.\r\n\r\nRAID0 - Fails after 1 drive being removed.\r\nRAID5 - Fails after 2 drives being removed.\r\nRAID6 - Fails after 3 drives being removed.\r\nRAID10 - Fails after 2 drives being removed.", "precondition": "", "steps": [{"step": "1", "description": "Description\nMake sure that the \"raid_fault_policy\" setting in /etc/lvm.conf is set to \"warn\"\n\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\nMake sure that the \"raid_fault_policy\" setting in /etc/lvm.conf is set to \"warn\"\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-145", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a 2-drive RAID0\r\n\r\nInput Data", "expected": "The RAID0 array is created successfully"}], "source": ""}
{"case_id": "case-146", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the drives in the RAID0 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-147", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-148", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-149", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove two of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-150", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-151", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-152", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nSurprise remove three of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-153", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-154", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-155", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nSurprise remove two of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-156", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "TC-53701", "name": "PCIe SSD: NVMe shutdown notification", "status": "Active", "type": "Manual", "description": "Verify NVMe PCIe SSD goes through the expected shutdown sequence during a graceful or ungraceful shutdown.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-158", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-159", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD shutdown sequence.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-160", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot to the OS and once drive handle is created start capturing the trace. Press power button gently once and allow system to reboot. \r\n\r\nInput Data", "expected": "The system starts rebooting and trace capture is in progress."}], "source": ""}
{"case_id": "case-161", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nOnce the boot starts again stop the trace capture. \r\n\r\nInput Data", "expected": "PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "case-162", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat step 4-5 but instead of using power button , issue Shutdown of the system from OS it self. \r\n\r\nInput Data", "expected": "Same as above steps"}], "source": ""}
{"case_id": "case-163", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nOnce in the OS start capturing the trace again.\r\nAC power off the system (pull AC power cable).\r\n\r\n\r\nInput Data", "expected": "The trace capture is in progress and system starts rebooting."}], "source": ""}
{"case_id": "case-164", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nOnce the boot process starts stop the trace capture. \r\n\r\nInput Data", "expected": "PCIe trace shows CC.SHN = 10b to indicate abrupt shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "TC-54468", "name": "PCIe SSD - OMSS Report Multiple Surprise Insertions", "status": "Active", "type": "Manual", "description": "Validate that OMSS successfully handles reporting multiple surprise insertions", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-166", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall OMSS version known to support PCIe SSD reporting and discover\r\n\r\nInput Data", "expected": "OMSS installed"}], "source": ""}
{"case_id": "case-167", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLaunch OMSS and navigate to PCIe SSD storage subsystem\r\n\r\nInput Data", "expected": "-User is able to navigate OMSS Menu\r\n\r\n-PCIe SSD Subsystem is clearly called out and selectable as a target link"}], "source": ""}
{"case_id": "case-168", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nKeep expanding the PCIe SSD subsystem tree until the physical disk menu is displayed\r\n\r\nInput Data", "expected": "-Tree expands\r\n\r\n-No physical disks listed as none should be installed at this point"}], "source": ""}
{"case_id": "case-169", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSurprise insert 2 drive2 into the two lowest enumerated slots on the chassis face known to support PCIeSSD drives\r\n\r\nInput Data", "expected": "-Both drives detected\r\n\r\n-Surprise insertion events detected by the OS and driver loaded\r\n\r\n-LED illuminted and indicates ready (steady Green)\r\n\r\n-Slot number is accurate to where the drive is installed\r\n\r\n-Physical Drive Properties page updated by OMSS and accurately reflects the following:\r\n\r\n--Physical Disk with slot number\r\n\r\n--State of the drive\r\n\r\n--Drop Down task menu\r\n\r\n--Protocol Type\r\n\r\n--Firmware Revision\r\n\r\n--Predictive Failure status"}], "source": ""}
{"case_id": "case-170", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRun some I/O to the drives to verify it is functional. Stop I/O after 30 seconds.\r\n\r\nInput Data", "expected": "-Drives responds to I/O requests without issue"}], "source": ""}
{"case_id": "case-171", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nDo a \"Prepare for Removal\" on the drive on the drive in the lowest slot\r\n\r\nInput Data", "expected": "-Drive removed, OS still functional, OMSS still functional and responsive"}], "source": ""}
{"case_id": "case-172", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nDo a \"Prepare for Removal\" on the second drive\r\n\r\nInput Data", "expected": "Same result as steps 6"}], "source": ""}
{"case_id": "case-173", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nPerform steps 5 through 7 on any slots not used in the previous steps, i.e. if drives were surprised inserted into slots 0 and 1 in step 5, surprise insert the two drives into slots 2 and 3 (if the platform supports that quantity of slots)\r\n\r\nInput Data", "expected": "-Same result as steps 5 and 7\r\n\r\n-Slot accurately reflects where the drive was inserted"}], "source": ""}
{"case_id": "TC-55211", "name": "PCIe SSD - Factory WinPE - NVMe driver", "status": "Active", "type": "Manual", "description": "To validate compatibility of NVMe PCIe SSD in WinPE environment. To confirm correct NVMe driver is installed and loaded as part of the FICore image.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-175", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPull the latest FICore image and boot to it.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-176", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify the correct NVMe driver is installed and loaded (please note that this may not necessarily be an Arev driver, depending on when the FICore image was created and/or pulled down). Ensure to pull the latest FICore image available. To do this, you may need to (1) navigate to the Windows\\System32\\drivers directory, (2) confirm nvme.sys driver file is present, (3) copy this file to check its properties\r\n\r\nInput Data", "expected": "NVMe driver is installed and loaded.\r\n\r\n\r\nIf testing with FICore image after NVMe drivers have been Arev, the NVMe driver that is installed must be the Arev driver."}], "source": ""}
{"case_id": "case-177", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRun some I/O to the NVMe PCIe SSD.\r\n\r\nInput Data", "expected": "I/O runs successfully."}], "source": ""}
{"case_id": "TC-55616", "name": "PCIe SSD: Hot insert: AER mask register is configured/restored on hot insertion using Quarch", "status": "Active", "type": "Manual", "description": "Verify that AER mask register for a PCIe SSD device is configured/restored on hot insertion per system BIOS defaults", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-179", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-180", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the drive from the system using Quarch\r\n\r\nInput Data", "expected": "The system is functional. No error/ fatal error is reported."}], "source": ""}
{"case_id": "case-181", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUsing Quarch Hot Insert the drive that was removed in step 4 back into the system\r\n\r\nInput Data", "expected": "The device is recognized by the OS and functional"}], "source": ""}
{"case_id": "case-182", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCapture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register\r\n\r\nInput Data", "expected": "The values of the registers are the same as when they were captured in step 2"}], "source": ""}
{"case_id": "TC-57395", "name": "PCIe SSD: Linux Filesystem Integrity after Sync Followed by Hot-Plug", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the data on the various Linux filesystems remains in-tact after being sync-ed, surprise removed (while still mounted), then re-inserted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a single partition on each NVMe drive in the system\r\n\r\nInput Data", "expected": "The partitions are successfully created"}, {"step": "1", "description": "Description\r\nCreate a single partition on each NVMe drive in the system\r\n\r\nInput Data", "expected": "The partitions are successfully created"}], "source": ""}
{"case_id": "case-184", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFormat each of the partitions on the NVMe drives to have one of the following filesystems:\r\next3\r\next4\r\nxfs\r\nbtrfs <- ONLY for SLES\r\n\r\n\r\nInput Data", "expected": "The filesystems are successfully created"}], "source": ""}
{"case_id": "case-185", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nMount the filesystems\r\n\r\nInput Data", "expected": "Mounts are successful"}], "source": ""}
{"case_id": "case-186", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPut some data files on each of the filesystems and create a checksum\r\n\r\nInput Data", "expected": "Data is successfully written and checksums are calculated"}], "source": ""}
{"case_id": "case-187", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCall \"sync -f\" on each filesystem\r\n\r\nInput Data", "expected": "The sync completes successfully"}], "source": ""}
{"case_id": "case-188", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWith the filesystem still mounted surprise remove each NVMe drive\r\n\r\nInput Data", "expected": "The device driver no longer enumerates the removed NVMe drives\r\nNOTE that stale mount points will likely still exist"}], "source": ""}
{"case_id": "case-189", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-Insert each NVMe drive back into the system\r\n\r\nInput Data", "expected": "The device driver enumerates all drives"}], "source": ""}
{"case_id": "case-190", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nMount each of the filesystems\r\n\r\nInput Data", "expected": "Filesystems successfully mount"}], "source": ""}
{"case_id": "case-191", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nCheck the filesystems with fsck\r\n\r\nInput Data", "expected": "The filesystem check doesn't report any errors"}], "source": ""}
{"case_id": "case-192", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nRe-calculate the checksums for each filesystem\r\n\r\nInput Data", "expected": "The checksums match that of the original values calculated before the previous unmount"}], "source": ""}
{"case_id": "TC-63095", "name": "PCIeSSD: NVMe MI - Hotplug and check the MTU size set by the idrac", "status": "Active", "type": "Manual", "description": "PCIeSSD: NVMe MI - Check the MTU size set by the idrac", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nOptional: Not Necessary\r\nHookup the I2C Analyzer to the System Back plane to capture the I2C traffic  \r\nNote: D4 is the device I2C address \r\nAs per system get the Channel  I2C mapping to slot\r\n\r\n\r\nInput Data", "expected": "NA"}, {"step": "1", "description": "Description\r\nOptional: Not Necessary\r\nHookup the I2C Analyzer to the System Back plane to capture the I2C traffic  \r\nNote: D4 is the device I2C address \r\nAs per system get the Channel  I2C mapping to slot\r\n\r\n\r\nInput Data", "expected": "NA"}], "source": ""}
{"case_id": "case-194", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAfter the system is booted without any PCIe SSD.  Hot plug a drive using quarch . \r\n\r\nInput Data", "expected": "Device is recognized normally"}], "source": ""}
{"case_id": "case-195", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the Configuration get command for the MCTP Transmission Unit Size.\r\n\r\nInput Data", "expected": "MTU should be at least 0x78 (120d)"}], "source": ""}
{"case_id": "TC-63576", "name": "PCIe SSD BOOT: LC OS Install using LVM or OS RAID with mix of FF and types", "status": "Active", "type": "Manual", "description": "Verify that the LifecyleController OS Deployment process will correctly install an OS to a PCIe SSD and the customer uses a fault tolerant configuration such as LVM or native raid OS.Also verify that the device boots normally and after a cold-swap of the devices, that it and any additional devices operate correctly, and that the system will survive a failure of one of the fault tolerant devices while running.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall various PCIe SSDs in the system of different form factors and flash types (ie. 2.5\", HHHL).\r\n\r\nInput Data", "expected": "System is correctly configured."}, {"step": "1", "description": "Description\r\nInstall various PCIe SSDs in the system of different form factors and flash types (ie. 2.5\", HHHL).\r\n\r\nInput Data", "expected": "System is correctly configured."}], "source": ""}
{"case_id": "case-197", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall the latest LC OS Driver Pack using the DUP with either LC Firmware Upgrade, remote iDrac firmware upgrade, or from an already installed OS.\r\n\r\nInput Data", "expected": "DUP installs successfully."}], "source": ""}
{"case_id": "case-198", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInstall at least two PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Status LED goes to solid on to indicate PCIe SSD is online and ready."}], "source": ""}
{"case_id": "case-199", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the BIOS Setup boot mode to UEFI (default mode). (no legacy mode)\r\n\r\nInput Data", "expected": "Setting saved successfully."}], "source": ""}
{"case_id": "case-200", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf necessary, attach a DVD drive to the system.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-201", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert OS installation media into the DVD drive.\r\n\r\nInput Data", "expected": "Installation media is detected."}], "source": ""}
{"case_id": "case-202", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nLaunch LC \"OS Deployment\", click \"Deploy OS\", select \"Go Directly to OS Deployment\", click \"Next\" and proceed to install the OS to the PCIe SSD. Ensure that the PCIe SSDs (mix of FF or types) are configured in a fault tolerant configuration such as LVM or native OS raid. This may need to be delayed until step 7. Record the configuration used in the test results Overall Notes.\r\n\r\nInput Data", "expected": "Installation process is successful.\r\n\r\nFault tolerant configuration successful (if done at this step).\r\n\r\nConfiguration used recorded."}], "source": ""}
{"case_id": "case-203", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nBoot to the OS and perform simple IO to all devices. Check logs for errors. If not possible in step 6, configure the devices into a fault tolerant configuration, for example, but using the native OS raid function to mirror the 2 PCIe-SSD's to turn the single boot PCIe-SSD into a mirroed bootable set of drives.\r\n\r\nInput Data", "expected": "No errors reported in logs.\r\n\r\nFault tolerant configuration successful (if done at this step)."}], "source": ""}
{"case_id": "case-204", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nReboot and ensure the OS is still bootable. check logs for errors.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-205", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nPower down system. Power back up and ensure OS boots. check logs.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-206", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nPower down system. With power off, swap the devices. Power back up and ensure OS boots. check logs.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-207", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nSurprise remove one of the devices (will need to select a 2.5\" FF to be SR).\r\n\r\nInput Data", "expected": "OS continues to run. Expected information is logged in the system logs."}], "source": ""}
{"case_id": "case-208", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nreboot. Check logs for errors.\r\n\r\nInput Data", "expected": "Degraded condition of the boot device is reported as expected, but no other errors are reported in logs."}], "source": ""}
{"case_id": "TC-65708", "name": "PCIe SSD ESXi - Hot-Plug of Assigned Physical RDM (VM On)", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is on", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a Physical RDM on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Physical RDM is successfully created"}, {"step": "1", "description": "Description\r\nCreate a Physical RDM on an NVMe drive (use more than 1 if possible)\r\n\r\nInput Data", "expected": "Physical RDM is successfully created"}], "source": ""}
{"case_id": "case-210", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created physical RDM to a virtual machine (1 to Windows and 1 to Linux)\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-211", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive"}], "source": ""}
{"case_id": "case-212", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWith the VM powered ON, remove the NVMe drive that has the physical RDM on it\r\n\r\nInput Data", "expected": "The hypervisor does not crash\r\nThe VM OS does not crash\r\nThe drive is removed from lspci from the hypervisor\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI\r\nThe virtual disk is removed from the VM OS (you can check \"cat /proc/partitions | grep sd\" in Linux or the Disk Manager in Windows)"}], "source": ""}
{"case_id": "TC-66176", "name": "PCIeSSD Virtualization - device in fault state", "status": "Active", "type": "Manual", "description": "Verify PCIe SSD VMware driver handles and manages devices in fault state.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one PCIe SSD in the system and boot to the OS. Ensure the device driver is installed for PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall at least one PCIe SSD in the system and boot to the OS. Ensure the device driver is installed for PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-214", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIf needed, cause the PCIeSSD to enter in a fault state (test all possible fault conditions if enabled, otherwise at least cover Read-Only and Security Locked State modes).\n\nTalk to the program lead for getting a device in Read-Only mode.\n\nInput Data", "expected": "PCIe SSD enters in fault mode."}], "source": ""}
{"case_id": "case-215", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify the driver detects the PCIe SSD in fault state. ie. an entry is added to the OS system log during PCIeSSD discovery indicating the device is in some fault state.\r\n\r\nInput Data", "expected": "System continues to function without issues. The system log shows device in a fault state (and there is no flooding of messages)."}], "source": ""}
{"case_id": "case-216", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAttempt to create a datastore on the fault device.\r\n\r\nInput Data", "expected": "Operation fails gracefully. Entries may be added in the OS system log indicating such."}], "source": ""}
{"case_id": "case-217", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nAttempt to configure PCIe SSD as passthrough, add it to a VM and boot to it. If not already done so, install the device driver.\r\n\r\nInput Data", "expected": "Device can be configured as a passthrough device with no issues. Device driver installs and/or loads successfully. Any host I/Os to the device fail gracefully. System continues to function correctly.\r\n\r\n\r\n\r\n\r\nIf the device is in read-only, only writes fail to the device."}], "source": ""}
{"case_id": "case-218", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf possible, save some data onto the PCIe SSD and get the PCIe SSD to transition to read only mode during runtime.\r\n\r\nInput Data", "expected": "PCIe SSD goes from Ready to Read Only. Data is still accessible in the device. System continues to function without issues. Unable to write further data to the device."}], "source": ""}
{"case_id": "TC-72252", "name": "PCIe SSD: LVM - Add a Hot-Inserted Drive to an Existing Array", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that a newly hot inserted device can be added to an existing RAID array.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a RAID1\r\n\r\nInput Data", "expected": "The RAID1 array is successfully created"}, {"step": "1", "description": "Description\r\nCreate a RAID1\r\n\r\nInput Data", "expected": "The RAID1 array is successfully created"}], "source": ""}
{"case_id": "case-220", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-221", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\n\r\nAdd the hot inserted drive to be a part of the RAID1\r\n\r\n\r\nFor example:\r\nvgextend vgname /dev/nvmeXnX\r\n\r\nlvconvert -m 2 vgname/lvname /dev/nvmeXnX\r\n\r\n\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID1\r\n\r\nYou can use:\r\nlvs -a -o name,raid_sync_action,copy_percent,devices vgname"}], "source": ""}
{"case_id": "case-222", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate a RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-223", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-224", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID5\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID5 and resyncs"}], "source": ""}
{"case_id": "TC-78048", "name": "PCIe SSD: Pre-OS hot remove [negative test]", "status": "Active", "type": "Manual", "description": "Verify that a drive removed during boot does not cause system errors and OS is able to load successfully.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall the device under test.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall the device under test.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-226", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the system and hot remove the device before the OS starts to load.\r\n\r\nInput Data", "expected": "Device is removed. No errors are reported. System continues to boot."}], "source": ""}
{"case_id": "case-227", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBoot to the OS.\r\n\r\nInput Data", "expected": "System boots successfully.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-228", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nVerify the OS loads properly and there are no errors in the event log.\r\n\r\nInput Data", "expected": "There are no errors in the windows event log or the SEL. The OS is fully functional.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-229", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRe-insert the previously hot removed device and verify it is still functional.\r\n\r\nInput Data", "expected": "Device is fully functional."}], "source": ""}
{"case_id": "TC-80474", "name": "PCIeSSD - PLX Capella 2 Switch ACS P2P Redirection Caution 1.13 Safety Bit Workaround", "status": "Active", "type": "Manual", "description": "This test case is used to confirm that bit 21 of offset 0x760 (station ports) is set to avoid Caution 1.13.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a system with one or more Capella 2 PCIe switches\r\n\r\nInput Data", "expected": "All switches are detected"}, {"step": "1", "description": "Description\r\nBoot into a system with one or more Capella 2 PCIe switches\r\n\r\nInput Data", "expected": "All switches are detected"}], "source": ""}
{"case_id": "case-231", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIdentify each PCIe switch's upstream BAR0 register by reading PCIe Cfg Space (offset 0x13-0x10)\r\n\r\nInput Data", "expected": "All Memory addresses are captured and saved"}], "source": ""}
{"case_id": "case-232", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIdentify all of the downstream station ports for each switch (*typically a multiple of 4: e.g. 0, 4, 8, etc.)\r\n\r\nInput Data", "expected": "All Downstream Switch ports identified for each Capella 2 switch"}], "source": ""}
{"case_id": "case-233", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRead 32 bits of memory using the following formula:\r\nBAR0 + (StationPortDeviceNumber * 0x1000) + 0x760\r\n\r\nDo this for each port identified in the step above\r\n\r\n\r\nInput Data", "expected": "Bit 21 should be set"}], "source": ""}
{"case_id": "TC-82475", "name": "PCIe SSD ESXi - Hot-Plug of Unassigned Physical RDM", "status": "Active", "type": "Manual", "description": "This test is intended to check if NVMe hot-plug works when there's a Physical RDM on the drive being hot-plugged, yet the drive is not assigned to any VM.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a physical RDM on an NVMe drive\r\n\r\nInput Data", "expected": "The physical RDM is successfully created"}, {"step": "1", "description": "Description\r\nCreate a physical RDM on an NVMe drive\r\n\r\nInput Data", "expected": "The physical RDM is successfully created"}], "source": ""}
{"case_id": "case-235", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nWithout assigning the RDM to any VM, surprise remove the NVMe drive\n\nInput Data", "expected": "The removed drive is no longer enumerated on the PCIe bus\r\nThe drive no longer shows up in the ESXi web GUI Storage->Datastores view"}], "source": ""}
{"case_id": "case-236", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the same NVMe drive back into the system\r\n\r\nInput Data", "expected": "The drive shows up on the PCIe bus\r\nThe drive shows back up in the ESXi web GUI Storage -> Datastores view"}], "source": ""}
{"case_id": "TC-83980", "name": "PCIeSSD: 4k Sector Size Capacity Check in OMSA", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, launch OMSS\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}, {"step": "1", "description": "Description\r\nWhile the drive is configured in the default 512B sector size, launch OMSS\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed. NOTE it down"}], "source": ""}
{"case_id": "case-238", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\r\n\r\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-239", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the OMSA page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-240", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "TC-85996", "name": "PCIe SSD: Surprise Hot removal / Insertion of a device doesn't alter ongoing activity of other devices  sharing the same device driver", "status": "Active", "type": "Manual", "description": "Verify that Hot removal of a device doesn't alter ongoing activity of other devices sharing the same device driver.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least two devices under test.\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall at least two devices under test.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-242", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS and load the driver for the device.\r\n\r\nInput Data", "expected": "The OS load successfully."}], "source": ""}
{"case_id": "case-243", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPerform some simple I/O operations on one of the drive.\r\n\r\nInput Data", "expected": "Drive is fully functional and no errors are reported from I/O activity."}], "source": ""}
{"case_id": "case-244", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPull the other device out in which I/O is not running. Check if I/O on the other drive is still running\r\n\r\nInput Data", "expected": "Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional.\r\n\r\n\r\nHot removal of a device doesn't alter ongoing activity of other devices"}], "source": ""}
{"case_id": "case-245", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRe-insert device and allow FTL rebuild to complete. check if I/O is running on the other drive is still running\r\n\r\nInput Data", "expected": "Events are generated as a result of a insertion and device is properly detected. Once FTL table rebuild completes, volume is available for use in operating system.\r\n\r\nI/O starts and runs successfully.\r\n\r\n\r\nNo fatal system errors (eg. blue screen, kernel panic) are encountered and the system continues to be functional."}], "source": ""}
{"case_id": "case-246", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 3-5 again.\r\n\r\nInput Data", "expected": "Results are the same for the 2nd attempt."}], "source": ""}
{"case_id": "TC-86097", "name": "PCIeSSD (exploratory performance): Validation of PCIe SSD Theoretical WriteBandwidth Limits", "status": "Active", "type": "Manual", "description": "Validate that the PCIe SSD devices are capable of capping at theoretical PCIe limits. This is an experimentation based test to explore the capabilities of the drive and that the drive is capable of performing accross multiple block transfer sizes, and queue depths.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall a single PCIe SSD drive and boot to Windows\r\n\r\nInput Data", "expected": "implicit"}, {"step": "1", "description": "Description\r\nInstall a single PCIe SSD drive and boot to Windows\r\n\r\nInput Data", "expected": "implicit"}], "source": ""}
{"case_id": "case-248", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConfigure performance monitor to display the PCIe SSD under test MB/s\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-249", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUse IOMeter to generate I/O for maximum write MB/s. Start I/O with 64k block transfers and queue depth of 256. Increase the queue depth as needed to reach peak throughput. If performance already seems to be near theoretical max, reduce queue depth until lane the x4 port no longer saturates. Allow I/O to run for 5 minutes before checking MB/s.\r\n\r\nInput Data", "expected": "Compare against PCIe theoretical limits.\r\n\r\n\r\nFor example, Gen 2 theoretical max throughput for a x4 PCIe SSD is approximately 2 GB/s minus overhead for protocol and 8b/10b encoding which is generally around 20%."}], "source": ""}
{"case_id": "case-250", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReduce the block transfer size from step 2 by half. Attempt to saturate link with queue depth 256. Raise or lower queue depth as needed to saturate the link. -Keep reducing block transfer size by half and adjusting queue depth as needed to achieve max performance and iterate until block transfer size is 512 bytes -Allow each for 5 minutes of run time prior to noting MB/s\r\n\r\nInput Data", "expected": "-Eventually, protocol overhead will prohibit the device from saturating the PCIe link. Record this block transfer size in the test results. Validate with vendor that this is the expected result for saturation cutoff."}], "source": ""}
{"case_id": "case-251", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPRECONDITION (precondition.icf) the PCIe SSD(s): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput \u2013 runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set \u2013 just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.\r\n\r\nInput Data", "expected": "PCIe SSD(s) preconditioned."}], "source": ""}
{"case_id": "case-252", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat step 3\r\n\r\nInput Data", "expected": "Observe and record the throughput value observed. This value gives the steady state performance of the device when having to manage the reclamation of erase blocks. Micron reports this to be approximately 600 MB/s. Write defect if less than this value.\r\n\r\n\r\nFor reference on expected performance, use Dell's RFQ or similar document."}], "source": ""}
{"case_id": "TC-87292", "name": "PCIe SSD ESXi - Hot-Plug of Unassigned Datastore", "status": "Active", "type": "Manual", "description": "This test is intended to check if NVMe hot-plug works when there's a VMFS datastore on the drive being hot-plugged, yet the drive is not assigned to any VM.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive\r\n\r\nInput Data", "expected": "The datastore is successfully created"}, {"step": "1", "description": "Description\r\nCreate a datastore on an NVMe drive\r\n\r\nInput Data", "expected": "The datastore is successfully created"}], "source": ""}
{"case_id": "case-254", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nWithout assigning the datastore to any VM, surprise remove the NVMe drive\r\n\r\nInput Data", "expected": "The removed drive is no longer enumerated on the PCIe bus\r\nThe drive no longer shows up in the ESXi web GUI Storage->Datastores view"}], "source": ""}
{"case_id": "case-255", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the same NVMe drive back into the system\r\n\r\nInput Data", "expected": "The drive shows up on the PCIe bus\r\nThe drive shows back up in the ESXi web GUI Storage -> Datastores view"}], "source": ""}
{"case_id": "TC-88770", "name": "PCIe SSD: LVM - Redundant Arrays Degrade at the Right Time when Drives are Removed", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that redundant RAID arrays will transition to the degraded state at the right time when drives are removed.\r\n\r\nRAID1 - Degrades after 1 drive being removed.\r\nRAID5 - Degrades after 1 drive being removed.\r\nRAID6 - Degrades after 2 drives being removed.\r\nRAID10 - Degrades after 1 drive being removed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nMake sure that the \"raid_fault_policy\" setting in /etc/lvm.conf is set to \"warn\"\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nMake sure that the \"raid_fault_policy\" setting in /etc/lvm.conf is set to \"warn\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-257", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a 2-drive RAID1\r\n\r\nInput Data", "expected": "The RAID1 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-258", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the drives in the RAID1 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-259", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-260", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-261", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-262", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nSurprise remove one of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-263", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-264", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-265", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nCreate a 5-drive RAID6.  LVM requires at least 5 drives for RAID 6\r\n\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-266", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nSurprise remove two of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-267", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-268", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-269", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-270", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "15", "description": "Description\r\nSurprise remove one of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-271", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "16", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-272", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "17", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "TC-88996", "name": "PCIeSSD (exploratory performance) - OS RAID Performance Analysis", "status": "Active", "type": "Manual", "description": "Validate that PCIe SSD drives can be used for OS RAIDs without crippling the subsystems performance.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall 4 PCIe SSD drives and boot to the OS\r\n\r\nInput Data", "expected": "implicit"}, {"step": "1", "description": "Description\r\nInstall 4 PCIe SSD drives and boot to the OS\r\n\r\nInput Data", "expected": "implicit"}], "source": ""}
{"case_id": "case-274", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSecure Erase the drives\r\n\r\nInput Data", "expected": "-Data erased from the drives"}], "source": ""}
{"case_id": "case-275", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPRECONDITION (precondition.icf): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput \u2013 runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set \u2013 just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.\r\n\r\nInput Data", "expected": "-drives preconditioned"}], "source": ""}
{"case_id": "case-276", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the drives into a 4 drive RAID 0\r\n\r\nInput Data", "expected": "RAID configured"}], "source": ""}
{"case_id": "case-277", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRun the comprehensive performance IOMeter test against the RAID 0. Save IOMeter output and label as 4 drive RAID 0 data\r\n\r\nInput Data", "expected": "I/O executes without error"}], "source": ""}
{"case_id": "case-278", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDelete the RAID 0 and configure a single worker/thread to run the conprehensive performance IOMeter suite against the 4 raw PCIe SSD devices. Save IOMeter output and label as 4 drive non-RAID data\r\n\r\nInput Data", "expected": "-RAID deleted\r\n\r\n-Data saved"}], "source": ""}
{"case_id": "case-279", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCompare results from both runs\r\n\r\nInput Data", "expected": "-OS RAID data set is within at least 10% of the non-raid data\r\n\r\n-no major \"sore spots\" in either data sets where performance does not scale with workload"}], "source": ""}
{"case_id": "TC-89055", "name": "PCIe SSD - Operating Systems - Full Filesystem (Negative)", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that files can be read on a full filesystem, but not written.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS with at least one PCIe SSD in the system\r\n\r\nInput Data", "expected": "The OS detects and loads the driver for the device"}, {"step": "1", "description": "Description\r\nBoot into a supported OS with at least one PCIe SSD in the system\r\n\r\nInput Data", "expected": "The OS detects and loads the driver for the device"}], "source": ""}
{"case_id": "case-281", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPartition and format the PCIe SSD\r\n\r\nInput Data", "expected": "The partition and filesystem is successfully applied"}], "source": ""}
{"case_id": "case-282", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nFill the entire filesystem with file(s) One way to do this in Windows is to use the \"Make-A-File\" aplpication, or using a combination of \"touch\" and \"dd\" in Linux\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-283", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAttempt to create a new file on the full filesystem\r\n\r\nInput Data", "expected": "The file is not allowed to be created"}], "source": ""}
{"case_id": "case-284", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nAttempt to copy a file from another location to the full filesystem\r\n\r\nInput Data", "expected": "The file is not allowed to be copied"}], "source": ""}
{"case_id": "case-285", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nCopy a file from the full filesystem to another location\r\n\r\nInput Data", "expected": "The file is successsfully copied"}], "source": ""}
{"case_id": "TC-89814", "name": "PCIe SSD: mdadm - Rebuild Array after Surprise Removal with Local Hot Spare", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that after a drive is surprise removed from a redundant RAID array, that a rebuild will start with the assigned hot-spare.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a redundant mdadm RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}, {"step": "1", "description": "Description\r\nCreate a redundant mdadm RAID array (like a RAID1)\r\n\r\nInput Data", "expected": "The array is created successfully and the background sync completes"}], "source": ""}
{"case_id": "case-287", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConfigure another NVMe drive that's not a part of the array to be a local hot-spare\r\n\r\nInput Data", "expected": "The drive is successfully configured as a hot-spare"}], "source": ""}
{"case_id": "case-288", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the NVMe drives that's a part of the redundant mdadm RAID array\r\n\r\nInput Data", "expected": "The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy."}], "source": ""}
{"case_id": "TC-91348", "name": "PCIe SSD - Operating Systems - Transition to Temperature Threshold Exceeded", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure that the PCIe SSD will throttle I/O performance to allow for cooling of the device.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS with at least one PCIe SSD\r\n\r\nInput Data", "expected": "The OS detects the device and loads the driver"}, {"step": "1", "description": "Description\nBoot into a supported OS with at least one PCIe SSD\n\nInput Data", "expected": "The OS detects the device and loads the driver"}], "source": ""}
{"case_id": "case-290", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBegin running I/O to the device where you can monitor performance (e.g. IOMeter, fio, or use a normal I/O tool with Perfmon)\r\n\r\nInput Data", "expected": "I/O continues to run successfully. There are no I/O errors or data miscompares"}], "source": ""}
{"case_id": "case-291", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWhile I/O is running, cause the device to enter the temperature exceeded threshold state\r\n\r\nInput Data", "expected": "The performance of the I/O drops off to allow for cooling. There are no I/O errors or data miscompares"}], "source": ""}
{"case_id": "TC-91646", "name": "PCIe SSD: Linux Filesystem Integrity after Unmount Followed by Hot-Plug", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the data on the various Linux filesystems remains in-tact after being unmounted, surprise removed, then re-inserted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nCreate a single partition on each NVMe drive in the system\r\n\r\nInput Data", "expected": "The partitions are successfully created"}, {"step": "1", "description": "Description\r\nCreate a single partition on each NVMe drive in the system\r\n\r\nInput Data", "expected": "The partitions are successfully created"}], "source": ""}
{"case_id": "case-293", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFormat each of the partitions on the NVMe drives to have one of the following filesystems:\r\next3\r\next4\r\nxfs\r\nbtrfs <- ONLY for SLES\r\n\r\n\r\nInput Data", "expected": "The filesystems are successfully created"}], "source": ""}
{"case_id": "case-294", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nMount the filesystems\r\n\r\nInput Data", "expected": "Mounts are successful"}], "source": ""}
{"case_id": "case-295", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPut some data files on each of the filesystems and create a checksum\r\n\r\nInput Data", "expected": "Data is successfully written and checksums are calculated"}], "source": ""}
{"case_id": "case-296", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUnmount each filesystem\r\n\r\nInput Data", "expected": "Unmounts are successful"}], "source": ""}
{"case_id": "case-297", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove each NVMe drive\r\n\r\nInput Data", "expected": "The device driver no longer enumerates the removed NVMe drives"}], "source": ""}
{"case_id": "case-298", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-Insert each NVMe drive back into the system\r\n\r\nInput Data", "expected": "The device driver enumerates all drives"}], "source": ""}
{"case_id": "case-299", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nMount each of the filesystems\r\n\r\nInput Data", "expected": "Filesystems successfully mount"}], "source": ""}
{"case_id": "case-300", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nCheck the filesystems with fsck\r\n\r\nInput Data", "expected": "The filesystem check doesn't report any errors"}], "source": ""}
{"case_id": "case-301", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nRe-calculate the checksums for each filesystem\r\n\r\nInput Data", "expected": "The checksums match that of the original values calculated before the previous unmount"}], "source": ""}
{"case_id": "TC-93321", "name": "Validate hot removal functionality on Vmware running with datastore devices mapped to a VM.", "status": "Active", "type": "Manual", "description": "Validate hot removal functionality on Vmware running with datastore devices mapped to a VM.", "precondition": "", "steps": [{"step": "1", "description": "Description\nInstall one or more PCIe SSDs in the host system and load appropriate ESXi host\ndriver.&nbsp; \n\n\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall one or more PCIe SSDs in the host system and load appropriate ESXi host\r\ndriver.&nbsp; \r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-303", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a datastore on the PCIeSSD and add it to a Windows VM. Install a supported guest OS on the VM. \r\n\r\n\r\nInput Data", "expected": "PCIe SSD\r\ndatastore added to guest VM."}], "source": ""}
{"case_id": "case-304", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLaunch the VM and run I/O to the PCIe SSD datastore.&nbsp; \r\n\r\n\r\nInput Data", "expected": "I/O runs without\r\nany issues."}], "source": ""}
{"case_id": "case-305", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStop I/O, and wait (idle) for about 10 seconds. Hot remove the PCIe SSD. \r\n\r\n\r\nInput Data", "expected": "Guest OS\r\ncontinues to run without issues. I/O can be run to other devices in the\r\nsystem through the guest OS. If any access attempt is done to the dev node\r\nassociated to the removed PCIe SSD (including fdisk), the command times out\r\nand the kernel prints out a stack dump after some predetermined time. The\r\nhost kernel log (vmkernel.log) shows a series of timeout and error messages\r\nrelated to the removed PCIe SSD but continues to run ok. The guest OS may not\r\nbe able to be rebooted if the PCIe SSD remains removed from the system. A\r\nhost reboot may be required for the system to become functional/responsive\r\nagain."}], "source": ""}
{"case_id": "case-306", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf running, shutdown the VM. \r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-307", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRe-insert the removed PCIe SSD into the host system. \r\n\r\n\r\nInput Data", "expected": "Host system\r\ncontinues to run without freeze or hang. The guest OS may not be able to be\r\nrestarted until the PCIe SSD datastore is recognized by the host. (A host\r\nreboot may be required for the system accept the datastore and become\r\nfunctional/responsive to the guest OS.)"}], "source": ""}
{"case_id": "case-308", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nLaunch the VM, and run some I/O to the PCIe SSD datastore. \r\n\r\n\r\nInput Data", "expected": "I/O runs\r\nsuccessfully."}], "source": ""}
{"case_id": "case-309", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat steps 1-7 but with a Linux VM. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-310", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nImplicit\r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-94974", "name": "Automated FRU validation - Dell P/N TJ9T4", "status": "New", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\nUse FRU_FRUDummyDataValidation.py to validate FRU on the drive\n\nInput Data", "expected": "Other than serial number and date of amnufacture all other comparison points should match with the reference FRU"}, {"step": "1", "description": "Description\nUse FRU_FRUDummyDataValidation.py to validate FRU on the drive\n\nInput Data", "expected": "Other than serial number and date of amnufacture all other comparison points should match with the reference FRU"}], "source": ""}
{"case_id": "TC-6428", "name": "PCIeSSD: Hotplug - Long-Term Manual Hotplugs", "status": "Active", "type": "Manual", "description": "The point of this test is to analyze the subsystem behavior after doing a significant amount of hotplug operations in a row.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-313", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInsert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "The PCIe SSD shows up everywhere (PCI bus, NVMe driver is loaded, disk. mgmt tools, etc.) and is functional"}], "source": ""}
{"case_id": "case-314", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the PCIe SSD from the system after you notice the OS has completed enumerated the previous insertion\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-315", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 124 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-316", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 2-4 for each slot in the given controller.\r\n\r\nFor example, let's say there's 3 PCIe extender cards in the system, and each one connects to 4 drives. Then in this case, you would run to each of the four slots of one of the extender cards.\r\n\r\nAnother example would be CPU direct-attach, if the CPU port controls, 2 drives, then 125 hotplugs will be performed for both slots.\r\n\r\n\r\nInput Data", "expected": "Same results as in steps 2-4"}], "source": ""}
{"case_id": "TC-26817", "name": "PCIeSSD: PCIe - Continuous Link Retrains", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}, {"step": "2", "description": "Description\r\nStart a script to cause a Link Retrain (bit 5 - Link Control Register) for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\r\n\r\nInput Data", "expected": "The script completes all 100 loops successfully."}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}], "source": ""}
{"case_id": "case-318", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart a script to cause a Link Retrain (bit 5 - Link Control Register) for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\n\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "TC-30914", "name": "PCIeSSD: Hotplug - Hot Insertion/Surprise Removal of Multiple Drives", "status": "Active", "type": "Manual", "description": "The point of this test is to make sure that hot inserting multiple drives at the same time results in all devices getting fully configured.\r\nThe point of this test is to make sure that surprise removing multiple drives at the same time results in all devices getting fully removed.", "precondition": "-", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-320", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert 2 or more (preferably the maximum amount) hotpluggable PCIe SSDs at the same time\r\n\r\nInput Data", "expected": "All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-321", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove all of the drives that were just inserted at the same time\r\n\r\nInput Data", "expected": "None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-322", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-50141", "name": "PCIeSSD: Hotplug - Surprise Removal after Partially Handled Insertion", "status": "Active", "type": "Manual", "description": "The point of this test is to analyze the subsystem behavior when a device is immediately removed after just have been inserted, but before the OS has finished undoing the actions from the initial insertion.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit\r\nonly have boot disk\r\n[root@rhel91 neuron]# nvme list\r\nNode Generic SN Model Namespace Usage Format FW Rev\r\n--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------\r\n/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0\r\n[root@rhel91 neuron]#"}, {"step": "1", "description": "Description\r\nBoot into the OS with no PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit\r\nonly have boot disk\r\n[root@rhel91 neuron]# nvme list\r\nNode Generic SN Model Namespace Usage Format FW Rev\r\n--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------\r\n/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0\r\n[root@rhel91 neuron]#"}], "source": ""}
{"case_id": "case-324", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInsert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-325", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the PCIe SSD from the system after you notice the OS starting to handle the previous insertion (adding drive to the OS however storage is not ready), but before it actually completes\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-326", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-51058", "name": "PCIe SSD: discovery after DC power cycle (long term)", "status": "Active", "type": "Manual", "description": "Verify PCIe SSDs are reliably discovered after D/C power cycle.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\n\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\nClear the system's SEL log.\n\nInput Data", "expected": "SEL log cleared."}, {"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "5", "description": "Description\nUsing a utility such as racadm (may use any other utilities that are available), DC power cycle the system after the system boots and the attempt has been made to discover all PCIe SSD devices. Sequence should look like: boot --> OS login --> Device Detection --> DC power cycle (if no errors) Using racadm, the command should look like: racadm serveraction powercycle\n\nInput Data", "expected": "Test is set up to run unattended."}, {"step": "6", "description": "Description\r\nAllow the system to repeat the D/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}, {"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}, {"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}, {"step": "1", "description": "Description\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-328", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-329", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-330", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-331", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUsing a utility such as racadm (may use any other utilities that are available), DC power cycle the system after the system boots and the attempt has been made to discover all PCIe SSD devices. Sequence should look like: boot --> OS login --> Device Detection --> DC power cycle (if no errors) Using racadm, the command should look like: racadm serveraction powercycle\r\n\r\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-332", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the D/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-333", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "case-334", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}], "source": ""}
{"case_id": "TC-55980", "name": "PCIeSSD: PCIe - Continuous Link Disables/Enables", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}], "source": ""}
{"case_id": "case-336", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart a script to:\n   1. cause a Link Disable (bit 4 - Link Control Register) by writing a 1\n   2. wait 3s\n   3. make sure the link is x0, Gen-1\n   4. re-enable the link by writing a 0\n   5. wait 3s\n   6. make sure the link width and speed is the maximum capable for the PCIe SSD\nfor 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\n\n\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "TC-57691", "name": "PCIe SSD: discovery after OS reboots (long term)", "status": "Active", "type": "Manual", "description": "Verify PCIe SSDs are reliably discovered after OS reboots and no errors are found.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}, {"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "5", "description": "Description\nSetup a script to do the following upon power on: boot --> OS login --> Device Detection --> OS reboot --> repeat\n\nInput Data", "expected": "Test is set up to run unattended."}, {"step": "6", "description": "Description\r\nAllow the system to repeat the reboots for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}, {"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}, {"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-338", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-339", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-340", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-341", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSetup a script to do the following upon power on: boot --> OS login --> Device Detection --> OS reboot --> repeat\r\n\r\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-342", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the reboots for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-343", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "case-344", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}], "source": ""}
{"case_id": "TC-70705", "name": "PCIeSSD: Hotplug - Hot Insertion after Fully Handled Removal", "status": "Active", "type": "Manual", "description": "The point of this test is to make sure a drive that was hot inserted is fully configured after it was previously successfully removed from the system.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}, {"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}], "source": ""}
{"case_id": "case-346", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "The PCIe SSD is completely removed from the system (PCI bus, NVMe driver unloaded, disk mgmt tools, etc.)"}], "source": ""}
{"case_id": "case-347", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the PCIe SSD back into the system after the OS has completely handled the previous removal\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-348", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-75213", "name": "PCIeSSD: PCIe - Continuous Secondary Bus Resets", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least two PCIe SSDs.\r\n\r\nInput Data", "expected": "Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space."}], "source": ""}
{"case_id": "case-350", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart a script to:\n   1. cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1\n   2. wait 3s\n   3. make sure the link is x0, Gen-1\n   4. take the device out of reset by writing a 0\n   5. wait 3s\n   6. make sure the link width and speed is the maximum capable for the PCIe SSD\nfor 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\n\n\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "case-351", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [], "source": ""}
{"case_id": "TC-86299", "name": "PCIeSSD: Hotplug - Hot Insertion after Partially Handled Removal", "status": "Active", "type": "Manual", "description": "The point of this test is to analyze the subsystem behavior when a device is immediately inserted after just have been removed, but before the OS has finished cleaning up the from the removal.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}, {"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}], "source": ""}
{"case_id": "case-353", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-354", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the PCIe SSD back into the system after you notice the OS starting to handle the previous surprise removal (removing drive from OS), but before it actually completes\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-355", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-56778", "name": "PCIeSSD - Hot insertion : Max Payload Size is correctly programmed upon hot insertion of a device", "status": "Active", "type": "Manual", "description": "Verify MPS is correctly programmed with system booted with device vs. newly added device during runtime", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot the system to OS without a PCIe SSD device installed.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot the system to OS without a PCIe SSD device installed.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-357", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a PCIe SSD\r\n\r\nInput Data", "expected": "Host system continues to run without freeze or hang after the device hot insertion."}], "source": ""}
{"case_id": "case-358", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the current and max payload of the inserted PCIe SSD and run some I/O to the drive\r\n\r\nInput Data", "expected": "Current and max payload values match system root complex.\r\n\r\nNo OS hang or any fatal error seen in the system"}], "source": ""}
{"case_id": "case-359", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2 and 3, but this time hot insert the drive in a different slot\r\n\r\nInput Data", "expected": "Same as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-12663", "name": "PCIe SSD: HII Telemetry Log Contents Validation", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the Telemetry log captured from the HII is valid by having the drive vendor verify the contents.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the HII of the system with a drive that supports the NVMe telemetry log page.\r\n\r\nInput Data", "expected": "The option to capture the Telemetry log page is available."}, {"step": "1", "description": "Description\nBoot into the HII of the system with a drive that supports the NVMe telemetry log page.\n\nInput Data", "expected": "The option to capture the Telemetry log page is available."}], "source": ""}
{"case_id": "case-361", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the Telemetry log\r\n\r\nInput Data", "expected": "The log page data is successfully obtained"}], "source": ""}
{"case_id": "case-362", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSend the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification\r\n\r\nInput Data", "expected": "The drive vendor approves the correct format of the Telemetry data"}], "source": ""}
{"case_id": "TC-35747", "name": "PCIe SSD: OMSS Telemetry Log Contents Validation", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the Telemetry log captured from OMSS is valid by having the drive vendor verify the contents.", "precondition": "", "steps": [{"step": "1", "description": "Description\nBoot into the OS of the system with a drive that supports the NVMe telemetry log page.\n\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS of the system with a drive that supports the NVMe telemetry log page.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-364", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the Telemetry log using OMSS\r\n\r\nInput Data", "expected": "The log page data is successfully obtained"}], "source": ""}
{"case_id": "case-365", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSend the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification\r\n\r\nInput Data", "expected": "The drive vendor approves the correct format of the Telemetry data"}], "source": ""}
{"case_id": "TC-2993", "name": "NVMe TCG Opal: iLKM single drive hot removal/insertion and partition enumeration check", "status": "Active", "type": "Manual", "description": "The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security", "precondition": "For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>\r\n\r\nTCG Opal tests should be run in a specific order. Please refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order>", "steps": [{"step": "1", "description": "Description\r\nBoot into system with iLKM enabled along with the devices to test. \r\nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \r\n\r\n\r\nInput Data", "expected": "The system boots up without any issue."}, {"step": "1", "description": "Description\r\nBoot into system with iLKM enabled along with the devices to test. \r\nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \r\n\r\n\r\nInput Data", "expected": "The system boots up without any issue."}], "source": ""}
{"case_id": "case-367", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. \r\n\r\nracadm raid get pdisks -o -p SecurityStatus\r\n\r\nFor example \r\n\r\nDisk.Bay.13:Enclosure.Internal.0-1\r\nSecurityStatus = Secured\r\n\r\n\r\nInput Data", "expected": "All the devices came as secured and no other status is displayed"}], "source": ""}
{"case_id": "case-368", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate partitions on a single drive under test\r\n\r\nInput Data", "expected": "The OS enumerates partitions on the device under test."}], "source": ""}
{"case_id": "case-369", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the drive and hot insert the drive in the same slot.\r\nCheck the partitions after 60sec\r\n\r\n\r\nInput Data", "expected": "All the partitions are enumerated correctly by the OS"}], "source": ""}
{"case_id": "TC-22694", "name": "NVMe TCG Opal: iLKM runtime secure of NVMe drives", "status": "Active", "type": "Manual", "description": "The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security", "precondition": "For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>\r\n\r\nTCG Opal tests should be run in a specific order. Please refer to the following:\r\n\r\nhttps://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order", "steps": [{"step": "1", "description": "Description\r\nBoot into system with iLKM enabled and auto secure disabled(Go to services->iDRAC Key Management)\r\nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \r\n\r\n\r\nInput Data", "expected": "The system boots up without any issue."}, {"step": "1", "description": "Description\r\nBoot into system with iLKM enabled and auto secure disabled(Go to services->iDRAC Key Management)\r\nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \r\n\r\n\r\nInput Data", "expected": "The system boots up without any issue."}], "source": ""}
{"case_id": "case-371", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert an unsecured NVMe SED into the system and check the status of the disk after sometime \r\nracadm raid get pdisks -o -p SecurityStatus\r\n\r\nThe hot inserted disk should show as Encryption Capable\r\nFor example \r\n\r\nDisk.Bay.13:Enclosure.Internal.0-1\r\nSecurityStatus = Encryption Capable \r\n\r\n\r\nInput Data", "expected": "The hot inserted device is not secured and can also be verified via iDRAC GUI"}], "source": ""}
{"case_id": "case-372", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo to Storage->physical disk and selection action to secure the drive \r\nSecure drive option shall be available in the drop down Action menu\r\n\r\n\r\nInput Data", "expected": "Secure drive Job is created and completes successfully"}], "source": ""}
{"case_id": "case-373", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the security state of the drive via Racadm command in step 2 or via GUI security section. \r\n\r\n\r\n\r\nInput Data", "expected": "The status should be \"secured\""}], "source": ""}
{"case_id": "TC-96088", "name": "NVMe TCG Opal: iLKM Rekey operation for NVMe SEDs", "status": "Active", "type": "Manual", "description": "The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security", "precondition": "For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>\n\nTCG Opal tests should be run in a specific order. Please refer to the following:\n\nhttps://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order", "steps": [{"step": "1", "description": "Description\r\nBoot into system with iLKM enabled along with the devices to test. \r\nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \r\n\r\n\r\nInput Data", "expected": "The system boots up without any issue."}, {"step": "1", "description": "Description\nBoot into system with iLKM enabled along with the devices to test. \nMake sure device doesn't have security enabled from the factory or coming out of revert operation. \n\n\nInput Data", "expected": "The system boots up without any issue."}], "source": ""}
{"case_id": "case-375", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCheck the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. \n\nracadm raid get pdisks -o -p SecurityStatus\n\nFor example \n\nDisk.Bay.13:Enclosure.Internal.0-1\nSecurityStatus = Secured\n\n\nInput Data", "expected": "All the devices came as secured and no other status is displayed"}], "source": ""}
{"case_id": "case-376", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nGo to services->iDRAC Key Management->Rekey\nPerform rekey operation  \n\n\nInput Data", "expected": "The rekey operation is successful and job completed successfully without any issue."}], "source": ""}
{"case_id": "TC-814", "name": "PCIe SSD: Hot Remove:  Transition to and from a low link power state", "status": "Active", "type": "Manual", "description": "Verify that transition to a low power state, if supported,hot removing the device will de-assert presence detect and will be removed from the system (PCI List)\r\n\r\n\r\nThis test case may fail on platforms earlier than 15G due to the behavior described in JIT-138589.\r\n <https://jira.gtie.dell.com/browse/JIT-138589>", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system. \r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system. \r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-378", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nOnce in OS, Check the power state of the device (Config space or trace capture) and check the presence detect bit by dumping the pci register\r\n\r\nInput Data", "expected": "The drive is in D0 and Link in L0 state and the presence detect bit is set to 1"}], "source": ""}
{"case_id": "case-379", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nFrom OS disable or unload the driver\r\n\r\n\r\nInput Data", "expected": "The driver is unloaded and no transactions going to the device"}], "source": ""}
{"case_id": "case-380", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the power state of the device by checking config space or trace\r\n\r\n\r\nInput Data", "expected": "Depending on OS the device should go to D3 state and if not write to the register to bring device to D3 state"}], "source": ""}
{"case_id": "case-381", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove the drive from the system and dump the pci register and check the presence detect bit\r\n\r\nInput Data", "expected": "The values of the presence detect bit is 0 for the port above the drive. (downstream switch port or root port)"}], "source": ""}
{"case_id": "TC-2844", "name": "PCIe SSD: Command Effects Log Page", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least one NVMe device in the system\r\n\r\nInput Data", "expected": "All NVme devices are detected"}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least one NVMe device in the system\r\n\r\nInput Data", "expected": "All NVme devices are detected"}], "source": ""}
{"case_id": "case-383", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake a list of all NVMe devices which are compliant to the NVMe 1.2 spec or greater.\r\n\r\nThis can be done by issuing an Identify Controller command and reading the VER offset, or by reading the MMIO location where the version is stored\r\n\r\n\r\nInput Data", "expected": "There is at least one NVMe device which is compliant to 1.2 or greater"}], "source": ""}
{"case_id": "case-384", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue the Get Log Page - Command Effects Log (Log Page ID = 5) to each of the drives discovered in step 2\r\n\r\nInput Data", "expected": "The command is successful"}], "source": ""}
{"case_id": "TC-6686", "name": "PCIe SSD: PCIe VDM Interoperability Test for NVMe MI Commands", "status": "Active", "type": "Manual", "description": "Description: This test will validate if the NVMe device can successfully respond to the NVMe-MI commands through PCIe VDM.\r\n    * Configuration Get\r\n    * Configuration Set\r\n    * Controller Health Status Poll\r\n    * NVM Subsystem Health Status Poll\r\n    * Read-NVMe-MI Data Structure\r\n    * Get Log Page\r\n    * Identify\r\n    * Set Features\r\n    * Get Features", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \r\n\r\n\r\nInput Data", "expected": "System boots without any issue and device have VDM support."}, {"step": "1", "description": "Description\nBoot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\n\nTo check for VDM support:\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\n\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \n\n\nInput Data", "expected": "System boots without any issue and device have VDM support."}], "source": ""}
{"case_id": "case-386", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue below NVMe MI Commands to the each drive (preferably via the automation script 'NVMeMICLI.py).\n\npython3 NVMeMICLI.py -i 'iDRAC IP' -a PCIe BDF'\n   1. Send Configuration Get\n   2. Send Configuration Set\n   3. Send Controller Health Status Poll\n   4. Send NVM Subsystem Health Status Poll\n   5. Send Get Log Page - Firmware Information\n   6. Send Get Log Page - SMART/Health Information\n   7. Send Get Log Page - Telemetry/PEL log\n   8. Send Identify - Controller\n   9. Send Identify - Namespace\n  10. Send Get Features\n  11. Send Set Features\n\n\n\nInput Data", "expected": "All the commands are successful, no NACKS or timeouts."}], "source": ""}
{"case_id": "case-387", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 after performing hotplug on all PCIe SSDs.\r\n\r\nInput Data", "expected": "All commands are successful after hotplug, no NACKs or timeouts."}], "source": ""}
{"case_id": "TC-7682", "name": "PCIe SSD: TCG Opal NVMe MI - Revert to factory default using SID/PSID key", "status": "Active", "type": "Manual", "description": "The test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.\nAlso check if device supports Opal 2+", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run once locking has been enabled on the device. \r\n\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "1", "description": "Description\nBoot to an operating system and make sure all devices are visible in the OS\n\nNote: This test case needs to be run once locking has been enabled on the device. \n\n\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-389", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-390", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue following command to query the drive of it's state\r\n\r\n\r\ncontroller id should be determined from identify controller response in OS\r\ntestlibsednvme query  <eid> <controllerid>\r\n\r\n\r\nFor example:\r\n\r\n testlibsedclient query 6 65\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Check if the locking enabled is turned on \r\nFor example:\r\nlocking enabled = 1\r\n\r\nIf not security needs to be enabled first."}], "source": ""}
{"case_id": "case-391", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nWrite some data to the device in band /OS\nEx-\nnvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1\n\nIssue a revert command using SID as user \n\ntestlibsednvme revert  <eid> <controllerID>  <key> <keylength> <user>\n\n\nAlso make sure function return code is 0\nThe user shall be SID which is 0.\nAlso, use the key that was used to enable security and if security is not enabled use default MSID key\nFor example \ntestlibsednvme revert 6 65 Dell1234 8 0\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\n\n\nInput Data", "expected": "The revert operation get's completed and return code is 0"}], "source": ""}
{"case_id": "case-392", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue following command to query the drive of it's state\r\n\r\ntestlibsednvme query <eid> <controllerID>\r\n\r\nFor example:\r\n\r\ntestlibsednvme query 6 65\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Locking is enabled is turned off \r\n\r\nFor example:\r\nlocking enabled = [0]\r\n\r\nAlso, Check the data written in step 4 is erased.\r\nEx-\r\nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1"}], "source": ""}
{"case_id": "case-393", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nEnable Security again on drive and \r\ngo to step 3 and repeat all steps except use PSID printed on device label and user as PSID which is 1. \r\n\r\ntestlibsednvme DellEnableSecurity <eid> <controllerid> <key> <keylength> 1 \r\n\r\n\r\nInput Data", "expected": "The same state of device is reached even after doing PSID revert."}], "source": ""}
{"case_id": "case-394", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nEnable Security and go to step 3. \r\nRepeat the sequence for for at least 20 times. \r\n\r\n\r\nInput Data", "expected": "All operations succeed fully"}], "source": ""}
{"case_id": "TC-8154", "name": "PCIe SSD: PCIe VDM Device Discovery after Hotplug", "status": "Active", "type": "Manual", "description": "Verify that the device responds to Discovery Commands after Hotplug", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the system with at least 2 PCIe SSD which supports PCIe VDM in the system. \r\n\r\nTo check for VDM support: \r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1 \r\n\r\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \r\n\r\n\r\nInput Data", "expected": "System boots without any issue and device supports PCIe VDM."}, {"step": "1", "description": "Description\nBoot into the system with at least 2 PCIe SSD which supports PCIe VDM in the system. \n\nTo check for VDM support: \npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1 \n\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \n\n\nInput Data", "expected": "System boots without any issue and device supports PCIe VDM."}], "source": ""}
{"case_id": "case-396", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Prepare for Endpoint Discovery and Endpoint Discovery command on the PCIe SSD (preferably via automation script .MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'\r\n\r\n\r\nInput Data", "expected": "Device responds to discovery commands."}], "source": ""}
{"case_id": "case-397", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise Remove PCIe SSDs under test in the system. \r\n\r\nInput Data", "expected": "None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)."}], "source": ""}
{"case_id": "case-398", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot Insert PCIe SSDs in the system which was removed.\r\n\r\nInput Data", "expected": "All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)."}], "source": ""}
{"case_id": "case-399", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue Prepare for Endpoint Discovery and Endpoint Discovery command on hot inserted PCIe SSD (preferably via automation script .MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'\r\n\r\nInput Data", "expected": "Device responds to discovery commands after hotplug."}], "source": ""}
{"case_id": "TC-13242", "name": "PCIeSSD - Hot Insertion : No data is lost, when surprise removed the drive, while IO is running", "status": "Active", "type": "Manual", "description": "Verify that No data is lost, when surprise removed the drive using Quarch, while IO is runing", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.\r\n\r\nInput Data", "expected": "Implict"}, {"step": "1", "description": "Description\r\nBoot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-401", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake sure the drive has some data and Run some I/O to the device.\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-402", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot remove the device using Quarch while I/O is running\r\n\r\nInput Data", "expected": "You might see I/O errror"}], "source": ""}
{"case_id": "case-403", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot insert the drive and check for the data loss\r\n\r\nInput Data", "expected": "Data is intact. No data loss is found."}], "source": ""}
{"case_id": "case-404", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat step 2, 3 and 4\r\n\r\nInput Data", "expected": "Result same as step 2,3 and 4."}], "source": ""}
{"case_id": "TC-18231", "name": "PCIe SSD: PCIe VDM Interoperability Test for MCTP Commands", "status": "Active", "type": "Manual", "description": "Description: This test will validate if the NVMe device can successfully respond to the MCTP commands through PCIe VDM.\r\n    * Set Endpoint ID\r\n    * Get Endpoint ID\r\n    * Get Endpoint UUID\r\n    * Get MCTP Version Support\r\n    * Get Message Type Support\r\n    * Prepare for Endpoint Discovery\r\n    * Endpoint Discovery", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \r\n\r\nInput Data", "expected": "System boots without any issue and device have VDM support."}, {"step": "1", "description": "Description\nBoot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\n\nTo check for VDM support:\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\n\nNote: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. \n\nInput Data", "expected": "System boots without any issue and device have VDM support."}], "source": ""}
{"case_id": "case-406", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue below MCTP commands to the each drive (preferably via the automation script 'MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'\r\n   1. Send Set Endpoint ID\r\n   2. Send Get Endpoint ID\r\n   3. Get Endpoint UUID\r\n   4. Get MCTP Version Support\r\n   5. Get Message Type Support\r\n   6. Prepare for Endpoint Discovery\r\n   7. Endpoint Discovery\r\n\r\n\r\nInput Data", "expected": "All the commands are successful, no NACKS or timeouts."}], "source": ""}
{"case_id": "case-407", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 after performing hotplug on all PCIe SSDs.\r\n\r\nInput Data", "expected": "All commands are successful after hotplug, no NACKs or timeouts."}], "source": ""}
{"case_id": "TC-18957", "name": "PCIe SSD: TCG Opal NVMe MI - Enable Security on NVMe SEDs", "status": "Active", "type": "Manual", "description": "The test case enables security on the device. It encompases several operations in the process like read MSID, activate SP, write data store, rekey", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation\r\n\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation\r\n\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-409", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-410", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\nIssue following command to query the drive of it's state\r\n\r\n\r\ncontroller id should be determined from identify controller response in OS\r\ntestlibsednvme query\r\n\r\n\r\nFor example:\r\n\r\ntestlibsedclient query 6 0\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Locking enabled is turned off \r\nFor example:\r\nlocking enabled = [0]\r\n\r\nIf the locking is enabled make sure to run revert test case prior to running this."}], "source": ""}
{"case_id": "case-411", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nEnable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. \r\nProvide user as Admin and it should be 1\r\n\r\ntestlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>\r\nAlso make sure function return code is 0\r\n\r\nFor example \r\ntestlibsednvme DellEnableSecurity 6 0 Dell123456 10 1\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. \r\n\r\nFor example \r\nlocking supported = [1]\r\nlocking enabled = [1]\r\ndatastore size = [10485760]\r\ndatastore flag = [2]\r\nold_keyId = [MSID KEY]\r\ncurrent_keyId = [Dell123456]"}], "source": ""}
{"case_id": "TC-19864", "name": "PCIe SSD: D3hot", "status": "Active", "type": "Manual", "description": "Verify that PCIe SSDs and bridge can be brought into and out of the D3 power state continuously.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one PCIe extender card in the system and attach the maximum number of PCIe SSDs supported. Make sure the system has the latest BIOS, CPLD, iDRAC FW, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall at least one PCIe extender card in the system and attach the maximum number of PCIe SSDs supported. Make sure the system has the latest BIOS, CPLD, iDRAC FW, etc.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-413", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to a DOS/DRMK bootable media with the D3hot and PCI utilities provided in this test case.\r\n\r\nInput Data", "expected": "Run pciall.exe to determine what the position is for the PCIe extender card and drives. Use these values and make sure that the script is updated correctly."}], "source": ""}
{"case_id": "case-414", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRun the script overnight.\r\n\r\nInput Data", "expected": "No PCIe fatal errors should be reported. Check the SEL logs for any errors."}], "source": ""}
{"case_id": "TC-21314", "name": "PCIe SSD: Flush commands interleaved with IO submission queue deletions (Linux only)", "status": "Active", "type": "Manual", "description": "This test case is to repeatedly issue a large number of NVME flush commands simultaneously with IO queue creations and deletions, in an attempt to trigger a situation where a flush command is still active when the corresponding IO submission queue is deleted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot system to a supported Linux operating system with an NVMe drive installed.\r\n\r\nInput Data", "expected": "System boots normally and drive is available."}, {"step": "1", "description": "Description\r\nBoot system to a supported Linux operating system with an NVMe drive installed.\r\n\r\nInput Data", "expected": "System boots normally and drive is available."}], "source": ""}
{"case_id": "case-416", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall the NVMe CLI tools from the operating system distribution.\r\n\r\nFor example:\r\nUbuntu: apt-get install nvme-cli\r\nRed Hat: yum install nvme-cli\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-417", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRun the attached shell script\r\n\r\nInput Data", "expected": "Script runs without any errors for 10 minutes and exits.\r\n\r\nSystem does not crash."}], "source": ""}
{"case_id": "case-418", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nVerify that the drive is still accessible by performing some IO to it.\r\n\r\n\r\n\r\nInput Data", "expected": "Drive responds normally and IO completes without error"}], "source": ""}
{"case_id": "TC-24071", "name": "PCIeSSD: Create and delete maximum number of namespace supported by Dell", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Boot to the supported OS with device that supports Namespace management. \r\n(check identify controller OACS field)", "expected": "Device is discovered and full capacity of device is listed in block layer. \r\nEX- nvme list  or lsblk can be used in linux"}, {"step": "1", "description": "Boot to the supported OS with device that supports Namespace management. \r\n(check identify controller OACS field)", "expected": "Device is discovered and full capacity of device is listed in block layer. \r\nEX- nvme list  or lsblk can be used in linux"}], "source": ""}
{"case_id": "case-420", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue identify namespace command and note down original name space size.", "expected": "Original namespace size is noted"}], "source": ""}
{"case_id": "case-421", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Detach and delete the original namespace by using nvme-cli or the automation framework. \r\nEx-\r\npython3 NVMeIOCTLCLI.py -dtns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>\r\npython3 NVMeIOCTLCLI.py -dlns <bdf>", "expected": "The original NS is detached and deleted."}], "source": ""}
{"case_id": "case-422", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Determine the maximum number of namespaces supported by the drive by sending an Identify Controller command to the drive, looking at the \"Number of Namespaces\" field.\r\n\r\nDivide the entire drive capacity by the \"Number of Namespaces\" field from above to obtain the new namespace size.\r\n\r\nCreate \"Number of Namepaces\" amount of namespaces using the calculated size from above.\r\n\r\nEx- 4 Namespaces\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\n------------------------------------------------------------------------\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -rc", "expected": "All commands are successful and the max. number of NS created is visible at block layer. \r\nEx- lsblk or nvme list"}], "source": ""}
{"case_id": "case-423", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Issue and Identify Namesapce to each of the newly created namespaces, taking note of the \"Namespace Globally Unique Identifier\" and \"IEEE Extended Unique Identifier\" fields", "expected": "The NGUID is unique for all namespaces OR, it is 0 for all namespaces and the EUI64 is unique for all namespaces.\r\n\r\nThe EUI64 is unique for all namespaces OR, it is 0 for all namespaces and the NGUID is unique for all namespaces."}], "source": ""}
{"case_id": "case-424", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Detach and delete all the NS created. \r\nEx- python3 ns_create_delete_max.py <bdf> -dlns <number of NS supported>", "expected": "All the NS is deleted and verified using appropriate command \r\nEx- lsblk or nvme list in linux"}], "source": ""}
{"case_id": "case-425", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "create and attach the original NS of size noted in step2. \r\npython3 NVMeIOCTLCLI.py -crns <bdf>  \r\npython3 NVMeIOCTLCLI.py -atns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "The original NS is created and visible to OS\r\nEx- lsblk or nvme list\r\nAlso check SMART log for any errors."}], "source": ""}
{"case_id": "TC-30397", "name": "PCIe SSD : Persistent Event Log-  Firmware Commit Event logging check", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}, {"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}], "source": ""}
{"case_id": "case-427", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\nNSID = 0x0\r\nLID= 0x0d\r\nsubpage = 0x0\r\nnum of dwords = 0x0\r\nevent notification = 0x0\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-428", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the current active firmware version running on the device. \r\nUpdate the firmware on the device, up rev or down rev both could be used for this test case with live firmware activate\r\nAny  utility could be used for updating firmware but DUP is a preferred method. \r\n\r\nNote down the version of the newly activated firmware. \r\n\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The firmware update was a successful operation and both old as well as new version was noted."}], "source": ""}
{"case_id": "case-429", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for Firmware Commit  correctly logged earlier in the Persistent Event Log data with all the respective fields correctly populated as per spec."}], "source": ""}
{"case_id": "TC-31502", "name": "PCIe SSD: TCG Opal NVMe MI - Device Query for Opal support", "status": "Active", "type": "Manual", "description": "iDrac 5.10+ and Linux are required for this testcase. \r\n\r\nThe test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.\r\nThe location of the test firmware is here . \r\n\\\\S3bnsx01nas05.amer.dell.com\\RAIDSERVER\\NVMe\\NVME_PCIeSSD\\NVMe_SEKM\\iDRACTCGOpaltestfirmware", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-431", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell  \r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands \r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-432", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side some IO\r\n\r\nIssue following command to get the discovery for determining if drive supports Locking \r\n testlibsednvme query < eid > <controller id in decimal>\r\n\r\n \r\ncontroller id should be determined from identify controller response\r\nand eid from previous step. \r\nFor example:\r\ntestlibsednvme query 4 65\r\n\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then \r\nLocking Enabled: 0 other wise 1 if already security is enabled"}], "source": ""}
{"case_id": "TC-35453", "name": "PCIeSSD: Concurrent IO to four namespaces on a multi-NS capable device", "status": "Active", "type": "Manual", "description": "Verify that it is possible to create four namespaces on a multi-NS device and run IO to all four simultaneously without error", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the supported OS with device that supports Namespace management. \r\n(check identify controller OACS field)\r\n\r\n\r\nInput Data", "expected": "Device is discovered and full capacity of device is listed in block layer. \r\nEX- nvme list  or lsblk can be used in linux"}, {"step": "1", "description": "Description\r\nBoot to the supported OS with device that supports Namespace management. \r\n(check identify controller OACS field)\r\n\r\n\r\nInput Data", "expected": "Device is discovered and full capacity of device is listed in block layer. \r\nEX- nvme list  or lsblk can be used in linux"}], "source": ""}
{"case_id": "case-434", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue identify namespace command and note down original name space size.\r\n\r\nInput Data", "expected": "Original namespace size is noted"}], "source": ""}
{"case_id": "case-435", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetach and delete the original NS by using nvme-cli or automation framework. \r\nEx- python3 NVMeIOCTLCLI.py -dtns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>\r\npython3 NVMeIOCTLCLI.py -dlns <bdf>\r\n\r\n\r\nInput Data", "expected": "The original NS is detached and deleted."}], "source": ""}
{"case_id": "case-436", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate and attach four namespaces\r\n \r\npython3 ns_create_delete_max.py <bdf> -crns 4\r\n\r\nTODO: Verify that this tool actually works this way\r\n\r\n\r\nInput Data", "expected": "Wait sufficient time for all of the namespaces to be created.  There should be 4 namespaces visible at the block layer\r\n \r\nEx- lsblk or nvme list"}], "source": ""}
{"case_id": "case-437", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUse a tool such as testio or diskio to write to all four namespaces simultaneously for at least 30 minutes, with multiple threads per namespace and data verification enabled.  This will entail running four instances of the tool, one per block device visible in the operating system\r\n\r\nInput Data", "expected": "IO test tools should all run to completion without errors noted"}], "source": ""}
{"case_id": "case-438", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDetach and delete all the NS created . \r\nEx- python3 ns_create_delete_max.py <bdf> -dlns 4\r\n\r\n\r\nInput Data", "expected": "All the NS is deleted and verified using appropriate command \r\nEx- lsblk or nvme list in linux"}], "source": ""}
{"case_id": "case-439", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\ncreate and attach the original NS of size noted in step2. \r\npython3 NVMeIOCTLCLI.py -crns <bdf>  \r\npython3 NVMeIOCTLCLI.py -atns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>\r\n\r\n\r\nInput Data", "expected": "The original NS is created and visible to OS\r\nEx- lsblk or nvme list\r\nAlso check SMART log for any errors."}], "source": ""}
{"case_id": "TC-36170", "name": "PCIe SSD: Error injection verification", "status": "Active", "type": "Manual", "description": "The objective is  to verify the drive functionality when the error is injected and drive smart health response", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nboot the SUT with atleast one PCIe SSD\r\n\r\nInput Data", "expected": "The device is detected in idarc and OS/"}, {"step": "S", "description": "Description\r\nboot the SUT with atleast one PCIe SSD\r\n\r\nInput Data", "expected": "The device is detected in idarc and OS/"}], "source": ""}
{"case_id": "case-441", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nGet the smart logs from the device \r\nplease use attachment in this test case to verify the test case \r\n\r\n\r\nInput Data", "expected": "The critical bits are not set and device status LED is solid green"}], "source": ""}
{"case_id": "case-442", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\ncreate the file SMARTErrorInjection.txt in the same directory where NVMEIOCTLCLI.py exists\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-443", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nEnter the values 1,2,4,8,10 in the SMARTErrorInjection.txt one at a time.\r\n\r\nThese values can be found in NVMe SPEC under SMART/Health information section\r\n\r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-444", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\n\r\nrun the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 \r\n\r\n\r\n\r\nInput Data", "expected": "get the smart logs and check the bit is set for the critcal bits"}], "source": ""}
{"case_id": "case-445", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWait for 20 mins and Check idrac, OMSS, HII for status/state and Failure predicted.\r\n\r\n\r\nInput Data", "expected": "The message across all the management application is same`"}], "source": ""}
{"case_id": "case-446", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\n1. Clear the bit , by entering 0 into SMARTErrorInjection.tx\r\n\r\n2.run the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 \r\n\r\n\r\n\r\nInput Data", "expected": "get the smart logs and check the bit is cleared"}], "source": ""}
{"case_id": "case-447", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat the steps from step 2 - 6 for next critical bits\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-36313", "name": "PCIe SSD : Telemetry Log", "status": "Active", "type": "Manual", "description": "The test case checks the device telemetry log feature and make sure the device vendor can decode the log.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to supported operating system with at least one NVMe device. \r\n\r\nInput Data", "expected": "The nvme device get's detected and enumerated by OS."}, {"step": "1", "description": "Description\r\nBoot to supported operating system with at least one NVMe device. \r\n\r\nInput Data", "expected": "The nvme device get's detected and enumerated by OS."}], "source": ""}
{"case_id": "case-449", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue an Identify Controller to the device  \r\n\r\nInput Data", "expected": "Check LPA (Log Page Attribute ) Field at offset 261 bit 3 to be set. \r\nIf set the device supports telemetry"}], "source": ""}
{"case_id": "case-450", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue a host initiated telemetry command for the all the data area to be returned as response.  \nIf using automation framework\nfollow below example NSID=0xFFFFFFFF\n\n[root@localhost PCIeSSD]# python3 NVMeIOCTLCLI.py -gl 24:00.0\n        \n\n        Log Page ID (0x00 - 0xFF) = 0x07\n        Log Page Sub ID (0x00 - 0xFF) = 0x0\n        Number of DWORDS (0x00 - 0xFF) = 0x7f\n        Retain Asynchronous Event (0 or 1) = 0\n\n\n\nInput Data", "expected": "The device responds with the required telemetry log."}], "source": ""}
{"case_id": "case-451", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nThe telemetry log returned is to be stored in a .bin file and should be saved. \r\n\r\nInput Data", "expected": "The log saved should be sent to the vendor for analysis and to be confirmed if data returned is good."}], "source": ""}
{"case_id": "TC-36856", "name": "PCIe SSD : Complete FRU validation", "status": "Active", "type": "Manual", "description": "FRU validation :\r\n==========\r\n14G system recommended.\r\n\r\nlibI2C read vs shipped image\r\nIPMI command read vs shipped image", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall PCIe SSD, boot to the OS \r\n\r\nInput Data", "expected": "OS should detect the drive"}, {"step": "1", "description": "Description\r\nInstall PCIe SSD, boot to the OS \r\n\r\nInput Data", "expected": "OS should detect the drive"}], "source": ""}
{"case_id": "case-453", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nread the FRU of the device using libi2c command from the slot where the PCIeSSD or Extender card is present\r\n\r\nPCIeSSD\r\nlibi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256'\r\n\r\nAdapteres\r\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\r\n\r\n\r\nInput Data", "expected": "FRU data is read from the device from the particular slot\r\nnote down the serial number and manufacturing date and time values"}], "source": ""}
{"case_id": "case-454", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInput the serial number and manufacturing date and time and calculate the checksum value for board information area format version.\r\nCompare the data from the shipped FRU image vs FRU read from the  device .\r\n\r\n\r\nInput Data", "expected": "The shipped FRU images and FRU from the device should match"}], "source": ""}
{"case_id": "case-455", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nread the FRU using IPMI command for the device and match against shipped image with the modified serial number, manufacturing date and time and checksum for the section which is already done in step 3.\r\n\r\nIPMI commands\r\nPCIESSD U.2\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 0x0  bay  slot 0x01 0x00 0x00 0x20\r\n\r\nAIC\r\n'ipmitool -U root -P calvin raw 0x30 0x36 0x01 slotnumer  0x01 0x01 0x00 0x00 0x20\r\n\r\nFor Extender card : IPMI commands donot support - 14G\r\n\r\n\r\nInput Data", "expected": "The values read using IPMI commands and idrac should match."}], "source": ""}
{"case_id": "TC-37090", "name": "PCIe SSD Crypto Erase with Shutdown notification (Linux Only)", "status": "Active", "type": "Manual", "description": "This test case covers drive behavior for getting a shutdown notification immediately after Crypto Erase is issued and then it compares if false data is reported for unsafe shutdown.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the supported Linux OS with at least 2 PCIe SSD. \r\n\r\nInput Data", "expected": "Systems boots successfully and all NVMe devices are discovered."}, {"step": "1", "description": "Description\r\nBoot to the supported Linux OS with at least 2 PCIe SSD. \r\n\r\nInput Data", "expected": "Systems boots successfully and all NVMe devices are discovered."}], "source": ""}
{"case_id": "case-457", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSelect a NVMe device and dump SMART log(OMSA Can be used). Take a note of Unsafe Shutdown Count. \r\n\r\nInput Data", "expected": "SMART data is successfully pulled."}], "source": ""}
{"case_id": "case-458", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a Crypto Erase to the drive (OMSA Can be used)\r\n\r\nInput Data", "expected": "The Command goes to the drive."}], "source": ""}
{"case_id": "case-459", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue a shutdown notification to the drive immediately after CE . (Driver unload and load will do ) \r\n\r\nInput Data", "expected": "Device is available."}], "source": ""}
{"case_id": "case-460", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDump the SMART Log for the drive and look for Unsafe Shutdown Count\r\n\r\nInput Data", "expected": "The Unsafe shutdown count remains same."}], "source": ""}
{"case_id": "case-461", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 2-5 for at least 5 times. \r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-38867", "name": "PCIeSSD SSD DUP: FW Update via iDRAC GUI w/ multiple devices", "status": "Active", "type": "Manual", "description": "Verify successful DUP execution against multiple devices via iDRAC.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least two PCIe SSDs with PCIe VDM support (preferably of same model with down-rev firmware version i.e. n-1.\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. \r\n\r\n\r\nInput Data", "expected": "Drive is installed without any issue."}, {"step": "1", "description": "Description\r\nInstall at least two PCIe SSDs with PCIe VDM support (preferably of same model with down-rev firmware version i.e. n-1.\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. \r\n\r\n\r\nInput Data", "expected": "Drive is installed without any issue."}], "source": ""}
{"case_id": "case-463", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf testing with iDRAC version is 5.0.0.0, cold boot the system.\r\nIf testing with version is 5.10.00.0 or greater, omit this step. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-464", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGet the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Device BDF's are listed in iDRAC log."}], "source": ""}
{"case_id": "case-465", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nLaunch the iDRAC GUI, go to Maintenance / System Update and Upload DUP for the PCIe SSD. Once you get success for the download, go ahead and select the \"Install\" button.\r\n\r\nNOTE: If you see Install and Reboot, Install Next Reboot buttons, it is a issue.\r\n\r\nPop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.\r\n\r\n\r\nInput Data", "expected": "Verified that the DUP package uploads successfully and both the job passed with no issues."}], "source": ""}
{"case_id": "case-466", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.\r\n   1.  SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version <version n>.)\r\n   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n>).\r\n   3.  PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version :<version n-1>, Current version: <version n>).\r\n\r\n\r\n\r\nInput Data", "expected": "User verified LC logs reported the correct entry for each PCIe SSD."}], "source": ""}
{"case_id": "case-467", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nGo to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to OS and verify that new FW version is reported on all drives you updated.\r\n\r\nInput Data", "expected": "User verified storage inventory reported the correct FW version for all drives.\r\n\r\nUser verified FW inventory reported the correct FW version for all drives.\r\n\r\nUser verified that OS reported the correct FW version for all drives."}], "source": ""}
{"case_id": "case-468", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-7 after performing hotplug operation to PCIe SSDs.\r\n\r\nInput Data", "expected": "Firmware is updated successfully after hotplug."}], "source": ""}
{"case_id": "TC-39349", "name": "PCIe SSD: Firmware activate and reset during I/O (Linux Only)", "status": "Active", "type": "Manual", "description": "Perform firmware activation and device reset during I/O stress.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBegin I/O to the target device.  \r\n    Example:\r\n        Linux:  testio -t50 -f/dev/nvme0n1\r\n        Windows:  testio.exe -f50 -f\\\\.\\PHYSICALDRIVE0\r\n        Framework:   \r\n            import ServerStorageSDK.Helpers.IO as IO\r\n            io = IO.IO()\r\n            io.Validate('testio', False)\r\n            io.Threads = 50\r\n            io.Start(['/dev/nvme0n1'])\r\n\r\n\r\n\r\nInput Data", "expected": "I/O starts."}, {"step": "1", "description": "Description\nBegin I/O to the target device.  \n    Example:\n        Linux:  testio -t50 -f/dev/nvme0n1\n        Windows:  testio.exe -f50 -f\\\\.\\PHYSICALDRIVE0\n        Framework:   \n            import ServerStorageSDK.Helpers.IO as IO\n            io = IO.IO()\n            io.Validate('testio', False)\n            io.Threads = 50\n            io.Start(['/dev/nvme0n1'])\n\n\n\nInput Data", "expected": "I/O starts."}, {"step": "2", "description": "Description\nDownload device firmware:\nLinux:\n    nvme fw-download /dev/nvme0n1 -f your_fw_file.tar\n\nUse the raw binary file or tar file for the FW (not the DUP)\n\n\nInput Data", "expected": "Firmware download completes successfully."}, {"step": "3", "description": "Description\r\nActivate FW w/o reset:\r\nLinux:\r\n    nvme fw-commit /dev/nvme0n1 -a 3-s 0\r\n\r\n\r\nInput Data", "expected": "Firmware activation succeeds.\r\nIO haults while FW download and commit take place and then re-starts"}, {"step": "1", "description": "Description\nBegin I/O to the target device.  \n    Example:\n        Linux:  testio -t50 -f/dev/nvme0n1\n        Windows:  testio.exe -f50 -f\\\\.\\PHYSICALDRIVE0\n        Framework:   \n            import ServerStorageSDK.Helpers.IO as IO\n            io = IO.IO()\n            io.Validate('testio', False)\n            io.Threads = 50\n            io.Start(['/dev/nvme0n1'])\n\n\n\nInput Data", "expected": "I/O starts."}], "source": ""}
{"case_id": "case-470", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDownload device firmware:\r\nLinux:\r\n    nvme fw-download /dev/nvme0n1 -f your_fw_file.tar\r\n\r\nUse the raw binary file or tar file for the FW (not the DUP)\r\n\r\n\r\nInput Data", "expected": "Firmware download completes successfully."}], "source": ""}
{"case_id": "case-471", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nActivate FW w/o reset:\r\nLinux:\r\n    nvme fw-commit /dev/nvme0n1 -a 3-s 0\r\n\r\n\r\nInput Data", "expected": "Firmware activation succeeds.\r\nIO haults while FW download and commit take place and then re-starts"}], "source": ""}
{"case_id": "TC-41756", "name": "PCIeSSD - NVMe Sanitize", "status": "Active", "type": "Manual", "description": "This test case is intended to validate that the NVMe Sanitize operations are supported and implemented correctly by the NVMe device.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least one NVMe device in the system\r\n\r\nInput Data", "expected": "The NVMe device is detected by the driver and displayed in the OS"}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least one NVMe device in the system\r\n\r\nInput Data", "expected": "The NVMe device is detected by the driver and displayed in the OS"}, {"step": "2", "description": "Description\nUsing a tool that can send IOCTLs to the NVMe driver (like nvme-cli in Linux/ESXi or the Dell NVMeIOCTLCLI tool), issue an Identify Controller command to the drive(s)\n\nInput Data", "expected": "Read the \"Sanitize Capabilities\" field (offset 331:328) and confirm that at the very least, bits 0 and 1 are set"}, {"step": "3", "description": "Description\nPartition, format, and put some data onto the drive(s)\n\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}, {"step": "4", "description": "Description\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x04 to the drive(s) in order to initiate a Sanitize - Cryptographic Erase operation\n\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}, {"step": "5", "description": "Description\r\nPartition, format, and put some data onto the drive(s)\r\n\r\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}, {"step": "6", "description": "Description\r\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x02 to the drive(s) in order to initiate a Sanitize - Block Erase operation\r\n\r\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least one NVMe device in the system\r\n\r\nInput Data", "expected": "The NVMe device is detected by the driver and displayed in the OS"}], "source": ""}
{"case_id": "case-473", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nUsing a tool that can send IOCTLs to the NVMe driver (like nvme-cli in Linux/ESXi or the Dell NVMeIOCTLCLI tool), issue an Identify Controller command to the drive(s)\n\nInput Data", "expected": "Read the \"Sanitize Capabilities\" field (offset 331:328) and confirm that at the very least, bits 0 and 1 are set"}], "source": ""}
{"case_id": "case-474", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nPartition, format, and put some data onto the drive(s)\n\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}], "source": ""}
{"case_id": "case-475", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x04 to the drive(s) in order to initiate a Sanitize - Cryptographic Erase operation\n\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}], "source": ""}
{"case_id": "case-476", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nPartition, format, and put some data onto the drive(s)\n\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}], "source": ""}
{"case_id": "case-477", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x02 to the drive(s) in order to initiate a Sanitize - Block Erase operation\n\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}], "source": ""}
{"case_id": "TC-42864", "name": "PCIe SSD: Issue PERST during initialization", "status": "Active", "type": "Manual", "description": "Issue a PEReset during device initialization.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nUse the automation framework, or:\r\n\r\nInput Data", "expected": ""}, {"step": "1", "description": "Description\r\nUse the automation framework, or:\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-479", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach a target drive to a Quarch and insert it into the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-480", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUsing the Quarch, remove the drive from the system.  Verify that the drive is not present in the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-481", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUsing the Quarch, reinsert the drive in the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-482", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nWait 45 seconds.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-483", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nUsing the Quarch, issue a P/E reset to the drive.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-484", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nUsing the Quarch, remove the drive from reset.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-485", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nWait 10 seconds.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-486", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nVerify that an identify controller issued to the drive returns successfully.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-44021", "name": "PCIe SSD: TCG Opal - Device Query for Opal support (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.\r\nAlso check if device supports Opal 2+", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "1", "description": "Description\r\nBoot to a Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-488", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\n\r\n\r\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-489", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a device discovery command using attached binary \"sedlib\". \r\nFor example \r\n./sedlib -a q -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The command completes successfully and device returns discovery data."}], "source": ""}
{"case_id": "case-490", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\ncheck feature: 0x2  specific fields along with Feature 0x 203\r\n\r\nInput Data", "expected": "The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then \r\nLocking Enabled: 0 other wise 1 if already SP is activated. \r\nAlso Feature 0x203 should advertise Opal 2 support"}], "source": ""}
{"case_id": "TC-46357", "name": "PCIe SSD: PCIe VDM EID Check after Hotplug", "status": "Active", "type": "Automation", "description": "Description: This test will validate if the NVMe device has a valid EID assigned through PCIe VDM before and after hotplug.\r\n* Set Endpoint ID", "precondition": "", "steps": [{"step": "1", "description": "Boot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: The system should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater.", "expected": "System boots without any issue and devices have VDM support."}, {"step": "1", "description": "Boot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: The system should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater.", "expected": "System boots without any issue and devices have VDM support."}], "source": ""}
{"case_id": "case-492", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue Get Endpoint ID (EID) MCTP command to each drive (preferably via the automation script 'MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'", "expected": "The command is successful and all the devices have a valid non-zero Endpoint ID (EID)."}], "source": ""}
{"case_id": "case-493", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Repeat step 2 after performing hotplug on all PCIe SSDs.", "expected": "The command is successful and all the devices have a valid non-zero Endpoint ID (EID)."}], "source": ""}
{"case_id": "TC-46466", "name": "PCIe SSD : Persistent Event Log-  Namespace Management logging check", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \n\nInput Data", "expected": "The device boots without any errors."}, {"step": "1", "description": "Description\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \n\nInput Data", "expected": "The device boots without any errors."}], "source": ""}
{"case_id": "case-495", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\nFor example \npython3 NVMeIOCTCLI.py -gl bdf \n\n NSID = 0xffffffff\nLID= 0x0d\nsubpage =0x0\nnum of dwords = 0x7f\n\n\n\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-496", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue delete name space  command to the drive . \nFor example\n\npython3 NVMeIOCTCLI.py -dlns bdf \n\n\n\n\nInput Data", "expected": "The name space got deleted without any issue."}], "source": ""}
{"case_id": "case-497", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nhIssue Controller reset, then Go to step 2 and dump the log. \nMake sure to save the log in different files. \nCompare the two logs\n\n\nInput Data", "expected": "The new event for Change namespace correctly logged earlier in the Persistent Event Log data\nMake sure the fields are programmed correctly."}], "source": ""}
{"case_id": "case-498", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nRestore the original namespace by using create name space and attach namespace.\nThe PEL event log could be used to know the size of the namespace deleted.\n\nFor example\npython3 NVMeIOCTCLI.py -crns bdf\n\npython3 NVMeIOCTCLI.py -atns bdf\n\n\nInput Data", "expected": "Namespace was created and attached."}], "source": ""}
{"case_id": "TC-46688", "name": "PCIe SSD: Long term mixed side band MI  and in band stress", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with maximum supported NVMe devices\r\n\r\nInput Data", "expected": "System boots up without any errors and all devices discovered"}, {"step": "1", "description": "Description\r\nBoot to the OS with maximum supported NVMe devices\r\n\r\nInput Data", "expected": "System boots up without any errors and all devices discovered"}], "source": ""}
{"case_id": "case-500", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running heavy IO on all the devices for 12 hrs and capture SMART logs from all devices\r\n\r\nInput Data", "expected": "No issue is found starting the IO and SMART logs are captured from all devices."}], "source": ""}
{"case_id": "case-501", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running NVMe Subsystem Health Status poll MI command similar to iDRAC. \r\nUse automation framework to start the traffic. \r\n\r\n\r\nInput Data", "expected": "Side band MI traffic started and commands start completing successfully"}], "source": ""}
{"case_id": "case-502", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRun both IO and side band command stress for 12 hrs. \r\nDump smart logs from all devices and compare from previous one collected at the beginning. \r\nAlso, check OS logs for the timeout or any errors.\r\n\r\n\r\nInput Data", "expected": "Test completes successfully and no errors are logged in SMART log."}], "source": ""}
{"case_id": "TC-48635", "name": "PCIe SSD: TCG Opal NVMe MI - Get MSID of the device", "status": "Active", "type": "Manual", "description": "iDrac 5.10+ and Linux are required for this testcase.\r\n\r\nThe test case prints MSID of the device. \r\nThe location of the test firmware is here .\r\n\\\\S3bnsx01nas05.amer.dell.com\\RAIDSERVER\\NVMe\\NVME_PCIeSSD\\NVMe_SEKM\\iDRACTCGOpaltestfirmware", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "0", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-504", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-505", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O + Admin command to the device.\r\nadmin command like identify or get log page could be run in a loop along side some IO\r\nAlso, if this is the first test after iDRAC reboot make sure you set MTU size. to 120 as recomended \r\ntestlibsednvme setMTUsize <eid> 120\r\n\r\n\r\nIssue following command to get the MSID of the device which is the default key \r\ntestlibsednvme getmsid < eid > <controller ID>\r\n\r\n\r\ncontroller id should be determined from identify controller response\r\nand eid from previous step.\r\nFor example:\r\ntestlibsednvme getmsid 4 0\r\n\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "The device should return the MSID. \r\nFor example \r\n msid = MSID_password\r\n\r\nThe msid varies from device to device and vendor to vendor."}], "source": ""}
{"case_id": "TC-49774", "name": "PCIe SSD: Connect refclk After 12V is Stable and PERST# De-Assertion", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to start the reference clock to the NVMe drive after the 12V power good, and PERST# de-asserting. Even though this is a PCIe spec. violation, it's expected that the drive remain functional after removing and re-inserting the drive.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect the target device to a quarch.\r\n\r\nInput Data", "expected": "Quarch is powered on and available, device is available to the OS."}, {"step": "1", "description": "Description\r\nConnect the target device to a quarch.\r\n\r\nInput Data", "expected": "Quarch is powered on and available, device is available to the OS."}], "source": ""}
{"case_id": "case-507", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nRemove the drive from the system\r\n\r\nInput Data", "expected": "The drive is no longer enumerated in the OS"}], "source": ""}
{"case_id": "case-508", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\n   1. Assign all signals to a source group.\r\nAssign all refclk signals to a separate source group\r\n\r\n   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source\r\n          o signal:ref_clk_0_mn:source 1 <1>\r\n          o add the other 3 similarly using a 100ms delay\r\n   2. \r\n\r\n\r\n\r\nInput Data", "expected": "Signals are added successfully."}], "source": ""}
{"case_id": "case-509", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInsert the drive so that all signals except the refclk are inserted\r\n\r\nInput Data", "expected": "The drive will likely not get detected but that's fine"}], "source": ""}
{"case_id": "case-510", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove the drive normally\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-511", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert the drive back in normally\r\n\r\nInput Data", "expected": "The OS is able to detect the drive"}], "source": ""}
{"case_id": "case-512", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRun I/O for a minute to the drive to verify functionality\r\n\r\nInput Data", "expected": "The drive successfully processes I/O"}], "source": ""}
{"case_id": "TC-50334", "name": "PCIe SSD: Hot insert: AER registers are configured/restored on hot insertion", "status": "Active", "type": "Manual", "description": "Verify that the AER registers for a PCIe SSD device are configured/restored on hot insertion per system BIOS defaults", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-514", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the values of the following PCIe registers: \r\n\r\nUncorrectale Error Mask Register (UEMsk)\r\nCorrectale Error Mask Register  (CEMsk)\r\nUncorrectable Error Severity Register  (UESvrt)\r\n\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-515", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the drive from the system\r\n\r\nInput Data", "expected": "The system is functional. No error/ fatal error is reported."}], "source": ""}
{"case_id": "case-516", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot Insert the drive that was removed in step 4 back into the system\r\n\r\nInput Data", "expected": "The device is recognized by the OS and functional"}], "source": ""}
{"case_id": "case-517", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCapture the values of the following PCIe registers: \r\n\r\nUncorrectale Error Mask Register (UEMsk)\r\nCorrectale Error Mask Register  (CEMsk)\r\nUncorrectable Error Severity Register  (UESvrt)\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The values of the registers are the same as when they were captured in step 2"}], "source": ""}
{"case_id": "TC-50480", "name": "PCIe SSD: TCG Opal - Lock/Unlock global range (Linux Only)", "status": "Active", "type": "Manual", "description": "This test case checks locking and unlocking of global range to be used by EKMS solution", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}, {"step": "1", "description": "Description\r\nBoot to the Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}], "source": ""}
{"case_id": "case-519", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck if device is enabled for locking by doing query. \r\nEx- ./sedlib -a q -d /dev/nvme0n1 -x nvme\r\nIf not enabled then activate SP \r\n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\nInput Data", "expected": "The device is activated for locking"}], "source": ""}
{"case_id": "case-520", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRead some data from the device \r\nEx- nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\r\n\r\n\r\n\r\nInput Data", "expected": "The data is read without any issue"}], "source": ""}
{"case_id": "case-521", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nLock the device for the global range (whole device) using Band 0 (global ) \r\nEx-\r\n./sedlib -a l -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\nInput Data", "expected": "The device is locked and command completes successfully. \r\nRun query command to confirm."}], "source": ""}
{"case_id": "case-522", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nTry to read data previously written . \r\nEx- \r\nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\r\n\r\n\r\nInput Data", "expected": "Access is denied showing device is locked"}], "source": ""}
{"case_id": "case-523", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nUnlock the device using following command and read data again \r\nEx-\r\n ./sedlib -a u -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The data is accessible."}], "source": ""}
{"case_id": "TC-52088", "name": "PCIe SSD: TCG Opal - Get MSID for the device  (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case is used to get MSID for the device , the MSID is used as default PIN for activating and configuring the device first time.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a linux OS with a supported TCG Opal device \r\n\r\nInput Data", "expected": "The device get's discovered by OS without any issues. \r\nAlso, perform some IO to make sure drive is functional."}, {"step": "1", "description": "Description\r\nBoot to a linux OS with a supported TCG Opal device \r\n\r\nInput Data", "expected": "The device get's discovered by OS without any issues. \r\nAlso, perform some IO to make sure drive is functional."}], "source": ""}
{"case_id": "case-525", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\n\r\n\r\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-526", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue print MSID command to get MSID for the device. \r\nEx. \r\n./sedlib -a pm -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The command get's completed successfully and MSID is printed, note down for future purpose. \r\nEx. \r\nAttempting to perform action: PRINT MSID\r\nMSID is 13 bytes long:\r\nMSID_password"}], "source": ""}
{"case_id": "TC-53753", "name": "PCIe SSD: Remove refclk Prior to 12V Loss and PERST# Assertion", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to remove the reference clock to the NVMe drive prior to the 12V power good going away, and PERST# asserting. Even though this is a PCIe spec. violation, it's expected that the drive remain functional after \"re-inserting\" the drive.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect the target device to a quarch.\r\n\r\nInput Data", "expected": "Quarch is powered on and available, device is available to the OS."}, {"step": "1", "description": "Description\r\nConnect the target device to a quarch.\r\n\r\nInput Data", "expected": "Quarch is powered on and available, device is available to the OS."}], "source": ""}
{"case_id": "case-528", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAdd the target devices reference clock pins to a quarch source.\r\n\r\n   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source\r\n          o signal:ref_clk_0_mn:source 1 <1>\r\n          o add the other 3 similarly\r\n   2. All other signals would be another source number with a delay of 10ms after the clock source group\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Signals are added successfully."}], "source": ""}
{"case_id": "case-529", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBegin I/O to the target device.  \r\n    Example:\r\n        Linux:  testio -t50 -f/dev/nvme0n1\r\n        Windows:  testio.exe -f50 -f\\\\.\\PHYSICALDRIVEX\r\n        Framework:   \r\n            import ServerStorageSDK.Helpers.IO as IO\r\n            io = IO.IO()\r\n            io.Validate('testio', False)\r\n            io.Threads = 50\r\n            io.Start(['/dev/nvme0n1'])\r\n\r\n\r\nInput Data", "expected": "I/O starts without error."}], "source": ""}
{"case_id": "case-530", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\n\r\nRemove the reference clock by turning the source off\r\n\r\n    * source:1:state off <1>\r\n\r\n\r\n\r\nInput Data", "expected": "I/O will likely fail"}], "source": ""}
{"case_id": "case-531", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nImmediately remove all other signals from the Quarch\r\n\r\nInput Data", "expected": "The drive is removed from the OS"}], "source": ""}
{"case_id": "case-532", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert the drive back in normally\r\n\r\nInput Data", "expected": "The OS is able to detect the drive"}], "source": ""}
{"case_id": "case-533", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRun I/O for a minute to the drive to verify functionality\r\n\r\nInput Data", "expected": "The drive successfully processes I/O"}], "source": ""}
{"case_id": "TC-58391", "name": "PCIe SSD: Expansion ROM Base Address Register Check", "status": "Active", "type": "Manual", "description": "This Test Case is to check if the Expansion ROM is present/enabled in any form for the device, as currently not supported by Dell.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the EFI Shell with at least one NVMe device installed \r\n\r\nInput Data", "expected": "The system boots without any errors"}, {"step": "1", "description": "Description\nBoot to the EFI Shell with at least one NVMe device installed \n\nInput Data", "expected": "The system boots without any errors"}], "source": ""}
{"case_id": "case-535", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck Expansion ROM Base Address Register at offset 30h in the Config space. \r\n\r\n\r\n\r\nInput Data", "expected": "The value of the register should be zero."}], "source": ""}
{"case_id": "TC-59418", "name": "PCIe SSD Virtualization - IO with admin command along with occasional controller reset (pass through)", "status": "Active", "type": "Manual", "description": "The intent of the test case is to verify drive behavior in a pass through configuration under reset and admin command in flight", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot with combination of drives in pass through and data store\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot with combination of drives in pass through and data store\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-537", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall a Linux VM and attach nvme device as passthrough along with data store nvme devices\r\n\r\nInput Data", "expected": "The VM boots and drive is attached without any errors."}], "source": ""}
{"case_id": "case-538", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInstall \"nvme-cli \" package and dump smart-log for each pass through device using following command. \r\n\"nvme smart-log /dev/nvmexn1\" . Save the output to  file. \r\n\r\n\r\nInput Data", "expected": "The package get's install and the drive logs are collected in a file."}], "source": ""}
{"case_id": "case-539", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart running IO to all devices (pass through as well as data store) and in the background run shell script to poll for smart log on all pass through devices.\r\n\"nvme smart-log /dev/nvmexn1\". \r\n\r\n\r\nInput Data", "expected": "IO runs fine and smart data is polled without any issues."}], "source": ""}
{"case_id": "case-540", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue controller reset to all pass through devices after every 20 min interval. please find the attached script for reference. \r\n\r\nInput Data", "expected": "The drive goes through a reset and temporarily IO is paused."}], "source": ""}
{"case_id": "case-541", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nLet the test run for at least 2 hrs and collect smart  log for all the devices mentioned in step 3. Also, check SEL and OS logs to make sure no errors are reported. \r\n\r\nInput Data", "expected": "There are no errors reported as part of SMART log and OS logs."}], "source": ""}
{"case_id": "TC-61268", "name": "PCIe SSD: FW DUP Upgrade-Downgrade from OS (Manual)", "status": "Active", "type": "Manual", "description": "Confirm operation of the FW DUPs within the OS (Windows/Linux)", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nMake sure all the devices are discovered in the OS\r\n\r\nInput Data", "expected": "All devices installed, are visible in the OS"}, {"step": "1", "description": "Description\r\nMake sure all the devices are discovered in the OS\r\n\r\nInput Data", "expected": "All devices installed, are visible in the OS"}], "source": ""}
{"case_id": "case-543", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFrom the OS, run the DUP as below -\r\n\r\n1) In Windows Server, double click on the DUP (.exe) and follow the prompts\r\n\r\n2) In Linux, open a terminal from where the DUP is located and execute it, and follow the prompts\r\n\r\n\r\nInput Data", "expected": "DUPs launch and the FW update process starts"}], "source": ""}
{"case_id": "case-544", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nOnce the FW update is completed, make sure to check from the OS if the device shows up with the correct FW\r\n\r\nIf you are using a Gen3 device, you will be prompted to reboot\r\nIf you are using a Gen4 device, reboot will not be required\r\n\r\nWindows Servers have different behavior, please check with the project lead for exact behvior on reboot prompts\r\n\r\n\r\nInput Data", "expected": "FW update applied in Step #2 is visible and device is at correct Firmware"}], "source": ""}
{"case_id": "case-545", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nFollow the steps #2 and #3 for Firmware Downgrade\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "TC-62832", "name": "PCIe SSD : Persistent Event Log-  NVM Subsystem Hardware Error logging check", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\nBoot to an OS that supports DPC with at least one NVMe device supporting PEL(Check Identify response). \n\nInput Data", "expected": "The device boots without any errors."}, {"step": "1", "description": "Description\nBoot to an OS that supports DPC with at least one NVMe device supporting PEL(Check Identify response). \n\nInput Data", "expected": "The device boots without any errors."}], "source": ""}
{"case_id": "case-547", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\nNSID = 0x0\r\nLID= 0x0d\r\nsubpage = 0x0\r\nnum of dwords = 0x0\r\nevent notification = 0x0\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-548", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nInject UR error on the device \n\nsetpci -s bdf 0x10.w=0xffff\n\n\n\n\n\n\nInput Data", "expected": "The device goes through DPC recovery"}], "source": ""}
{"case_id": "case-549", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for NVM subsystem Hardware Error Event  correctly logged in the Persistent Event Log with event code as 0x05"}], "source": ""}
{"case_id": "TC-62905", "name": "PCIe SSD: PCIe VDM Enablement Check", "status": "Active", "type": "Manual", "description": "To verify if the NVMe device has PCIe VDM Support.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nDump the FRU of the PCIe SSD (preferably via automation script 'GetPCIeSSDFRU.py'). Eg:\r\n\r\npython3 GetPCIeSSDFRU.py\r\n\r\nThen, save the output to a file.\r\n\r\n\r\nInput Data", "expected": "FRU Data is collected."}, {"step": "1", "description": "Description\r\nDump the FRU of the PCIe SSD (preferably via automation script 'GetPCIeSSDFRU.py'). Eg:\r\n\r\npython3 GetPCIeSSDFRU.py\r\n\r\nThen, save the output to a file.\r\n\r\n\r\nInput Data", "expected": "FRU Data is collected."}], "source": ""}
{"case_id": "case-551", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the MCTP Support Bit is set to 1 in NVMe PCIe MultiRecord Area.\r\n\r\nInput Data", "expected": "MCTP Support Bit is set to 1 confirms that PCIe VDM is supported on the device."}], "source": ""}
{"case_id": "TC-64013", "name": "PCIe SSD : Persistent Event Log-  Sanitize operation logging check", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}, {"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}], "source": ""}
{"case_id": "case-553", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\n NSID = 0xffffffff\r\nLID= 0x0d\r\nsubpage =0x0\r\nnum of dwords = 0x7f\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-554", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue Sanitize command to the drive . \r\nFor example\r\n\r\npython3 NVMeIOCTCLI.py -sn bdf \r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Sanitize operation successfully completed without any errors."}], "source": ""}
{"case_id": "case-555", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue Controller reset, then Go to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for Sanitize correctly logged earlier in the Persistent Event Log data"}], "source": ""}
{"case_id": "TC-64172", "name": "PCIeSSD - NVMe Device Self-Test", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to ensure the NVMe device supports and can successfully complete a Device Self-Test", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating system with at least  one NVMe device in the system\r\n\r\nInput Data", "expected": "The NVMe drive detects the device and it's seen within the OS"}, {"step": "1", "description": "Description\r\nBoot to a supported operating system with at least  one NVMe device in the system\r\n\r\nInput Data", "expected": "The NVMe drive detects the device and it's seen within the OS"}], "source": ""}
{"case_id": "case-557", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue an Identify Controller command to the drive(s)\r\n\r\nInput Data", "expected": "The \"Optional Admin Command Support\" field (offset 257:256) shows that bit 4 is set"}], "source": ""}
{"case_id": "case-558", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a Device Self-Test command with the \"Self-test Code\" set to 0x01 in order to initiate a short DST\r\n\r\nInput Data", "expected": "The command completes successfully"}], "source": ""}
{"case_id": "case-559", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue an Identify Controller command and read the \"Extended Device Self-test Time\" field (offset 317:316)\r\n\r\nInput Data", "expected": "The value read is non-zero"}], "source": ""}
{"case_id": "case-560", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue a Device Self-test command with the \"Self-test Code\" set to 0x02 in order to initiate an extended DST\r\n\r\nInput Data", "expected": "The command completes successfully and takes no longer than 20% of the value specified from step 4. For example, if the value from step 4 says 5 minutes, then the test should take no longer than 6 minutes."}], "source": ""}
{"case_id": "TC-65342", "name": "PCIe SSD: A/C Cycle with Controller Reset, SBR, PERST (Linux Only)", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported operating system with at least one 2.5\" PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot into a supported operating system with at least one 2.5\" PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-562", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake sure that PCIe SSD is connected to Qurach module and system is connected to APC outlet.\r\n\r\nInput Data", "expected": "The device is discovered is functional in the OS."}], "source": ""}
{"case_id": "case-563", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nWrite a script to:\n\n1.     Issue Controller Reset to the PCIe SSD\n\nUsing nvmecli: nvme reset /dev/nvme0n1\n\nUsing framework: python3 NVMeIOCTL.py -rc B:D.F\n\n2.     Wait 10s\n\n3.     Issue a Secondary Bus Reset the PCIe SSD:\n\na.     Cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1\n\nb.     Wait 3s\n\nc.     Make sure the link is x0, Gen-1\n\nd.     Take the device out of reset by writing a 0\n\ne.     Wait 10s\n\nf.      Make sure the link width and speed is the maximum capable for the PCIe SSD\n\ne.   The link width and speed is the maximum capable for the PCIe SSD \n\n1.                4.  Wait 10s. \n\n1.                 5. Issue PERST to the PCIe SSD:\n\na.     Unload the NVMe Driver to prevent a UR\n\nb.     Assert PERST to the drive using Quarch\n\nc.     Wait 10s\n\nd.     Make sure the link was fully disabled\n\ne.     De-assert PERST to the drive using Quarch\n\nf.      Verify that drive is available, and no smart warning is issued and drive is Gen 3, x4\n\ng.     Load NVMe driver\n\n2.                  6. Wait 10s\n\nfor 15 loops. After each loop. make sure that device is trained to maximum link width and speed. After 15 loops, perform A/C cycle to the system. Repeat this for 12 hours. \n\n\n\nInput Data", "expected": "The script runs successfully with no errors."}], "source": ""}
{"case_id": "TC-65940", "name": "PCIe SSD: Read only Firmware slot (Slot1)", "status": "Active", "type": "Automation", "description": "Read only Firmware slot (Slot1)", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall NVMe devices and boot to the OS\r\n\r\nInput Data", "expected": "The system is booted and no relevant errors are reported in the OS logs."}, {"step": "1", "description": "Description\nInstall NVMe devices and boot to the OS\n\nInput Data", "expected": "The system is booted and no relevant errors are reported in the OS logs."}], "source": ""}
{"case_id": "case-565", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Identify controller to the device and get the response.\r\nnvme-cli (linux only) or NVMeIOCTL (Automation Framework) can be used. \r\n\r\n\r\nInput Data", "expected": "The drive responds with Identify Controller data structure."}], "source": ""}
{"case_id": "case-566", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck for the \"Firmware Updates\" field that is byte 260. \r\n\r\nInput Data", "expected": "The drive reports firmware slot 1 to be read only."}], "source": ""}
{"case_id": "TC-71793", "name": "PCIe SSD: ASPM control", "status": "Active", "type": "Manual", "description": "Dell systems disable Active State Power Management (ASPM) - No L0 or L1 support, regardless if the PCIe SSD supports it", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-568", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-569", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nPower on the system and dump PCIe config space for the PCIe SSD. Verify ASPM is disabled.\n\nInput Data", "expected": "Link Control Register bits 0 and 1 are set to 0 (disabled)"}], "source": ""}
{"case_id": "TC-73119", "name": "Namespace check after IO and Hot Reset & MI with Sudden Power Loss", "status": "Active", "type": "Manual", "description": "This test case checks for the namespace availability after performing IO and Hot Reset, followed by running MI traffic with Sudden Power Loss.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with at least 2 NVMe SSD installed\r\n\r\nInput Data", "expected": "System boots up without any errors and all devices are discovered"}, {"step": "1", "description": "Description\r\nBoot to the OS with at least 2 NVMe SSD installed\r\n\r\nInput Data", "expected": "System boots up without any errors and all devices are discovered"}], "source": ""}
{"case_id": "case-571", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDelete all the partitions on the drives to be tested\r\n\r\nInput Data", "expected": "The partitions are deleted and raw volume is available."}], "source": ""}
{"case_id": "case-572", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart heavy IO on the drives\r\n\r\nInput Data", "expected": "IO runs without any issue"}], "source": ""}
{"case_id": "case-573", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue a Hot reset to the drives (Secondary Bus Reset can be used) \r\n\r\nInput Data", "expected": "The drives goes through reset and Namespace is still available"}], "source": ""}
{"case_id": "case-574", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStart MI traffic to the drives along with IO running \r\n\r\nInput Data", "expected": "No issue running MI commands and drive responds without any errors"}], "source": ""}
{"case_id": "case-575", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIssue a DC cycle for the Sudden Power Loss scenario for the drives \r\n\r\nInput Data", "expected": "The system goes through a power cycle and OS boots back without any issue"}], "source": ""}
{"case_id": "case-576", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCheck if all devices are discovered and available \r\n\r\nInput Data", "expected": "All devices shows up"}], "source": ""}
{"case_id": "case-577", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nrepeat steps 3-8 50 times \r\n\r\nInput Data", "expected": "No errors reported"}], "source": ""}
{"case_id": "TC-73472", "name": "PCIe SSD: Mixed Read/Write/DSM workload (Linux Only)", "status": "Active", "type": "Manual", "description": "Run read, write and trim commands to a device in equal quantities.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nStart Reads, Writes, and Trim operations to the drive at the same time, running for 1 minute.\r\n\r\nnote - Due to lack of dsm support on Windows, this test can only be run under Linux.\r\n\r\n\r\nInput Data", "expected": "All reads, writes, and Trim operations complete successfully"}, {"step": "1", "description": "Description\r\nStart Reads, Writes, and Trim operations to the drive at the same time, running for 1 minute.\r\n\r\nnote - Due to lack of dsm support on Windows, this test can only be run under Linux.\r\n\r\n\r\nInput Data", "expected": "All reads, writes, and Trim operations complete successfully"}], "source": ""}
{"case_id": "TC-74677", "name": "PCIe SSD: Persistent Event Log Collection  (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks the command response of the Persistent Event Log from the drive and also checks if the data is valid.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to supported operating system with at least one NVMe device. \r\n\r\nInput Data", "expected": "The nvme device get's detected and enumerated by OS"}, {"step": "1", "description": "Description\r\nBoot to supported operating system with at least one NVMe device. \r\n\r\nInput Data", "expected": "The nvme device get's detected and enumerated by OS"}], "source": ""}
{"case_id": "case-580", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue identify controller to the device. \nFor example \npython3 NVMeIOCTLCLI.py -ic bdf\n\n\nInput Data", "expected": "Check byte 261 bit 4 of LPA or else look at the decoded response of IC. \r\nThe bit should be set advertising PEL support"}], "source": ""}
{"case_id": "case-581", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue get log page command with log page id 0xd for persistent event log \n\nFor example:\npython3 NVMeIOCTLCLI.py -gl bdf\n\nNSID=0\nLID=0xd\nsubpageid=0\nnumofdwords=0x7f\nRAE=0\n\n\nInput Data", "expected": "The  device responds with required Persistent Event log. \r\nMake sure the header fields are correct like Log identifier,model number,POH and supported event. \r\nMake sure device advertise all event as per requirement document. \r\nContact device lead for the information."}], "source": ""}
{"case_id": "TC-78641", "name": "PCIeSSD SSD DUP: FW Downgrade via iDRAC GUI w/ multiple devices", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least two PCIe SSDs with PCIe VDM support (preferably of same model with latest firmware versions).\r\n\r\nTo check for VDM support:\r\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\r\n\r\nNote: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. \r\n\r\n\r\nInput Data", "expected": "Drive is installed without any issue."}, {"step": "1", "description": "Description\nInstall at least two PCIe SSDs with PCIe VDM support (preferably of same model with latest firmware versions).\n\nTo check for VDM support:\npython3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1\n\nNote: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. \n\n\nInput Data", "expected": "Drive is installed without any issue."}], "source": ""}
{"case_id": "case-583", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf testing with iDRAC version is 5.0.0.0, cold boot the system.\r\nIf testing with version is 5.10.00.0 or greater, omit this step. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-584", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGet the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.\r\n\r\n\r\n\r\nInput Data", "expected": "Device BDF's are listed in iDRAC log."}], "source": ""}
{"case_id": "case-585", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nLaunch the iDRAC GUI, go to Maintenance / System Update and Upload n-1 FW DUP for the PCIe SSD. Once you get success for the download, go ahead and select the \"Install\" button.\r\n\r\nNOTE: If you see Install and Reboot, Install Next Reboot buttons, it is an issue.\r\n\r\nPop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.\r\n\r\nInput Data", "expected": "Verified that the DUP package uploads successfully and both the job passed with no issues."}], "source": ""}
{"case_id": "case-586", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.\r\n   1. SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version n-1).\r\n   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n-1>).\r\n   3. PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version: <version n>, Current version: <version n-1>).\r\n\r\n\r\nInput Data", "expected": "User verified LC logs reported the correct entry for each PCIe SSD."}], "source": ""}
{"case_id": "case-587", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nGo to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to OS and verify that new FW version is reported on all drives you updated.\r\n\r\nInput Data", "expected": "User verified storage inventory reported the correct FW version for all drives.\r\n\r\nUser verified FW inventory reported the correct FW version for all drives.\r\n\r\nUser verified that OS reported the correct FW version for all drives."}], "source": ""}
{"case_id": "case-588", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-7 after performing hotplug operation to PCIe SSDs.\r\n\r\nInput Data", "expected": "Firmware is updated successfully after hotplug."}], "source": ""}
{"case_id": "TC-81104", "name": "PCIe SSD: Firmware Download with Controller Reset (Linux Only)", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported operating systems with at least one PCIe SSD. \r\n\r\nInput Data", "expected": "PCIe SSD is discovered and link is fully trained to maximum width and speed."}, {"step": "1", "description": "Description\r\nBoot to a supported operating systems with at least one PCIe SSD. \r\n\r\nInput Data", "expected": "PCIe SSD is discovered and link is fully trained to maximum width and speed."}, {"step": "2", "description": "Description\n\n Write a script to: \n\n1.     Issue FW download to the PCIe SSD. You can get the binary or tar file of the FW by extracting its DUP.\n\nUsing nvmecli: nvme fw-download /dev/nvme0n1 -f FW.bin\n\nUsing framework: python3 NVMeIOCTL.py -fd B:D.F <path to FW file>\n\n2.     Issue Controller Reset to the PCIe SSD. \n\nUsing nvmecli: nvme reset /dev/nvme0n1\n\nUsing framework: python3 NVMeIOCTL.py -rc B:D.F\n\n3.     Unload NVMe Driver. In linux, it can be done by issuing modprobe -r nvme. In windows, use framework.\n\n4.     Load NVMe Driver. In Linux, it can be done by issuing modprobe nvme. In windows, use framework.\n\nfor 12 hours. After each loop, make sure device is discovered. If it doesn't, exit the script with a a failure.\n\n\n\n\nInput Data", "expected": "The script runs for 12 hours successfully."}, {"step": "1", "description": "Description\r\nBoot to a supported operating systems with at least one PCIe SSD. \r\n\r\nInput Data", "expected": "PCIe SSD is discovered and link is fully trained to maximum width and speed."}], "source": ""}
{"case_id": "case-590", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\n\n Write a script to: \n\n1.     Issue FW download to the PCIe SSD. You can get the binary or tar file of the FW by extracting its DUP.\n\nUsing nvmecli: nvme fw-download /dev/nvme0n1 -f FW.bin\n\nUsing framework: python3 NVMeIOCTL.py -fd B:D.F <path to FW file>\n\n2.     Issue Controller Reset to the PCIe SSD. \n\nUsing nvmecli: nvme reset /dev/nvme0n1\n\nUsing framework: python3 NVMeIOCTL.py -rc B:D.F\n\n3.     Unload NVMe Driver. In linux, it can be done by issuing modprobe -r nvme. In windows, use framework.\n\n4.     Load NVMe Driver. In Linux, it can be done by issuing modprobe nvme. In windows, use framework.\n\nfor 12 hours. After each loop, make sure device is discovered. If it doesn't, exit the script with a a failure.\n\n\n\n\nInput Data", "expected": "The script runs for 12 hours successfully."}], "source": ""}
{"case_id": "TC-82712", "name": "PCIe SSD : Persistent Event Log-  Thermal Excursion event logging check", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}, {"step": "1", "description": "Description\r\nBoot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). \r\n\r\nInput Data", "expected": "The device boots without any errors."}], "source": ""}
{"case_id": "case-592", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\n NSID = 0xffffffff\r\nLID= 0x0d\r\nsubpage =0x0\r\nnum of dwords = 0x7f\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-593", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nCheck if the Thermal event is supported by reading the NVMe header section of the PEL log.\n\n\n\n\n\nInput Data", "expected": "The device supports the event and if the device doesn't support the event then this test case is N/A.\r\nCheck with the device lead for the same."}], "source": ""}
{"case_id": "case-594", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nThe device composite temperature is allowed to cross WCTEMP.\nUse any applicable method to achieve this.\n\n\nInput Data", "expected": "The thermal excursion get's logged and all the fields correctly displayed."}], "source": ""}
{"case_id": "TC-85464", "name": "PCIe SSD: TCG Opal - Activate Locking SP and changing admin PIN  (Linux Only)", "status": "Active", "type": "Manual", "description": "/*must do this on new drive or after revert:  enables OPAL Admin1 authority with MSID credentials */\r\n/* note that both SID and Admin1 authorities have MSID credentials after activate.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to a linux system with supported TCG Opal drive \r\n\r\nInput Data", "expected": "The system boots and drive is visible to the OS without any errors"}, {"step": "1", "description": "Description\r\nBoot to a linux system with supported TCG Opal drive \r\n\r\nInput Data", "expected": "The system boots and drive is visible to the OS without any errors"}], "source": ""}
{"case_id": "case-596", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO \r\n\r\n\r\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-597", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a discovery command and make sure the locking is not enabled.\r\nEX- \r\n./sedlib -a q -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The Feature 0x2 shows the drive locking is not enabled"}], "source": ""}
{"case_id": "case-598", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue an activate SP command to enable locking of the device for Admin1 authority\r\nEx- where (MSID_password is the key to enable locking)\r\n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The command completes successfully without any errors."}], "source": ""}
{"case_id": "case-599", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue a level 0 discovery command again to check if locking is enabled. \r\nEx-\r\n./sedlib -a q -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The discovery data now shows locking is enabled. \r\nLocking Enabled: 1"}], "source": ""}
{"case_id": "case-600", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nChange the PIN of the admin to a new PIN and upon successful completion change back to the original \r\n\r\nEx for reference only :\r\n\r\n./sedlib -a cp -w admin1 -o S6X053AJH9T6GLEHJEVD0QCYS8C0N7R9 -P S6X053AJH9T6GLEHJEVD0QCYS8C0N7R8 -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The PIN was changed successfully and then restored back to original key"}], "source": ""}
{"case_id": "TC-85634", "name": "PCIe SSD: Delete original NameSpace and recreate an identical NameSpace", "status": "Active", "type": "Manual", "description": "The test case checks the device for Namespace management support", "precondition": "", "steps": [{"step": "1", "description": "Boot to the supported OS with device supporting Namespace management", "expected": "The devices shows up in OS and no errors  were reported in SMART and OS logs"}, {"step": "1", "description": "Boot to the supported OS with device supporting Namespace management", "expected": "The devices shows up in OS and no errors  were reported in SMART and OS logs"}, {"step": "2", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size.\r\n\r\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The command completes successfully and the value is saved"}, {"step": "3", "description": "Detach the current single namespace.\r\nEx- python3 NVMeIOCTLCLI.py -dtns <bdf>\r\n\r\nReset the controller (do this since not all drives support dynamic namespace change reporting)\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "Both commands are successful"}, {"step": "4", "description": "Delete the current single namespace \r\npython3 NVMeIOCTLCLI.py -dlns <bdf>", "expected": "The command is successful and the block device is gone.\r\n\r\nEx - lsblk no longer shows the drive"}, {"step": "5", "description": "Create a new namespace of the same size as noted in Step 2\r\nEx- python3 NVMeIOCTLCLI.py -crns <bdf>\r\n\r\nAttach the newly created namespace\r\nEx- python3 NVMeIOCTLCLI.py -atns <bdf>\r\n\r\nReset to controller (do this since not all drives support dynamic namespace change reporting)\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "All commands were successful and the drive block device is now enumerated\r\n\r\n\r\nEx - lsblk now shows a new drive"}, {"step": "6", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size\r\n\r\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The Namespace Size has the same value as in step 2"}, {"step": "1", "description": "Boot to the supported OS with device supporting Namespace management", "expected": "The devices shows up in OS and no errors  were reported in SMART and OS logs"}], "source": ""}
{"case_id": "case-602", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size.\n\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The command completes successfully and the value is saved"}], "source": ""}
{"case_id": "case-603", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Detach the current single namespace.\nEx- python3 NVMeIOCTLCLI.py -dtns <bdf>\n\nReset the controller (do this since not all drives support dynamic namespace change reporting)\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "Both commands are successful"}], "source": ""}
{"case_id": "case-604", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Delete the current single namespace \r\npython3 NVMeIOCTLCLI.py -dlns <bdf>", "expected": "The command is successful and the block device is gone.\r\n\r\nEx - lsblk no longer shows the drive"}], "source": ""}
{"case_id": "case-605", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Create a new namespace of the same size as noted in Step 2\r\nEx- python3 NVMeIOCTLCLI.py -crns <bdf>\r\n\r\nAttach the newly created namespace\r\nEx- python3 NVMeIOCTLCLI.py -atns <bdf>\r\n\r\nReset to controller (do this since not all drives support dynamic namespace change reporting)\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "All commands were successful and the drive block device is now enumerated\r\n\r\n\r\nEx - lsblk now shows a new drive"}], "source": ""}
{"case_id": "case-606", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size\r\n\r\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The Namespace Size has the same value as in step 2"}], "source": ""}
{"case_id": "TC-87469", "name": "PCIe SSD: NVMe shutdown notification across D3hot transition (Windows Only)", "status": "Active", "type": "Manual", "description": "Verify PCIe SSD transitions out of D3hot correctly.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-608", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-609", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD D3hot transition.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-610", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart capturing the PCIe trace. Power on the system and put the PCIe SSD in D3hot. Stop PCIe trace capture.\r\n\r\nInput Data", "expected": "PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation\r\n\r\nPCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "case-611", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStart capturing the PCIe trace. Transition the PCIe SSD out of D3hot. Stop the PCIe trace capture.\r\n\r\nInput Data", "expected": "Verify the PCIe SSD does not reset when transitioning out of D3hot (PMCSR No_Soft_Reset = 1)"}], "source": ""}
{"case_id": "TC-87655", "name": "PCIe SSD: TCG Opal - Revert SP to restore the drive state (Linux Only)", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to Linux OS with a TCG Opal enabled device \r\n\r\nInput Data", "expected": "The OS boots without any errors and device is visible to OS.\r\nMake sure this test case is run after device is fully configured and locked"}, {"step": "1", "description": "Description\r\nBoot to Linux OS with a TCG Opal enabled device \r\n\r\nInput Data", "expected": "The OS boots without any errors and device is visible to OS.\r\nMake sure this test case is run after device is fully configured and locked"}], "source": ""}
{"case_id": "case-613", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSet SID credentials which can be used to revert the device state . \r\nTry to put same MSID as new key to avoid losing key\r\nEX-\r\n./sedlib -a cp -w sid -o MSID_password -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The SID key is set without any issues"}], "source": ""}
{"case_id": "case-614", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDo a device discovery and make sure device is locked, if not already locked.  Also write some data to the device.\r\nnvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1\r\n\r\nIssue a revert SP command using admin as SP and sid as user (admin or psid can also be used)\r\n./sedlib -a rev -S admin -u sid -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The command get's completed successfully"}], "source": ""}
{"case_id": "case-615", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue a discovery command and make sure the device state goes to initial state without SP enabled and unlocked. \r\n./sedlib -a q -d /dev/nvme0n1 -x nvme\r\nAlso check the data written to the device earlier. \r\n\r\n\r\nInput Data", "expected": "The device is restored to it's initial state and all data erased as well.\r\nDo a read of the data written\r\nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\r\n\r\nAll data returned should be 0."}], "source": ""}
{"case_id": "TC-87961", "name": "PCIe SSD: TCG Opal - Re key while running I/O to the device (Linux Only)", "status": "Active", "type": "Manual", "description": "This test case checks locking and unlocking of global range to be used by EKMS solution", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}, {"step": "1", "description": "Description\r\nBoot to the Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}, {"step": "2", "description": "Description\nCheck if device is enabled for locking by doing query. \nEx- ./sedlib -a q -d /dev/nvme0n1 -x nvme\nIf not enabled then activate SP \n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\n\nThe default password is set as MSID and can be retrieved via below command\n./sedlib -a pm -d /dev/nvme0n1 -x nvme\n\n\n\nInput Data", "expected": "The device is activated for locking"}, {"step": "3", "description": "Description\nStart running I/O to the device \nEx- ./diskio -f /dev/nvme0n1 -b 128k -t 10\n\n\n\nInput Data", "expected": "The I/O starts running on the device"}, {"step": "4", "description": "Description\nChange the key of the device \nEx-\n./sedlib -a cp -w admin1 -o MSID_password -P MSID_passwordnew -d /dev/nvme0n1 -x nvme\n\n\n\n\n\nInput Data", "expected": "The pass key get's changed without any issue."}, {"step": "5", "description": "Description\r\nCheck the status of I/O running from step 3\r\n\r\nInput Data", "expected": "The I/O continues to run uninterrupted."}, {"step": "6", "description": "Description\r\nChange the key of the device to default passkey\r\nEx-\r\n./sedlib -a cp -w admin1 -o MSID_passwordnew -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The key is changed back to default key i.e MSID"}, {"step": "1", "description": "Description\r\nBoot to the Linux OS with TCG Opal enabled device\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}], "source": ""}
{"case_id": "case-617", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck if device is enabled for locking by doing query. \r\nEx- ./sedlib -a q -d /dev/nvme0n1 -x nvme\r\nIf not enabled then activate SP \r\n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\nThe default password is set as MSID and can be retrieved via below command\r\n./sedlib -a pm -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\nInput Data", "expected": "The device is activated for locking"}], "source": ""}
{"case_id": "case-618", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O to the device \r\nEx- ./diskio -f /dev/nvme0n1 -b 128k -t 10\r\n\r\n\r\n\r\nInput Data", "expected": "The I/O starts running on the device"}], "source": ""}
{"case_id": "case-619", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nChange the key of the device \r\nEx-\r\n./sedlib -a cp -w admin1 -o MSID_password -P MSID_passwordnew -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The pass key get's changed without any issue."}], "source": ""}
{"case_id": "case-620", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck the status of I/O running from step 3\r\n\r\nInput Data", "expected": "The I/O continues to run uninterrupted."}], "source": ""}
{"case_id": "case-621", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nChange the key of the device to default passkey\r\nEx-\r\n./sedlib -a cp -w admin1 -o MSID_passwordnew -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The key is changed back to default key i.e MSID"}], "source": ""}
{"case_id": "TC-89513", "name": "PCIe SSD: Firmware activation without reset", "status": "Active", "type": "Manual", "description": "NVMe devices must support Firmware Activation without Reset. Requiring a reset under any condition should be\navoided if possible", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall NVMe device in the system and boot to the supported OS \r\n\r\nInput Data", "expected": "The system boots up without any relevant error in OS logs"}, {"step": "1", "description": "Description\r\nInstall NVMe device in the system and boot to the supported OS \r\n\r\nInput Data", "expected": "The system boots up without any relevant error in OS logs"}, {"step": "2", "description": "Description\r\nIssue identify controller command to the device and check if firmware activation without reset is supported and also note down current firmware version. nvme-cli(linux only) or NVMeIOCTL (Automation Framework) can be used. \r\n\r\nInput Data", "expected": "The drive reports that firmware activation without reset is supported"}, {"step": "3", "description": "Description\r\nIssue firmware download command with right payload/binary path. \r\nSame tool as above can be used. \r\n\r\n\r\nInput Data", "expected": "The command completes successfully without any failure."}, {"step": "4", "description": "Description\r\nIssue firmware activation command with slot to be activated and firmware commit action to be 3. \r\n\r\nInput Data", "expected": "Command completes successfully without any errors"}, {"step": "5", "description": "Description\r\nIssue identify controller and check firmware revision \r\n\r\nInput Data", "expected": "The firmware provided for the flash was activated."}, {"step": "1", "description": "Description\r\nInstall NVMe device in the system and boot to the supported OS \r\n\r\nInput Data", "expected": "The system boots up without any relevant error in OS logs"}], "source": ""}
{"case_id": "case-623", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue identify controller command to the device and check if firmware activation without reset is supported and also note down current firmware version. nvme-cli(linux only) or NVMeIOCTL (Automation Framework) can be used. \r\n\r\nInput Data", "expected": "The drive reports that firmware activation without reset is supported"}], "source": ""}
{"case_id": "case-624", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue firmware download command with right payload/binary path. \r\nSame tool as above can be used. \r\n\r\n\r\nInput Data", "expected": "The command completes successfully without any failure."}], "source": ""}
{"case_id": "case-625", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue firmware activation command with slot to be activated and firmware commit action to be 3. \r\n\r\nInput Data", "expected": "Command completes successfully without any errors"}], "source": ""}
{"case_id": "case-626", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue identify controller and check firmware revision \r\n\r\nInput Data", "expected": "The firmware provided for the flash was activated."}], "source": ""}
{"case_id": "TC-90540", "name": "PCIe SSD: Hot insert: Completion Time out value from boot on hot insertion", "status": "Active", "type": "Manual", "description": "Verify that the CTO value from boot, on hot insertion as per specification.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS with a drive installed in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-628", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPerform the following steps:\r\n\r\n- Dump the PCI registers of the endpoint device\r\n\r\n- Check the range of completion time out value under Device Control 2 register (bit location 0-3)\r\n\r\n- Surprise remove the device\r\n\r\nInput Data", "expected": "Check if the value is programmed as per the spec, which states a value of 0x6 (65ms - 210ms)"}], "source": ""}
{"case_id": "case-629", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert the device and dump the PCI register and check the time out value again.\r\n\r\nInput Data", "expected": "The value is reprogrammed on hot insertion as per the spec, 0x6 (65ms - 210ms)"}], "source": ""}
{"case_id": "TC-93915", "name": "PCIe SSD: TCG Opal NVMe MI- CSTS.RDY check for 60sec delay when locked", "status": "Active", "type": "Manual", "description": "This test case checks locking and unlocking of global range to be used by EKMS solution \nThe test firmware is placed here. \n\\\\S3bnsx01nas05.amer.dell.com\\RAIDSERVER\\NVMe\\NVME_PCIeSSD\\NVMe_SEKM\\iDRACTCGOpaltestfirmware", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run on a drive where either security was never enabled or has gone through revert operation prior.\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}, {"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run on a drive where either security was never enabled or has gone through revert operation prior.\r\n\r\nInput Data", "expected": "The OS boots without any issue and device is accessible."}], "source": ""}
{"case_id": "case-631", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCheck CAP.TO value available part of MMIO space. Any tool can be used.\n\nFor example:\npython3 NVMeIOCLTCLI.py -mr bdf\n\nInput Data\nsudo", "expected": "Note down the CAP.TO value before enabling security."}], "source": ""}
{"case_id": "case-632", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nSSH into the iDRAC supporting side band tool for TCG Support into rootshell\n\nIf performing tests first time after iDRAC reboot run following 2 commands\nsetenforce 0\ntestlibsednvme\n\n\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-633", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nActivate and Lock the device for the global range (whole device) using user as admin via side band\n\ncontroller id should be determined from identify controller response\nThe user is Admin and the value passed should be 1\ntestlibsednvme Dellenablesecurity <eid> <controller id> <new key> <key length> 1\n\n testlibsednvme lock <eid> <controllerid> <key> <keylength> <user>\n\nFor example :\ntestlibsednvme lock 6 0 Dell123456 10 1\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "The device is locked and command completes successfully. \nRun query command to confirm. \n\nFor example \ntestlibsednvme query 6 0\n\nOutput:\nlocked = 1\nlocking supported = 1\nlocking enabled = 1"}], "source": ""}
{"case_id": "case-634", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove the drive and hot insert it back. \r\nCheck OS log \r\n\r\n\r\nInput Data", "expected": "Note down the time at which hot plug interrupt was generated and when the controller becomes ready (OS starts polling for queues and block layer)\nIf this couldn't be determined via OS logs please collect PCIe trace to verify CSTS.RDY turning 1 after ~60 sec from the time CC.EN =1"}], "source": ""}
{"case_id": "case-635", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nCheck CAP.TO value available part of MMIO space. Any tool can be used. \r\n\r\nFor example:\r\npython3 NVMeIOCLTCLI.py -mr bdf\r\n\r\n\r\nInput Data", "expected": "The CAP.TO value is set to 60 sec or greater \r\n\r\nNote :\r\nCAP.TO field have value in units of 500ms. So, make appropriate conversion."}], "source": ""}
{"case_id": "case-636", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\nIssue a revert operation to bring the device to default state. \n\ntestlibsednvme revert <eid> <controllerid> <key> <key_length> 0\n\n\nInput Data", "expected": "Issue query to make sure security is disabled."}], "source": ""}
{"case_id": "case-637", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\nActivate and lock device in band . \n\nFor example \n./sedlib -a asp -P <MSID> -d /dev/nvme0n1 -x nvme\n\n./sedlib -a l -B 0 -P MSID -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "Issue query to determine if device is locked. \n./sedlib -a q -d /dev/nvme0n1 -x nvme"}], "source": ""}
{"case_id": "case-638", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nHot remove the drive and re insert.\r\nCheck the OS logs or verify via other methods if device has been gone ready i.e CSTS.RDY bit set to 1 in less than 60 sec. \r\n\r\n\r\nInput Data", "expected": "The CSTS.RDY got set to 1 in less than or equal to 56 sec"}], "source": ""}
{"case_id": "case-639", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nCheck CAP.TO value available part of MMIO space. Any tool can be used.\r\n\r\nFor example:\r\npython3 NVMeIOCLTCLI.py -mr bdf\r\n\r\nInput Data", "expected": "The CAP.TO value is less than or equal to 56 sec.\r\n\r\nNote :\r\nCAP.TO field have value in units of 500ms. So, make appropriate conversion."}], "source": ""}
{"case_id": "TC-94994", "name": "Sudden Power Loss during Crypto Erase with FPI check", "status": "Active", "type": "Manual", "description": "The test case checks the update of Format Progress Indicator when a SPO (Sudden Power Loss) event happen while crypto erase is in progress.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with at least 2 NVMe SSD installed \r\n\r\nInput Data", "expected": "System boots up without any errors and all devices are discovered."}, {"step": "1", "description": "Description\r\nBoot to the OS with at least 2 NVMe SSD installed \r\n\r\nInput Data", "expected": "System boots up without any errors and all devices are discovered."}], "source": ""}
{"case_id": "case-641", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a partition on a drive and write at least 30 GB data to it \r\n\r\nInput Data", "expected": "Partition is created and data is successfully written"}], "source": ""}
{"case_id": "case-642", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running Crypto Erase in the back ground \r\n\r\nInput Data", "expected": "Crypto Erases are successfully completing"}], "source": ""}
{"case_id": "case-643", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPerform Sudden Power Loss for drive (DC cycle through IDRAC does) \r\n\r\nInput Data", "expected": "drive goes through power cycle"}], "source": ""}
{"case_id": "case-644", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck FPI (Format Progress Indicator) by issuing Identify Namespace Command\r\n\r\nInput Data", "expected": "The value of FPI is zero if the field is supported by the device."}], "source": ""}
{"case_id": "TC-96322", "name": "PCIe SSD: TCG Opal NVMe MI - Enable/Disable Security on NVMe SEDs Stress testing", "status": "Active", "type": "Manual", "description": "The test case enables security on the device. It encompases several operations in the process like read MSID, activate SP, write data store, rekey", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation\r\n\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}, {"step": "1", "description": "Description\r\nBoot to an operating system and make sure all devices are visible in the OS\r\n\r\nNote: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation\r\n\r\n\r\nInput Data", "expected": "The system boot successfully and device discovered by OS. \r\nPerform some basic IO to make sure device is functional."}], "source": ""}
{"case_id": "case-646", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-647", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\nIssue following command to query the drive of it's state\r\n\r\n\r\ncontroller id should be determined from identify controller response in OS\r\ntestlibsednvme query\r\n\r\n\r\nFor example:\r\n\r\ntestlibsedclient query 6 0\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Locking enabled is turned off \r\nFor example:\r\nlocking enabled = [0]\r\n\r\nIf the locking is enabled make sure to run revert test case prior to running this."}], "source": ""}
{"case_id": "case-648", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nEnable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. \r\nProvide user as Admin and it should be 1\r\n\r\ntestlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>\r\nAlso make sure function return code is 0\r\n\r\nFor example \r\ntestlibsednvme DellEnableSecurity 6 0 Dell123456 10 1\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. \r\n\r\nFor example \r\nlocking supported = [@1]\r\nlocking enabled = [@1]\r\ndatastore size = [10485760]\r\ndatastore flag = [@2]\r\nold_keyId = [MSID KEY]\r\ncurrent_keyId = [Dell123456]"}], "source": ""}
{"case_id": "case-649", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nWait for 1 minute and Disable Security by issuing Revert \r\nUse the same key to issue revert which was used for enabling security \r\nGo to step 4 and repeat for at least 20 times\r\n\r\n\r\nInput Data", "expected": "Operations are successful in all steps."}], "source": ""}
{"case_id": "TC-101686", "name": "PCIe SSD: Power State Control via NVMe-MI w/ I/O Stress", "status": "Active", "type": "Automated", "description": "The test case is used to validate that NVMe drives can successfully transition (via NVMe-MI) to and from all supported power states while continuing to service I/O.", "precondition": "", "steps": [{"step": "1", "description": "Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the \"Number of Power States Supported\" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.", "expected": "The drives are installed and recognized by the host OS."}, {"step": "1", "description": "Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the \"Number of Power States Supported\" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.", "expected": "The drives are installed and recognized by the host OS."}], "source": ""}
{"case_id": "case-651", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Start I/O stress to the NVMe drives which support power states.", "expected": "I/O is being processed successfully"}], "source": ""}
{"case_id": "case-652", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Lower the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-653", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-654", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Repeat steps 3 and 4 until no power states are remaining.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 3 and 4"}], "source": ""}
{"case_id": "case-655", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Raise the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-656", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-657", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Repeat steps 6 and 7 until the drive is back at the default power state 0.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 6 and 7"}], "source": ""}
{"case_id": "case-658", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Stop the I/O stress to the NVMe drives", "expected": "The I/O stops successfully"}], "source": ""}
{"case_id": "TC-103781", "name": "PCIe SSD: Power State Control via NVMe w/ I/O Stress", "status": "Active", "type": "Automated", "description": "The test case is used to validate that NVMe drives can successfully transition (via NVMe) to and from all supported power states while continuing to service I/O.", "precondition": "", "steps": [{"step": "1", "description": "Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the \"Number of Power States Supported\" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.", "expected": "The drives are installed and recognized by the host OS."}, {"step": "1", "description": "Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the \"Number of Power States Supported\" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.", "expected": "The drives are installed and recognized by the host OS."}], "source": ""}
{"case_id": "case-660", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Start I/O stress to the NVMe drives which support power states.", "expected": "I/O is being processed successfully"}], "source": ""}
{"case_id": "case-661", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Lower the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-662", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-663", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Repeat steps 3 and 4 until no power states are remaining.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 3 and 4"}], "source": ""}
{"case_id": "case-664", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Raise the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-665", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-666", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Repeat steps 6 and 7 until the drive is back at the default power state 0.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 6 and 7"}], "source": ""}
{"case_id": "case-667", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Stop the I/O stress to the NVMe drives", "expected": "The I/O stops successfully"}], "source": ""}
{"case_id": "TC-304", "name": "PCIe SSD ESXi DPC: Error Injection at endpoint & it's upstream port  with EDR notification/recovery check (ESXi Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging\r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging\r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-669", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-670", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-671", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInject error on up stream port . \r\nThis can be done in many ways. \r\nFor example \r\nChange MPS of up stream  port that is less than endpoint Max Payload Size\r\nRun some I/O to the device\r\n\r\n\r\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "TC-784", "name": "PCIe SSD - UEFI Driver - ePSA UEFI Diagnostics", "status": "Active", "type": "Manual", "description": "To test that the NVM_EXPRESS_PASSTHRU_PROTOCOL has been implemented by the UEFI driver", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "2", "description": "Description\nMake sure to install the latest DUP for the ePSA UEFI Diagnostics utility\n\nInput Data", "expected": "DUP installs successfully"}, {"step": "3", "description": "Description\r\nBoot into the \"F11 (Boot Manager)->System Utilties->Launch Diagnostics\"\r\n\r\nInput Data", "expected": "The ePSA utility opens"}, {"step": "4", "description": "Description\r\nClick the \"Configuration\" tab In the \"[PCIe]\" section, make sure that you see the NVMe device, and the PCIe Bridge Card (if there are 2.5\" PCIe SSD devices in the system) In the \"[Storage]\" section, find the hard drive(s) that have type \"NVMe\"\r\n\r\nInput Data", "expected": "The tab is present\r\n\r\n\r\nThe PCIe Bridge Card (if present) and all NVMe PCIe SSDs are listed and have the correct, \"Slot Number\" \"Vendor\" \"Device\" \"SubVendor\" and \"SubDevice\" IDs.\r\n\r\n\r\nAll devices are displayed as unique hard drives with the correct information, \"OEM\" \"product\" \"revision\" \"S/N\" \"type\" \"size\" \"CTRL\""}, {"step": "5", "description": "Description\r\nDouble-click each of the NVMe PCIe SSD hard drive numbers (identified in step 4)\r\n\r\nInput Data", "expected": "The tests run successfully and report the results to the \"Results\" tab\r\n\r\nIn the \"Results\" tab, if the device supports the NVMe Device Self-test command, then make sure that the results indicate that a DST Short or Long was ran in place of simply the SMART data"}, {"step": "1", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-673", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake sure to install the latest DUP for the ePSA UEFI Diagnostics utility\r\n\r\nInput Data", "expected": "DUP installs successfully"}], "source": ""}
{"case_id": "case-674", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBoot into the \"F11 (Boot Manager)->System Utilties->Launch Diagnostics\"\r\n\r\nInput Data", "expected": "The ePSA utility opens"}], "source": ""}
{"case_id": "case-675", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nClick the \"Configuration\" tab In the \"[PCIe]\" section, make sure that you see the NVMe device, and the PCIe Bridge Card (if there are 2.5\" PCIe SSD devices in the system) In the \"[Storage]\" section, find the hard drive(s) that have type \"NVMe\"\r\n\r\nInput Data", "expected": "The tab is present\r\n\r\n\r\nThe PCIe Bridge Card (if present) and all NVMe PCIe SSDs are listed and have the correct, \"Slot Number\" \"Vendor\" \"Device\" \"SubVendor\" and \"SubDevice\" IDs.\r\n\r\n\r\nAll devices are displayed as unique hard drives with the correct information, \"OEM\" \"product\" \"revision\" \"S/N\" \"type\" \"size\" \"CTRL\""}], "source": ""}
{"case_id": "case-676", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDouble-click each of the NVMe PCIe SSD hard drive numbers (identified in step 4)\r\n\r\nInput Data", "expected": "The tests run successfully and report the results to the \"Results\" tab\r\n\r\nIn the \"Results\" tab, if the device supports the NVMe Device Self-test command, then make sure that the results indicate that a DST Short or Long was ran in place of simply the SMART data"}], "source": ""}
{"case_id": "TC-1076", "name": "PCIe SSD DPC: DPC Enablement Check", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-678", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nGet all parent BDFs to the NVMe drives (regardless if the slots are populated).\n\nIf the system has a PCIe switch in it, then get then get the root port above the switch, switch upstream port, and all switch downstream ports.\n\n\nInput Data", "expected": "All parent BDFs are obtained"}], "source": ""}
{"case_id": "case-679", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDump PCIe config. space for each port that was found in the previous step\r\n\r\nInput Data", "expected": "If the OS and Hardware Supports DPC (EDR), then the \"DPC Control Register's\" DPC Trigger Enable should be set to 0x2.\r\n\r\nIf the OS or Hardware do not Support DPC (EDR), then the DPC capability will not be found or, the \"DPC Control Register's\" DPC Trigger Enable should be set to 0x0."}], "source": ""}
{"case_id": "TC-1610", "name": "PCIe SSD DPC: Hot removal/insertion after single error Injection on same endpoint  (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-681", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-682", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-683", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the drive \r\n\r\nInput Data", "expected": "The device is removed and not visible both at PCI and NVMe level"}], "source": ""}
{"case_id": "case-684", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert the drive back in the same slot\r\n\r\nInput Data", "expected": "device is enumerated properly"}], "source": ""}
{"case_id": "TC-3128", "name": "PCIe SSD ESXi DPC: Hot removal/insertion after  error Injection on different endpoints  (ESXi Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging\r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \n\nRun below command to enable ACPI logging\nesxcli system settings kernel set -s acpiDbgLevel -v 2\n\n(Could be verified by checking DPC control register of parent port above endpoint)\n\n\n\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-686", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-687", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-688", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat the steps 2-3 on a different end point\r\n\r\n\r\nInput Data", "expected": "The devices are properly enumerated"}], "source": ""}
{"case_id": "case-689", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove both the drives on which error was injected & recovered\r\n\r\n\r\nInput Data", "expected": "The devices are removed and not visible both at PCIe and NVMe level"}], "source": ""}
{"case_id": "case-690", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nHot insert the drives back in the same slots\r\n\r\n\r\nInput Data", "expected": "The devices are enumerated properly both at PCIe level and NVMe block level"}], "source": ""}
{"case_id": "TC-3362", "name": "PCIe_SSD - Physical Slot Number parameter in Slot Capabilities register of host", "status": "Active", "type": "Manual", "description": "Verify the 'Physical Slot Number' parameter in the Slot Capabilities register of the root or downstream-facing switch port is correctly programmed for each NVMe capable slot in the platform:  \r\n\r\n31:27 - Zeroes\r\n\r\n26 - Unique Bit Always Set to 1\r\n\r\n25:24 - Bay ID\r\n\r\n23:19 - Slot ID\r\n\r\nNote this applies to SFF slots only; AIC slots should be omitted for this TC.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nFor each NVMe-capable SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.\r\n\r\nE.g. In Linux, as root issue:\r\n\r\nlspci -xxx -s c0:03.3\r\nor\r\nlspci -vvv -s c0:03.3 (for decoded output. Slot number is listed as Slot # under the SltCap register)\r\n\r\nwhere 'c0:03.3' is the bdf of the root port attached to an NVMe device.\r\n\r\nIn Windows, the 'RW Everything' tool can be used to dump config space data.\r\n\r\n\r\nInput Data", "expected": "The config space read is successful."}, {"step": "1", "description": "Description\r\nFor each NVMe-capable SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.\r\n\r\nE.g. In Linux, as root issue:\r\n\r\nlspci -xxx -s c0:03.3\r\nor\r\nlspci -vvv -s c0:03.3 (for decoded output. Slot number is listed as Slot # under the SltCap register)\r\n\r\nwhere 'c0:03.3' is the bdf of the root port attached to an NVMe device.\r\n\r\nIn Windows, the 'RW Everything' tool can be used to dump config space data.\r\n\r\n\r\nInput Data", "expected": "The config space read is successful."}], "source": ""}
{"case_id": "case-692", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCompare the Physical Slot Number (bits 31:19) in the Slot Capabilities register:\r\n\r\n31:27 - Zeroes\r\n\r\n26 - Unique Bit Always Set to 1\r\n\r\n25:24 - Bay ID\r\n\r\n23:19 - Slot ID\r\n\r\n\r\nto the expected value for each NVMe-capable SFF slot.\r\n\r\n\r\nInput Data", "expected": "The Physical Slot Number info matches the expectation for each NVMe capable SFF slot in the system. See the attached file 'example_decode.txt' for an in-depth decode of the Slot Capabilities register in the raw hex config space data.\r\n\r\nThe Bay / Slot ID may be found from the Storage::Physical Disks menu in the iDRAC GUI; this info should match the decode from the Slot Capabilities register."}], "source": ""}
{"case_id": "TC-3397", "name": "PCIe SSD: HII Telemetry Log", "status": "Active", "type": "Manual", "description": "Verify HII Debug Log page displays the correct properties. Verify user is able to save the NVMe Telemetry log for all drives in the system that support that log page.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)\r\n\r\nIf possible, install a device that does not support the Telemetry log page.\r\n\r\n\r\nInput Data", "expected": "System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe).\r\n\r\nIf there's a drive that does not support Telemetry, then the option to perform a Telemetry Log capture should not exist in the HII."}, {"step": "1", "description": "Description\r\nInstall at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)\r\n\r\nIf possible, install a device that does not support the Telemetry log page.\r\n\r\n\r\nInput Data", "expected": "System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe).\n\nIf there's a drive that does not support Telemetry, then the option to perform a Telemetry Log capture should not exist in the HII."}], "source": ""}
{"case_id": "case-694", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Telemetry Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).\r\n\r\nInput Data", "expected": "1. Save Debug Log page will show the following options/fields:\r\n\r\nSelect File System target (header)\r\n\r\nSelect File System (link)\r\n\r\n\r\nSelect Directory (header)\r\n\r\nDirectory list selection\r\n\r\n\r\nExport Log File path (header)\r\n\r\nFile path\r\n\r\n\r\nExport Log (link)\r\n\r\n\r\n\r\n\r\n2. All options/fields display corresponding help text at the bottom of the screen."}], "source": ""}
{"case_id": "case-695", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSelect a file system target (ie. if there is more than one USB key inserted)\r\n\r\nInput Data", "expected": "1. All attached file systems are listed under \"Select File System Target\". The default (root) directory should be selected by default.\r\n\r\n2. \"Select File System Target\" (link) can be used to change currently selected File System."}], "source": ""}
{"case_id": "case-696", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect a directory.\r\n\r\nInput Data", "expected": "1. All attached directories are listed under \"Select Directory\". The default (root) directory should be selected by default.\r\n\r\n2. User can choose appropriate directory to save the file to under \"Select Directory\".\r\n\r\n3. \"Select Directory\" (link) can be used to change currently selected Directory."}], "source": ""}
{"case_id": "case-697", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect Telemetry Log.\r\n\r\nInput Data", "expected": "Message displayed is \"Log saved successfully. PCIeSSD_(date time string).log\".\r\n\r\n\r\nFor NVMe PCIe SSD log, User can choose the any filename with extension .log"}], "source": ""}
{"case_id": "case-698", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRetrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly.\r\n\r\nInput Data", "expected": "The file size is non-zero"}], "source": ""}
{"case_id": "case-699", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "TC-4695", "name": "PCIe SSD: FMP protocol", "status": "Active", "type": "Manual", "description": "Verify user can update firmware on a PCIe SSD in UEFI.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall one PCIe SSD in the system and boot into UEFI shell.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall one PCIe SSD in the system and boot into UEFI shell.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-701", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to the directory where UpdateTest.efi is saved, and run \"UpdateTest.efi\" to get a list of controller handles. (UpdateTest.efi: download from Agile ENG0011622)\r\n\r\nInput Data", "expected": "PCIe SSD is listed as a controller that supports UEFI update. The display name is \"Dell [NVMe] PCIe SSD Controller\"."}], "source": ""}
{"case_id": "case-702", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nExecute getImageInfo(). \"UpdateTest.efi CtrlHdl\" where CtrlHdl is the controller handle for a PCIe SSD. Example: Step 2 reported Controller Handle CD for PCIeSSD. You would type \"UpdateTest.efi CD\"\r\n\r\nInput Data", "expected": "Package Version (int): \"0xFFFFFFFE\"\r\n\r\nPackage Version (str): firmware package version running on the PCIeSSD\r\n\r\n\r\nRemaining fields shall report values per Dell IHV and UEFI specs."}], "source": ""}
{"case_id": "case-703", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nExecute SetImage() to upgrade the firmware. Run \"UpdateTest.efi CtrlHdl -f firmware_img\".\r\n\r\nInput Data", "expected": "Firmware starts flashing on the device. Activity LED is blinking on PCIeSSD. Return success."}], "source": ""}
{"case_id": "case-704", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nReboot the system and verify firmware update flashed successfully. Perform some I/O to the device to ensure functionality.\r\n\r\nInput Data", "expected": "Firmware flashed successfully. Device fully functional."}], "source": ""}
{"case_id": "case-705", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nOptional: Repeat step 6 and 7 but flashing to an older version of the firmware.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-706", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nGetImage() and SetPackageInfo() are not required by Dell so vendor may have selectively chosen to not support these.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "TC-7389", "name": "PCIeSSD: Hotplug - Hot Insertion after Unhandled Removal", "status": "Active", "type": "Manual", "description": "The point of this test is to analyze the subsystem behavior when a device is immediately inserted after just have been removed.", "precondition": "-", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}, {"step": "1", "description": "Description\r\nBoot into the OS with at least one hot-pluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "The PCIe SSD is discovered once in the OS"}], "source": ""}
{"case_id": "case-708", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-709", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nImmediately re-insert the PCIe SSD back into the system\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-710", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-8867", "name": "PCIe SSD: Link Disable during I/O Stress", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to make sure that the system does not crash when the link is disabled while I/O is in progress.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nDetermine the parent BDFs of all hot-pluggable NVMe drives in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nDetermine the parent BDFs of all hot-pluggable NVMe drives in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-712", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBegin running I/O stress on all hot-pluggable NVMe drives\r\n\r\nInput Data", "expected": "The I/O is successful"}], "source": ""}
{"case_id": "case-713", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWhile the I/O is in progress, disable the link to the NVMe drives by writing a '1' to bit 4 of the parent BDF's Link Control Register\r\n\r\nInput Data", "expected": "I/O stops\r\nThe NVMe drive is removed from the system\r\nThe system does not crash"}], "source": ""}
{"case_id": "case-714", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-enable the link by writing a '0' to bit 4 of all parent BDF's Link Control Register\r\n\r\nInput Data", "expected": "The NVMe drives are re-enumerated by the OS"}], "source": ""}
{"case_id": "TC-9604", "name": "PCIe SSD ESXi DPC:  Hot removal/insertion after single error Injection on same endpoint  (ESXi Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \n\nRun below command to enable ACPI logging\nesxcli system settings kernel set -s acpiDbgLevel -v 2\n\n(Could be verified by checking DPC control register of parent port above endpoint)\n\n\n\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging\r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-716", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\n\nHere 196 = bus (in decimal) for the endpoint bdf\n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/vmkernel.log\n\n\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-717", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-718", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove  the drive on which error was injected & recovered\r\n\r\n\r\nInput Data", "expected": "The device is removed and not visible both at PCIe and NVMe level"}], "source": ""}
{"case_id": "case-719", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert the drive back in the same slots\r\n\r\n\r\nInput Data", "expected": "The device is enumerated properly both at PCIe level and NVMe block level"}], "source": ""}
{"case_id": "TC-9694", "name": "PCIe SSD: Inband Drive FRU Validation", "status": "Active", "type": "Manual", "description": "Unit Testing of FRU Objects created for PCIeSSD Card FRU Data.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nPlug in a mixture of form factor and device model NVMe drives and boot to an operating system. Wait 5-10 minutes once in the OS just to make sure the iDRAC is fully initialized.\r\n\r\nInput Data", "expected": "All devices are detected"}, {"step": "1", "description": "Description\r\nPlug in a mixture of form factor and device model NVMe drives and boot to an operating system. Wait 5-10 minutes once in the OS just to make sure the iDRAC is fully initialized.\r\n\r\nInput Data", "expected": "All devices are detected"}], "source": ""}
{"case_id": "case-721", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nUsing ipmitool (or GetPCIeSSDFRU.py automation script), read the contents of the FRU for each NVMe device using the following commands:\r\n\r\nU.2 devices (NOTE for Windows that, \"-I wmi\" will have to be added before the -U):\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x00 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x20 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x40 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x60 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x80 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xA0 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xC0 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xE0 0x00 0x20\r\n\r\nAIC devices (NOTE for Windows that, \"-I wmi\" will have to be added before the -U):\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x00 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x20 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x40 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x60 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x80 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xA0 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xC0 0x00 0x20\r\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xE0 0x00 0x20\r\n\r\n\r\nInput Data", "expected": "All ipmi commands successfully pass and the FRU contents are saved for each device"}], "source": ""}
{"case_id": "case-722", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUsing libi2ctest (or GetPCIeSSDFRU.py automation script), read the FRU for each NVMe device in the system using the following commands:\r\n\r\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\r\n\r\nNOTE if you're not using automation, then the I2C_bus_num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file from the iDRAC filesystem\r\n\r\n\r\nInput Data", "expected": "All libi2ctest commands successfully pass and the FRU data is saved"}], "source": ""}
{"case_id": "case-723", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCompare the FRU data read from I2C in step 3 with the FRU data read from IPMI for each device\r\n\r\nInput Data", "expected": "There should be no difference"}], "source": ""}
{"case_id": "TC-11407", "name": "PCIe SSD - 14G Hot Insertion PERST# Logic Validation", "status": "Active", "type": "Manual", "description": "This test case will be used to determine the PERST# logic that applies when hot inserting an NVMe device is correctly functioning.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConfirm from the test notes that this test case is applicable to your SUT\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nConfirm from the test notes that this test case is applicable to your SUT\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-725", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the NVME_PRES and PERST# signals to an oscilloscope\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-726", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-727", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of NVME_PRES\r\n\r\nInput Data", "expected": "Trigger enabled"}], "source": ""}
{"case_id": "case-728", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nConfigure the horizontal divisions to be 500ms\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-729", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nConfigure the vertical divisions for both signals to be 1V\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-730", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The trigger occurs\r\n\r\nPrior to the falling edge of NVME_PRES, PERST# was low\r\n500ms after the falling edge of NVME_PRES, PERST# went high"}], "source": ""}
{"case_id": "TC-12242", "name": "PCIeSSD: PCIe - Read Tracking on Bridge with Surprise Removal", "status": "Active", "type": "Manual", "description": "This test case is intended to test the Read Tracking feature of the Dell PCIe Extender Card. In the event of an endpoint device suddenly not being available while a Non-Posted request is still outstanding, then normally a Completion Timeout would be generated. However, with the Read Tracking feature, a response of all Fs should be synthesized by the bridge downstream port, along with a Completer Abort event.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-732", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with a hotpluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-733", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-734", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-735", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-736", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests\r\n\r\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is removed from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-737", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-738", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-739", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-740", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-741", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, a Completer Abort is generated with a Completer ID equal to the endpoint PCIe SSD that was removed\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-742", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-743", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nFrom the PCIe trace, an ERR_FATAL message is generated by the parent of the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-744", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer Changed bit is set"}], "source": ""}
{"case_id": "TC-12564", "name": "PCIe_SSD - Slot Power Limit parameters in Slot Capabilities register of host", "status": "Active", "type": "Manual", "description": "Verify the 'Slot Power Limit Scale' and 'Slot Power Limit Value' parameters in the Slot Capabilities register of the root or downstream-facing switch port is correctly programmed for each NVMe capable slot in the platform: \n\n14:7 = 0xFA\n\n16:15 = 0b01\n\nIf the values are programmed thusly, the power limit of the slot is set to 25 W.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nFor each SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.\r\n\r\nE.g. In Linux, as root issue:\r\n\r\nlspci -xxx -s c0:03.3\r\n\r\nwhere 'c0:03.3' is the bdf of the root port attached to an NVMe device.\r\n\r\nIn Windows, the 'RW Everything' tool can be used to dump config space data.\r\n\r\n\r\nInput Data", "expected": "The config space read is successful."}, {"step": "1", "description": "Description\r\nFor each SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.\r\n\r\nE.g. In Linux, as root issue:\r\n\r\nlspci -xxx -s c0:03.3\r\n\r\nwhere 'c0:03.3' is the bdf of the root port attached to an NVMe device.\r\n\r\nIn Windows, the 'RW Everything' tool can be used to dump config space data.\r\n\r\n\r\nInput Data", "expected": "The config space read is successful."}], "source": ""}
{"case_id": "case-746", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCompare the 'Slot Power Limit Scale' and 'Slot Power Limit Value' data (bits 16:7) to either of the following values:\r\n\r\n14:7 = 0xFA\r\n\r\n16:15 = 0b01\r\n\r\n\r\nOR:\r\n\r\n\r\n14:7 = 0x19\r\n\r\n16:15 = 0b00\r\n\r\n\r\nfor each slot.\r\n\r\n\r\nBoth of these encoding corresponds to a limit of 25 W. In the first case, we have 0d250 * .1 = 25 W. In the second case, we have 0d25 * 1 = 25 W.\r\n\r\n\r\nInput Data", "expected": "The 'Slot Power Limit Scale' and 'Slot Power Limit Value' are programmed as specified, indicating a slot power limit of 25 W."}], "source": ""}
{"case_id": "TC-13227", "name": "PCIe SSD - UEFI Driver - FQDD", "status": "Active", "type": "Manual", "description": "Will check that the PCIe SSD FQDDs have been implemented correctly", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInsert at least one PCIe SSD in the system and boot to an EFI-bootable USB key, preferrably one of each type of form factor (2.5\" and an add-in adapter card)\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInsert at least one PCIe SSD in the system and boot to an EFI-bootable USB key, preferrably one of each type of form factor (2.5\" and an add-in adapter card)\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-748", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nType \"DlpDump.efi\"\r\n\r\nInput Data", "expected": "All PCIe SSDs in the system are discovered and they have FQDDs as follows:\r\n\r\n\r\nIf 2.5\":\r\n\r\nDisk.Bay.XX:Enclosure.Internal.0-1:PCIeExtender.Slot.Y\" where XX is the backplane slot number and Y is the PCIe slot that the PCIe SSD Extender card is in\r\n\r\n\r\nIf Adapter Card:\r\n\r\nPCIeSSD.Slot.X where X is the PCIe slot that the PCIe SSD is in"}], "source": ""}
{"case_id": "TC-14716", "name": "PCIeSSD: Hotplug - Detailed Surprise Removal Verification", "status": "Active", "type": "Manual", "description": "This test case is intended to test the full surprise removal behavior of the PCIe SSD subsystem as well as the operating system.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-750", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with a hotpluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-751", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-752", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIf possible, disable or unload the PCIe SSD driver. The reason is to reduce the chances that any traffic will be outstanding to the PCIe SSD once it's removed.\r\n\r\nInput Data", "expected": "The driver is disabled or unloaded"}], "source": ""}
{"case_id": "case-753", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-754", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests\r\n\r\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is removed from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-755", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-756", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-757", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-758", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-759", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-760", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set"}], "source": ""}
{"case_id": "case-761", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set"}], "source": ""}
{"case_id": "TC-15174", "name": "PCIe SSD: Overnight I/O Stress", "status": "Active", "type": "Manual", "description": "TestDrive TestCase Objective was not specified.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nClear the SEL\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nClear the SEL\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "2", "description": "Description\r\nRun stress to all PCIe SSD devices using MLTT, iogen, or diskio overnight.\r\n\r\nInput Data", "expected": "implicit."}, {"step": "3", "description": "Description\r\nReview logs from all management applications, the test tool, and OS logs.\r\n\r\nInput Data", "expected": "No errors in logs."}, {"step": "4", "description": "Description\r\nCheck the SEL for any correctable errors\r\n\r\nInput Data", "expected": "No correctable errors are found"}, {"step": "1", "description": "Description\r\nClear the SEL\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-763", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nRun stress to all PCIe SSD devices using MLTT, iogen, or diskio overnight.\r\n\r\nInput Data", "expected": "implicit."}], "source": ""}
{"case_id": "case-764", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReview logs from all management applications, the test tool, and OS logs.\r\n\r\nInput Data", "expected": "No errors in logs."}], "source": ""}
{"case_id": "case-765", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the SEL for any correctable errors\r\n\r\nInput Data", "expected": "No correctable errors are found"}], "source": ""}
{"case_id": "TC-15555", "name": "PCIe SSD ESXi DPC: Operating system error threshold  check (ESXi Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging \r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nRun below command to enable ACPI logging \r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint)\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-767", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSet the threshold value to 10 using below command\r\n\r\nesxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 10\r\nand verify\r\nesxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit\r\n\r\n\r\nInput Data", "expected": "The OS error threshold is set to 10"}], "source": ""}
{"case_id": "case-768", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nRun some activity like\r\nesxcli nvme device get -A vmhba3\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-769", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-770", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat step 3-4  at least 11 times \r\n\r\nInput Data", "expected": "The driver for the corresponding device is unloaded and device is not visible anymore in the OS inventory. \r\n\r\nCheck the device list\r\nesxcli nvme device list"}], "source": ""}
{"case_id": "TC-15837", "name": "PCIe SSD: SAS/SATA combo backplane with PCIe SSD", "status": "Active", "type": "Manual", "description": "Verify system correctly detects and handles incorrect drive type in combo backplane when PCIe SSD is installed in PERC slot.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nMake sure the SUT has a backplane that supports both SAS/SATA as well as NVMe slots\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nMake sure the SUT has a backplane that supports both SAS/SATA as well as NVMe slots\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-772", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one PCIe SSD in a SAS/SATA slot and power on the system.\r\n\r\nInput Data", "expected": "PCIe SSD is not detected in the system.\r\n\r\nStatus LED blinks identify pattern (Green on/off).\r\n\r\nLifecycle log reports incorrect drive type on slot detected \"Invalid Device Type Installed\""}], "source": ""}
{"case_id": "case-773", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 until all PERC slots have been tested with a PCIe SSD.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-774", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInstall at least one SAS or SATA drive and at least one PCIe SSD in the SAS/SATA slots (ie. the SAS or SATA drive on slot 0 and the PCIe SSD on slot 1). ** this step is N/A on blade systems.\r\n\r\nInput Data", "expected": "PCIe SSD is not detected in the system.\r\n\r\nStatus LED blinks identify pattern (Green on/off).\r\n\r\nLifecycle Log reports incorrect drive type on slot detected \"Invalid Device Type Installed\"\r\n\r\nSAS/SATA drive Status LED is solid Green"}], "source": ""}
{"case_id": "case-775", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInstall a SAS/SATA drive in one of the PCIe SSD slots\r\n\r\nInput Data", "expected": "The Status LED blink identify (Green on/off) and is not detected in the system\r\nSEL reports incorrect drive type on slot detected \"Invalid Device Type Installed\""}], "source": ""}
{"case_id": "case-776", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat step 5 until all PCIe SSD slots have been tested\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "TC-16932", "name": "Backplane Drive Type Evaluation for 15G", "status": "Active", "type": "Manual", "description": "This test is intended to validate the backplane's determination of the drive type.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nSelect an NVMe-only U.2 slot and identify the slot's PCIe port BDF.  This will be the parent BDF of an NVMe endpoint device inserted in the slot.\r\n\r\nInput Data", "expected": "implicit"}, {"step": "1", "description": "Description\r\nSelect an NVMe-only U.2 slot and identify the slot's PCIe port BDF.  This will be the parent BDF of an NVMe endpoint device inserted in the slot.\r\n\r\nInput Data", "expected": "implicit"}], "source": ""}
{"case_id": "case-778", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nRemove any drives and examine the Presence Detect bit in the Slot Status Register\r\n\r\nInput Data", "expected": "The PD bit should be off (zero)."}], "source": ""}
{"case_id": "case-779", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInsert a SAS drive into the slot and examine the Presence Detect bit in the Slot Status Register\r\n\r\nInput Data", "expected": "The PD bit should still be off"}], "source": ""}
{"case_id": "case-780", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRemove the SAS drive and insert and NVMe device into the slot.  Examine the Presence Detect bit in the Slot Status Register\r\n\r\nInput Data", "expected": "The PD bit should now be on (one)"}], "source": ""}
{"case_id": "TC-18741", "name": "PCIeSSD - Orderly Removal", "status": "Active", "type": "Manual", "description": "This test is used to confirm that the low-level orderly removal process if functional.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with 2.5\" NVMe devices in the system\r\n\r\nInput Data", "expected": "The devices are discovered in the OS"}, {"step": "1", "description": "Description\r\nBoot to the OS with 2.5\" NVMe devices in the system\r\n\r\nInput Data", "expected": "The devices are discovered in the OS"}], "source": ""}
{"case_id": "case-782", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nOpen the OS logging mechanism (e.g. Event Viewer in Windows or tail -f /var/log/messages in Linux)\r\n\r\nInput Data", "expected": "The OS logs are being recorded"}], "source": ""}
{"case_id": "case-783", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWindows - \r\nGo to the bottom right-corner taskbar and click the \"^\" symbol.\r\nSelect the USB icon\r\n\r\nLinux -\r\nGo to /sys/bus/pci/slots/<SLOT> # The correct SLOT can be determined by looking at the contents of the address file or using grep command\r\nFor example\r\ngrep -ir 0000:e4:00\r\n\r\n\r\nInput Data", "expected": "Windows - \r\nThe NVMe drives are enumerated\r\n\r\nLinux - \r\nThe correct SLOT folder is found and a file exists named, \"power\""}], "source": ""}
{"case_id": "case-784", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWindows - \r\nSelect the NVMe device to cause the safe removal process\r\n\r\nLinux - \r\necho 0 > /sys/pci/slots/SLOT/power # where SLOT is the value you determined in the previous step\r\n\r\n\r\nInput Data", "expected": "The NVMe drive is removed from the system.\r\n\r\nOn Windows, the OS logs the removal.\r\n\r\nOn Linux, the OS is not required to log the removal."}], "source": ""}
{"case_id": "case-785", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove the drive from the slot, either manually, or using a quarch.\r\n\r\n\r\nInput Data", "expected": "No crashes or aberrant behavior is observed."}], "source": ""}
{"case_id": "case-786", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRe-insert the drive back into the same slot\r\n\r\nInput Data", "expected": "The NVMe drive is fully discovered"}], "source": ""}
{"case_id": "case-787", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 2-4\r\n\r\nInput Data", "expected": "Same results as above"}], "source": ""}
{"case_id": "case-788", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat steps 2-6 on another other drive slots (all drive slots if reasonable)\r\n\r\nInput Data", "expected": "Same results as above"}], "source": ""}
{"case_id": "TC-18998", "name": "PCIeSSD: Hotplug - Surprise Removal after Unhandled Insertion", "status": "Active", "type": "Manual", "description": "The point of this test is to analyze the subsystem behavior when a device is immediately removed after just have been inserted.", "precondition": "-", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with no hot-pluggable PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description \nBoot into the OS with no hot-pluggable PCIe SSDs in the system\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-790", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-791", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nImmediately remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up in the OS (PCI bus, NVMe driver loaded, or disk mgmt utilities)"}], "source": ""}
{"case_id": "case-792", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "TC-22499", "name": "PCIe SSD - UEFI NVMe Crypto Erase - Format NVM vs. Sanitize", "status": "Active", "type": "Manual", "description": "This test case is intended to make sure that the UEFI driver sends the correct kind of Cryptographic Erase. If the drive supports Sanitize, then it should be sent, else falling back to Format NVM is the expected behavior.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInsert a drive that supports the NVMe Sanitize command and a drive that does not and only supports Format NVM\r\n\r\nOptional: If possible, insert a device that doesn't support either Sanitize or Format NVM (there are probably no drives that support neither one)\r\n\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInsert a drive that supports the NVMe Sanitize command and a drive that does not and only supports Format NVM\r\n\r\nOptional: If possible, insert a device that doesn't support either Sanitize or Format NVM (there are probably no drives that support neither one)\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-794", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\n\r\nConnect a PCIe analyzer to the system such that the traffic to the NVMe devices can be captured.\r\n\r\n(Note: it is possible to run this test without using an analyzer by examining the contents of the drive's Sanitize log page after each step and noting how the status bits change.)\r\n\r\nInput Data", "expected": "implicit"}], "source": ""}
{"case_id": "case-795", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server and boot to the HII\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-796", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to the Physical Device Operations section for the device that supports Sanitize and issue the operation\r\n\r\nInput Data", "expected": "The operation completes successfully and the PCIe trace shows that an NVMe Sanitize was used instead of a Format NVM"}], "source": ""}
{"case_id": "case-797", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to the Physical Device Operations for the device that only supports Format NVM and issue the operation\r\n\r\nInput Data", "expected": "The operation completes successfully and the PCIe trace shows that a Format NVM was sent to the drive instead of a Sanitize"}], "source": ""}
{"case_id": "case-798", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf you have a device that does not support Sanitize or Format NVM, the operation to perform Cryptographic Erase should either be greyed out or not available\r\n\r\nInput Data", "expected": "Cryptographic Erase should either be greyed out or not available"}], "source": ""}
{"case_id": "TC-22931", "name": "PCIeSSD: PCIe - Read Tracking on Bridge with Unresponsive Endpoint", "status": "Active", "type": "Manual", "description": "This test case is intended to test the Read Tracking feature of the Dell PCIe Extender Card. In the event that an endpoint device suddenly stops responding, then normally a Completion Timeout would be generated. However, with the Read Tracking feature, a response of all Fs should be synthesized by the bridge downstream port, along with a Completer Abort event.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect a PCIe analyzer between the Root Port and a PCIe Extender card that has the Read-Tracking capability enabled. The system should not have the option to mask CTO but if it does then make sure CTO masking is disabled\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\nConnect a PCIe analyzer between the Root Port and a PCIe Extender card that has the Read-Tracking capability enabled. The system should not have the option to mask CTO but if it does then make sure CTO masking is disabled\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-800", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-801", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-802", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-803", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-804", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\n\r\nHave the PCIe SSD stop responding to the Configuration Reads (do not stop the tool/script that's issuing the config. reads). \r\n\r\n\r\nFor example, in the case of PM1725a, a drive with special Error Injection firmware is used.  The drive is cabled as a USB COM port.  Setting up the com port is per instruction found at NVMe\\NVME_PCIeSSD\\Tools\\UART_Capture\\Setup.  The command used for this step are:  urdev =1 to stop drive from responding.  urdev=0 to put drive back to normal state\r\n\r\n\r\n\r\nInput Data", "expected": "The operating system crashes"}], "source": ""}
{"case_id": "case-805", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-806", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the Non-Posted request that was ignored by the endpoint (it will have a completion type of Completer Abort)\r\n\r\nInput Data", "expected": "The Completer Abort is found"}], "source": ""}
{"case_id": "case-807", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, zero the timestamp of the Non-Posted Request that received the Completer Abort\r\n\r\nInput Data", "expected": "The amount of time between the command being issued and the Completer Abort completion is 60ms"}], "source": ""}
{"case_id": "TC-26558", "name": "PCIeSSD: Hotplug - Detailed Hot Insertion Verification", "status": "Active", "type": "Manual", "description": "This test case is intended to test the full hot insertion behavior of the PCIe SSD subsystem as well as the operating system.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\nConnect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-809", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with no hotpluggable PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-810", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-811", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-812", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInsert the PCIe SSD\r\n\r\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is enumerated from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) shows up from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) shows up after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s)shows up after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-813", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-814", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was inserted\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-815", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 1\r\n\r\nData Link Layer State Changed (DLLSC) = 0"}], "source": ""}
{"case_id": "case-816", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 1\r\n\r\nData Link Layer State Changed (DLLSC) = 0"}], "source": ""}
{"case_id": "case-817", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was inserted\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-818", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 0\r\n\r\nData Link Layer State Changed (DLLSC) = 1"}], "source": ""}
{"case_id": "case-819", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 0\r\n\r\nData Link Layer State Changed (DLLSC) = 1"}], "source": ""}
{"case_id": "TC-31081", "name": "PCIe SSD - Orderly Removal Operation Dynamically Available", "status": "Active", "type": "Manual", "description": "This test case is used to test that a hot inserted device is allowed to be orderly removed from iDRAC.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the OS with no NVMe drives, waiting a few minutes to allow iDRAC I2C discovery to occur\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the OS with no NVMe drives, waiting a few minutes to allow iDRAC I2C discovery to occur\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-821", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to the \"Configuration->Storage Configuration\" section of the iDRAC GUI\r\n\r\nInput Data", "expected": "There are no NVMe PCIe SSDs listed"}], "source": ""}
{"case_id": "case-822", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The PCIe SSD get's enumerated in the \"Configuration->Storage Configuration\" view\r\n\r\nNOTE that a \"refresh\" may be needed"}], "source": ""}
{"case_id": "case-823", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect the drop-down \"Action\" menu\r\n\r\nInput Data", "expected": "The option to \"Prepare to remove\" is available"}], "source": ""}
{"case_id": "TC-35143", "name": "PCIe SSD - iDRAC - SEL Logging of Hotplug Events", "status": "Active", "type": "Manual", "description": "This test case is intended to test that NVMe hotplug operations are getting logged into the iDRAC SEL.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the operating system and wait a few minutes for iDRAC to finish I2C discovery if starting from a cold boot\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nBoot into the operating system and wait a few minutes for iDRAC to finish I2C discovery if starting from a cold boot\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-825", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf there are 2.5\" NVMe drives already in the system, remove them from the system\r\n\r\nInput Data", "expected": "The SEL log shows an entry for each drive that was removed and it's location.  For tests run on systems with DPC, you will see 5 entries (1 Critical Error listing the drive removal, 2 warnings, one PCIe correctable error for the drive and one for the parent port, one warning about a low severity error, listing the Bay and Slot of the drive you removed, and an informational event noting that an OEM diagnostic event occurred."}], "source": ""}
{"case_id": "case-826", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInsert NVMe drives back into the system\r\n\r\nInput Data", "expected": "The SEL log shows an entry for each drive that was inserted and it's location"}], "source": ""}
{"case_id": "TC-35868", "name": "PCIe SSD ESXi DPC: Multiple Error Injection at endpoint & it's upstream port  with EDR notification/recovery check (ESXi Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \r\n\r\nesxcli system settings kernel set -s acpiDbgLevel -v 2\r\n\r\n(Could be verified by checking DPC control register of parent port above endpoint) \r\n\r\nAlso increase the error threshold to higher value. \r\nesxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 15\r\nand verify\r\nesxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\nBoot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. \n\nesxcli system settings kernel set -s acpiDbgLevel -v 2\n\n(Could be verified by checking DPC control register of parent port above endpoint) \n\nAlso increase the error threshold to higher value. \nesxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 15\nand verify\nesxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit\n\n\n\n\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-828", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-829", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-830", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat step 2-3 at least four times \r\n\r\nInput Data", "expected": "The device get's enumerated successfully after each recovery. \r\nThe device is visible in \r\n\"esxcli nvme device list\""}], "source": ""}
{"case_id": "case-831", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nrepeat step 2-4 instead inject error on upstream port by using Malformed TLP mechanism. \r\n\r\nInput Data", "expected": "The devices are visible in OS"}], "source": ""}
{"case_id": "TC-43325", "name": "PCIe SSD - Operating Systems - DSM", "status": "Active", "type": "Manual", "description": "The objective of this test case is to ensure that the DSM name is showing up for the PCIe SSDs of all form factors, and that it's correct.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS with at least one 2.5\" PCIe SSD. \r\n\r\nInput Data", "expected": "The OS detects all PCIe SSDs in the system and loads the driver for them."}, {"step": "1", "description": "Description\r\nBoot into a supported OS with at least one 2.5\" PCIe SSD. \r\n\r\nInput Data", "expected": "The OS detects all PCIe SSDs in the system and loads the driver for them."}], "source": ""}
{"case_id": "case-833", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf Windows -\r\nComputer Management->Device Manager->Storage Controllers\r\nRight-click one of the PCIe SSDs and select \"Properties\"\r\nClick the \"Details\" tab\r\nClick the Property drop-down and select the \"PCI label string\"\r\nElse if Linux -\r\nRun the attached dslot.sh shell script\r\nElse if ESXi -\r\nThere is a tool called \"smbiosDump\" that will display the SMBIOS/DSM information\r\n\r\n\r\nInput Data", "expected": "PCIe SSD in Slot X in Bay Y (where X is the slot number, and Y is the backplane ID)"}], "source": ""}
{"case_id": "case-834", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIf Windows - Repeat step 2 for the other form factor PCIe SSD (the Linux shell script will show all devices)\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-835", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [], "source": ""}
{"case_id": "TC-43995", "name": "PCIe SSD - Max_Payload_Size Verification w/o Hotplug", "status": "Active", "type": "Manual", "description": "This test case is used to verify that the Max_Payload_Size being used is always set to the same value, regardless of the presence of devices or not.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the Dell UEFI shell with no NVMe devices in the system\r\n\r\nInput Data", "expected": "System boots"}, {"step": "1", "description": "Description\nBoot into the Dell UEFI shell with no NVMe devices in the system\n\nInput Data", "expected": "System boots"}], "source": ""}
{"case_id": "case-837", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDiscover the PCIe topology for all NVMe slots. \r\nFor CPU direct-attach slots, it will just be a single CPU root port BDF. \r\nFor PCIe switch-connected slots, it will be something like: CPU Root Port -> Switch Upstream Port -> Switch Downstream Port.\r\n\r\nNOTE that the easiest way of doing this is imply to look-up the information on the PCIeSSD Confluence page. Look for the \"Slot BDF Mapping\" page.\r\n\r\n\r\nInput Data", "expected": "The PCIe BDF topology is dsicovered for all NVMe slots"}], "source": ""}
{"case_id": "case-838", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRead the Device Control register from PCIe config. space for the CPU root port at the top of the tree for each slot.\r\n\r\nThe UEFI command to read PCIe config space is \"pci BUS DEVICE FUNCTION -i\", ie \"pci 65 00 00 -i\" for a BDF of 65:00.0.  This command takes BDFs in hex.\r\n\r\nTo specifically read the Max_Payload_Size, you can take advantage of DellGrep (only in the Dell UEFI shell) and run this for example: \"pci 65 00 00 -i | DellGrep Max_Payload_Size\"\r\n\r\n\r\nInput Data", "expected": "The configured Max_Payload_Size is set to 256B for each root port"}], "source": ""}
{"case_id": "case-839", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRead the Max_Payload_Size field from the Device Control Register from the CPU root port all the way down to the switch downstream port (if applicable)\r\n\r\nInput Data", "expected": "The Max_Payload_Size is set to 256B for all BDFs"}], "source": ""}
{"case_id": "case-840", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nShutdown the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-841", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert NVMe devices into the slots that were checked previously and boot into the Dell UEFI shell\r\n\r\nInput Data", "expected": "The system boots successfully and all NVMe devices are discovered"}], "source": ""}
{"case_id": "case-842", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3 and 4\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-843", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRead the Max_Payload_Size field from the Device Control Register of the NVMe devices\r\n\r\nInput Data", "expected": "Each device has the Max_Payload_Size set to 256B"}], "source": ""}
{"case_id": "TC-44299", "name": "PCIe SSD - 15G Hot Insertion PERST# Logic Validation", "status": "Active", "type": "Manual", "description": "This test case will be used to determine the PERST# logic that applies when hot inserting an NVMe device is correctly functioning.", "precondition": "For the documented steps, you will need an oscilloscope, but this test has an automation script, so it is not strictly required.", "steps": [{"step": "1", "description": "Description\r\nConfirm from the test notes that this test case is applicable to your SUT\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nConfirm from the test notes that this test case is applicable to your SUT\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-845", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the NVME_PRES, PERST#, and P4 signals to an oscilloscope\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-846", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-847", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of NVME_PRES\r\n\r\nInput Data", "expected": "Trigger enabled"}], "source": ""}
{"case_id": "case-848", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nConfigure the horizontal divisions to be 500ms\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-849", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nConfigure the vertical divisions for both signals to be 1V\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-850", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The trigger occurs\r\n\r\n==============================\r\nBefore the trigger occurs, P4 and NVME_PRES are both high (~3.3V).  PERST# is low (~0V).\r\n\r\nUpon insertion of the device, P4 immediately transitions to 0V.\r\n\r\nOne second after insertion, PERST transitions to high, and NVME_PRES transitions to low."}], "source": ""}
{"case_id": "TC-44399", "name": "PCIe SSD - iDRAC Health Poll Dynamic NVMe Health Change", "status": "Active", "type": "Manual", "description": "This test case is intended to make sure that the iDRAC can detect an NVMe device that goes into a failure state during runtime.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the operating system with at least one U.2 NVMe PCIe SSD that supports Dell PowerEdge NVMe Error Injection (or any other vendor proprietary way of injecting NVMe critical warnings without the need of a reboot)\r\n\r\nWait between 5-10 minutes once in the OS to allow the iDRAC to fully initialize\r\n\r\n\r\nInput Data", "expected": "The system boots and detects the NVMe device(s)"}, {"step": "1", "description": "Description\r\nBoot into the operating system with at least one U.2 NVMe PCIe SSD that supports Dell PowerEdge NVMe Error Injection (or any other vendor proprietary way of injecting NVMe critical warnings without the need of a reboot)\r\n\r\nWait between 5-10 minutes once in the OS to allow the iDRAC to fully initialize\r\n\r\n\r\nInput Data", "expected": "The system boots and detects the NVMe device(s)"}], "source": ""}
{"case_id": "case-852", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the Status LED of the NVMe device\r\n\r\nInput Data", "expected": "The Status LED is solid green"}], "source": ""}
{"case_id": "case-853", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPut the device into a failed state:\r\n    * NVM Subsystem Reliability Degraded\r\n    * Volatile Memory Backup Failed\r\n    * Read Only\r\n    * (special case) Available spare below threshold\r\n    * (special case) Temperature above threshold\r\n\r\n\r\nInput Data", "expected": "The device successfully goes into the failed state (can be verified by an in-band Get Log Page -SMART/Health command)\r\n\r\nWithin 1 minute, the Status LED is now in the following state:\r\n    * Read only, Back fail, or reliability degraded:  blinking amber/off\r\n    * Spare below threshold:  blinking amber/green/off\r\n    * Temperature:  solid green (normal operation, no physical indicator)"}], "source": ""}
{"case_id": "case-854", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nD/C cycle the server and repeat the above steps, but choosing a different failure reason than before\r\n\r\nInput Data", "expected": "Same results as earlier"}], "source": ""}
{"case_id": "case-855", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nD/C cycle the server and repeat the above steps, but this time choose for the device to go into Approaching Read-Only mode instead of one of the failure scenarios\r\n\r\nInput Data", "expected": "The status LED should now blink Green/Amber"}], "source": ""}
{"case_id": "TC-50677", "name": "PCIe SSD - SMBIOS Bay/Slot Information", "status": "Active", "type": "Manual", "description": "This test validates if the correct Bay/Slot information for U.2 NVMe devices is correctly populated into the SMBIOS Type 9 table.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInsert NVMe devices into all applicable NVMe slots on the backplane.\r\n\r\n*If not enough devices are available to populate all slots at one time, then test as many as possible, power off, then move the devices to the next slots and re-test. Perform this until all slots have been tested.\r\n\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInsert NVMe devices into all applicable NVMe slots on the backplane.\r\n\r\n*If not enough devices are available to populate all slots at one time, then test as many as possible, power off, then move the devices to the next slots and re-test. Perform this until all slots have been tested.\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-857", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into an operating system or UEFI shell\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-858", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGet the PCIe BDFs of each of the U.2 NVMe devices in the system (lspci, Device Manager->Storage Contollers, etc.)\r\n\r\nInput Data", "expected": "BDFs are obtained for all U.2 NVMe PCIe SSDs"}], "source": ""}
{"case_id": "case-859", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDump the SMBIOS table\r\n\r\nWindows:\r\nRWEverything -> SMBIOS\r\n\r\nLinux:\r\ndmidecode\r\n\r\nUEFI shell (Note you need to be using the Dell UEFI shell):\r\nsmbios\r\n\r\n\r\nInput Data", "expected": "Windows:\r\n   1. Go to the Type 9 section\r\n   2. Find the entry that has one of the U.2 NVMe bus numbers you saved\r\n   3. Check the \"Slot Location\" and confirm it's the correct location for the given device\r\nLinux:\r\n   1. Go to the Type 9 section (grep for DMI type 9)\r\n   2. Find the entry tat has a bus address equal to one of the U.2 NVMe bus numbers you saved\r\n   3. Check the \"Designation\" and confirm it's the correct location for the given device"}], "source": ""}
{"case_id": "case-860", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 4 for all slots\r\n\r\nInput Data", "expected": "Same results as in step 4"}], "source": ""}
{"case_id": "TC-51432", "name": "PCIe SSD - PLX PCIe Switch Port Eye Diagram Capture", "status": "Active", "type": "Manual", "description": "The purpose of this test case is to check the signal integrity for all ports of the PCIe switch by capturing the eye diagrams.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall U.2 NVMe devices into each backplane slot that connects to a PLX PCIe switch\r\n\r\nNOTE if you don't have enough drives to populate all slots at one time, then power cycle the server and move your drives to the next slots and repeat the test until all slots have been covered.\r\n\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nInstall U.2 NVMe devices into each backplane slot that connects to a PLX PCIe switch\r\n\r\nNOTE if you don't have enough drives to populate all slots at one time, then power cycle the server and move your drives to the next slots and repeat the test until all slots have been covered.\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-862", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf the operating system does not support the PLX SDK (ESXi or the UEFI shell), then connect an Aardvark to the debug I2C port on the switch.\r\n\r\nElse install the PLX SDK onto the SUT\r\n\r\n\r\nInput Data", "expected": "Aardvark is connected or PLX SDK is installed directly onto the SUT"}], "source": ""}
{"case_id": "case-863", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLaunch the PLX PEX Device Editor software and select the Serdes Eye Width operation\r\n\r\nInput Data", "expected": "A SerDes Eye tab opens"}], "source": ""}
{"case_id": "case-864", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUse the Select a Port drop-down menu to choose a port (only choose a port that actually has an NVMe drive plugged into it)\r\n\r\nClick the Click to Draw Eye button\r\n\r\n\r\nInput Data", "expected": "The test completes and you see the eye \"open\"\r\n\r\nThe data may need to be analyzed by a hardware engineer to determine pass/fail"}], "source": ""}
{"case_id": "case-865", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat the test for all possible NVMe slots\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "TC-52181", "name": "PCIeSSD: PCIe - Completion Timeout Reporting with Unresponsive Endpoint", "status": "Active", "type": "Manual", "description": "This test case is intended to test that in the event that an endpoint device suddenly stops responding, a Completion Timeout is generated and correctly logged.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nMake sure the SUT is a CPU direct-attach system, a switch configured system cannot be used.\r\n\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nMake sure the SUT is a CPU direct-attach system, a switch configured system cannot be used.\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-867", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-868", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetermine the parent PCIe BDF to the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-869", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-870", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHave the PCIe SSD suddenly stop responding to the Non-Posted Requests\r\n\r\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.\r\n\r\n\r\nInput Data", "expected": "If the OS and platform do not support Downstream Port Containment, the system crashes.\r\n\r\nIf DPC is supported, then the OS should log a Completion Timeout and attempt to recover."}], "source": ""}
{"case_id": "case-871", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDump the system SEL (e.g. racadm getsel -E)\r\n\r\nInput Data", "expected": "If no DPC support, there's an entry for a Completion Timeout logged by the root port above the endpoint that stopped responding.\r\n\r\nWith DPC support, there will be a DPC event logged with a reason of Completion Timeout."}], "source": ""}
{"case_id": "TC-57125", "name": "Backplane Drive Type Evaluation for 14G", "status": "Active", "type": "Manual", "description": "This test is intended to validate the backplane's determination of the drive type.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nRe-work one of the NVMe drive slots on the backplane according to the test configuration notes.\r\n\r\nInput Data", "expected": "The wires have been added"}, {"step": "1", "description": "Description\r\nRe-work one of the NVMe drive slots on the backplane according to the test configuration notes.\r\n\r\nInput Data", "expected": "The wires have been added"}], "source": ""}
{"case_id": "case-873", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the oscilloscope probes to the P4, P10, and NVMe_PRES wires.\r\n\r\nInput Data", "expected": "The probes are added and channels are enabled."}], "source": ""}
{"case_id": "case-874", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of the P4 signal.\r\n\r\nSet the horizontal divisions to 200ms divisions.\r\n\r\nSet the vertical divisions for P4, P10, and NVME_PRES to 1V.\r\n\r\n\r\nInput Data", "expected": "The oscilloscope is configured"}], "source": ""}
{"case_id": "case-875", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPower on the server with no drive plugged into the slot that's been wired for the measurement\r\n\r\nInput Data", "expected": "The server powers on and boots into an operating system or UEFI environment"}], "source": ""}
{"case_id": "case-876", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert an NVMe drive into the slot\r\n\r\nInput Data", "expected": "The oscilloscope triggers"}], "source": ""}
{"case_id": "case-877", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAnalyze the oscilloscope capture\r\n\r\nInput Data", "expected": "1. The time before the trigger, all three signals were high (3.3V)\r\n   2. At the trigger, the P4 signal went low (0V) while the other two signals remained high\r\n   3. *500ms later, the P10 signal remains high, but the NVME_PRES went low\r\n*The parts are allowed to have some small deviation from 500ms. E.g. 490ms, 510ms, etc. but should not vary much more than that"}], "source": ""}
{"case_id": "TC-57740", "name": "PCIe SSD: identify physical device in HII", "status": "Active", "type": "Manual", "description": "Verify user can locate/identify a PCIe SSD through HII.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least one PCIe SSD of each capacity in the system and boot to HII.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall at least one PCIe SSD of each capacity in the system and boot to HII.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-879", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Physical Device Operations menu option.\r\n\r\nInput Data", "expected": "Blink/Ublink operations are displayed and active (they are not grayed out)."}], "source": ""}
{"case_id": "case-880", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInitiate identify on a PCIe SSD. (Blink)\r\n\r\nInput Data", "expected": "1. Blink operation starts successfully\r\n\r\n2. The PCIe SSD is blinking its status LED"}], "source": ""}
{"case_id": "case-881", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect Unblink.\r\n\r\nInput Data", "expected": "1. Unblink operations starts successfully\r\n\r\n2. The PCIe SSD stops blinking its activity LED"}], "source": ""}
{"case_id": "case-882", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 3 and 4 but select to blink more than one device. For Unblink, unblink one drive first, wait 10 seconds, unblink the second device.\r\n\r\nInput Data", "expected": "For blink: user is able to blink more than one device at the same time.\r\n\r\n\r\nFor unblink: unblink of one device does not disrupt the LED pattern of the other drive(s), ie. other device continues to blink until user selects unblink."}], "source": ""}
{"case_id": "TC-63651", "name": "PCIe SSD - Correctable/Uncorrectable Error Check after I/O", "status": "Active", "type": "Manual", "description": "This test case is intended to check the signal integrity to the NVMe devices.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the operating system with NVMe devices populated behind each cable routed to the backplane\r\n\r\nInput Data", "expected": "The system boots and the devices are discovered"}, {"step": "1", "description": "Description\r\nBoot to the operating system with NVMe devices populated behind each cable routed to the backplane\r\n\r\nInput Data", "expected": "The system boots and the devices are discovered"}, {"step": "2", "description": "Description\r\nDisable correctable error reporting for all NVMe drives, and parents BDFs above them (write to PCIe Cfg Space - Device Control Register)\r\n\r\nClear the Correctable Error Mask register\r\n\r\n\r\nInput Data", "expected": "Correctable Error Reporting is disabled and all errors have been masked"}, {"step": "3", "description": "Description\r\nBegin running I/O to all of the devices and allow it to run for 70 minutes\r\nWhile I/O is in progress, poll the Correctable Error Status registers of the NVMe drives and parents of the drives\r\n\r\n\r\nInput Data", "expected": "I/O runs successfully\r\nNo correctable errors are detected"}, {"step": "4", "description": "Description\r\nDump the system event log (e.g. racadm getsel -E)\r\n\r\nInput Data", "expected": "There are no Correctable or Uncorrectable errors being reported by the NVMe devices or parent of the NVMe devices in the log"}, {"step": "5", "description": "Description\r\nReboot the system and repeat steps 2-4 an additional 9 times\r\n\r\nInput Data", "expected": "Same results"}, {"step": "1", "description": "Description\r\nBoot to the operating system with NVMe devices populated behind each cable routed to the backplane\r\n\r\nInput Data", "expected": "The system boots and the devices are discovered"}], "source": ""}
{"case_id": "case-884", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDisable correctable error reporting for all NVMe drives, and parents BDFs above them (write to PCIe Cfg Space - Device Control Register)\r\n\r\nClear the Correctable Error Mask register\r\n\r\n\r\nInput Data", "expected": "Correctable Error Reporting is disabled and all errors have been masked"}], "source": ""}
{"case_id": "case-885", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBegin running I/O to all of the devices and allow it to run for 70 minutes\r\nWhile I/O is in progress, poll the Correctable Error Status registers of the NVMe drives and parents of the drives\r\n\r\n\r\nInput Data", "expected": "I/O runs successfully\r\nNo correctable errors are detected"}], "source": ""}
{"case_id": "case-886", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDump the system event log (e.g. racadm getsel -E)\r\n\r\nInput Data", "expected": "There are no Correctable or Uncorrectable errors being reported by the NVMe devices or parent of the NVMe devices in the log"}], "source": ""}
{"case_id": "case-887", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nReboot the system and repeat steps 2-4 an additional 9 times\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "TC-64460", "name": "PCIe SSD - DPC - Error containment & recovery", "status": "Active", "type": "Manual", "description": "The test case is intended to check if the Error generated by end point is contained and a recovery is attempted", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to OS & BIOS that supports DPC and enabled with at least one PCIe SSD\r\n\r\nInput Data", "expected": "System boots without error and device is visible to OS"}, {"step": "1", "description": "Description\nBoot to OS & BIOS that supports DPC and enabled with at least one PCIe SSD\n\nInput Data", "expected": "System boots without error and device is visible to OS"}], "source": ""}
{"case_id": "case-889", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNote down the BDF of the endpoint and try to inject a FATAL/Non-Fatal error . \r\nEx- A malformed TLP can be generated by changing MPS of endpoint causing mismatch with the root port.  \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-890", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nThe device Max Payload Size has been changed and reflected in config space \r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-891", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRun heavy IO to device to make sure error is generated in short time\r\n\r\nInput Data", "expected": "/var/log/message logs when the error is generated and can be seen there"}], "source": ""}
{"case_id": "case-892", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck /var/log/message and make sure DPC event triggered information is logged along with successful device recovery \r\n\r\nInput Data", "expected": "The expected functionality was logged correctly"}], "source": ""}
{"case_id": "TC-67703", "name": "PCIe SSD DPC: Port Containment with Unresponsive Endpoint", "status": "Active", "type": "Manual", "description": "This test case is intended to test that in the event that an endpoint device suddenly stops responding, a Completion Timeout is generated and correctly logged.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nMake sure the SUT is a CPU direct-attach system, a switch configured system cannot be used\r\n\r\nInput Data", "expected": "Implicit"}, {"step": "1", "description": "Description\r\nMake sure the SUT is a CPU direct-attach system, a switch configured system cannot be used\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-894", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported config which has DPC support both from BIOS as well as OS\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-895", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetermine the parent PCIe BDF to the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-896", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous I/O to the device\r\n\r\nInput Data", "expected": "The I/O starts without any issue"}], "source": ""}
{"case_id": "case-897", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHave the PCIe SSD suddenly stop responding to the Non-Posted Requests\r\n\r\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.\r\n\r\n\r\nInput Data", "expected": "The system doesn't crash"}], "source": ""}
{"case_id": "case-898", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDump the PCIe CFG space of parent port and check DPC Trigger Status \r\n\r\nInput Data", "expected": "For Linux:\r\n\r\nThe DPC Trigger Status should be set\r\n\r\nFor ESXi:\r\n\r\nThe DPC Trigger Status should be clear, and the device driver is not loaded for the endpoint (drive). NOTE: ESXi does not leave the port in containment, and instead takes it out to unload the driver)"}], "source": ""}
{"case_id": "case-899", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCheck the OS message for recovery failure and EDR event triggered \r\n\r\nInput Data", "expected": "The message indicates EDR event and also recovery failure"}], "source": ""}
{"case_id": "case-900", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the SEL log for DPC event \r\n\r\nInput Data", "expected": "The SEL log has DPC event captured"}], "source": ""}
{"case_id": "TC-69183", "name": "PCIe SSD DPC: Error threshold check and SEL decoding check  (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\nAlso clear SEL logs before starting the test\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\nAlso clear SEL logs before starting the test\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-902", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-903", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-904", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 14 times\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-905", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInsert 15th error to the same end point \r\nand get the SEL logs\r\n\r\n\r\nInput Data", "expected": "The end point devices is not visible and DPC Status is set to triggered mode. \r\nGet the SEL logs and make sure there are 14 DPC error event and 1 Fatal error event. \r\nAlso, check if the SEL decoding is correct and logging right event and errors along with right bdf"}], "source": ""}
{"case_id": "TC-69196", "name": "PCIeSSD: Export Log via Support Assist", "status": "Active", "type": "Manual", "description": "Collect Support Assist bundle and verify inventory for each installed PCIeSSD (NVMe)", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall NVMe PCIe SSDs and boot to a supported OS.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInstall NVMe PCIe SSDs and boot to a supported OS.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-907", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPlace your system on the network such that you're able to remotely access it via iDRAC.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-908", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLog into the iDRAC GUI and go into the \"Maintenance -> Support Assist\" section\r\n\r\nClick on the Start a Collection button\r\n\r\nIn the Data to Collect section, select all options\r\n\r\nIn the Collection Preferences section, select Save Locally\r\n\r\nClick Collect\r\n\r\n\r\nInput Data", "expected": "The collection completes successfully"}], "source": ""}
{"case_id": "case-909", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nExtract the zip file that gets generated\r\n\r\nExtract the zip file inside of that zip file as well\r\n\r\nNavigate into the tsr -> storagelog directory\r\n\r\n\r\nInput Data", "expected": "There should be files for each NVMe drive present"}], "source": ""}
{"case_id": "case-910", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nOpen each file\r\n\r\nInput Data", "expected": "The SMART/Health and Error Information is present and accurate (this can be confirmed via Get Log Page from an in-band tool)"}], "source": ""}
{"case_id": "TC-69641", "name": "PCIe SSD - LED Management - The status LED must turn on to solid green within a few seconds of the backplane receiving power.", "status": "Active", "type": "Manual", "description": "Validate that the healthy device status LED turns on to solid green within a few seconds of the backplane receiving power.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall atleast one healthy PCIe SSDs and a backplne in the system Note: Make sure that the system is up to date.Specially the Backplane and the PCIe SSD\r\n\r\nInput Data", "expected": "The status LED is solid Green."}, {"step": "1", "description": "Description\r\nInstall atleast one healthy PCIe SSDs and a backplne in the system Note: Make sure that the system is up to date.Specially the Backplane and the PCIe SSD\r\n\r\nInput Data", "expected": "The status LED is solid Green."}], "source": ""}
{"case_id": "case-912", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the status LED of the device as soon as you boot the system\r\n\r\nInput Data", "expected": "The status LED of the device should turn on green as soon as the Backplane is powered on.\r\n\r\n\r\n\r\nNote: Usually the staus LED is set to solid green within 1-3 second after the system is booted."}], "source": ""}
{"case_id": "case-913", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWait till the system boots to OS and check the LED of the drives\r\n\r\nInput Data", "expected": "The LED of the drive stays solid green"}], "source": ""}
{"case_id": "case-914", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReboot the system and check the status LED of the drives\r\n\r\nInput Data", "expected": "The status LED of the drive should stay Green all the time."}], "source": ""}
{"case_id": "TC-70512", "name": "PCIe SSD - Completion Timeout Value Verification", "status": "Active", "type": "Manual", "description": "This test case is used to make sure that the completion timeout value being programmed from the CPU root port on down is correct", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into an operating system or UEFI shell with NVMe devices in the system\r\n\r\nInput Data", "expected": "The devices are discovered"}, {"step": "1", "description": "Description\r\nBoot into an operating system or UEFI shell with NVMe devices in the system\r\n\r\nInput Data", "expected": "The devices are discovered"}], "source": ""}
{"case_id": "case-916", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFind out the parent BDF to the NVMe devices\r\n\r\nWindows:\r\nDevice Manager -> View by Connection\r\n\r\nLinux:\r\nlspci -t\r\n\r\n\r\nInput Data", "expected": "The parent BDFs for each NVMe drive are captured"}], "source": ""}
{"case_id": "case-917", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDump PCIe config. space for each parent BDF determined in the previous step\r\n\r\nInput Data", "expected": "PCIe config. space is successfully captured"}], "source": ""}
{"case_id": "case-918", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the Device Control 2 Register, bits 0-3\r\n\r\nInput Data", "expected": "The value decodes to 0x6"}], "source": ""}
{"case_id": "TC-73519", "name": "PCIe SSD: downgraded PCIe link speed", "status": "Active", "type": "Manual", "description": "TestDrive TestCase Objective was not specified.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card known to train at downgraded link speed (ie. if Gen3 PCIe SSD, the PCIe SSD trains at Gen1 or Gen2).\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card known to train at downgraded link speed (ie. if Gen3 PCIe SSD, the PCIe SSD trains at Gen1 or Gen2).\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-920", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link speed.\r\n\r\nInput Data", "expected": "BIOS halts due to link down train error, reporting the actual versus expected speed. \r\n\r\nThe error is reported to screen with the BDF of the parent of the NVMe device. \r\n\r\nThere is an entry for this error in the Lifecycle Log.\r\n\r\nIf the system is 15G or newer, then the bay and slot of the link degradation is reported as well."}], "source": ""}
{"case_id": "case-921", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same results as above except the BIOS does not pause during POST"}], "source": ""}
{"case_id": "TC-75007", "name": "PCIe SSD: HII Physical Disk Properties", "status": "Active", "type": "Manual", "description": "Verify:1. Physical Disks are displayed correctly2. Physical Disk Properties are displayed correctly3. Help content is displayed correctly", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall a PCIe SSD in the system of each capacity and boot to HII.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nInstall a PCIe SSD in the system of each capacity and boot to HII.\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-923", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to the \"View Physical Device Properties\" menu option.\r\n\r\nInput Data", "expected": "1. Under Physical Disk Properties, following fields listed:\r\n    * Physical Device ID\r\n    * Form Factor\r\n    * State\r\n    * Capacity\r\n    * Bus Protocol (PCIe)\r\n    * Bus Protocol Version\r\n    * Device Protocol, \r\n    * Device Life Remaining (AHCI)/Remaining Rated Write Endurance (NVMe)\r\n    * Failure Predicted\r\n    * Firmware revision\r\n    * Serial number\r\n    * Model number\r\n    * Capable Transfer Speed (AHCI)/PCIe Maximum Link Speed(NVMe)\r\n    * PCIe Maximum Link Width\r\n    * PCIe Negotiated Link Width \r\n 2. Physical Device ID is in the form of:\r\n    * AHCI X:Y:Z (Port:Bay:Slot)\r\n    * NVMe \"PCIe SSD in Slot (Slot#) in Bay (Bay#)\r\n    * NVMe HHHL Adapter: \"PCIe SSD in Slot (Slot#)\" \r\n 3. All fields are non-editable strings. \r\n\r\n 4. All options/fields will display corresponding help text at the bottom of the screen or in the help screen."}], "source": ""}
{"case_id": "TC-82414", "name": "PCIe SSD - I2C Communication to all Available NVMe Slots", "status": "Active", "type": "Manual", "description": "This test case is intended to validate that I2C communication is allowed to propgate to all possible NVMe slots in the system.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into the operating system with all U.2 NVMe slots populated and at least one AIC\r\n\r\nNOTE if you don't have enough drives to populate all backplane slots, then simply shutdown the server and move the current drives to the remaining slots until all have been tested.\r\n\r\n\r\nInput Data", "expected": "The boot is successful and all devices are detected"}, {"step": "1", "description": "Description\r\nBoot into the operating system with all U.2 NVMe slots populated and at least one AIC\r\n\r\nNOTE if you don't have enough drives to populate all backplane slots, then simply shutdown the server and move the current drives to the remaining slots until all have been tested.\r\n\r\n\r\nInput Data", "expected": "The boot is successful and all devices are detected"}], "source": ""}
{"case_id": "case-925", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue an NVMe-MI command to each backplane slot (and wherever the AIC PCI slot is). For example, the command could be the NVM Subsystem Health Status Poll:\r\n\r\nlibi2ctest -pec -d -c I2C_Bus_Num 100 100 0 -v 0x20 -a 0xD4 -r 27 0xf 0x19 0x21 0x1 0x0 0x0 0xc8 0x84 0x8 0x0 0x0 0x1 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xd2 0xd4 0x77 0x36 30\r\n\r\nNOTE that the I2C_Bus_Num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file in the iDRAC filesystem\r\n\r\nOr the NVMeMICLI.py tool can be used in place\r\n\r\nExample of a Passing test output using NVMeMICLI.py\r\n\r\npython3 NVMeMICLI.py -c ns -b 1 -s 1\r\nClear Status (0 or 1) = 0\r\nWARNING:root:Backplane - No type match found for BP type 389 in I2Ctopology, guessing...\r\n\r\n\r\n0x00000: 20 0F 19 3B 01 00 00 C0 84 88 00 00 00 00 00 00 ..;............\r\n0x00010: 38 FF 24 01 00 00 00 00 AF B1 49 94 59 8.$.......I.Y\r\n\r\n\r\nReserved - 0x0\r\nNVM Subsystem Status - 0x38\r\nSmart Warnings - 0xff\r\nComposite Temperature - 36\r\nPercentage Drive Life Used - 1\r\nComposite Controller Status - 0x0\r\n\r\n\r\nInput Data", "expected": "The I2C command is successful (no NAK, Unknown error, or Timeout) for all NVMe backplane slots as well as the AIC"}], "source": ""}
{"case_id": "TC-85396", "name": "PCIe SSD - SEP Memory Map Dynamic Drive Presence Detection", "status": "Active", "type": "Manual", "description": "This test case is used to ensure that the SEP memory map will dynamically store the correct state of whether an NVMe drive is present in the system or not.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot the system\r\n\r\nInput Data", "expected": "Implicit[root@rhel91 neuron]# nvme list\r\nNode Generic SN Model Namespace Usage Format FW Rev\r\n--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------\r\n/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0\r\n/dev/nvme3n1 /dev/ng3n1 1240A01FTX47 Dell NVMe CD7 E3.S 1.92TB 1 524.29 MB / 1.92 TB 512 B + 0 B 2.0.0\r\n/dev/nvme2n1 /dev/ng2n1 12T0A01UTX57 Dell NVMe CD7 E3.S 3.84TB 1 6.83 GB / 3.84 TB 512 B + 0 B 2.0.0\r\n/dev/nvme1n1 /dev/ng1n1 Z1H0A067TX57 Dell NVMe CD7 E3.S 3.84TB 1 11.27 GB / 3.84 TB 512 B + 0 B 2.0.0\r\n/dev/nvme0n1 /dev/ng0n1 Y1J0A077TX47 Dell NVMe CD7 E3.S 1.92TB 1 319.97 GB / 1.92 TB 512 B + 0 B 2.0.1\r\n[root@rhel91 neuron]#"}, {"step": "1", "description": "Description\r\nBoot the system\r\n\r\nInput Data", "expected": "Implicit[root@rhel91 neuron]# nvme list\r\nNode Generic SN Model Namespace Usage Format FW Rev\r\n--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------\r\n/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0\r\n/dev/nvme3n1 /dev/ng3n1 1240A01FTX47 Dell NVMe CD7 E3.S 1.92TB 1 524.29 MB / 1.92 TB 512 B + 0 B 2.0.0\r\n/dev/nvme2n1 /dev/ng2n1 12T0A01UTX57 Dell NVMe CD7 E3.S 3.84TB 1 6.83 GB / 3.84 TB 512 B + 0 B 2.0.0\r\n/dev/nvme1n1 /dev/ng1n1 Z1H0A067TX57 Dell NVMe CD7 E3.S 3.84TB 1 11.27 GB / 3.84 TB 512 B + 0 B 2.0.0\r\n/dev/nvme0n1 /dev/ng0n1 Y1J0A077TX47 Dell NVMe CD7 E3.S 1.92TB 1 319.97 GB / 1.92 TB 512 B + 0 B 2.0.1\r\n[root@rhel91 neuron]#"}], "source": ""}
{"case_id": "case-927", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nssh or serial into the iDRAC and go to the iDRAC console (rootshell or gilchrist or racadm debug invoke rootshellash)\r\n\r\nInput Data", "expected": "root access to the iDRAC is obtained"}], "source": ""}
{"case_id": "case-928", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRun the \"bptest\" command\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-929", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect the SEP number of where you're planning on inserting drives\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-930", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect the \"Drive Area\" sub-menu and verify that the presence information is correct\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-931", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert NVMe drives into all available NVMe drive slots\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-932", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-read the \"Drive Area\" section (may require to exit bptest and re-start it)\r\n\r\nInput Data", "expected": "The newly inserted drives correctly show that there are NVMe drives present in the correct slots"}], "source": ""}
{"case_id": "case-933", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRemoval all of the NVMe drives from the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-934", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nRe-read the \"Drive Area\" section (may require to exit bptest and re-start it)\r\n\r\nInput Data", "expected": "The removed drives correctly show as the slots no longer have any NVMe drives present"}], "source": ""}
{"case_id": "TC-85765", "name": "PCIe SSD: discovery after A/C power cycle (long term)", "status": "Active", "type": "Manual", "description": "Verify PCIe SSDs are reliably discovered after A/C power.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}, {"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "5", "description": "Description\r\nUse a controllable PDU to remove AC power from the system after the system boots and the attempt has been made to discover all PCIe SSD devices. This will require some tweaking of parameters depending on how long the device discovery takes.\r\nSequence should look like: boot --> OS login --> Device Detection --> AC power off --> repeat\r\n\r\nInput Data", "expected": "Test is set up to run unattended."}, {"step": "6", "description": "Description\r\nAllow the system to repeat the A/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}, {"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}, {"step": "1", "description": "Description\r\nVerify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-936", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-937", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-938", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-939", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUse a controllable PDU to remove AC power from the system after the system boots and the attempt has been made to discover all PCIe SSD devices. This will require some tweaking of parameters depending on how long the device discovery takes.\r\nSequence should look like: boot --> OS login --> Device Detection --> AC power off --> repeat\r\n\r\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-940", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the A/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-941", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "TC-88986", "name": "PCIe SSD DPC: Hot removal/insertion after  error Injection on different endpoints  (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-943", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-944", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-945", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat the steps 2-3 on a different end point\r\n\r\nInput Data", "expected": "The devices are properly enumerated"}], "source": ""}
{"case_id": "case-946", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove  both the drives on which error  was injected & recovered\r\n\r\nInput Data", "expected": "The devices are removed and not visible both at PCI and NVMe level"}], "source": ""}
{"case_id": "case-947", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nHot insert the drives back in the same slots\r\n\r\nInput Data", "expected": "devices are enumerated properly"}], "source": ""}
{"case_id": "TC-93173", "name": "PCIe SSD: downgraded PCIe link width", "status": "Active", "type": "Manual", "description": "Verify if a PCIe SSD SFF drive trains at a lower link width than advertised max capable, the BIOS reports an error but let's user continue booting without issues when prompted.\r\n\r\nNote:There is no BIOS notification for HHHL/AIC cards that train at a lower link with. BIOS notification  only supported on SFF devices.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SFF SSD device known to train at downgraded link width (or use the Quarch to disable lanes 2 and 3).\r\n\r\nTo configure a quarch to cause a link width downtrain:\r\n1) log into your quarch\r\n2) Issue the following to your target module:\r\n    \"signal:lane#:source 0 <X>\"\r\n         - X is the number of the quarch module (ie quarch slot) you want to downtrain\r\n         - # is the lane to downtrain, 0 through 3\r\n         - ie:  \"signal:lane3:source 0 <1>\"   will disable lane 3 on module 1\r\n3) Repeat step 2 for all lanes you wish to disable\r\n        - lanes 2 and 3 to cause a device to train to x2\r\n\r\nTo restore normal function, set your lanes to source 8.\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SFF SSD device known to train at downgraded link width (or use the Quarch to disable lanes 2 and 3).\r\n\r\nTo configure a quarch to cause a link width downtrain:\r\n1) log into your quarch\r\n2) Issue the following to your target module:\r\n    \"signal:lane#:source 0 <X>\"\r\n         - X is the number of the quarch module (ie quarch slot) you want to downtrain\r\n         - # is the lane to downtrain, 0 through 3\r\n         - ie:  \"signal:lane3:source 0 <1>\"   will disable lane 3 on module 1\r\n3) Repeat step 2 for all lanes you wish to disable\r\n        - lanes 2 and 3 to cause a device to train to x2\r\n\r\nTo restore normal function, set your lanes to source 8.\r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-949", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link width.\r\n\r\nInput Data", "expected": "BIOS halts due to link down train error\r\n\r\nThe error is reported to screen with correct BDF\r\n\r\nThere is an entry for this error in the Lifecycle Log\r\n\r\nIf the system is 15G or newer, then the bay and slot location of the failure will be reported as well"}], "source": ""}
{"case_id": "case-950", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPress F1 to continue.\r\n\r\nInput Data", "expected": "System continues to boot without issues. PCIe SSD device is accessible through the OS without any issues."}], "source": ""}
{"case_id": "case-951", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReboot the system.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-952", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDC power cycle the system (press power button to turn off/on, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-953", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-954", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same as above except the BIOS should not pause during POST"}], "source": ""}
{"case_id": "TC-93174", "name": "PCIe SSD: link training issues", "status": "Active", "type": "Manual", "description": "Verify correct error handling is in place when a PCIe link training error occurs.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card that fails to complete link training (or use the Quarch to turn off all lanes). Install at least one known good PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nSee Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card that fails to complete link training (or use the Quarch to turn off all lanes). Install at least one known good PCIe SSD.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-956", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST.\r\n\r\nInput Data", "expected": "BIOS pauses at an F1/F2 prompt displaying that a link training error has occurred.\r\n\r\nThe error is reported to screen with correct BDF. \r\n\r\nUser can proceed system boot with F1 or F2.\r\n\r\nIf the system is a 15G or newer, then the bay and slot of where the training failure occurred should be shown."}], "source": ""}
{"case_id": "case-957", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReboot the system.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-958", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDC power cycle the system (press power button to turn off/on, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-959", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nAC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-960", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same results except the BIOS won't pause in POST, although the messaging should still be the same."}], "source": ""}
{"case_id": "TC-94156", "name": "PCIe SSD: HII Export Log", "status": "Active", "type": "Manual", "description": "Verify HII Debug Log page displays the correct properties. Verify user is able to save the debug log (smart data) for all drives in the system using Export Log.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInstall at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)\r\n\r\nInput Data", "expected": "System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe)."}, {"step": "1", "description": "Description\r\nInstall at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)\r\n\r\nInput Data", "expected": "System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe)."}], "source": ""}
{"case_id": "case-962", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Export Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).\r\n\r\nInput Data", "expected": "1. Save Debug Log page will show the following options/fields:\r\n\r\nSelect File System target (header)\r\n\r\nSelect File System (link)\r\n\r\n\r\nSelect Directory (header)\r\n\r\nDirectory list selection\r\n\r\n\r\nExport Log File path (header)\r\n\r\nFile path\r\n\r\n\r\nExport Log (link)\r\n\r\n\r\n\r\n\r\n2. All options/fields display corresponding help text at the bottom of the screen."}], "source": ""}
{"case_id": "case-963", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSelect a file system target (ie. if there is more than one USB key inserted)\r\n\r\nInput Data", "expected": "1. All attached file systems are listed under \"Select File System Target\". The default (root) directory should be selected by default.\r\n\r\n2. \"Select File System Target\" (link) can be used to change currently selected File System."}], "source": ""}
{"case_id": "case-964", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect a directory.\r\n\r\nInput Data", "expected": "1. All attached directories are listed under \"Select Directory\". The default (root) directory should be selected by default.\r\n\r\n2. User can choose appropriate directory to save the file to under \"Select Directory\".\r\n\r\n3. \"Select Directory\" (link) can be used to change currently selected Directory."}], "source": ""}
{"case_id": "case-965", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect Export Log.\r\n\r\nInput Data", "expected": "Message displayed is \"Log saved successfully. PCIeSSD_(date time string).log\".\r\n\r\n\r\nFor NVMe PCIe SSD log, User can choose the any filename with extension .log"}], "source": ""}
{"case_id": "case-966", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nBoot into your OS and retrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly. Logs saved on the USB key will be visible as normal. Logs saved to file systems will be in the EFI partition of the OS. This will be mounted as normal in Linux. In windows, get an Administrator powershell prompt, and type \"mountvol P: /S\" (P can be any available mount point). Logs can then be viewed under P:\\ as normal.\r\n\r\nInput Data", "expected": "Data and values are returned correctly for all drives."}], "source": ""}
{"case_id": "case-967", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "TC-94528", "name": "PCIe SSD - I2C Drive FRU Validation", "status": "Active", "type": "Manual", "description": "Verify FRU using CM538_A09_Modular_FRU_Specification.pdfTwo sections to verify, Board Information (p.15) and Thermal Information (p.111)Instructions on how to access and verify the FRU located in RAID Server > NVMe > FRU > FRU_Validation_Instructions.docx", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nRead the device FRU from I2C of a shipping system using the following commands (alternatively, automation script GetPCIeSSDFRU.py can be used):\r\nU.2 NVMe PCIe SSD\r\nlibi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256\r\n\r\nAIC NVMe PCIe SSD\r\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\r\n\r\n# the Virtual_Bus and I2C_Bus_Num fields would have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file on the iDRAC filesystem\r\n\r\n\r\n\r\nInput Data", "expected": "The FRU data is successfully read"}, {"step": "1", "description": "Description\nRead the device FRU from I2C of a shipping system using the following commands (alternatively, automation script GetPCIeSSDFRU.py can be used):\nU.2 NVMe PCIe SSD\nlibi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256\n\nAIC NVMe PCIe SSD\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\n\n# the Virtual_Bus and I2C_Bus_Num fields would have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file on the iDRAC filesystem\n\n\n\nInput Data", "expected": "The FRU data is successfully read"}], "source": ""}
{"case_id": "case-969", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nUsing the same drive(s) that was used in step 1, put those into the new SUT and again read the FRU as in step 1\r\n\r\nNOTE that the virtual/I2C bus number are likely different and need to be updated\r\n\r\n\r\nInput Data", "expected": "The FRU data is successfully read"}], "source": ""}
{"case_id": "case-970", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCompare the FRU contents from step 1 and step 2\r\n\r\nInput Data", "expected": "There are no differences"}], "source": ""}
{"case_id": "TC-102266", "name": "PCIe SSD ESXi DPC: Port Containment with Unresponsive Endpoint (ESXi Only)", "status": "Design", "type": "Manual", "description": "", "precondition": "Make sure the SUT is a CPU direct-attach system, a switch configured system cannot be used for this test case", "steps": [{"step": "1", "description": "Boot into a supported config which has DPC support both from BIOS as well as ESXi OS version", "expected": "Implicit"}, {"step": "1", "description": "Boot into a supported config which has DPC support both from BIOS as well as ESXi OS version", "expected": "Implicit"}], "source": ""}
{"case_id": "case-972", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Determine the parent PCIe BDF to the PCIe SSD under test.(the DUT here is NVMe device with special firmware that can go unresponsive)", "expected": "Implicit"}], "source": ""}
{"case_id": "case-973", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Start generating continuous I/O to the device", "expected": "The I/O starts without any issue"}], "source": ""}
{"case_id": "case-974", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Have the PCIe SSD suddenly stop responding to the Non-Posted Requests\r\n\r\n\r\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.", "expected": "The system doesn't crash and EDR event is logged in the OS log"}], "source": ""}
{"case_id": "case-975", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Check the OS log and look for recovery failure message", "expected": "There will be recovery failure message post EDR event logging as the device won't come back up"}], "source": ""}
{"case_id": "case-976", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Dump the PCIe CFG space of parent port and check DPC Trigger Status", "expected": "The DPC Trigger Status should be cleared.\r\n\r\n\r\nNote: BIOS puts the port in Software Triggered DPC but ESXi brings the port back from containment."}], "source": ""}
{"case_id": "case-977", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Check the SEL log for DPC event", "expected": "The SEL log has DPC event captured"}], "source": ""}
{"case_id": "TC-23886", "name": "GHES Recovery: Error event severity marked as non-recoverable upon crossing threshold (deprecated)", "status": "Active", "type": "Manual", "description": "This test case checks upon crossing the error threshold, the error severity is marked as non-recoverable instead of recoverable.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the Non-DPC aware OS that supports error recovery. Clear SEL logs before starting the test case. \r\n\r\nInput Data", "expected": "The system boots and all devices are visible."}, {"step": "1", "description": "Description\r\nBoot to the Non-DPC aware OS that supports error recovery. Clear SEL logs before starting the test case. \r\n\r\nInput Data", "expected": "The system boots and all devices are visible."}], "source": ""}
{"case_id": "case-979", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject PCIe errors  upto the threshold (16 errors) on NVMe devices and check OS logs. Upon crossing the threshold the error severity is marked as non-recoverable. \r\nEx- UR or Malformed TLP \r\n\r\n\r\nInput Data", "expected": "The correct error severity is set upon crossing the threshold."}], "source": ""}
{"case_id": "case-980", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL logs\r\n\r\nInput Data", "expected": "The SEL logs have all the errors logged with correct BDF and error type information"}], "source": ""}
{"case_id": "TC-50046", "name": "GHES Recovery: Crash with Non-Recoverable OS on PCIe error injection", "status": "Active", "type": "Manual", "description": "The test case is to make sure OS that doesn't support recover crash after receiving FATAL/Non-Fatal  error.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS that doesn't support recovery.\r\nClear SEL logs\r\n\r\n\r\nInput Data", "expected": "The system boots without any issue and all nvme devices are visible"}, {"step": "1", "description": "Description\nBoot to the OS that doesn't support recovery.\nClear SEL logs\n\n\nInput Data", "expected": "The system boots without any issue and all nvme devices are visible"}], "source": ""}
{"case_id": "case-982", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject errors such as UR or Malformed TLP is generated by the nvme device. \r\n\r\nInput Data", "expected": "The system crashes . (BSOD,PSOD etc)"}], "source": ""}
{"case_id": "case-983", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL Logs and decode \r\n\r\nInput Data", "expected": "Make sure the correct errors are logged."}], "source": ""}
{"case_id": "TC-97303", "name": "GHES Recovery : Recovery attempted by fatal/non-fatal error injection", "status": "Active", "type": "Manual", "description": "The test case verify if the BIOS set's fatal/non-fatal error as recoverable if within threshold and system doesn't crash if recovery was attempted and successful", "precondition": "", "steps": [{"step": "1", "description": "Description\r\n\r\nBoot into the system that supports GHES Recovery and OS that supports recovery . Make sure you have debug messages enabled . For example on Linux.\r\n\r\nAdd following kernel boot parameters\r\n\r\nacpi.debug_layer=0xffffffff acpi.debug_level=0x2\r\n\r\n\r\n\r\nInput Data", "expected": "The system boots without any errors."}, {"step": "1", "description": "Description\n\nBoot into the system that supports GHES Recovery and OS that supports recovery . Make sure you have debug messages enabled . For example on Linux.\n\nAdd following kernel boot parameters\n\nacpi.debug_layer=0xffffffff acpi.debug_level=0x2\n\n\n\nInput Data", "expected": "The system boots without any errors."}], "source": ""}
{"case_id": "case-985", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\n\r\nClear the SEL logs and clear the OS logs if possible (ex- dmesg --clear)\r\n\r\nInject a Fatal or Non Fatal errors on one of the  NVMe device. You can either generate Malformed TLP, UR or any other PCIe errors.\r\n\r\n\r\nInput Data", "expected": "It's OS discretion to attempt recovery but most OS does. \r\nThe error reported back by BIOS is marked as \"Recoverable\" . Check OS logs (/var/log/message) to see relevant messages."}], "source": ""}
{"case_id": "case-986", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL logs and make sure the error was logged. \r\n \r\n\r\n\r\nInput Data", "expected": "The errors are logged in the SEL and if recovery was successful device will be available for use."}], "source": ""}
{"case_id": "TC-88957", "name": "PCIe SSD DPC: Multiple error Injection on same endpoint & its upstream port with EDR notification/recovery check (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-988", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-989", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-990", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInject error on up stream port . \r\nThis can be done in many ways. \r\nFor example \r\nChange MPS of up stream  port that is less than endpoint Max Payload Size\r\nRun some I/O to the device\r\n\r\n\r\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "case-991", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 1-4 at least 2 times\r\n\r\nInput Data", "expected": "Endpoint device is enumerated properly"}], "source": ""}
{"case_id": "TC-67861", "name": "PCIe SSD DPC: Error Injection at endpoint & its upstream port  with EDR notification/recovery check (Linux Only)", "status": "Active", "type": "Manual", "description": "The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \r\nCheck test case notes\r\n\r\n\r\n\r\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}, {"step": "1", "description": "Description\nBoot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. \nCheck test case notes\n\n\n\nInput Data", "expected": "All NVMe devices are enumerated and no errors are logged in OS logs."}], "source": ""}
{"case_id": "case-993", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-994", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-995", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInject error on up stream port . \r\nThis can be done in many ways. \r\nFor example \r\nChange MPS of up stream  port that is less than endpoint Max Payload Size\r\nRun some I/O to the device\r\n\r\n\r\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "TC-3422", "name": "OMSA: Verify 'Crypto Erase Sanitize' is issued", "status": "Active", "type": "Manual", "description": "Verify OMSA issues a Sanitize erase (vs. a Format NVM, etc).", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nInsert (or boot with) an NVMe device that supports sanitize Crypto Erase. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nInstall the latest version of OMSA.\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nInsert (or boot with) an NVMe device that supports sanitize Crypto Erase. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nInstall the latest version of OMSA.\r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-997", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than what an OMSA-issues Crypto Erase sanitize will present. It is recommended to do this in Linux.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 \r\n\r\nCollect the sanitize log once the operation has completed. \r\n\r\nLinux:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\nWindows:\r\n\r\npython NVMeMICLI.py -c gl -b 0 -s 1\r\nController ID = 0x0000\r\nNamespace ID = 0xffffffff\r\nLog Page ID = 0x81\r\nLog Page Sub ID = 0x00\r\nNumber of DWORDS = 0x08\r\nRetain Asynchronous Event = 1\r\n\r\n\r\nInput Data", "expected": "The erase operation succeeds. \r\n\r\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xa\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0"}], "source": ""}
{"case_id": "case-998", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNow, issue a Crypto Erase via OMSA while using the OS intended for this testcase, whether that be Linux, Windows or ESXi.\r\n\r\nDump the sanitize get-log page to determine the type of erase issued, e.g.:\r\n\r\nLinux: \r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nWindows:\r\n\r\npython NVMeMICLI.py -c gl -b 0 -s 1\r\nController ID = 0x0000\r\nNamespace ID = 0xffffffff\r\nLog Page ID = 0x81\r\nLog Page Sub ID = 0x00\r\nNumber of DWORDS = 0x08\r\nRetain Asynchronous Event = 1\r\n\r\n\r\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nSee the Sanitize Status Log section of the NVMe spec for a full decode of the log.\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.\r\n\r\nNote: Until OMSA implements JIT-154745, SCDW10 will be '0x4,' indicating Crypto Erase sanitize in restricted mode."}], "source": ""}
{"case_id": "TC-12291", "name": "Sanitize: BIOS Handling in POST", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nIt is recommended to use a Linux OS to initiate the Block Erase sanitize operation.\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nIt is recommended to use a Linux OS to initiate the Block Erase sanitize operation.\r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1000", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nConfirm the sanitize operation is in progress via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nHot remove the device prior to the completion of the sanitize operation.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation is successfully launched; the NVMe device is removed prior to completion of the sanitize operation."}], "source": ""}
{"case_id": "case-1001", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower down the machine. Once the machine is off, insert the NVMe device and power on the machine.\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The sanitize operation should resume immediately following application of power to the NVMe device slot. The drive should not exit POST prior to the completion of the sanitize operation. A message may be printed to the screen indicating a sanitize operation is in progress."}], "source": ""}
{"case_id": "TC-12934", "name": "Verify Crypto Erase Method in HII and iDRAC", "status": "Active", "type": "Manual", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device that support Cryptographic Erase sanitize. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nInstall the latest version of OMSA.\r\n\r\nIt is recommended to use Linux for its passthru command capabilities.\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nBoot to the OS with an NVMe device that support Cryptographic Erase sanitize. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\n\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\n\nInstall the latest version of OMSA.\n\nIt is recommended to use Linux for its passthru command capabilities.\n\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1003", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than that created by a management software-issued Crypto Erase.\r\n\r\nTo issue the Block Erase sanitize:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u\r\n\r\nCollect the sanitize log once the operation has completed. \r\n\r\nLinux:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\n\r\nInput Data", "expected": "The erase operation succeeds. \r\n\r\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xa\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0"}], "source": ""}
{"case_id": "case-1004", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIn the iDRAC GUI, navigate to Configuration -> Storage Configuration. Select the 'Cryptographic Erase' action and the 'Apply at Next Reboot' option; click 'Apply.' Reboot the machine.\r\n\r\nFollowing the execution of the Cryptographic Erase operation via LC (and once the machine has booted to the OS), read the Sanitize log:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "case-1005", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nNext, repeat step 2 in order to update the Sanitize log with data to reflect a Block Erase operation.\r\n\r\nOnce that is finished and verified, boot to HII. Navigate the NVMe device page and issue a Cryptographic Erase. Then, boot to the OS and read the Sanitize log:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\n \r\n\r\n\r\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "case-1006", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\n(Optional)\r\n\r\nRepeat steps 2 and 3, this time selecting the 'Apply at Scheduled Time' operation mode in the iDRAC GUI.\r\n\r\n\r\nInput Data", "expected": "The erase is performed at the expected time and subsequently succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "case-1007", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\n\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 \n\nBegin timing the operation immediately upon issuing the command. Monitor the Sanitize Status log while the operation is in progress by repeatedly issuing\n\nnvme sanitize-log /dev/nvme7n1\n\nuntil the operation completes. Stop the timer once the operation completes.  (The operation is complete once 'SSTAT' is 0b101). \n\n\nInput Data", "expected": "While the operation is in progress, the 'SPROG' and 'SSTAT' fields are updated, For example:\n\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize in Unrestricted Completion Mode was initiated. 'SPROG' contains a value less than 65536, indicating the fraction of the operation that has been completed at the time of the log read. Finally, 'SSTAT' is 0b010, indicating a sanitize operation is in progress. For example:\n\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\nSanitize Progress (SPROG) : 32335\nSanitize Status (SSTAT) : 0x002\nSanitize Command Dword 10 Information (SCDW10): 0xa\nEstimated Time For Overwrite : 0\nEstimated Time For Block Erase : 93\nEstimated Time For Crypto Erase : 0\n\nAdditionally, the timed value of the operation execution duration is withink 10% of the value reported in the 'Estimated Time for Block Erase' field. In the example above, the log indicates the operation is estimated to take 93 s on this particular device."}], "source": ""}
{"case_id": "case-1008", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nRepeat step 2 for a Crypto Erase sanitize:\nnvme sanitize /dev/nvme7n1 -a 4 -u 1 \n\n\n\nInput Data", "expected": "Analogous to the expectation for step 2. Note that a Crypto Erase sanitize may complete virtually instantly (in less than 1 s). Hence, it may not be feasible to time this operation manually nor to observe SPROG and SSTAT at 'in progress' values. However, SCDW10 should be set to '0xc' to indicate a Crypto Erase in Unrestricted Mode was performed."}], "source": ""}
{"case_id": "case-1009", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\n(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).\r\n\r\nRepeat step 2 using the Overwrite sanitize operation (if the device supports this method):\r\n\r\nnvme sanitize /dev/nvme7n1 -a 3 -u 1\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 2. In particular, pay attention to the time it takes to execute the operation and compare this value to the estimated time listed in the Sanitize Status log."}], "source": ""}
{"case_id": "case-1010", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf the device is NVMe rev 1.4 compliant, repeat step 2 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 -d\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 2. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "case-1011", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf the device is NVMe rev 1.4 compliant, repeat step 3 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 4 -u 1 -d\r\n\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 3. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "case-1012", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\n(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).\r\n\r\nIf the device is NVMe rev 1.4 compliant (and support Overwrite sanitize), repeat step 4 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 3 -u 1 -d\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 4. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "TC-61166", "name": "Sanitize hot remove / hot insert; OS Handling", "status": "Active", "type": "Manual", "description": "Confirm sanitize operation behavior if interrupted by a hot remove (and following a reinsertion). Furthermore, confirm OS behavior following a hot insertion of a drive with a sanitize operation in progress.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\nIt is recommended to use a Linux OS to initiate the Block Erase sanitize operation. If this TC was intended to be run in Windows, initiate the operation via Linux and then hot insert the device to the DUT running Windows.\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \n\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\n\nIt is recommended to use a Linux OS to initiate the Block Erase sanitize operation. If this TC was intended to be run in Windows, initiate the operation via Linux and then hot insert the device to the DUT running Windows.\n\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1014", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nConfirm the sanitize operation is in progress via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nHot remove the device prior to the completion of the sanitize operation.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation is successfully launched and interrupted via a hot removal of the device prior to completion."}], "source": ""}
{"case_id": "case-1015", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReinsert the NVMe device. Check the progress of the sanitize operation:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\nIn Windows, check the progress of the operation via:\r\n\r\nWindows:\r\n\r\npython NVMeMICLI.py -c gl -b 0 -s 1\r\nController ID = 0x0000\r\nNamespace ID = 0xffffffff\r\nLog Page ID = 0x81\r\nLog Page Sub ID = 0x00\r\nNumber of DWORDS = 0x08\r\nRetain Asynchronous Event = 1\r\n\r\nContinue monitoring the progress of the operation until it completes. Furthermore, check to ensure the device is enumerated in the system device tree; check OS errors logs, etc.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation should resume on the device; eventually, the sanitize operation completes successfully.\r\n\r\nThe OS enumerates the NVMe device.\r\n\r\nNo abnormal or critical errors are logged."}], "source": ""}
{"case_id": "case-1016", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInstall OMSA.\r\n\r\nIf debug FW is available (or an NVMe device in sanitize failure mode is available), while the OS is up hot insert a drive in sanitize failure mode into the system.\r\n\r\nInput Data", "expected": "The NVMe device is enumerated by the OS. \r\n\r\nOMSA lists the device and initially presents a warning or alert status indicating a recovery action is needed on the device. OMSA presents an option to perform a Cryptographic Erase on the device.\r\n\r\nNo abnormal or critical errors are logged."}], "source": ""}
{"case_id": "case-1017", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf debug FW is available (or an NVMe device in sanitize failure mode is available), attempt to perform a FW update via DUP on the device. \r\n\r\nInput Data", "expected": "The DUP update should fail with an error message indicating the failure was due to the device being in sanitize failure mode and should suggest corrective action of sanitizing the device."}], "source": ""}
{"case_id": "TC-96244", "name": "Sanitize: Permitted vs. Non-Permitted Commands", "status": "Active", "type": "Manual", "description": "While a sanitize operation is in progress, confirm permitted commands execute successfully and that non-permitted commands are aborted.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\n\r\nInput Data", "expected": "Implicit."}, {"step": "1", "description": "Description\nBoot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: \n\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\n\n\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1019", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nConfirm the sanitize operation is in progress via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\n\r\nInput Data", "expected": "The sanitize operation is sucessfully launched."}], "source": ""}
{"case_id": "case-1020", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWhile the sanitize operation remains in progress, issue the following permitted commands:\r\n\r\nnvme smart-log /dev/nvme8n1\r\nnvme error-log /dev/nvme8n1\r\nnvme id-ctrl /dev/nvme8n1\r\nnvme id-ns /dev/nvme8n1\r\nnvme get-feature /dev/nvme8n1 -f 7\r\necho \"abcdef\" | nvme set-feature /dev/nvme7n1 -f 0x81 -l 8\r\nnvme get-feature /dev/nvme7n1 -f 0x81\r\n\r\nIt is crucial that the sanitize operation be in progress while these commands are submitted. Monitor the Sanitize Status log frequently to confirm the operation is in progress:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\n\r\nInput Data", "expected": "All of the commands complete successfully while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1021", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUpon completion of the first sanitize operation, Issue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation remains in progress, issue the following MI command:\r\n\r\npython3 NVMeMICLI.py -c gl -b X -s Y\r\n\r\nwhere the NVMe device is in Bay X and Slot Y. Enter the following parameters when prompted:\r\n\r\nController Id - 0x0000\r\nNamespace Id - 0xffffffff\r\nLogpage Id - 0x02\r\nLog page Sub Id - 0x00\r\nNumber of DWords - 0xxff\r\nRetain Async Event - 0\r\n\r\n\r\nConfirm the sanitize operation is in progress before and after issuing the above MI command via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\n\r\nInput Data", "expected": "The MI command completes successfully while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1022", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a small file with some text data. For example,\r\n\r\nvi /root/Documents/mydata.txt\r\n\r\nEnter some text, \"This is my data in my file!\" and save.\r\n\r\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, attempt to write data to the device:\r\n\r\nhexdump mydata.txt > /dev/nvme7n1\r\n\r\nAgain, confirm the sanitize operation is in progress before and after attempting the write to the device:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\n\r\nInput Data", "expected": "The write to the NVMe device undergoing the sanitize operation should fail. (Hence, the 'hexdump' command should fail)."}], "source": ""}
{"case_id": "case-1023", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, issue the following commands to the device:\r\n\r\nnvme fw-log /dev/nvme7n1\r\nnvme device-self-test /dev/nvme7n1 -s 1\r\n\r\nVerify the targeted device supports device self test before issuing the command. And once again, verify the sanitize is in progress before and after the above commands:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n \r\n\r\n\r\nInput Data", "expected": "The 'fw-log' and 'device-self-test' commands fail while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1024", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf the device supports telemetry logs and persistent event logging, issue another sanitize Block Erase to the NVMe device in unrestricted mode:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, issue the following commands to the device:\r\n\r\nnvme telemetry-log /dev/nvme7n1 -o output.bin\r\nnvme get-log /dev/nvme7n1 -i 0x0d -l 0x20\r\n\r\n\r\nOnce again, verify the sanitize is in progress before and after the above commands:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\n\r\nNote: The persistent event log command above needs to be verified on a device that supports PEL.\r\n\r\n\r\nInput Data", "expected": "The telemetry and persistent event log commands fail while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1025", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, attempt a DUP update of FW on the device.\r\n\r\nVerify the sanitize is in progress before and after launching the DUP:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n \r\n\r\n\r\nInput Data", "expected": "The DUP update should fail and provide an error message that specifies the reason for the failure (a sanitize was in progress on the device) and suggest corrective action (reattempt the update after the sanitize operation has finished). It should also indicate that if repeated attempts to execute the DUP receive the same error message, it is recommended that the drive be sanitized via HII."}], "source": ""}
{"case_id": "TC-8786", "name": "PCIe SSD: PCIe SSD: Max link width/ Link Speed on a hot inserted device", "status": "Active", "type": "TBD", "description": "Verify that a PCIe SSD device can train to max supported link width and link speed on hot insertion", "precondition": "", "steps": [{"step": "1", "description": "Description\n\nBoot to the OS.\n\n\n\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\n\nHot insert the the device under test when the OS is fully booted.\n\n\n\nInput Data", "expected": "Verify that the new hardware is added to the system and will configure it if the driver is available."}, {"step": "3", "description": "Description\n\nRead the Link Status Register of the parent PCIe port immediately above the NVMe endpoint device.\n\n\n\nInput Data", "expected": "The Data Link Layer Link Active bit is set and\n\nThe PCIe SSD settings are trained to max supported link width and speed"}, {"step": "4", "description": "Description\n\nPerform some I/O on the hot inserted NVMe device\n\n\n\nInput Data", "expected": "I/O is successful"}, {"step": "5", "description": "Description\n\nRepeat step 3 and 4 but this time hot add the drive while the system is booting to OS.\n\n\n\nInput Data", "expected": "Same result as in 3 and 4."}], "source": ""}
{"case_id": "TC-9772", "name": "PCIeSSD: RE (iDRAC GUI) physical disk Firmware inventory", "status": "Active", "type": "Manual", "description": "Verify iDRAC GUI discovers NVMe PCIe SSDs and displays its current firmware correctly", "precondition": "", "steps": [{"step": "1", "description": "Description\n\nInstall the maximum number supported PCIe SSDs\n\n\n\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\n\nPlace your system on the network such that you're able to remotely access it via iDRAC.\n\n\n\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\n\nLaunch the iDRAC GUI and navigate to Overview --> System Inventory--> Firmware Inventory.\n\n\n\nInput Data", "expected": "From the list of all the components check for PCIe SSD and its Current firmware version."}], "source": ""}
{"case_id": "TC-14919", "name": "PCIe SSD - LED Management - Status and Activity LED with and without IO", "status": "Active", "type": "Manual", "description": "Validate that the activity LED should always be blinking Green as long as IO is running and should be off when there is not any activity going on in the drive. Status LED is unaffected by activity LED.", "precondition": "", "steps": [{"step": "1", "description": "Description\n\nInstall atleast one healthy PCIe SSDs and boot to OS\n\n\n\nInput Data", "expected": "The status LED is solid Green as soon as backplane receives power and/or device has been inserted to already powered on backplane."}, {"step": "2", "description": "Description\n\nOnce in OS start running IO to the device\n\n\n\nInput Data", "expected": "The device activity LED starts Blinking Green wehere as the status LED stays solid green\n\n\n\nFor EDSFF devices: The Green Status LED will blink during I/O."}, {"step": "3", "description": "Description\n\nStop running IO to the device\n\n\n\nInput Data", "expected": "The device activity LED stops Blinking Green and the status LED is Solid Green.\n\n\n\nFor EDSFF devices: The Green Status LED will return to solid once I/O has completed."}], "source": ""}
{"case_id": "TC-11686", "name": "PCIe SSD - Led Management - HII - Blink/Un-Blink Drives", "status": "Active", "type": "Manual", "description": "Validate that issuing a blink command from HII results in the status LED for the device to blink green regardless of the device's current state", "precondition": "", "steps": [{"step": "1", "description": "Description\n\nInstall two or more PCIe SSDs and boot the system into the OS. The drives used for this test should be at different state conditions.\n\n\n\n\n\nInput Data", "expected": "The state of the drive should be solid Green"}, {"step": "2", "description": "Description\n\nReboot the system and go to HII (You can go to HII by pressing F2 during boot) and check the state of the drives during reboot.\n\n\n\nInput Data", "expected": "During reboot the state of the drive should stay Solid green."}, {"step": "3", "description": "Description\n\nSelect the Physical disks from the listed device list\n\n\n\nInput Data", "expected": "-User is able to select the PCIe SSD physical disks installed in the system"}, {"step": "4", "description": "Description\n\nOpen the drop down menu for one of the drives and select the operation Blink\n\n\n\nInput Data", "expected": "- Drive LED blinks Green with identify pattern 250 milliseconds on and 250 milliseconds off regardless of the device current state\n\n\n\nFor ESDFF devices, the Blue LED will blink one second on and one second off. The Status LED should not be affected by identify operations."}, {"step": "5", "description": "Description\n\nOpen the drop down menu for the second drive and select the operation Blink\n\n\n\nInput Data", "expected": "-Second drive LED blinks with the same pattern as shown in step 4"}, {"step": "6", "description": "Description\n\nOpen the drop down menu for the drive selected in step 4 or 5 and select unblink\n\n\n\nInput Data", "expected": "- Blinking stops for drive from step 4 or 5 and returns to the LED pattern and color correspondent to just before the blink command was issued."}], "source": ""}
{"case_id": "TC-87484", "name": "PCIeSSD: RE (iDRAC GUI) physical disk inventory", "status": "Active", "type": "Manual", "description": "Verify iDRAC GUI storage overview discovers NVMe PCIe SSDs and displays its properties correctly", "precondition": "", "steps": [{"step": "1", "description": "Description\n\nInstall the maximum number supported PCIe SSDs\n\n\n\nInput Data", "expected": "Implicit."}, {"step": "2", "description": "Description\n\nPlace your system on the network such that you're able to remotely access it via iDRAC.\n\n\n\nInput Data", "expected": "Implicit."}, {"step": "3", "description": "Description\n\nLaunch the iDRAC GUI and navigate to Storage --> Summary.\n\n\n\nInput Data", "expected": "Number displayed in the \"summary of disks\" field under \"Physical Disks\" should include all PCIe SSDs in the system\n\n\n\n\n\nPhysical Disks summary should report the correct state for the NVMe PCIe SSDs. These include; Status, Name, State, Slot Number, Size, Security Status, Bus Protocol, Media Type, Hot Spare and Remaining Write Endurance."}, {"step": "4", "description": "Description\n\nClick on \"Physical Disks\"\n\n\n\nInput Data", "expected": "All disks in the system including NVMe PCIe SSDs are listed under \"Health and Properties\"\n\n\n\n\n\nStatus, Name, Slot Number, Size, Security Status, Bus Protocol, Media Type,, Hot Spare, and Remaining Rated Write Endurance fields should be properly populated."}, {"step": "5", "description": "Description\n\nChange the filter to \"Group by\" Virtual Disks.\n\n\n\nInput Data", "expected": "No NVMe PCIe SSDs are listed under \"Health and Properties\""}, {"step": "6", "description": "Description\n\nSetup filter by changing \"Group by\" to Enclosure PCIe SSD BP 1 and click apply. For Universal BP it will be listed as BP14G+EXP\n\n\n\nInput Data", "expected": "Only NVMe PCIe SSDs are listed under \"Health and Properties\"\n\n\n\nNote: AIC PCIe SSDs will not show up\u201d"}, {"step": "7", "description": "Description\n\nExpand the Advanced Properties for the NVMe PCIe SSDs and verify all information displayed is correct.\n\n\n\nInput Data", "expected": "Advanced Properties should display correct information for the following fields:\n\n\n\nStatus, Name, Device Description, State, slot Number, Size, Bus Protocol, Media Type Remaining Rated Write Endurance, Failure Predicted, PCIe Negotiated Link Speed, PCIe Max Link Speed, Device Protocol, Model, Manufacturer, Product ID, Revision, Serial Number, Form Factor, PCIe Negotiated Link Width, PCIe Capable Link Width, Self Encrypting Drive Capability, Controller (For 2.5\" SFF only), and Enclosure ."}], "source": ""}
{"case_id": "DSSTC-571", "name": "SED - Security Key Change and Locked Foreign Configuration Import (PERC)", "status": "", "type": "Manual - PERC", "description": "Verify SED can be locked and unlocked by PERC", "precondition": "", "steps": [{"step": "1", "description": "Boot SUT with SED drive", "expected": "SUT boots successfully"}, {"step": "2", "description": "View all the controllers, PDs, VDs and the slot numbers of the target drive. # perccli /call/eall/sall show", "expected": "Note the Controller id, Enclosure id and the slot id of the target drive."}, {"step": "3", "description": "Convert the drive to JBOD/Non-RAID Mode. PERC11: # perccli /cx/ex/sx set jbod force PERC12: # perccli2 /cx/ex/sx set NonRAID force", "expected": "The drive was successfully set to JBOD/Non-RAID Mode."}, {"step": "4", "description": "Enable the Security Key on the Controller and set the Security Key with the Key ID provided. PERC11: # perccli /cx set securitykey=Dell@123 keyid=1 PERC12: # perccli2 /cx set security securitykey=Dell@123 keyid=1 Alternatively, go to iDRAC GUI -> Storage -> Controllers -> Actions -> Edit -> Security -> Create Security Key", "expected": "The Security Key and Key ID was successfully set on the Controller."}, {"step": "5", "description": "Secure the drive. # perccli /cx set security=on", "expected": "Secured PD created."}, {"step": "6", "description": "Physically remove the drive from SUT. Change Security Key on the Controller. PERC11: # perccli /cx set securitykey=Dell@123456 oldsecuritykey=Dell@123 keyid=1 PERC12: # perccli2 /cx set security rekey oldsecuritykey=Dell@123 securitykey=Dell@123456 keyid=1", "expected": "The Controller Security Key was changed successfully."}, {"step": "7", "description": "Re-insert the drive into SUT. Verify the PD State is \"F\". # perccli /call/eall/sall show", "expected": "The PD is in Foreign State."}, {"step": "8", "description": "Attempt to import foreign configuration by providing old controller security key. PERC11: # perccli /cx/fall import securityKey=Dell@123 PERC12: # perccli2 /cx/fall import securityKey=Dell@123 keyid=1 Alternatively, go to BIOS System setup -> Device Settings -> RAID Controller -> Main Menu -> Configuration Management -> Manage Foreign Configuration -> Enter Passphrase for Locked Disks", "expected": "The foreign PD is unlocked and imported successfully."}, {"step": "9", "description": "Verify the Controller and PD State. # perccli /call/eall/sall show", "expected": "No Foreign Configuration on the Controller. The PD is in JBOD/Non-RAID Mode."}, {"step": "10", "description": "Convert the drive to Unconfigured Good State. PERC11: # perccli /cx/ex/sx set good force PERC12: # perccli2 /cx/ex/sx set uconf force", "expected": "The drive was set to Unconfigured Good State successfully."}, {"step": "11", "description": "Perform Secure Erase on the drive. PERC11: # perccli /cx/ex/sx secureerase force PERC12: # perccli2 /cx/ex/sx start erase type=reprovision force", "expected": "The Drive Secure Erase was performed successfully."}, {"step": "12", "description": "Delete the Security Key on the Controller. PERC11: # perccli /cx delete securitykey PERC12: # perccli2 /cx delete security securitykey", "expected": "The Security Key on the Controller was deleted successfully."}], "source": ""}
{"case_id": "DSSTC-1067", "name": "Verify a consistency check on new VDs completes successfully", "status": "", "type": "Manual - PERC", "description": "Confirm that no drive issues are found with a consistency check of a fault tolerant RAID VD on PERC", "precondition": "", "steps": [{"step": "1", "description": "Boot into BIOS Setup, go to Devices, RAID (PERC) controller.", "expected": "Successfully boots into controller BIOS."}, {"step": "2", "description": "If have not already been done, create a RAID 1 or 5 VD, according to SOW if applicable. Otherwise create a small VD (100 GB or so) for the sake of time. Select a full initialization. # perccli /call/vall show // Get VD number # perccli /cx/vx start init full force # perccli /cx/vx show init // Check initialization status", "expected": "Successfully creates VDs."}, {"step": "3", "description": "Boot into OS.", "expected": ""}, {"step": "4", "description": "Verify full initialization is complete. Example: perccli /c0 /v0 show init", "expected": "Full initialization completes successfully."}, {"step": "5", "description": "Execute consistency check on VDs using perccli. Example: perccli /c0 /v0 start cc", "expected": "Consistency check execution is successful. CC may take some time depending on size of VD."}, {"step": "6", "description": "Verify that CC was executed in controller event logs and iDRAC Lifecycle log (PERC.) Check for start, stop, completed etc. Example: perccli/c0 /v0 show cc (show cc progress) Note: CC will not run if full init has not been completed. After cc complete: perccli /c0 show events > events.log", "expected": "Events captured in logs."}, {"step": "7", "description": "Allow CC to complete.", "expected": "CC completes successfully. No inconsistency should be found."}], "source": ""}
{"case_id": "DSSTC-3266", "name": "iDRAC - iDRAC Logs Check", "status": "", "type": "Manual", "description": "Check for errors reported against the device under test in the Lifecycle Log and the System Event Log. This check should occur throughout validation, not just once.", "precondition": "", "steps": [{"step": "1", "description": "Navigate to the Lifecycle Log section of the iDRAC GUI located at Maintenance -> Lifecycle Log", "expected": "The contents of the Lifecycle log is displayed."}, {"step": "2", "description": "Check the Lifecycle log for errors related to", "expected": ""}, {"step": "3", "description": "Navigate to Maintenance -> System event Log", "expected": "System Event Log displays."}, {"step": "4", "description": "Check the SEL log for errors related to device under test.", "expected": "No error or warning messages related to device under test are present."}], "source": ""}
{"case_id": "DSSTC-4210", "name": "Verify drive information in BIOS via UEFI HII or RAID/HBA Controller Utility", "status": "", "type": "Manual", "description": "Verify the Drive under Test (DUT) is able to be detected by BIOS and HII device configuration (System Setup)", "precondition": "", "steps": [{"step": "1", "description": "Power on the (SUT) Server Under Test. When prompted, press F2 to enter System Setup (BIOS).", "expected": "Server powered and successfully entered System BIOS."}, {"step": "2", "description": "This step is only for CPU-direct NVMe SSD. For drive installed on PERC, please omit. Check if the NVMe SSD is able to be detected in Device Settings list. And check the information of NVMe SSD shows in the BIOS are correct comparing to the NVMe SSD specification. Note: Some channel drives might fail this test when BIOS NVMe Driver was set to default \u201cDell Qualified Drives\u201d. \u201cAll Drives\u201d option might help these channel drives PASS this test, but might cause some other unexpected system behaviors. If \"All Drives\" option is found to be necessary for correct functionality, note this in the test report and communicate to the DM for the intake.", "expected": "NVMe SSD is able to be detected by BIOS. The NVMe SSD information shown in the BIOS are correct as its specification."}, {"step": "3", "description": "This step is only for drive installed on PERC. For CPU-direct NVMe SSD, please omit.\u00a0Enter the BIOS setup -> Device Settings -> RAID Controller Configuration Utility.", "expected": "Utility launches correctly or access the RAID controller configuration normally."}, {"step": "4", "description": "This step is only for drive installed on PERC. For CPU-direct NVMe SSD, please omit.\u00a0Verify all drives attached to controller/s are displayed.", "expected": "All attached drives are reported on the correct channel and ID."}, {"step": "5", "description": "This step is only for drive installed on PERC. For CPU-direct NVMe SSD, please omit.\u00a0 Verify\u202fthe correct drive model, drive capacity, and firmware version is displayed for each drive.", "expected": "All the drive Information is consistent with the drive label (SAS/SATA protocol, speed, capacity, etc) and the known latest FW update. Drive mode is reported properly for all integrated devices."}], "source": ""}
{"case_id": "DSSTC-4668", "name": "SED - Secured VD Creation and Drive Secure Erase (PERC)", "status": "", "type": "Manual - PERC", "description": "Check that drives can be secured through creating a secure VD and can be erased after deleting the VD.", "precondition": "", "steps": [{"step": "1", "description": "Although perccli utility is easier to run this test, it is allowed to execute on iDRAC or BIOS.", "expected": ""}, {"step": "2", "description": "Boot into OS and install the DSS Validation Toolkit. perccli utility will be installed as part of the DSS Validation Toolkit.", "expected": "perccli utility is installed in the SUT."}, {"step": "3", "description": "Execute the command below to choose the Physical disks you want to Secure Erase. View all the PDs, VDs, controller and the slot numbers of the drive. # perccli /call/eall/sall show", "expected": "Noted the Controller id, Enclosure id and the slot id of the drive to perform Secure Erase on."}, {"step": "4", "description": "Execute the command below to enable the Security Key on the Controller and set the Security Key with the Key ID provided. PERC11: # perccli /cx set securitykey=Dell@123 keyid=1 PERC12: # perccli2 /cx set security securitykey=Dell@123 keyid=1", "expected": "The Security Key and Key ID was successfully set on the Controller."}, {"step": "5", "description": "VD creation and perccli secure erase does not support drive in Non-RAID State. Execute the command below to convert the drive to Unconfigured Good State. PERC11: # perccli /cx/ex/sx set good force PERC12: # perccli2 /cx/ex/sx set uconf force", "expected": "The drive was successfully set to Unconfigured Good State."}, {"step": "6", "description": "Execute the command below to create a Secured Virtual Disk. PERC11: # perccli /cx add vd r0 drives=EnclosureID:DriveSlotID SED PERC12: # perccli2 /cx add vd r0 drives=EnclosureID:DriveSlotID secure", "expected": "The Secured Virtual Disk was successfully created."}, {"step": "7", "description": "Execute the command below to verify the security key was enabled on the drive and the physical disk was secured. PERC11: # perccli /cx/ex/sx show securityKey keyid PERC12: # perccli /cx/ex/sx show security keyid", "expected": "The security key was successfully enabled on the drive and the physical disk was successfully secured."}, {"step": "8", "description": "Before a secure erase of the drive can occur, the virtual disk needs to be deleted. Execute the command below to choose the VD you want to delete. # perccli /call/vall show", "expected": "Noted the Controller id and virtual disk to delete."}, {"step": "9", "description": "Execute the command below to delete the VD you choose. # perccli /cx/vx del force", "expected": "Status = Success Description = Delete VD succeeded The virtual disk is deleted successfully."}, {"step": "10", "description": "Perform Secure Erase on the drive we selected. PERC11: # perccli /cx/ex/sx secureerase force PERC12: # perccli2 /cx/ex/sx start erase type=reprovision force /cx - Specifies a controller where x is the controller index /ex - Specifies an enclosure where x is the enclosure device ID. /sx - Specifies a physical drive where x is the slot number Note: You will receive error message \"Secure Erase is not allowed on this drive\" if the SED drive does not support Secure Erase feature.", "expected": "Status = Success Description = Drive Secure Erase Succeeded. The Drive Secure Erase was performed successfully. All the SED drives should be in Unconfigured Good state after Secure Erase."}, {"step": "11", "description": "Execute the command below to delete the Security Key on the Controller. PERC11: # perccli /cx delete securitykey PERC12: # perccli2 /cx delete security securitykey", "expected": "The Security Key on the Controller was deleted successfully."}], "source": ""}
{"case_id": "DSSTC-5255", "name": "Opal: Opal Drive Identification - perccli", "status": "", "type": "Manual - PERC", "description": "Using Opal drives, verify PERCcli correctly identifies them as Opal and supporting encryption.", "precondition": "", "steps": [{"step": "1", "description": "Show all the PD by running: # perccli /call/eall/sall show", "expected": "All the PD listed. For PERC11: The column \"SED\" in the PD list shows \"Y\" for TCG Opal drives. For PERC12: The column \"SED_Type\" in the PD list shows \"Opal\" for TCG Opal drives."}, {"step": "2", "description": "Choose an Opal drive and output the detailed information by running: # perccli /cx/ex/sx show all J", "expected": "The detailed information of the Opal drive listed in JSON format."}, {"step": "3", "description": "Verify the Opal drive is identified as Opal compliant. For PERC11, check \"FDE Type=TCG Opal\" For PERC12, check \"SED_Type=Opal\"", "expected": "Drive shows encryption capable, encryption not being disabled by FW, and type OPAL"}, {"step": "4", "description": "Verify the Opal drive is identified as SED capable. For PERC11/12, check \"SED Capable=Yes\"", "expected": "Drive shows encryption capable, encryption not being disabled by FW, and type OPAL"}], "source": ""}
{"case_id": "DSSTC-5262", "name": "Opal: Opal Drive Identification and Cryptographic Erase - iDRAC", "status": "", "type": "Manual", "description": "Verify iDRAC correctly identifies Opal drive as Opal. iDRAC is able to successfully execute Cryptographic Erase option on an Opal-enabled secure drive.", "precondition": "", "steps": [{"step": "1", "description": "Start with Opal enabled drive in system. Use a non-boot drive for this test. Note that the drive needs to be unlocked or reverted for iDRAC to be able to do a Cryptographic Erase.", "expected": ""}, {"step": "2", "description": "Go to iDRAC Storage -> Physical Disks. Choose a target Opal drive, click the \"+\" sign next to the PD, and check the drive information. Verify the PD security related information indicates the drive which support encryption (Opal) correctly. \"Encryption Protocol\" = \"TCG Opal SSC\" \"Security Status\" = \"Encryption Capable\"", "expected": "iDRAC lists the PD and shows Opal capability correctly. Drive shows encryption protocol as Opal and encryption capable. Notes: Some channel drives might fail this test when BIOS NVMe Driver was set to default \u201cDell Qualified Drives\u201d. \u201cAll Drives\u201d option might help these channel drives PASS this test but might cause some other unexpected system behaviors."}, {"step": "3", "description": "Omit this step if the target Opal drive is already in Ready State. PERC11: If the target Opal drive is Non-RAID State, go to \"Virtual Disks\" and delete its Non-RAID VD. PERC12: Select the target Opal drive and perform \"Convert to RAID\" operation.", "expected": "Drive is successfully converted to Ready State."}, {"step": "4", "description": "Select the target Opal drive PD and select Cryptographic Erase in \"Actions\" drop-down menu. Run the erase and verify successful completion.", "expected": "Cryptographic Erase is complete successfully."}], "source": ""}
{"case_id": "DSSTC-5289", "name": "Drive PD Management - perccli", "status": "", "type": "Manual - PERC", "description": "Verify drive management using perccli", "precondition": "", "steps": [{"step": "1", "description": "Install latest perccli utility on the system.", "expected": ""}, {"step": "2", "description": "Verify drive properties. # perccli /call show all // Show information about all controllers, including enclosure & slots. # perccli /cx/ex/sx show all // Show properties for a specific disk. Substitute 'x' for the controller ID, enclosure ID, and slot number.", "expected": "All expected drive properties are displayed with accurate value."}, {"step": "3", "description": "Set the drive to Non-RAID mode. PERC11: # perccli /cx/ex/sx set jbod force PERC12: # perccli2 /cx/ex/sx set NonRAID force", "expected": "Non-RAID Disk was created on the drive."}, {"step": "4", "description": "Set the drive to Unconfigured Good status. PERC11: # perccli /cx/ex/sx set good force PERC12: # perccli2 /cx/ex/sx set uconf force", "expected": "The drive was set to Unconfigured Good status successfully."}, {"step": "5", "description": "Perform PD Erase on the drive. Any erase method that could successfully erase the drive was accepted. For Non-SED drive, perform Crypto Erase or Sanitize: PERC11: # perccli /cx/ex/sx start erase crypto PERC12: # perccli2 /cx/ex/sx start erase type=crypto force For SED drive, perform Secure Erase: PERC11: # perccli /cx/ex/sx secureerase force PERC12: # perccli2 /cx/ex/sx start erase type=reprovision force You can also perform Sanitize on PERC12: # perccli2 /cx/ex/sx start erase type=sanitize mode=2 force", "expected": "Erase command performed on the drive. PD erase starts and completes successfully. Erase progress is available every few seconds in TTY log and in the application."}, {"step": "6", "description": "Perform \"Export Log\" on a drive. # perccli /cx show all logfile=<perccli_controller>.txt # perccli /cx/ex/sx show all logfile=<perccli_drive>.txt", "expected": "Logs exported successfully"}, {"step": "7", "description": "Create Virtual Disk on the drive. # perccli /cx add vd r0 drives=<e:s>", "expected": "Virtual Disk could be created successfully."}], "source": ""}
{"case_id": "DSSTC-5291", "name": "Drive PD Management - HII", "status": "", "type": "Manual - PERC", "description": "Verify drive management using HII (BIOS Setup)", "precondition": "", "steps": [{"step": "1", "description": "Go to BIOS System Setup -> Device Settings -> RAID Controller -> Physical Disk Verify drive properties Notes: If the drive is a TCG Opal drive, the property should indicate Opal security.", "expected": "All expected drive properties are displayed with accurate value. Opal security verified for TCG Opal drive."}, {"step": "2", "description": "Perform \"Convert to Non-RAID Disk\" operation", "expected": "Non-RAID Disk created on the drive"}, {"step": "3", "description": "Perform \"Convert to RAID Capable\" operation", "expected": "Non-RAID Disk deleted"}, {"step": "4", "description": "Perform Cryptographic Erase on a drive", "expected": "PD erase starts and completes successfully."}, {"step": "5", "description": "Blink and then unblink LEDs", "expected": "LEDs can be blinked and then unblinked"}], "source": ""}
{"case_id": "DSSTC-5346", "name": "iDRAC - HW Inventory Verification (Channel Commodities)", "status": "", "type": "Manual", "description": "The purpose of this test case is to gather information in iDRAC's HW Inventory section for channel devices - that is, devices that are NOT Dell-certified and who's information is NOT expected to fully populate in iDRAC. Channel devices usually have spotty coverage in iDRAC. This test case is NOT to be run as a pass / fail. Instead, this test case should be utilized as one would think of a 'task' -- once all information is gathered in the HW Inventory, report the information and mark this test case as 'Complete'.", "precondition": "", "steps": [{"step": "1", "description": "Log in to the iDRAC web UI and navigate to System -> Inventory -> HW Inventory.", "expected": ""}, {"step": "2", "description": "Locate the DUT(s) in the list of HW devices. It may be necessary to page through the HW Inventory to locate the DUT. IMPORTANT: Some PCI devices may have more than one list element. It may be necessary to remove the DUT and compare the two inventories in order to identify all of the associated HW devices, such as PCI or UHCI chipsets. IMPORTANT: If the Device Under Test (DUT) is a channel NVMe drive, the System BIOS setting (System BIOS Settings - NVMe Settings - BIOS NVMe Driver) may affect the test results. Generally, setting it to \"All Drives\" allows more drive properties to be recognized in iDRAC. Using the default setting \"Dell Qualified Drives\" will only show limited properties. Note: Testing should follow the settings specified in the test requirements. If not specified, use the default settings. When issues arise, communicate with the Device Manager (DM) to determine if settings need to be changed for testing.", "expected": "The DUT is present in the list of HW."}, {"step": "3", "description": "Review the hardware information for the DUT and verify that all of the device's attributes are populated and accurate. Attributes that are listed as \"Information Not Available\" mean that iDRAC cannot find that information. NOTE: Some of the bus numbers are in hex and others are in decimal. It is recommended to use tools such as those provided by the OS or the vendor to verify the accuracy of the device's attributes.", "expected": "Collect all HW Inventory information shown and add this information to your project folder (HW Inventory allows you to export its list to an XML file) Make special note of any missing information in the DUTs section of the HW Inventory in the final report."}], "source": ""}
{"case_id": "DSSTC-5351", "name": "Opal: Security Operations - sedutil (PCIe)", "status": "", "type": "Manual", "description": "This test case verifies the Opal functionality of MBR Shadowing, Locking Range, and PSID Revert on an TCG OPAL-compliant drive in OS. This test case only applies to PCIe-direct SSD.", "precondition": "", "steps": [{"step": "1", "description": "This test case only applies to PCIe-direct SSD. Get PSID printed on the drive label to revert the drive and erase all data. This will be a long hexadecimal number. If there are any dashes in the number, remove them. Follow the steps in Test Setup to complete sedutil tool installation.", "expected": ""}, {"step": "2", "description": "Scan for Opal compliant drives: # sedutil-cli --scan Example: Scanning for Opal compliant disks /dev/nvme0 No INTEL SSDPF2KE128T1 9CV10200 /dev/nvme1 2 MTFDKCC3T8TGP-1BK1DABYY E3MQ000 /dev/nvme0: No Opal Support /dev/nvme1: TCG Opal2.0 Compliant", "expected": "Opal compliant disks are listed."}, {"step": "3", "description": "Make sure the drive is a valid SED drive: # sedutil-cli --isValidSED /dev/nvmeX Example: /dev/nvme1 SED -2- MTFDKCC3T8TGP-1BK1DABYY E3MQ000 /dev/nvme1: TCG Opal2.0 Compliant", "expected": "Disks are indicated to be SED."}, {"step": "4", "description": "Perform the initial setup step: # sedutil-cli --initialSetup /dev/nvmeX Example: # sedutil-cli --initialSetup Dell1234 /dev/nvme1 takeOwnership complete Locking SP Activate Complete LockingRange0 disabled LockingRange0 set to RW MBRDone set on MBRDone set on MBREnable set on Initial setup of TPer complete on /dev/nvme1", "expected": "Initial setup is successful."}, {"step": "5", "description": "Disable MBR shadowing and mark MBR unlocking process as complete: # sedutil-cli --setMBREnable off /dev/nvmeX # sedutil-cli --setMBRDone off /dev/nvmeX Example: # sedutil-cli --setMBREnable off Dell1234 /dev/nvme1 MBRDone set on MBREnable set off # sedutil-cli --setMBRDone off Dell1234 /dev/nvme1 MBRDone set off", "expected": "MBR shadowing is disabled. Data access is allowed without pre-boot authentication."}, {"step": "6", "description": "Enable a Locking Range on the entire drive: # sedutil-cli --enableLockingRange 0 /dev/nvmeX Example: # sedutil-cli --enableLockingRange 0 Dell1234 /dev/nvme1 LockingRange0 enabled ReadLocking,WriteLocking", "expected": "Locking range is enabled. The entire drive is set to a locked state."}, {"step": "7", "description": "Set the status of the Locking Range to Read/Write access: # sedutil-cli --setLockingRange 0 RW /dev/nvmeX Example: # sedutil-cli --setLockingRange 0 RW Dell1234 /dev/nvme1 LockingRange0 set to RW", "expected": "Locking range is set to Read/Write access."}, {"step": "8", "description": "Run Read/Write I/O for 30s on the drive: # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=readwrite --runtime=30", "expected": "Verify successful data access and no error reported. Read and write I/O runs without error."}, {"step": "9", "description": "Set the status of the Locking Range to Locked Mode: # sedutil-cli --setLockingRange 0 LK /dev/nvmeX Example: # sedutil-cli --setLockingRange 0 LK Dell1234 /dev/nvme1 LockingRange0 set to LK", "expected": "Locking range is set to locked (LK.)"}, {"step": "10", "description": "Run Read I/O on the drive. I/O running should Fail. # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=read --runtime=5 Run Write I/O on the drive. I/O running should Fail. # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=write --runtime=5", "expected": "Verify data access is locked. Read and write I/O should both fail."}, {"step": "11", "description": "Set the status of the Locking Range to Read Only: # sedutil-cli --setLockingRange 0 RO /dev/nvmeX Example: # sedutil-cli --setLockingRange 0 RO Dell1234 /dev/nvme1 LockingRange0 set to RO", "expected": "Locking range is set to read-only."}, {"step": "12", "description": "Run Read I/O on the drive. I/O running should Succeed. # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=read --runtime=5 Run Write I/O on the drive. I/O running should Fail. # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=write --runtime=5", "expected": "Verify Read access is allowed but Write access is locked. Reads should succeed and writes should fail in read-only mode."}, {"step": "13", "description": "Set the status of the Locking Range back to Read/Write access: # sedutil-cli --setLockingRange 0 RW /dev/nvmeX Example: # sedutil-cli --setLockingRange 0 RW Dell1234 /dev/nvme1 LockingRange0 set to RW", "expected": "Locking range is set back to read-write."}, {"step": "14", "description": "Run Read/Write I/O for 30s on the drive: # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=readwrite --runtime=30", "expected": "Verify Read/Write data access is unlocked/restored and no error reported. Read and write I/O runs without error."}, {"step": "15", "description": "Set the status of the Locking Range to Locked Mode again: # sedutil-cli --setLockingRange 0 LK /dev/nvmeX Verify consistent Locking Range functionality. Example: # sedutil-cli --setLockingRange 0 LK Dell1234 /dev/nvme1 LockingRange0 set to LK", "expected": "Locking range is set to locked (LK.)"}, {"step": "16", "description": "Disable the Locking Range on the drive: # sedutil-cli --disableLockingRange 0 /dev/nvmeX Example: # sedutil-cli --disableLockingRange 0 Dell1234 /dev/nvme1 LockingRange0 disabled", "expected": "Locking range is disabled."}, {"step": "17", "description": "Run Read/Write I/O for 30s on the drive: # fio --direct=1 --filename=/dev/nvmeXn1 --name=test --rw=readwrite --runtime=30", "expected": "Verify successful data access and no error reported. Read and write I/O runs without error."}, {"step": "18", "description": "Use PSID to revert the drive and erase all data. PSID is a long hexadecimal number printed on the drive label. If there are any dashes in the number, remove them. # sedutil-cli --yesIreallywanttoERASEALLmydatausingthePSID /dev/nvmeX Example: # sedutil-cli --yesIreallywanttoERASEALLmydatausingthePSID 016C0234011A0941AB08EE89D18D8C87 /dev/nvme1 revertTper completed successfully", "expected": "Drive is reverted successfully."}], "source": ""}
{"case_id": "DSSTC-5381", "name": "iDRAC Compatibility with Drive", "status": "", "type": "Manual", "description": "Objective \u2013 Verification of\u202fSystem Inventory page for drive. Verification of Storage Summary Page for physical disks, storage summary table and Recently Logged Storage Events. Verification of disk write endurance info in iDRAC for drives.", "precondition": "", "steps": [{"step": "1", "description": "Login to iDRAC GUI and Navigate to System Page.", "expected": "System Page launched Successfully."}, {"step": "2", "description": "Choose the Inventory tab. Verify the 'Firmware Inventory' table", "expected": "The table contain the following: Two columns: Component and FW Version Check whether iDRAC support to display the FW version for the NVMe under test"}, {"step": "3", "description": "Choose the Inventory tab. Verify the 'Hardware Inventory' table.", "expected": "For PCIe SSD Hardware Inventory: To check whether two items listed for each NVMe under test PCIe SSD in Slot X in Bay Y, it lists the Bus number, DeviceProtocol, FormFactor, Speed, PCIe LinkWidth, ProductID, MediaType, Model, SerialNumber, Slot, SystemEraseCapability etc. PCIe SSD in Slot X in Bay Y - PCI Device, it lists the BusNumber, DataBusWidth, DeviceDescription, DeviceType, PCIDeviceID, PCISubDeviceID, PCISubVendorID, PCIVendorID, SLotType etc. Note: Some channel drives might fail this test when BIOS NVMe Driver was set to default \u201cDell Qualified Drives\u201d. \u201cAll Drives\u201d option might help these channel drives PASS this test but might cause some other unexpected system behaviors."}, {"step": "4", "description": "Login in to iDRAC GUI and Navigate to Storage Page.", "expected": "Storage Page launched Successfully."}, {"step": "5", "description": "Verify the 'Storage Summary' table", "expected": "The table should contain the following: Physical Disks Overview: The pie chart should show the count of Online, Ready, Removed, Failed, Non-RAID, Foreign, Unknown, Blocked, Offline Disks Summary of Disks: Should show the number of Physical Disks, Virtual Disks, Global and Dedicated hotspares Clicking on the Physical Disks and Virtual Disks link should launch the respective pages The Physical Disks count should include all types of disks (HDD, SATA/SAS SSD, PCIe SSD)"}, {"step": "6", "description": "Verify the 'Recently Logged Storage Events' table.", "expected": "Should show the latest Storage Logs."}, {"step": "7", "description": "Click on the Refresh Button.", "expected": "The page should get refreshed successfully."}, {"step": "8", "description": "Select the 'Physical Disks' tab, verify the 'Physical Disks' table.", "expected": "The table should contain the following: e.g. PCIe SSD in Slot X in Bay Y: it displays the State, Slot Number, Size, Bus Protocol, Meida Type and Actions etc. Click the PCIe SSD in Slot X in Bay Y, it shows Drives Details which including Failure Predicted, Remaining Rated Write Endurance, Model, SAS/SATA/PCIe/NVMe Drive information, Security, Manufacturing Information etc."}, {"step": "9", "description": "Examine the \"Remaining Rated Write Endurance\" values for all the installed devices being tested.\u202f (Ex. 100%) in \"Physical Disks\" section under \"Storage\" page.", "expected": "A numeric percentage value should be reported for all the devices being tested.\u202f (Example: 100%) Pre-check: For factory new SSD: RRWE should be 99%-100%. For non-new SSD (e.g., from Proto Lab/HWL): RRWE should be >=80% at\u202fthe start of validation. If SSD RRWE was below the above criteria, check with the vendor for sample replacement, or flag it as a concern/risk. Post-check: SSD RRWE should not drop more than 1%-2% during a validation cycle. Any >1% RRWE drop should be noted, analyzed and checked with the vendor. Notes: a) For a channel drive, the \"Remaining Rated Write Endurance\" value might not show on iDRAC. You can use \"smartctl -x \" to check \"Percentage Used\" value. b) This test will fail for drives that don\u2019t have NVMe-MI smbus/mctp implemented. Also, results may vary slightly for SAS/SATA vs NVMe."}, {"step": "10", "description": "In the 'Physical Disks' tab, pick the drive under test, verify the 'Actions'", "expected": "The 'Actions\u2018 table should contain the following: Prepare to remove Cryptographic Erase PSID Revert View Enclosures Prepare to remove: Select 'Prepare to remove' action, the iDRAC should prompt the window to \u2019Apply Operation Mode', confirm 'Apply Now' and click Apply button. Then 'Warning' let you know and continue to press OK."}], "source": ""}
{"case_id": "DSSTC-5386", "name": "Verify drive information using vendor tools", "status": "", "type": "Manual", "description": "Objective \u2013 Verify the drive information is being reported correctly in the OS.", "precondition": "", "steps": [{"step": "1", "description": "For drives behind the Dell PERC controller utilize perccli to get drive information. See Test Case Notes for perccli usage information.", "expected": "Execute perccli\u202fto get\u202fdrive information and redirect to a text file.\u202f Example: \u202f perccli /c0/eall/sall show all > disks.txt\u202f Drive information is displayed and accurate."}, {"step": "2", "description": "For drives not behind a Dell PERC controller, use appropriate vendor tool to verify\u202fdrive information.", "expected": "Example: Micron msecli -L\u202f\u202f (lists Micron drive information) Drive information is displayed and accurate."}, {"step": "3", "description": "For Dell storage arrays, use DSS_Vallidation tool to view drive information:", "expected": "ldstate\u202finfo Use array management GUI or CLI tool(s) to view drive information if applicable. Drive information is displayed and accurate."}], "source": ""}
{"case_id": "DSSTC-5390", "name": "Drive Hot-Swap (RAID Mode Only)", "status": "", "type": "Manual - PERC", "description": "Objective \u2013 Verify drives attached to PERC can be hot-swapped without failures.", "precondition": "", "steps": [{"step": "1", "description": "Convert the drives to Unconfigured Good status and Create a Virtual Drive (VD) with fault tolerance (RAID1, 5, 10, etc.)", "expected": "VD should be created for full volume of drive. Convert drive to Unconfigured Good: PERC11: # perccli /cx/ex/sx set good force PERC12: # perccli2 /cx/ex/sx set uconf force Create Virtual Disk: #\u202fperccli /cx add vd r drives=<e:s"}, {"step": "2", "description": "After creating the VD do a fast initialization.", "expected": "# perccli /call/vall show // Get VD number # perccli /cx/vx start init force #\u202fperccli /cx/vx show init // Check initialization status You can alternatively perform a fast initialization on iDRAC GUI, go to Virtual Disk management -> Select the VD -> go in operation drop down menu and select Fast Initialization. A fast initialization should start. Check the progress in the Virtual Disk management tab. Let the initialization complete depending on the drive capacity it may take few minutes."}, {"step": "3", "description": "After initialization complete, boot into OS and start \"./diskio\" under \"/root/DSS_Validation/Tools/diskio/\" on this particular VD.", "expected": "# ./diskio -f /dev/sdX -P -i1 -b64k -t16 -s1 -p1 -r50 20G -d14400 Alternatively, another I/O tool capable of data comparisons may be used. I/O running."}, {"step": "4", "description": "You should see the activity LED on the drive blinking. Wait for 1~2min to let diskio running stable. FAIL a single drive member by removing one drive from the VD.", "expected": "No unexpected error was reported in diskio output, SEL and LClog. The RAID array should continue to function with loss of one drive. Activity LED should continue on the remaining drives in the RAID volume."}, {"step": "5", "description": "Insert a new clean drive. In case you do not have a new FOB drive please insert the same drive removed. Ensure the drive is the same model type/family.", "expected": "Drive insertion should be detected and see status LED. No unexpected error was reported in diskio output, SEL and LClog."}, {"step": "6", "description": "The rebuild process will start automatically. If not, manually import the drive and begin the array rebuild: # perccli /cx/fall import While drive rebuilding is in progress, check the status LED of the drive.", "expected": "The drive should be successfully imported. Rebuild should start immediately. When drive rebuild starts, verify the drive Status LED starts Blinking Green: ON 400 ms OFF 100 ms"}], "source": ""}
{"case_id": "TC-128789", "name": "SPDM - Response While in the Link Disabled State", "status": "Active", "type": "Automated", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Identify the PCIe SBDFs of the ports above the NVMe drives in the system.", "expected": "The SBDFs are captured"}], "source": ""}
{"case_id": "case-1046", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Disable the link to the NVMe drives by writing a '1' to bit 4 of the SBDF's Link Control Register.\r\n\r\nYou can use the LTSSM.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now cleared."}], "source": ""}
{"case_id": "case-1047", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "With the link now disabled, send the SPDM Discovery command sequence to each drive over SMBus:\r\n\r\nGet_Version\r\n\r\nGet_Capabilities\r\n\r\nNegotiate_Algorithms\r\n\r\nGet_Digests\r\n\r\nGet_Certificate", "expected": "All commands work successfully"}], "source": ""}
{"case_id": "case-1048", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Enable the link to the NVMe drives by writing a '0' to bit 4 of the SBDF's Link Control Register.\r\n\r\nYou can use the LTSSM.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now set."}], "source": ""}
{"case_id": "TC-128791", "name": "SPDM - Response While in the Hot Reset State", "status": "Active", "type": "Automated", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Identify the PCIe SBDFs of the ports above the NVMe drives in the system.", "expected": "The SBDFs are captured"}], "source": ""}
{"case_id": "case-1050", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Put the NVMe drives in hot reset by writing a '1' to bit 6 of the SBDF's Bridge Control Register.\r\n\r\nYou can use the LTSSM.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now cleared."}], "source": ""}
{"case_id": "case-1051", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "With the link now disabled, send the SPDM Discovery command sequence to each drive over SMBus:\n\nGet_Version\n\nGet_Capabilities\n\nNegotiate_Algorithms\n\nGet_Digests\n\nGet_Certificate", "expected": "All commands work successfully"}], "source": ""}
{"case_id": "case-1052", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Take the NVMe drives out of hot reset by writing a '0' to bit 6 of the SBDF's Bridge Control Register.\r\n\r\nYou can use the LTSSM.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now set."}], "source": ""}
{"case_id": "TC-128792", "name": "SPDM - Response While in the PERST# State", "status": "Active", "type": "Automated", "description": "", "precondition": "", "steps": [{"step": "1", "description": "Identify the PCIe SBDFs of the ports above the NVMe drives in the system.", "expected": "The SBDFs are captured"}], "source": ""}
{"case_id": "case-1054", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Put the NVMe drives into PCIe reset by asserting the signal via a Quarch\r\n\r\nYou can use the QuarchControl.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now cleared."}], "source": ""}
{"case_id": "case-1055", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "With the link now in reset, send the SPDM Discovery command sequence to each drive over SMBus:\r\n\r\nGet_Version\r\n\r\nGet_Capabilities\r\n\r\nNegotiate_Algorithms\r\n\r\nGet_Digests\r\n\r\nGet_Certificate", "expected": "All commands work successfully"}], "source": ""}
{"case_id": "case-1056", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Take the NVMe drives out of PCIe reset by de-asserting the signal via the Quarch\r\n\r\nYou can use the QuarchControl.py script/tool if you have the SDK installed.", "expected": "The \"Data Link Layer Link Active bit (bit 13) of the SBDF's Link Status Register is now set."}], "source": ""}
{"case_id": "TC-128793", "name": "SPDM - All Commands Complete within Specified Time", "status": "Active", "type": "Manual", "description": "", "precondition": "SPDMCLI can be used throughout this test for sending SPDM commands\r\n\r\nA PCIe analyzer is needed for timing the responses", "steps": [{"step": "1", "description": "Send a Get_Version command to all NVMe drives in the system", "expected": "The Get_Version command completes successfully"}], "source": ""}
{"case_id": "case-1058", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Send a Get_Capabilities command to all NVMe drives in the system", "expected": "The Get_Capabilities command completes successfully and the value for CTExponent is noted down"}], "source": ""}
{"case_id": "case-1059", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Translate the CTExponent value to microseconds by using the following formula:\n\n2 ^ (CTExponent)", "expected": "The actual time for CTExponent is decoded"}], "source": ""}
{"case_id": "case-1060", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Send the following SPDM commands:\r\n\r\nGet_Version\r\n\r\nGet_Capabilities\r\n\r\nNegotiate_Algorithms\r\n\r\nGet_Digests\r\n\r\nGet_Certificates", "expected": "Each SPDM command completes successfully, and within 100ms"}], "source": ""}
{"case_id": "case-1061", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Send a Challenge SPDM command while timing its response", "expected": "The Challenge command completes in less time than the CTExponent time decoded in the step above"}], "source": ""}
{"case_id": "case-1062", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Repeat steps 1-5, but this time use the opposite medium used originally. E.g., if you sed PCIe VDM first, the use SMBus, and vice versa.", "expected": "The same results as in steps 1-5"}], "source": ""}
{"case_id": "TC-128795", "name": "SPDM - Long-Term Authentication Stress across D/C Power Cycles", "status": "Active", "type": "Manual", "description": "", "precondition": "Make sure there are NVMe drives present in the system that support SPDM", "steps": [{"step": "1", "description": "Boot into the OS and read from an iDRAC interface the SPDM status for all drives that support SPDM", "expected": "SPDM Capability = Capable\n\nSPDM Version = 1.1.0.0 (or higher)\n\nSPDM Digest and Certificate = Enabled\n\nSPDM Challenge Auth Response = Enabled\n\nSPDM Device Cert Status = Success\n\nSPDM Device Challenge Status = Success"}], "source": ""}
{"case_id": "case-1064", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Perform a D/C power cycle of the server and go back to step 1", "expected": "The system boots back into the OS successfully"}], "source": ""}
{"case_id": "case-1065", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Repeat steps 1-2 for 3 hours", "expected": "Same results as steps 1 and 2"}], "source": ""}
{"case_id": "case-1066", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFor AHCI PCIe SSDs: navigate to the PD properties and ensure the device is listed under the PD selection list. Otherwise (for NVMe PCIe SSDs), skip to step 4.\r\n\r\nInput Data", "expected": "PCIe SSD is displayed and accessible."}], "source": ""}
{"case_id": "case-1067", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNavigate out to the main configuration menu.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1068", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the PCIe SSD.\r\n\r\nInput Data", "expected": "PCIe SSD main configuration page (for NVMe) may still be displayed, or the PCIe SSD may still be listed under PD properties (for AHCI) with \"invalid\" or stale data; however:\r\n\r\n\r\n1. Verify system is still stable and functional.\r\n\r\n2. Verify user can navigate within HII Configuration Utility."}], "source": ""}
{"case_id": "case-1069", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower off the system. Insert one PCIe SSD and boot into HII.\r\n\r\nInput Data", "expected": "Dell PCIe SSD Configuration Utility is displayed."}], "source": ""}
{"case_id": "case-1070", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWhile in the main configuration page, hot insert a new PCIe SSD in the system.\r\n\r\nInput Data", "expected": "PCIe SSD may not get displayed (record exact behavior seen in the test results)\r\n\r\n\r\n1. Verify system is still stable and functional.\r\n\r\n2. Verify user can navigate within HII Configuration Utility."}], "source": ""}
{"case_id": "case-1071", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\nReboot the system and boot into HII.\n\nInput Data", "expected": "Hot inserted PCIe SSD from step 6 is now displayed properly and is accessible."}], "source": ""}
{"case_id": "case-1072", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFrom a terminal, run the command, \"fdisk -l\"\r\n\r\nInput Data", "expected": "The PCIe SSD device node is listed"}], "source": ""}
{"case_id": "case-1073", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nFrom a terminal, run the command, \"fdisk /dev/DEVICE\" where DEVICE is the PCIe SSD in the system If there are any partitions on the device already, delete them with the \"d\" command and then create a new partition, otherwise just create a new partition as follows: n p 1 w\r\n\r\nInput Data", "expected": "\"cat /proc/partitions\" now shows that the PCIe SSD has a partition on it now"}], "source": ""}
{"case_id": "case-1074", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIn the left pane, click Hardware configuration\r\n\r\nInput Data", "expected": "Option displayed"}], "source": ""}
{"case_id": "case-1075", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIn the right pane, click hardware Inventory\r\n\r\nInput Data", "expected": "Option displayed"}], "source": ""}
{"case_id": "case-1076", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nClick view Current Inventory and from the listed device inventory look for PCIe SSD.\r\n\r\nInput Data", "expected": "Lifecycle controller displays the Hardware inventory of the selected PCIe SSD."}], "source": ""}
{"case_id": "case-1077", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nFollow below step: 1. Hotremove the installed PCie SSD and hot inset the pcie SSD in the same slot 2. Hot remove the SSD again and hot insert in a different slot\r\n\r\nInput Data", "expected": "No kernel panic or Blue screen. system is functional"}], "source": ""}
{"case_id": "case-1078", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nReboot the system and boot to OS. Run some IO to the drives\r\n\r\nInput Data", "expected": "Implict. No I/O errors. Drive is fully functional."}], "source": ""}
{"case_id": "case-1079", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nExport the PCIe SSD logs via a supported utility such as OMSS or HII.\n\nInput Data", "expected": "Logs exported for all devices in the system. Make record of the %life used and spare blocks."}], "source": ""}
{"case_id": "case-1080", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup an IO utility to run heavy IO to the PCIe SSD with a high thread count for 1min. \r\n\r\nInput Data", "expected": "IO runs without issues."}], "source": ""}
{"case_id": "case-1081", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAfter IO is stopped from step 3, SRSI the PCIe SSD (surprise remove the PCIe SSD followed by a surprise insertion).  \r\n\r\nRepeat steps 3 and 4 10 times if doing manual, or 1000 times if automated (preferred). Wait 1 second in between SR, SI and restarting IO.\r\n\r\n\r\nInput Data", "expected": "No issues during SRSI cycles."}], "source": ""}
{"case_id": "case-1082", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nExport the PCIe SSD logs via a supported utility such as OMSS or HII.\r\n\r\nInput Data", "expected": "Logs exported for all devices in the system. %life used and spare blocks have not changed significantly."}], "source": ""}
{"case_id": "case-1083", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nReview the SEL, OS logs, and other applicable management logs for any issues or oddities.\r\n\r\nInput Data", "expected": "No issues."}], "source": ""}
{"case_id": "case-1084", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS and load the driver for the device. Perform some simple I/O operations on the drive.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1085", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPull the device out.\r\n\r\nInput Data\r\nI/O halted and reported unknown error upon pulling device out\r\nbut system continues to function  without any fatal system error", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}], "source": ""}
{"case_id": "case-1086", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the drive. If supported by the I/O utility, verify data integrity (no data loss) when write caching is disabled.\r\n\r\nInput Data", "expected": "Drive is visible and accessible. Data processed prior to the removal is intact. No data loss."}], "source": ""}
{"case_id": "case-1087", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf applicable to the device, complete steps 1-4 for drives that have write caching enabled (might experience data loss).\r\n\r\nInput Data\r\nno differences  noted with & without windows OS Cache enabled/disabled\r\nsystem continues to function irrespective", "expected": "I/O halts. The OS should report I/O errors saying that it could not complete certain I/O\u2019s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional."}], "source": ""}
{"case_id": "case-1088", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 2-5 10 times.\r\n\r\nInput Data\r\nresults duplicated every repitition", "expected": "Same results."}], "source": ""}
{"case_id": "case-1089", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS\r\n\r\nInput Data", "expected": "OS loads successfully.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-1090", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify that the hot inserted device functions properly (ie. perform some I/O)\r\n\r\nInput Data", "expected": "The PCIe SSD device functions correctly (correct link width and speed). No errors are reported.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-1091", "name": "", "status": "", "type": "", "description": "", "precondition": "md1", "steps": [{"step": "2", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-1092", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID0\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID0"}], "source": ""}
{"case_id": "case-1093", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate a RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1094", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-1095", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID5\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID5 and resyncs"}], "source": ""}
{"case_id": "case-1096", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDump the PCIe configuration space of the root ports or PCIe switch ports above where the NVMe drives would be\r\n\r\nInput Data", "expected": "The \"Memory Base\" and \"Memory Limit\" registers are both non-zero, and equal to each other."}], "source": ""}
{"case_id": "case-1097", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\r\n\r\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\r\n\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1098", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the HII page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-1099", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1100", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nPull the latest FICore image and boot to it.\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1101", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUsing the factory utility, retrieve the NVMe PCIe SSD properties. This step will need to be repeated for every different type of NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Device properties are retrieved successfully. All expected properties are returned and these contain the correct value (also formatted correctly)."}], "source": ""}
{"case_id": "case-1102", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created datastore to a virtual machine\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-1103", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWith the VM powered OFF, remove the NVMe drive that has the datastore on it\r\n\r\nInput Data", "expected": "The OS does not crash\r\nThe drive is removed from lspci\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI"}], "source": ""}
{"case_id": "case-1104", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the NVMe drive that was removed\r\n\r\nInput Data", "expected": "The device is re-enumerated in lspci\r\nThe device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)"}], "source": ""}
{"case_id": "case-1105", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The virtual disks carved from the NVMe datastore is detected within the VM and can successfully complete I/O (run for a minute)"}], "source": ""}
{"case_id": "case-1106", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the SUT without any NVMe drive into the OS\r\n\r\nNOTE if you must have another NVMe drive installed as the OS, then you will see traffic going to that drive if it's in the same bay as the drive you will be inserting. If this is the case, then consult the I2CTopology.bin file in the iDRAC's root filesystem to view the MUX information to understand when the iDRAC is communicating to the OS drive versus the hotplugged drive.\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1107", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart the I2C trace capture/recording\r\n\r\nInput Data", "expected": "You should not see any communication with I2C address 0xD4 or 0x3A"}], "source": ""}
{"case_id": "case-1108", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "Within 10s, in the I2C trace:\n1. The FRU of the device will be read from 0xA6 address\n2. NVMe-MI traffic to I2C address 0x3A (or 0xD4 if an old device) starts (likely a Read NVme-MI Data Structure command)\n\nThe order of items #1 and #2 does not matter."}], "source": ""}
{"case_id": "case-1109", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove that same drive that was just inserted\r\n\r\nInput Data", "expected": "Within 10s, no more I2C communication with I2C addresses 0xD4 or 0x3A is seen"}], "source": ""}
{"case_id": "case-1110", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nType \"DlpDump.efi\"\n\nInput Data", "expected": "The FQDD for the PCIe SSD is displayed"}], "source": ""}
{"case_id": "case-1111", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nType \"HiiDump.efi -f -d FQDD > tempFile.txt\" where FQDD is the FQDD from step 2\r\n\r\nInput Data", "expected": "In the \"Form Set #1\" section, \"x-UEFI\" is listed as a supported language"}], "source": ""}
{"case_id": "case-1112", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert an NVMe drive into the system\r\n\r\nInput Data", "expected": "The NVMe drive is discovered and enumerated by the device driver"}], "source": ""}
{"case_id": "case-1113", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nConfigure the hot inserted NVMe drive to be a local hot-spare for the RAID1 array\r\n\r\nInput Data", "expected": "The drive is successfully configured as a local hot-spare for the RAID1 array"}], "source": ""}
{"case_id": "case-1114", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert an NVMe drive into the system\r\n\r\nInput Data", "expected": "The NVMe drive is discovered and enumerated by the device driver"}], "source": ""}
{"case_id": "case-1115", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nConfigure the hot inserted NVMe drive to be a global hot-spare\n\nFor example:\n\nvgextend testvg /dev/nvme8n1\n\n\nInput Data", "expected": "The drive is successfully configured as a global hot-spare"}], "source": ""}
{"case_id": "case-1116", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot remove the device using Quarch.\r\n\r\nInput Data", "expected": "Host system continues to run without freeze or hang after the device hot removed and the device is removed from the system."}], "source": ""}
{"case_id": "case-1117", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert the device using Quarch and run some I/O\r\n\r\nInput Data", "expected": "The device is detected by the system and I/O runs fine."}], "source": ""}
{"case_id": "case-1118", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat step 2 and 3 for 30 minutes\r\n\r\nInput Data", "expected": "Result same as step 2 and 3."}], "source": ""}
{"case_id": "case-1119", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created datastore to a virtual machine (1 to Windows and 1 to Linux)\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-1120", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive"}], "source": ""}
{"case_id": "case-1121", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWith the VM powered ON, remove the NVMe drive that has the datastore on it\r\n\r\nInput Data", "expected": "The hypervisor does not crash\r\nThe VM OS does not crash\r\nThe drive is removed from lspci from the hypervisor\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI\r\nThe virtual disk is removed from the VM OS (you can check \"cat /proc/partitions | grep sd\" in Linux or the Disk Manager in Windows)"}], "source": ""}
{"case_id": "case-1122", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall the device under test while the OS is running.\r\n\r\nInput Data", "expected": "Verify that the new hardware is added to the system and will configure it if the driver is available. Pull the SMART/Error log from the device."}], "source": ""}
{"case_id": "case-1123", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify that the hot inserted device functions properly (ie. perform some I/O)\r\n\r\nInput Data", "expected": "The PCIe SSD device functions correctly after the hot insertion operation. The PCIe SSD default settings are unchanged. Device config space is unchanged.\r\n\r\nSMART/Error log reports 0 errors or abnormalities."}], "source": ""}
{"case_id": "case-1124", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2 and 3 at least 10 times.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1125", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nUsing Quarch equipment (or other automation method) to perform at least 50 cycles of a PCIe SSD hot insertion with a running system.\n\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1126", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nConfigure another NVMe drive that's not a part of the array to be a local hot-spare\n\nInput Data", "expected": "The drive is successfully configured as a hot-spare"}], "source": ""}
{"case_id": "case-1127", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart I/O to the virtual disk\r\n\r\nInput Data", "expected": "I/O is being handled successfully"}], "source": ""}
{"case_id": "case-1128", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove one of the NVMe drives that's a part of the redundant LVM RAID array\r\n\r\nInput Data", "expected": "The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy.\r\n\r\nI/O continues to be processed."}], "source": ""}
{"case_id": "case-1129", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStop the I/O stress to allow the resync to finish quicker\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1130", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDuring execution, pull the AC cable out from the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1131", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRestore power to the system and boot the system into the OS.\r\n\r\nInput Data", "expected": "Device is present and functional."}], "source": ""}
{"case_id": "case-1132", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nMake sure the devices are available and repeat the steps 2,3,4 10 times. \r\n\r\nInput Data", "expected": "Make sure that device contains the N-1 firmware as power was pulled during DUP execution."}], "source": ""}
{"case_id": "case-1133", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nMake sure device is available at block layer and is accessible. \r\n\r\nInput Data", "expected": "Test completes successfully"}], "source": ""}
{"case_id": "case-1134", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the SUT with atleast 1 NVMe SSD\r\n\r\nInput Data", "expected": "NA"}], "source": ""}
{"case_id": "case-1135", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the drive is inventoried in idrac.\r\n\r\nInput Data", "expected": "Drive should be detected under storage - physical drives"}], "source": ""}
{"case_id": "case-1136", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove one of the drives in the RAID0 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-1137", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1138", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove two of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-1139", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1140", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove three of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-1141", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1142", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nSurprise remove two of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array is now failed"}], "source": ""}
{"case_id": "case-1143", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created Physical RDM to a virtual machine\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-1144", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWith the VM powered OFF, remove the NVMe drive that has the Physical RDM on it\r\n\r\nInput Data", "expected": "The OS does not crash\r\nThe drive is removed from lspci\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI"}], "source": ""}
{"case_id": "case-1145", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-insert the NVMe drive that was removed\r\n\r\nInput Data", "expected": "The device is re-enumerated in lspci\r\nThe device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)"}], "source": ""}
{"case_id": "case-1146", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The virtual disks carved from the NVMe Physical RDM is detected within the VM and can successfully complete I/O (run for a minute)"}], "source": ""}
{"case_id": "case-1147", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\n\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\n\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1148", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the iDRAC page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-1149", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1150", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove one of the drives in the RAID1 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-1151", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1152", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSurprise remove one of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-1153", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1154", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove two of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-1155", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1156", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nSurprise remove one of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array is now degraded"}], "source": ""}
{"case_id": "case-1157", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf using Windows, copy the IOMeter.exe and dynamo.exe files to the system. Else if using Linux, copy the source files to the system and run: 1. touch /usr/include/stropts.h 2. make -f Makefile-Linux.x86_64 dynamo\r\n\r\nInput Data", "expected": "IOMeter is successfully installed on the test system."}], "source": ""}
{"case_id": "case-1158", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nEnsure that the PCIe SSD to be tested is not partitioned and does not have a filesystem on it.\r\n\r\nInput Data", "expected": "The drive is raw."}], "source": ""}
{"case_id": "case-1159", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, you'll need another computer to run a Windows version of IOMeter on it. Then, you'll have to make sure that both the Linux test machine and the Windows computer are on the same network and can ping each other. The firewall on both machines will also have to be disabled ( service iptbales stop for the Linux machine). Once, this is setup, edit the /etc/hosts file on the Linux machine and add an entry for the new IP address of your Linux machine. Last, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-1160", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nDownload the .icf files that are attached to this test case and save them somewhere on the test system if using Windows, or somewhere on the Windows computer if using Linux.\n\nInput Data", "expected": "The .icf files are copied onto the appropriate machine."}], "source": ""}
{"case_id": "case-1161", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the PreCondition.icf file .\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-1162", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1163", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFor each worker, remove the \"4kRandWrite4kAlign\" access specification from the \"Access Specifications\" tab.\r\n\r\nInput Data", "expected": "Each worker only has the \"64kSeq..\" test to run."}], "source": ""}
{"case_id": "case-1164", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}], "source": ""}
{"case_id": "case-1165", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = (2 * C) / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to twice over is calculated."}], "source": ""}
{"case_id": "case-1166", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}], "source": ""}
{"case_id": "case-1167", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nNow remove the \"64kSeq...\" test from each workers \"Access Specifications\" tab and add the \"4kSeqWrite..\" test in its place.\r\n\r\nInput Data", "expected": "Each worker only has the \"4kSeq..\" test to run."}], "source": ""}
{"case_id": "case-1168", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nClick the \"Start Tests\" green flag button and the results do not need to be saved so you can click \"Cancel\" on the pop-up screen.\r\n\r\nInput Data", "expected": "IO starts on the PCIe SSD."}], "source": ""}
{"case_id": "case-1169", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nYou need to calculate the amount of time to let the test run. Select the \"Results Display\" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = C / B\r\n\r\nInput Data", "expected": "Number of seconds to allow the PCIe SSD to be written to once is calculated."}], "source": ""}
{"case_id": "case-1170", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "15", "description": "Description\r\nStop the I/O after the amount of time calulated in the step above.\r\n\r\nInput Data", "expected": "I/O stops."}], "source": ""}
{"case_id": "case-1171", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "16", "description": "Description\r\nClose the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1172", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "17", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-1173", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "18", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Latency.icf file.\r\n\r\nInput Data", "expected": "You see only 1 worker listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-1174", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "19", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1175", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "20", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}], "source": ""}
{"case_id": "case-1176", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "21", "description": "Description\r\nOnce the \"Latency\" test is done, close the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1177", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "22", "description": "Description\r\nIf using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i \"IP-Address of Windows computer\" -m \"my current IP-Address\" Then, go to the Windows computer and double-click the IOMeter.exe file.\r\n\r\nInput Data", "expected": "IOMeter shows the system that you plan on testing underneath \"All Managers.\" If Windows, it will look something like, \"WIN-...,\" else if using Linux, it will be the hostname of the machine."}], "source": ""}
{"case_id": "case-1178", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "23", "description": "Description\r\nFrom the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Run4kA.icf file.\r\n\r\nInput Data", "expected": "You see only 4 workers listed now underneath the manager of the test system."}], "source": ""}
{"case_id": "case-1179", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "24", "description": "Description\r\nAfter expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its \"Disk Target\"\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1180", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "25", "description": "Description\r\nClick the \"Start Tests\" green flag and make sure to save the results this time.\r\n\r\nInput Data", "expected": "I/O starts and the output is saved to a .csv file."}], "source": ""}
{"case_id": "case-1181", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "26", "description": "Description\r\nBoth of the results files should be analyzed.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1182", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a 2-drive RAID0\r\n\r\nInput Data", "expected": "The RAID0 array is created successfully"}], "source": ""}
{"case_id": "case-1183", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the drives in the RAID0 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-1184", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-1185", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1186", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove two of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-1187", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-1188", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCreate a 4-drive RAID6\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1189", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nSurprise remove three of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-1190", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-1191", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1192", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nSurprise remove two of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array may not fail until I/O has started"}], "source": ""}
{"case_id": "case-1193", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O fails and the status of the array is now failed"}], "source": ""}
{"case_id": "case-1194", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1195", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD shutdown sequence.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1196", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot to the OS and once drive handle is created start capturing the trace. Press power button gently once and allow system to reboot. \r\n\r\nInput Data", "expected": "The system starts rebooting and trace capture is in progress."}], "source": ""}
{"case_id": "case-1197", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nOnce the boot starts again stop the trace capture. \n\nInput Data", "expected": "PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "case-1198", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nRepeat step 4-5 but instead of using power button , issue Shutdown of the system from OS it self. \n\nInput Data", "expected": "Same as above steps"}], "source": ""}
{"case_id": "case-1199", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\nOnce in the OS start capturing the trace again.\nAC power off the system (pull AC power cable).\n\n\nInput Data", "expected": "The trace capture is in progress and system starts rebooting."}], "source": ""}
{"case_id": "case-1200", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nOnce the boot process starts stop the trace capture. \r\n\r\nInput Data", "expected": "PCIe trace shows CC.SHN = 10b to indicate abrupt shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "case-1201", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall OMSS version known to support PCIe SSD reporting and discover\r\n\r\nInput Data", "expected": "OMSS installed"}], "source": ""}
{"case_id": "case-1202", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLaunch OMSS and navigate to PCIe SSD storage subsystem\r\n\r\nInput Data", "expected": "-User is able to navigate OMSS Menu\r\n\r\n-PCIe SSD Subsystem is clearly called out and selectable as a target link"}], "source": ""}
{"case_id": "case-1203", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nKeep expanding the PCIe SSD subsystem tree until the physical disk menu is displayed\r\n\r\nInput Data", "expected": "-Tree expands\r\n\r\n-No physical disks listed as none should be installed at this point"}], "source": ""}
{"case_id": "case-1204", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSurprise insert 2 drive2 into the two lowest enumerated slots on the chassis face known to support PCIeSSD drives\r\n\r\nInput Data", "expected": "-Both drives detected\r\n\r\n-Surprise insertion events detected by the OS and driver loaded\r\n\r\n-LED illuminted and indicates ready (steady Green)\r\n\r\n-Slot number is accurate to where the drive is installed\r\n\r\n-Physical Drive Properties page updated by OMSS and accurately reflects the following:\r\n\r\n--Physical Disk with slot number\r\n\r\n--State of the drive\r\n\r\n--Drop Down task menu\r\n\r\n--Protocol Type\r\n\r\n--Firmware Revision\r\n\r\n--Predictive Failure status"}], "source": ""}
{"case_id": "case-1205", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRun some I/O to the drives to verify it is functional. Stop I/O after 30 seconds.\r\n\r\nInput Data", "expected": "drives responds to I/O requests without issue"}], "source": ""}
{"case_id": "case-1206", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nDo a \"Prepare for Removal\" on the drive on the drive in the lowest slot\r\n\r\nInput Data", "expected": "Drive removed, OS still functional, OMSS still functional and responsive"}], "source": ""}
{"case_id": "case-1207", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nDo a \"Prepare for Removal\" on the second drive\r\n\r\nInput Data", "expected": "Same result as steps 6"}], "source": ""}
{"case_id": "case-1208", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nPerform steps 5 through 7 on any slots not used in the previous steps, i.e. if drives were surprised inserted into slots 0 and 1 in step 5, surprise insert the two drives into slots 2 and 3 (if the platform supports that quantity of slots)\r\n\r\nInput Data", "expected": "-Same result as steps 5 and 7\r\n\r\n-Slot accurately reflects where the drive was inserted"}], "source": ""}
{"case_id": "case-1209", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPull the latest FICore image and boot to it.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1210", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nVerify the correct NVMe driver is installed and loaded (please note that this may not necessarily be an Arev driver, depending on when the FICore image was created and/or pulled down). Ensure to pull the latest FICore image available. To do this, you may need to (1) navigate to the Windows\\System32\\drivers directory, (2) confirm nvme.sys driver file is present, (3) copy this file to check its properties\r\n\r\nInput Data", "expected": "NVMe driver is installed and loaded.\r\n\r\n\r\nIf testing with FICore image after NVMe drivers have been Arev, the NVMe driver that is installed must be the Arev driver."}], "source": ""}
{"case_id": "case-1211", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRun some I/O to the NVMe PCIe SSD.\r\n\r\nInput Data", "expected": "I/O runs successfully."}], "source": ""}
{"case_id": "case-1212", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-1213", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the drive from the system using Quarch\r\n\r\nInput Data", "expected": "The system is functional. No error/ fatal error is reported."}], "source": ""}
{"case_id": "case-1214", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUsing Quarch Hot Insert the drive that was removed in step 4 back into the system\r\n\r\nInput Data", "expected": "The device is recognized by the OS and functional"}], "source": ""}
{"case_id": "case-1215", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCapture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register\r\n\r\nInput Data", "expected": "The values of the registers are the same as when they were captured in step 2"}], "source": ""}
{"case_id": "case-1216", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFormat each of the partitions on the NVMe drives to have one of the following filesystems:\r\next3\r\next4\r\nxfs\r\nbtrfs <- ONLY for SLES\r\n\r\n\r\nInput Data", "expected": "The filesystems are successfully created"}], "source": ""}
{"case_id": "case-1217", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nMount the filesystems\r\n\r\nInput Data", "expected": "Mounts are successful"}], "source": ""}
{"case_id": "case-1218", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPut some data files on each of the filesystems and create a checksum\r\n\r\nInput Data", "expected": "Data is successfully written and checksums are calculated"}], "source": ""}
{"case_id": "case-1219", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCall \"sync -f\" on each filesystem\r\n\r\nInput Data", "expected": "The sync completes successfully"}], "source": ""}
{"case_id": "case-1220", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWith the filesystem still mounted surprise remove each NVMe drive\r\n\r\nInput Data", "expected": "The device driver no longer enumerates the removed NVMe drives\r\nNOTE that stale mount points will likely still exist"}], "source": ""}
{"case_id": "case-1221", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-Insert each NVMe drive back into the system\r\n\r\nInput Data", "expected": "The device driver enumerates all drives"}], "source": ""}
{"case_id": "case-1222", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nMount each of the filesystems\r\n\r\nInput Data", "expected": "Filesystems successfully mount"}], "source": ""}
{"case_id": "case-1223", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nCheck the filesystems with fsck\r\n\r\nInput Data", "expected": "The filesystem check doesn't report any errors"}], "source": ""}
{"case_id": "case-1224", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nRe-calculate the checksums for each filesystem\r\n\r\nInput Data", "expected": "The checksums match that of the original values calculated before the previous unmount"}], "source": ""}
{"case_id": "case-1225", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAfter the system is booted without any PCIe SSD.  Hot plug a drive using quarch . \r\n\r\nInput Data", "expected": "Device is recognized normally"}], "source": ""}
{"case_id": "case-1226", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the Configuration get command for the MCTP Transmission Unit Size.\r\n\r\nInput Data", "expected": "MTU should be at least 0x78 (120d)"}], "source": ""}
{"case_id": "case-1227", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall the latest LC OS Driver Pack using the DUP with either LC Firmware Upgrade, remote iDrac firmware upgrade, or from an already installed OS.\r\n\r\nInput Data", "expected": "DUP installs successfully."}], "source": ""}
{"case_id": "case-1228", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInstall at least two PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Status LED goes to solid on to indicate PCIe SSD is online and ready."}], "source": ""}
{"case_id": "case-1229", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the BIOS Setup boot mode to UEFI (default mode). (no legacy mode)\r\n\r\nInput Data", "expected": "Setting saved successfully."}], "source": ""}
{"case_id": "case-1230", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf necessary, attach a DVD drive to the system.\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1231", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert OS installation media into the DVD drive.\r\n\r\nInput Data", "expected": "Installation media is detected."}], "source": ""}
{"case_id": "case-1232", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nLaunch LC \"OS Deployment\", click \"Deploy OS\", select \"Go Directly to OS Deployment\", click \"Next\" and proceed to install the OS to the PCIe SSD. Ensure that the PCIe SSDs (mix of FF or types) are configured in a fault tolerant configuration such as LVM or native OS raid. This may need to be delayed until step 7. Record the configuration used in the test results Overall Notes.\r\n\r\nInput Data", "expected": "Installation process is successful.\r\n\r\nFault tolerant configuration successful (if done at this step).\r\n\r\nConfiguration used recorded."}], "source": ""}
{"case_id": "case-1233", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nBoot to the OS and perform simple IO to all devices. Check logs for errors. If not possible in step 6, configure the devices into a fault tolerant configuration, for example, but using the native OS raid function to mirror the 2 PCIe-SSD's to turn the single boot PCIe-SSD into a mirroed bootable set of drives.\r\n\r\nInput Data", "expected": "No errors reported in logs.\r\n\r\nFault tolerant configuration successful (if done at this step)."}], "source": ""}
{"case_id": "case-1234", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nReboot and ensure the OS is still bootable. check logs for errors.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-1235", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nPower down system. Power back up and ensure OS boots. check logs.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-1236", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nPower down system. With power off, swap the devices. Power back up and ensure OS boots. check logs.\r\n\r\nInput Data", "expected": "No errors reported in logs."}], "source": ""}
{"case_id": "case-1237", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nSurprise remove one of the devices (will need to select a 2.5\" FF to be SR).\r\n\r\nInput Data", "expected": "OS continues to run. Expected information is logged in the system logs."}], "source": ""}
{"case_id": "case-1238", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nreboot. Check logs for errors.\r\n\r\nInput Data", "expected": "Degraded condition of the boot device is reported as expected, but no other errors are reported in logs."}], "source": ""}
{"case_id": "case-1239", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAssign a virtual disk from the newly created physical RDM to a virtual machine (1 to Windows and 1 to Linux)\r\n\r\nInput Data", "expected": "The virtual disk is successfully assigned to the VM"}], "source": ""}
{"case_id": "case-1240", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the VM\r\n\r\nInput Data", "expected": "The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive"}], "source": ""}
{"case_id": "case-1241", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWith the VM powered ON, remove the NVMe drive that has the physical RDM on it\r\n\r\nInput Data", "expected": "The hypervisor does not crash\r\nThe VM OS does not crash\r\nThe drive is removed from lspci from the hypervisor\r\nThe drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI\r\nThe virtual disk is removed from the VM OS (you can check \"cat /proc/partitions | grep sd\" in Linux or the Disk Manager in Windows)"}], "source": ""}
{"case_id": "case-1242", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf needed, cause the PCIeSSD to enter in a fault state (test all possible fault conditions if enabled, otherwise at least cover Read-Only and Security Locked State modes).\r\n\r\nTalk to the program lead for getting a device in Read-Only mode.\r\n\r\nInput Data", "expected": "PCIe SSD enters in fault mode."}], "source": ""}
{"case_id": "case-1243", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nVerify the driver detects the PCIe SSD in fault state. ie. an entry is added to the OS system log during PCIeSSD discovery indicating the device is in some fault state.\n\nInput Data", "expected": "System continues to function without issues. The system log shows device in a fault state (and there is no flooding of messages)."}], "source": ""}
{"case_id": "case-1244", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAttempt to create a datastore on the fault device.\r\n\r\nInput Data", "expected": "Operation fails gracefully. Entries may be added in the OS system log indicating such."}], "source": ""}
{"case_id": "case-1245", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nAttempt to configure PCIe SSD as passthrough, add it to a VM and boot to it. If not already done so, install the device driver.\r\n\r\nInput Data", "expected": "Device can be configured as a passthrough device with no issues. Device driver installs and/or loads successfully. Any host I/Os to the device fail gracefully. System continues to function correctly.\r\n\r\n\r\n\r\n\r\nIf the device is in read-only, only writes fail to the device."}], "source": ""}
{"case_id": "case-1246", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf possible, save some data onto the PCIe SSD and get the PCIe SSD to transition to read only mode during runtime.\r\n\r\nInput Data", "expected": "PCIe SSD goes from Ready to Read Only. Data is still accessible in the device. System continues to function without issues. Unable to write further data to the device."}], "source": ""}
{"case_id": "case-1247", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-1248", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\n\r\nAdd the hot inserted drive to be a part of the RAID1\r\n\r\n\r\nFor example:\r\nvgextend vgname /dev/nvmeXnX\r\n\r\nlvconvert -m 2 vgname/lvname /dev/nvmeXnX\r\n\r\n\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID1\r\n\r\nYou can use:\r\nlvs -a -o name,raid_sync_action,copy_percent,devices vgname"}], "source": ""}
{"case_id": "case-1249", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate a RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1250", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert a new NVMe drive into the system\r\n\r\nInput Data", "expected": "It is successfully discovered by the device driver"}], "source": ""}
{"case_id": "case-1251", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAdd the hot inserted drive to be a part of the RAID5\r\n\r\nInput Data", "expected": "The hot added drive is now successfully a part of the RAID5 and resyncs"}], "source": ""}
{"case_id": "case-1252", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot the system and hot remove the device before the OS starts to load.\r\n\r\nInput Data", "expected": "Device is removed. No errors are reported. System continues to boot."}], "source": ""}
{"case_id": "case-1253", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBoot to the OS.\r\n\r\nInput Data", "expected": "System boots successfully.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-1254", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nVerify the OS loads properly and there are no errors in the event log.\r\n\r\nInput Data", "expected": "There are no errors in the windows event log or the SEL. The OS is fully functional.\r\n\r\nNo fatal system side effects occur."}], "source": ""}
{"case_id": "case-1255", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRe-insert the previously hot removed device and verify it is still functional.\r\n\r\nInput Data", "expected": "Device is fully functional."}], "source": ""}
{"case_id": "case-1256", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIdentify each PCIe switch's upstream BAR0 register by reading PCIe Cfg Space (offset 0x13-0x10)\r\n\r\nInput Data", "expected": "All Memory addresses are captured and saved"}], "source": ""}
{"case_id": "case-1257", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIdentify all of the downstream station ports for each switch (*typically a multiple of 4: e.g. 0, 4, 8, etc.)\r\n\r\nInput Data", "expected": "All Downstream Switch ports identified for each Capella 2 switch"}], "source": ""}
{"case_id": "case-1258", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRead 32 bits of memory using the following formula:\r\nBAR0 + (StationPortDeviceNumber * 0x1000) + 0x760\r\n\r\nDo this for each port identified in the step above\r\n\r\n\r\nInput Data", "expected": "Bit 21 should be set"}], "source": ""}
{"case_id": "case-1259", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nWithout assigning the RDM to any VM, surprise remove the NVMe drive\r\n\r\nInput Data", "expected": "The removed drive is no longer enumerated on the PCIe bus\r\nThe drive no longer shows up in the ESXi web GUI Storage->Datastores view"}], "source": ""}
{"case_id": "case-1260", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the same NVMe drive back into the system\r\n\r\nInput Data", "expected": "The drive shows up on the PCIe bus\r\nThe drive shows back up in the ESXi web GUI Storage -> Datastores view"}], "source": ""}
{"case_id": "case-1261", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nChange the format of the drive to 4kB (do not enable PI, use the format with no MS).\r\n\r\nHere's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1262", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo back into the OMSA page for the newly formatted drive\r\n\r\nInput Data", "expected": "In the \"View Physical Properties\" menu, the device capacity is displayed and matches the value originally recorded"}], "source": ""}
{"case_id": "case-1263", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDon't forget to put the drive back to 512B format.\r\n\r\nInput Data", "expected": "The format completes successfully"}], "source": ""}
{"case_id": "case-1264", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot to the OS and load the driver for the device.\r\n\r\nInput Data", "expected": "The OS load successfully."}], "source": ""}
{"case_id": "case-1265", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPerform some simple I/O operations on one of the drive.\r\n\r\nInput Data", "expected": "Drive is fully functional and no errors are reported from I/O activity."}], "source": ""}
{"case_id": "case-1266", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPull the other device out in which I/O is not running. Check if I/O on the other drive is still running\r\n\r\nInput Data", "expected": "Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional.\n\n\nHot removal of a device doesn't alter ongoing activity of other devices"}], "source": ""}
{"case_id": "case-1267", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRe-insert device and allow FTL rebuild to complete. check if I/O is running on the other drive is still running\r\n\r\nInput Data", "expected": "Events are generated as a result of a insertion and device is properly detected. Once FTL table rebuild completes, volume is available for use in operating system.\r\n\r\nI/O starts and runs successfully.\r\n\r\n\r\nNo fatal system errors (eg. blue screen, kernel panic) are encountered and the system continues to be functional."}], "source": ""}
{"case_id": "case-1268", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 3-5 again.\r\n\r\nInput Data", "expected": "Results are the same for the 2nd attempt."}], "source": ""}
{"case_id": "case-1269", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConfigure performance monitor to display the PCIe SSD under test MB/s\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1270", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUse IOMeter to generate I/O for maximum write MB/s. Start I/O with 64k block transfers and queue depth of 256. Increase the queue depth as needed to reach peak throughput. If performance already seems to be near theoretical max, reduce queue depth until lane the x4 port no longer saturates. Allow I/O to run for 5 minutes before checking MB/s.\r\n\r\nInput Data", "expected": "Compare against PCIe theoretical limits.\r\n\r\n\r\nFor example, Gen 2 theoretical max throughput for a x4 PCIe SSD is approximately 2 GB/s minus overhead for protocol and 8b/10b encoding which is generally around 20%."}], "source": ""}
{"case_id": "case-1271", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReduce the block transfer size from step 2 by half. Attempt to saturate link with queue depth 256. Raise or lower queue depth as needed to saturate the link. -Keep reducing block transfer size by half and adjusting queue depth as needed to achieve max performance and iterate until block transfer size is 512 bytes -Allow each for 5 minutes of run time prior to noting MB/s\r\n\r\nInput Data", "expected": "#NAME?"}], "source": ""}
{"case_id": "case-1272", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPRECONDITION (precondition.icf) the PCIe SSD(s): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput \u2013 runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set \u2013 just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.\r\n\r\nInput Data", "expected": "PCIe SSD(s) preconditioned."}], "source": ""}
{"case_id": "case-1273", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat step 3\r\n\r\nInput Data", "expected": "Observe and record the throughput value observed. This value gives the steady state performance of the device when having to manage the reclamation of erase blocks. Micron reports this to be approximately 600 MB/s. Write defect if less than this value.\r\n\r\n\r\nFor reference on expected performance, use Dell's RFQ or similar document."}], "source": ""}
{"case_id": "case-1274", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nWithout assigning the datastore to any VM, surprise remove the NVMe drive\r\n\r\nInput Data", "expected": "The removed drive is no longer enumerated on the PCIe bus\r\nThe drive no longer shows up in the ESXi web GUI Storage->Datastores view"}], "source": ""}
{"case_id": "case-1275", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the same NVMe drive back into the system\r\n\r\nInput Data", "expected": "The drive shows up on the PCIe bus\r\nThe drive shows back up in the ESXi web GUI Storage -> Datastores view"}], "source": ""}
{"case_id": "case-1276", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a 2-drive RAID1\r\n\r\nInput Data", "expected": "The RAID1 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1277", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the drives in the RAID1 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-1278", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-1279", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1280", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nCreate a 3-drive RAID5\r\n\r\nInput Data", "expected": "The RAID5 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1281", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nSurprise remove one of the drives in the RAID5 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-1282", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-1283", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1284", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nCreate a 5-drive RAID6.  LVM requires at least 5 drives for RAID 6\r\n\r\n\r\nInput Data", "expected": "The RAID6 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1285", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nSurprise remove two of the drives in the RAID6 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-1286", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-1287", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1288", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nCreate a 4-drive RAID10\r\n\r\nInput Data", "expected": "The RAID10 is created successfully, and the background resync completes"}], "source": ""}
{"case_id": "case-1289", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "15", "description": "Description\r\nSurprise remove one of the drives in the RAID10 array\r\n\r\nInput Data", "expected": "The status of the array may not degraded until I/O is started"}], "source": ""}
{"case_id": "case-1290", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "16", "description": "Description\r\nStart I/O\r\n\r\nInput Data", "expected": "The I/O is successful, but the status of the array is now degraded"}], "source": ""}
{"case_id": "case-1291", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "17", "description": "Description\r\nStop I/O\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1292", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSecure Erase the drives\r\n\r\nInput Data", "expected": "#NAME?"}], "source": ""}
{"case_id": "case-1293", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPRECONDITION (precondition.icf): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput \u2013 runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set \u2013 just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.\r\n\r\nInput Data", "expected": "#NAME?"}], "source": ""}
{"case_id": "case-1294", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the drives into a 4 drive RAID 0\r\n\r\nInput Data", "expected": "RAID configured"}], "source": ""}
{"case_id": "case-1295", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRun the comprehensive performance IOMeter test against the RAID 0. Save IOMeter output and label as 4 drive RAID 0 data\r\n\r\nInput Data", "expected": "I/O executes without error"}], "source": ""}
{"case_id": "case-1296", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDelete the RAID 0 and configure a single worker/thread to run the conprehensive performance IOMeter suite against the 4 raw PCIe SSD devices. Save IOMeter output and label as 4 drive non-RAID data\r\n\r\nInput Data", "expected": "-RAID deleted\r\n\r\n-Data saved"}], "source": ""}
{"case_id": "case-1297", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCompare results from both runs\r\n\r\nInput Data", "expected": "-OS RAID data set is within at least 10% of the non-raid data\r\n\r\n-no major \"sore spots\" in either data sets where performance does not scale with workload"}], "source": ""}
{"case_id": "case-1298", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPartition and format the PCIe SSD\r\n\r\nInput Data", "expected": "The partition and filesystem is successfully applied"}], "source": ""}
{"case_id": "case-1299", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nFill the entire filesystem with file(s) One way to do this in Windows is to use the \"Make-A-File\" aplpication, or using a combination of \"touch\" and \"dd\" in Linux\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1300", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nAttempt to create a new file on the full filesystem\r\n\r\nInput Data", "expected": "The file is not allowed to be created"}], "source": ""}
{"case_id": "case-1301", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nAttempt to copy a file from another location to the full filesystem\r\n\r\nInput Data", "expected": "The file is not allowed to be copied"}], "source": ""}
{"case_id": "case-1302", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nCopy a file from the full filesystem to another location\r\n\r\nInput Data", "expected": "The file is successsfully copied"}], "source": ""}
{"case_id": "case-1303", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConfigure another NVMe drive that's not a part of the array to be a local hot-spare\r\n\r\nInput Data", "expected": "The drive is successfully configured as a hot-spare"}], "source": ""}
{"case_id": "case-1304", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove one of the NVMe drives that's a part of the redundant mdadm RAID array\r\n\r\nInput Data", "expected": "The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy."}], "source": ""}
{"case_id": "case-1305", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBegin running I/O to the device where you can monitor performance (e.g. IOMeter, fio, or use a normal I/O tool with Perfmon)\n\nInput Data", "expected": "I/O continues to run successfully. There are no I/O errors or data miscompares"}], "source": ""}
{"case_id": "case-1306", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nWhile I/O is running, cause the device to enter the temperature exceeded threshold state\n\nInput Data", "expected": "The performance of the I/O drops off to allow for cooling. There are no I/O errors or data miscompares"}], "source": ""}
{"case_id": "case-1307", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFormat each of the partitions on the NVMe drives to have one of the following filesystems:\r\next3\r\next4\r\nxfs\r\nbtrfs <- ONLY for SLES\r\n\r\n\r\nInput Data", "expected": "The filesystems are successfully created"}], "source": ""}
{"case_id": "case-1308", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nMount the filesystems\r\n\r\nInput Data", "expected": "Mounts are successful"}], "source": ""}
{"case_id": "case-1309", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPut some data files on each of the filesystems and create a checksum\r\n\r\nInput Data", "expected": "Data is successfully written and checksums are calculated"}], "source": ""}
{"case_id": "case-1310", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUnmount each filesystem\r\n\r\nInput Data", "expected": "Unmounts are successful"}], "source": ""}
{"case_id": "case-1311", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove each NVMe drive\r\n\r\nInput Data", "expected": "The device driver no longer enumerates the removed NVMe drives"}], "source": ""}
{"case_id": "case-1312", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-Insert each NVMe drive back into the system\r\n\r\nInput Data", "expected": "The device driver enumerates all drives"}], "source": ""}
{"case_id": "case-1313", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nMount each of the filesystems\r\n\r\nInput Data", "expected": "Filesystems successfully mount"}], "source": ""}
{"case_id": "case-1314", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nCheck the filesystems with fsck\r\n\r\nInput Data", "expected": "The filesystem check doesn't report any errors"}], "source": ""}
{"case_id": "case-1315", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nRe-calculate the checksums for each filesystem\r\n\r\nInput Data", "expected": "The checksums match that of the original values calculated before the previous unmount"}], "source": ""}
{"case_id": "case-1316", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a datastore on the PCIeSSD and add it to a Windows VM. Install a supported guest OS on the VM. \r\n\r\n\r\nInput Data", "expected": "PCIe SSD\r\ndatastore added to guest VM."}], "source": ""}
{"case_id": "case-1317", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nLaunch the VM and run I/O to the PCIe SSD datastore.&nbsp; \n\n\nInput Data", "expected": "I/O runs without\r\nany issues."}], "source": ""}
{"case_id": "case-1318", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStop I/O, and wait (idle) for about 10 seconds. Hot remove the PCIe SSD. \r\n\r\n\r\nInput Data", "expected": "Guest OS\r\ncontinues to run without issues. I/O can be run to other devices in the\r\nsystem through the guest OS. If any access attempt is done to the dev node\r\nassociated to the removed PCIe SSD (including fdisk), the command times out\r\nand the kernel prints out a stack dump after some predetermined time. The\r\nhost kernel log (vmkernel.log) shows a series of timeout and error messages\r\nrelated to the removed PCIe SSD but continues to run ok. The guest OS may not\r\nbe able to be rebooted if the PCIe SSD remains removed from the system. A\r\nhost reboot may be required for the system to become functional/responsive\r\nagain."}], "source": ""}
{"case_id": "case-1319", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf running, shutdown the VM. \r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1320", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRe-insert the removed PCIe SSD into the host system. \r\n\r\n\r\nInput Data", "expected": "Host system\r\ncontinues to run without freeze or hang. The guest OS may not be able to be\r\nrestarted until the PCIe SSD datastore is recognized by the host. (A host\r\nreboot may be required for the system accept the datastore and become\r\nfunctional/responsive to the guest OS.)"}], "source": ""}
{"case_id": "case-1321", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nLaunch the VM, and run some I/O to the PCIe SSD datastore. \r\n\r\n\r\nInput Data", "expected": "I/O runs\r\nsuccessfully."}], "source": ""}
{"case_id": "case-1322", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat steps 1-7 but with a Linux VM. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1323", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nImplicit\r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1324", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInsert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "The PCIe SSD shows up everywhere (PCI bus, NVMe driver is loaded, disk. mgmt tools, etc.) and is functional"}], "source": ""}
{"case_id": "case-1325", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the PCIe SSD from the system after you notice the OS has completed enumerated the previous insertion\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-1326", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 124 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1327", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 2-4 for each slot in the given controller.\r\n\r\nFor example, let's say there's 3 PCIe extender cards in the system, and each one connects to 4 drives. Then in this case, you would run to each of the four slots of one of the extender cards.\r\n\r\nAnother example would be CPU direct-attach, if the CPU port controls, 2 drives, then 125 hotplugs will be performed for both slots.\r\n\r\n\r\nInput Data", "expected": "Same results as in steps 2-4"}], "source": ""}
{"case_id": "case-1328", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart a script to cause a Link Retrain (bit 5 - Link Control Register) for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\r\n\r\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "case-1329", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert 2 or more (preferably the maximum amount) hotpluggable PCIe SSDs at the same time\r\n\r\nInput Data", "expected": "All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-1330", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove all of the drives that were just inserted at the same time\r\n\r\nInput Data", "expected": "None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-1331", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1332", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInsert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-1333", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the PCIe SSD from the system after you notice the OS starting to handle the previous insertion (adding drive to the OS however storage is not ready), but before it actually completes\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)"}], "source": ""}
{"case_id": "case-1334", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1335", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1336", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nClear the system's SEL log.\n\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-1337", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1338", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nUsing a utility such as racadm (may use any other utilities that are available), DC power cycle the system after the system boots and the attempt has been made to discover all PCIe SSD devices. Sequence should look like: boot --> OS login --> Device Detection --> DC power cycle (if no errors) Using racadm, the command should look like: racadm serveraction powercycle\n\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-1339", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the D/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-1340", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "case-1341", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}], "source": ""}
{"case_id": "case-1342", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart a script to:\r\n   1. cause a Link Disable (bit 4 - Link Control Register) by writing a 1\r\n   2. wait 3s\r\n   3. make sure the link is x0, Gen-1\r\n   4. re-enable the link by writing a 0\r\n   5. wait 3s\r\n   6. make sure the link width and speed is the maximum capable for the PCIe SSD\r\nfor 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\r\n\r\n\r\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "case-1343", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1344", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-1345", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1346", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nSetup a script to do the following upon power on: boot --> OS login --> Device Detection --> OS reboot --> repeat\n\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-1347", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the reboots for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-1348", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "case-1349", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the system's SEL log for any errors.\r\n\r\nInput Data", "expected": "No errors related to PCIe SSD are found."}], "source": ""}
{"case_id": "case-1350", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "The PCIe SSD is completely removed from the system (PCI bus, NVMe driver unloaded, disk mgmt tools, etc.)"}], "source": ""}
{"case_id": "case-1351", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the PCIe SSD back into the system after the OS has completely handled the previous removal\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-1352", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1353", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart a script to:\n   1. cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1\n   2. wait 3s\n   3. make sure the link is x0, Gen-1\n   4. take the device out of reset by writing a 0\n   5. wait 3s\n   6. make sure the link width and speed is the maximum capable for the PCIe SSD\nfor 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.\n\n\nInput Data", "expected": "The script completes all 100 loops successfully."}], "source": ""}
{"case_id": "case-1354", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [], "source": ""}
{"case_id": "case-1355", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-1356", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRe-insert the PCIe SSD back into the system after you notice the OS starting to handle the previous surprise removal (removing drive from OS), but before it actually completes\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-1357", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1358", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a PCIe SSD\r\n\r\nInput Data", "expected": "Host system continues to run without freeze or hang after the device hot insertion."}], "source": ""}
{"case_id": "case-1359", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the current and max payload of the inserted PCIe SSD and run some I/O to the drive\r\n\r\nInput Data", "expected": "Current and max payload values match system root complex.\r\n\r\nNo OS hang or any fatal error seen in the system"}], "source": ""}
{"case_id": "case-1360", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2 and 3, but this time hot insert the drive in a different slot\r\n\r\nInput Data", "expected": "Same as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1361", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCapture the Telemetry log\r\n\r\nInput Data", "expected": "The log page data is successfully obtained"}], "source": ""}
{"case_id": "case-1362", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSend the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification\r\n\r\nInput Data", "expected": "The drive vendor approves the correct format of the Telemetry data"}], "source": ""}
{"case_id": "case-1363", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCapture the Telemetry log using OMSS\n\nInput Data", "expected": "The log page data is successfully obtained"}], "source": ""}
{"case_id": "case-1364", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSend the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification\r\n\r\nInput Data", "expected": "The drive vendor approves the correct format of the Telemetry data"}], "source": ""}
{"case_id": "case-1365", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. \r\n\r\nracadm raid get pdisks -o -p SecurityStatus\r\n\r\nFor example \r\n\r\nDisk.Bay.13:Enclosure.Internal.0-1\r\nSecurityStatus = Secured\r\n\r\n\r\nInput Data", "expected": "All the devices came as secured and no other status is displayed"}], "source": ""}
{"case_id": "case-1366", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCreate partitions on a single drive under test\r\n\r\nInput Data", "expected": "The OS enumerates partitions on the device under test."}], "source": ""}
{"case_id": "case-1367", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the drive and hot insert the drive in the same slot.\r\nCheck the partitions after 60sec\r\n\r\n\r\nInput Data", "expected": "All the partitions are enumerated correctly by the OS"}], "source": ""}
{"case_id": "case-1368", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nHot insert an unsecured NVMe SED into the system and check the status of the disk after sometime \nracadm raid get pdisks -o -p SecurityStatus\n\nThe hot inserted disk should show as Encryption Capable\nFor example \n\nDisk.Bay.13:Enclosure.Internal.0-1\nSecurityStatus = Encryption Capable \n\n\nInput Data", "expected": "The hot inserted device is not secured and can also be verified via iDRAC GUI"}], "source": ""}
{"case_id": "case-1369", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo to Storage->physical disk and selection action to secure the drive \r\nSecure drive option shall be available in the drop down Action menu\r\n\r\n\r\nInput Data", "expected": "Secure drive Job is created and completes successfully"}], "source": ""}
{"case_id": "case-1370", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the security state of the drive via Racadm command in step 2 or via GUI security section. \r\n\r\n\r\n\r\nInput Data", "expected": "The status should be \"secured\""}], "source": ""}
{"case_id": "case-1371", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. \r\n\r\nracadm raid get pdisks -o -p SecurityStatus\r\n\r\nFor example \r\n\r\nDisk.Bay.13:Enclosure.Internal.0-1\r\nSecurityStatus = Secured\r\n\r\n\r\nInput Data", "expected": "All the devices came as secured and no other status is displayed"}], "source": ""}
{"case_id": "case-1372", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGo to services->iDRAC Key Management->Rekey\r\nPerform rekey operation  \r\n\r\n\r\nInput Data", "expected": "The rekey operation is successful and job completed successfully without any issue."}], "source": ""}
{"case_id": "case-1373", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nOnce in OS, Check the power state of the device (Config space or trace capture) and check the presence detect bit by dumping the pci register\n\nInput Data", "expected": "The drive is in D0 and Link in L0 state and the presence detect bit is set to 1"}], "source": ""}
{"case_id": "case-1374", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nFrom OS disable or unload the driver\n\n\nInput Data", "expected": "The driver is unloaded and no transactions going to the device"}], "source": ""}
{"case_id": "case-1375", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the power state of the device by checking config space or trace\r\n\r\n\r\nInput Data", "expected": "Depending on OS the device should go to D3 state and if not write to the register to bring device to D3 state"}], "source": ""}
{"case_id": "case-1376", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove the drive from the system and dump the pci register and check the presence detect bit\r\n\r\nInput Data", "expected": "The values of the presence detect bit is 0 for the port above the drive. (downstream switch port or root port)"}], "source": ""}
{"case_id": "case-1377", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nMake a list of all NVMe devices which are compliant to the NVMe 1.2 spec or greater.\n\nThis can be done by issuing an Identify Controller command and reading the VER offset, or by reading the MMIO location where the version is stored\n\n\nInput Data", "expected": "There is at least one NVMe device which is compliant to 1.2 or greater"}], "source": ""}
{"case_id": "case-1378", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue the Get Log Page - Command Effects Log (Log Page ID = 5) to each of the drives discovered in step 2\n\nInput Data", "expected": "The command is successful"}], "source": ""}
{"case_id": "case-1379", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue below NVMe MI Commands to the each drive (preferably via the automation script 'NVMeMICLI.py).\n\npython3 NVMeMICLI.py -i 'iDRAC IP' -a PCIe BDF'\n   1. Send Configuration Get\n   2. Send Configuration Set\n   3. Send Controller Health Status Poll\n   4. Send NVM Subsystem Health Status Poll\n   5. Send Get Log Page - Firmware Information\n   6. Send Get Log Page - SMART/Health Information\n   7. Send Get Log Page - Telemetry/PEL log\n   8. Send Identify - Controller\n   9. Send Identify - Namespace\n  10. Send Get Features\n  11. Send Set Features\n\n\n\nInput Data", "expected": "All the commands are successful, no NACKS or timeouts."}], "source": ""}
{"case_id": "case-1380", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 after performing hotplug on all PCIe SSDs.\r\n\r\nInput Data", "expected": "All commands are successful after hotplug, no NACKs or timeouts."}], "source": ""}
{"case_id": "case-1381", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nSSH into the iDRAC having test firmware for TCG Support into rootshell\n\nIf performing tests first time after iDRAC reboot run following 2 commands\nsetenforce 0\ntestlibsednvme\n\n\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1382", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue following command to query the drive of it's state\n\n\ncontroller id should be determined from identify controller response in OS\ntestlibsednvme query  <eid> <controllerid>\n\n\nFor example:\n\n testlibsedclient query 6 65\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "Check if the locking enabled is turned on \r\nFor example:\r\nlocking enabled = 1\r\n\r\nIf not security needs to be enabled first."}], "source": ""}
{"case_id": "case-1383", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nWrite some data to the device in band /OS\nEx-\nnvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1\n\nIssue a revert command using SID as user \n\ntestlibsednvme revert  <eid> <controllerID>  <key> <keylength> <user>\n\n\nAlso make sure function return code is 0\nThe user shall be SID which is 0.\nAlso, use the key that was used to enable security and if security is not enabled use default MSID key\nFor example \ntestlibsednvme revert 6 65 Dell1234 8 0\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\n\n\nInput Data", "expected": "The revert operation get's completed and return code is 0"}], "source": ""}
{"case_id": "case-1384", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue following command to query the drive of it's state\r\n\r\ntestlibsednvme query <eid> <controllerID>\r\n\r\nFor example:\r\n\r\ntestlibsednvme query 6 65\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Locking is enabled is turned off \n\nFor example:\nlocking enabled = [0]\n\nAlso, Check the data written in step 4 is erased.\nEx-\nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1"}], "source": ""}
{"case_id": "case-1385", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nEnable Security again on drive and \r\ngo to step 3 and repeat all steps except use PSID printed on device label and user as PSID which is 1. \r\n\r\ntestlibsednvme DellEnableSecurity <eid> <controllerid> <key> <keylength> 1 \r\n\r\n\r\nInput Data", "expected": "The same state of device is reached even after doing PSID revert."}], "source": ""}
{"case_id": "case-1386", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nEnable Security and go to step 3. \r\nRepeat the sequence for for at least 20 times. \r\n\r\n\r\nInput Data", "expected": "All operations succeed fully"}], "source": ""}
{"case_id": "case-1387", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Prepare for Endpoint Discovery and Endpoint Discovery command on the PCIe SSD (preferably via automation script .MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'\r\n\r\n\r\nInput Data", "expected": "Device responds to discovery commands."}], "source": ""}
{"case_id": "case-1388", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise Remove PCIe SSDs under test in the system. \r\n\r\nInput Data", "expected": "None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)."}], "source": ""}
{"case_id": "case-1389", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot Insert PCIe SSDs in the system which was removed.\r\n\r\nInput Data", "expected": "All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)."}], "source": ""}
{"case_id": "case-1390", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue Prepare for Endpoint Discovery and Endpoint Discovery command on hot inserted PCIe SSD (preferably via automation script .MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'\r\n\r\nInput Data", "expected": "Device responds to discovery commands after hotplug."}], "source": ""}
{"case_id": "case-1391", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake sure the drive has some data and Run some I/O to the device.\r\n\r\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-1392", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot remove the device using Quarch while I/O is running\r\n\r\nInput Data", "expected": "You might see I/O errror"}], "source": ""}
{"case_id": "case-1393", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot insert the drive and check for the data loss\r\n\r\nInput Data", "expected": "Data is intact. No data loss is found."}], "source": ""}
{"case_id": "case-1394", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat step 2, 3 and 4\r\n\r\nInput Data", "expected": "Result same as step 2,3 and 4."}], "source": ""}
{"case_id": "case-1395", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue below MCTP commands to the each drive (preferably via the automation script 'MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'\r\n   1. Send Set Endpoint ID\r\n   2. Send Get Endpoint ID\r\n   3. Get Endpoint UUID\r\n   4. Get MCTP Version Support\r\n   5. Get Message Type Support\r\n   6. Prepare for Endpoint Discovery\r\n   7. Endpoint Discovery\r\n\r\n\r\nInput Data", "expected": "All the commands are successful, no NACKS or timeouts."}], "source": ""}
{"case_id": "case-1396", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 after performing hotplug on all PCIe SSDs.\r\n\r\nInput Data", "expected": "All commands are successful after hotplug, no NACKs or timeouts."}], "source": ""}
{"case_id": "case-1397", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1398", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\nIssue following command to query the drive of it's state\r\n\r\n\r\ncontroller id should be determined from identify controller response in OS\r\ntestlibsednvme query\r\n\r\n\r\nFor example:\r\n\r\ntestlibsedclient query 6 0\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "Locking enabled is turned off \r\nFor example:\r\nlocking enabled = [0]\r\n\r\nIf the locking is enabled make sure to run revert test case prior to running this."}], "source": ""}
{"case_id": "case-1399", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nEnable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. \r\nProvide user as Admin and it should be 1\r\n\r\ntestlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>\r\nAlso make sure function return code is 0\r\n\r\nFor example \r\ntestlibsednvme DellEnableSecurity 6 0 Dell123456 10 1\r\n\r\n\r\nNote : This is just an example change according to your device\r\nSending command to wrong eid can result in hang and racreset is required\r\n\r\n\r\nInput Data", "expected": "The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. \r\n\r\nFor example \r\nlocking supported = [1]\r\nlocking enabled = [1]\r\ndatastore size = [10485760]\r\ndatastore flag = [2]\r\nold_keyId = [MSID KEY]\r\ncurrent_keyId = [Dell123456]"}], "source": ""}
{"case_id": "case-1400", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBoot to a DOS/DRMK bootable media with the D3hot and PCI utilities provided in this test case.\n\nInput Data", "expected": "Run pciall.exe to determine what the position is for the PCIe extender card and drives. Use these values and make sure that the script is updated correctly."}], "source": ""}
{"case_id": "case-1401", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nRun the script overnight.\n\nInput Data", "expected": "No PCIe fatal errors should be reported. Check the SEL logs for any errors."}], "source": ""}
{"case_id": "case-1402", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInstall the NVMe CLI tools from the operating system distribution.\n\nFor example:\nUbuntu: apt-get install nvme-cli\nRed Hat: yum install nvme-cli\n\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1403", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nRun the attached shell script\n\nInput Data", "expected": "Script runs without any errors for 10 minutes and exits.\r\n\r\nSystem does not crash."}], "source": ""}
{"case_id": "case-1404", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nVerify that the drive is still accessible by performing some IO to it.\r\n\r\n\r\n\r\nInput Data", "expected": "Drive responds normally and IO completes without error"}], "source": ""}
{"case_id": "case-1405", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue identify namespace command and note down original name space size.", "expected": "Original namespace size is noted"}], "source": ""}
{"case_id": "case-1406", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Detach and delete the original namespace by using nvme-cli or the automation framework. \r\nEx-\r\npython3 NVMeIOCTLCLI.py -dtns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>\r\npython3 NVMeIOCTLCLI.py -dlns <bdf>", "expected": "The original NS is detached and deleted."}], "source": ""}
{"case_id": "case-1407", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Determine the maximum number of namespaces supported by the drive by sending an Identify Controller command to the drive, looking at the \"Number of Namespaces\" field.\r\n\r\nDivide the entire drive capacity by the \"Number of Namespaces\" field from above to obtain the new namespace size.\r\n\r\nCreate \"Number of Namepaces\" amount of namespaces using the calculated size from above.\r\n\r\nEx- 4 Namespaces\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -crns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\n------------------------------------------------------------------------\r\npython3 NVMeIOCTLCLI.py <bdf> -atns\r\npython3 NVMeIOCTLCLI.py <bdf> -rc", "expected": "All commands are successful and the max. number of NS created is visible at block layer. \r\nEx- lsblk or nvme list"}], "source": ""}
{"case_id": "case-1408", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Issue and Identify Namesapce to each of the newly created namespaces, taking note of the \"Namespace Globally Unique Identifier\" and \"IEEE Extended Unique Identifier\" fields", "expected": "The NGUID is unique for all namespaces OR, it is 0 for all namespaces and the EUI64 is unique for all namespaces.\r\n\r\nThe EUI64 is unique for all namespaces OR, it is 0 for all namespaces and the NGUID is unique for all namespaces."}], "source": ""}
{"case_id": "case-1409", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Detach and delete all the NS created. \r\nEx- python3 ns_create_delete_max.py <bdf> -dlns <number of NS supported>", "expected": "All the NS is deleted and verified using appropriate command \r\nEx- lsblk or nvme list in linux"}], "source": ""}
{"case_id": "case-1410", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "create and attach the original NS of size noted in step2. \npython3 NVMeIOCTLCLI.py -crns <bdf>  \npython3 NVMeIOCTLCLI.py -atns <bdf>\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "The original NS is created and visible to OS\r\nEx- lsblk or nvme list\r\nAlso check SMART log for any errors."}], "source": ""}
{"case_id": "case-1411", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\nFor example \npython3 NVMeIOCTCLI.py -gl bdf \n\nNSID = 0x0\nLID= 0x0d\nsubpage = 0x0\nnum of dwords = 0x0\nevent notification = 0x0\n\n\n\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-1412", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the current active firmware version running on the device. \r\nUpdate the firmware on the device, up rev or down rev both could be used for this test case with live firmware activate\r\nAny  utility could be used for updating firmware but DUP is a preferred method. \r\n\r\nNote down the version of the newly activated firmware. \r\n\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The firmware update was a successful operation and both old as well as new version was noted."}], "source": ""}
{"case_id": "case-1413", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for Firmware Commit  correctly logged earlier in the Persistent Event Log data with all the respective fields correctly populated as per spec."}], "source": ""}
{"case_id": "case-1414", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell  \r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands \r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1415", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nStart running I/O + Admin command to the device. \nadmin command like identify or get log page could be run in a loop along side some IO\n\nIssue following command to get the discovery for determining if drive supports Locking \n testlibsednvme query < eid > <controller id in decimal>\n\n \ncontroller id should be determined from identify controller response\nand eid from previous step. \nFor example:\ntestlibsednvme query 4 65\n\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then \r\nLocking Enabled: 0 other wise 1 if already security is enabled"}], "source": ""}
{"case_id": "case-1416", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue identify namespace command and note down original name space size.\r\n\r\nInput Data", "expected": "Original namespace size is noted"}], "source": ""}
{"case_id": "case-1417", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetach and delete the original NS by using nvme-cli or automation framework. \r\nEx- python3 NVMeIOCTLCLI.py -dtns <bdf>\r\npython3 NVMeIOCTLCLI.py -rc <bdf>\r\npython3 NVMeIOCTLCLI.py -dlns <bdf>\r\n\r\n\r\nInput Data", "expected": "The original NS is detached and deleted."}], "source": ""}
{"case_id": "case-1418", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCreate and attach four namespaces\r\n \r\npython3 ns_create_delete_max.py <bdf> -crns 4\r\n\r\nTODO: Verify that this tool actually works this way\r\n\r\n\r\nInput Data", "expected": "Wait sufficient time for all of the namespaces to be created.  There should be 4 namespaces visible at the block layer\r\n \r\nEx- lsblk or nvme list"}], "source": ""}
{"case_id": "case-1419", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUse a tool such as testio or diskio to write to all four namespaces simultaneously for at least 30 minutes, with multiple threads per namespace and data verification enabled.  This will entail running four instances of the tool, one per block device visible in the operating system\r\n\r\nInput Data", "expected": "IO test tools should all run to completion without errors noted"}], "source": ""}
{"case_id": "case-1420", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDetach and delete all the NS created . \r\nEx- python3 ns_create_delete_max.py <bdf> -dlns 4\r\n\r\n\r\nInput Data", "expected": "All the NS is deleted and verified using appropriate command \r\nEx- lsblk or nvme list in linux"}], "source": ""}
{"case_id": "case-1421", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\ncreate and attach the original NS of size noted in step2. \npython3 NVMeIOCTLCLI.py -crns <bdf>  \npython3 NVMeIOCTLCLI.py -atns <bdf>\npython3 NVMeIOCTLCLI.py -rc <bdf>\n\n\nInput Data", "expected": "The original NS is created and visible to OS\r\nEx- lsblk or nvme list\r\nAlso check SMART log for any errors."}], "source": ""}
{"case_id": "case-1422", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nGet the smart logs from the device \r\nplease use attachment in this test case to verify the test case \r\n\r\n\r\nInput Data", "expected": "The critical bits are not set and device status LED is solid green"}], "source": ""}
{"case_id": "case-1423", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\ncreate the file SMARTErrorInjection.txt in the same directory where NVMEIOCTLCLI.py exists\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1424", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nEnter the values 1,2,4,8,10 in the SMARTErrorInjection.txt one at a time.\r\n\r\nThese values can be found in NVMe SPEC under SMART/Health information section\r\n\r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1425", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\n\r\nrun the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 \r\n\r\n\r\n\r\nInput Data", "expected": "get the smart logs and check the bit is set for the critcal bits"}], "source": ""}
{"case_id": "case-1426", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nWait for 20 mins and Check idrac, OMSS, HII for status/state and Failure predicted.\r\n\r\n\r\nInput Data", "expected": "The message across all the management application is same`"}], "source": ""}
{"case_id": "case-1427", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\n1. Clear the bit , by entering 0 into SMARTErrorInjection.tx\n\n2.run the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 \n\n\n\nInput Data", "expected": "get the smart logs and check the bit is cleared"}], "source": ""}
{"case_id": "case-1428", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat the steps from step 2 - 6 for next critical bits\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1429", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue an Identify Controller to the device  \r\n\r\nInput Data", "expected": "Check LPA (Log Page Attribute ) Field at offset 261 bit 3 to be set. \r\nIf set the device supports telemetry"}], "source": ""}
{"case_id": "case-1430", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue a host initiated telemetry command for the all the data area to be returned as response.  \nIf using automation framework\nfollow below example NSID=0xFFFFFFFF\n\n[root@localhost PCIeSSD]# python3 NVMeIOCTLCLI.py -gl 24:00.0\n        \n\n        Log Page ID (0x00 - 0xFF) = 0x07\n        Log Page Sub ID (0x00 - 0xFF) = 0x0\n        Number of DWORDS (0x00 - 0xFF) = 0x7f\n        Retain Asynchronous Event (0 or 1) = 0\n\n\n\nInput Data", "expected": "The device responds with the required telemetry log."}], "source": ""}
{"case_id": "case-1431", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nThe telemetry log returned is to be stored in a .bin file and should be saved. \r\n\r\nInput Data", "expected": "The log saved should be sent to the vendor for analysis and to be confirmed if data returned is good."}], "source": ""}
{"case_id": "case-1432", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nread the FRU of the device using libi2c command from the slot where the PCIeSSD or Extender card is present\n\nPCIeSSD\nlibi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256'\n\nAdapteres\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\n\n\nInput Data", "expected": "FRU data is read from the device from the particular slot\r\nnote down the serial number and manufacturing date and time values"}], "source": ""}
{"case_id": "case-1433", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInput the serial number and manufacturing date and time and calculate the checksum value for board information area format version.\r\nCompare the data from the shipped FRU image vs FRU read from the  device .\r\n\r\n\r\nInput Data", "expected": "The shipped FRU images and FRU from the device should match"}], "source": ""}
{"case_id": "case-1434", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nread the FRU using IPMI command for the device and match against shipped image with the modified serial number, manufacturing date and time and checksum for the section which is already done in step 3.\n\nIPMI commands\nPCIESSD U.2\nipmitool -U root -P calvin raw 0x30 0x36 0x00 0x0  bay  slot 0x01 0x00 0x00 0x20\n\nAIC\n'ipmitool -U root -P calvin raw 0x30 0x36 0x01 slotnumer  0x01 0x01 0x00 0x00 0x20\n\nFor Extender card : IPMI commands donot support - 14G\n\n\nInput Data", "expected": "The values read using IPMI commands and idrac should match."}], "source": ""}
{"case_id": "case-1435", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSelect a NVMe device and dump SMART log(OMSA Can be used). Take a note of Unsafe Shutdown Count. \r\n\r\nInput Data", "expected": "SMART data is successfully pulled."}], "source": ""}
{"case_id": "case-1436", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a Crypto Erase to the drive (OMSA Can be used)\r\n\r\nInput Data", "expected": "The Command goes to the drive."}], "source": ""}
{"case_id": "case-1437", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue a shutdown notification to the drive immediately after CE . (Driver unload and load will do ) \r\n\r\nInput Data", "expected": "Device is available."}], "source": ""}
{"case_id": "case-1438", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDump the SMART Log for the drive and look for Unsafe Shutdown Count\r\n\r\nInput Data", "expected": "The Unsafe shutdown count remains same."}], "source": ""}
{"case_id": "case-1439", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 2-5 for at least 5 times. \r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1440", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf testing with iDRAC version is 5.0.0.0, cold boot the system.\r\nIf testing with version is 5.10.00.0 or greater, omit this step. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1441", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGet the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Device BDF's are listed in iDRAC log."}], "source": ""}
{"case_id": "case-1442", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nLaunch the iDRAC GUI, go to Maintenance / System Update and Upload DUP for the PCIe SSD. Once you get success for the download, go ahead and select the \"Install\" button.\r\n\r\nNOTE: If you see Install and Reboot, Install Next Reboot buttons, it is a issue.\r\n\r\nPop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.\r\n\r\n\r\nInput Data", "expected": "Verified that the DUP package uploads successfully and both the job passed with no issues."}], "source": ""}
{"case_id": "case-1443", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.\r\n   1.  SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version <version n>.)\r\n   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n>).\r\n   3.  PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version :<version n-1>, Current version: <version n>).\r\n\r\n\r\n\r\nInput Data", "expected": "User verified LC logs reported the correct entry for each PCIe SSD."}], "source": ""}
{"case_id": "case-1444", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nGo to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.\r\n\r\nGo to OS and verify that new FW version is reported on all drives you updated.\r\n\r\nInput Data", "expected": "User verified storage inventory reported the correct FW version for all drives.\n\nUser verified FW inventory reported the correct FW version for all drives.\n\nUser verified that OS reported the correct FW version for all drives."}], "source": ""}
{"case_id": "case-1445", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-7 after performing hotplug operation to PCIe SSDs.\r\n\r\nInput Data", "expected": "Firmware is updated successfully after hotplug."}], "source": ""}
{"case_id": "case-1446", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nDownload device firmware:\nLinux:\n    nvme fw-download /dev/nvme0n1 -f your_fw_file.tar\n\nUse the raw binary file or tar file for the FW (not the DUP)\n\n\nInput Data", "expected": "Firmware download completes successfully."}], "source": ""}
{"case_id": "case-1447", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nActivate FW w/o reset:\r\nLinux:\r\n    nvme fw-commit /dev/nvme0n1 -a 3-s 0\r\n\r\n\r\nInput Data", "expected": "Firmware activation succeeds.\r\nIO haults while FW download and commit take place and then re-starts"}], "source": ""}
{"case_id": "case-1448", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nUsing a tool that can send IOCTLs to the NVMe driver (like nvme-cli in Linux/ESXi or the Dell NVMeIOCTLCLI tool), issue an Identify Controller command to the drive(s)\n\nInput Data", "expected": "Read the \"Sanitize Capabilities\" field (offset 331:328) and confirm that at the very least, bits 0 and 1 are set"}], "source": ""}
{"case_id": "case-1449", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nPartition, format, and put some data onto the drive(s)\n\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}], "source": ""}
{"case_id": "case-1450", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x04 to the drive(s) in order to initiate a Sanitize - Cryptographic Erase operation\n\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}], "source": ""}
{"case_id": "case-1451", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nPartition, format, and put some data onto the drive(s)\r\n\r\nInput Data", "expected": "Data is successfully copied onto the drive(s)"}], "source": ""}
{"case_id": "case-1452", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nUsing a tool for sending an IOCTL, issue a Sanitize command with the \"Sanitize Action\" set to 0x02 to the drive(s) in order to initiate a Sanitize - Block Erase operation\r\n\r\nInput Data", "expected": "The command completes successfully and the data on the drive(s) is no longer accessible"}], "source": ""}
{"case_id": "case-1453", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach a target drive to a Quarch and insert it into the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1454", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nUsing the Quarch, remove the drive from the system.  Verify that the drive is not present in the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1455", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUsing the Quarch, reinsert the drive in the system.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1456", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nWait 45 seconds.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1457", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nUsing the Quarch, issue a P/E reset to the drive.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1458", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nUsing the Quarch, remove the drive from reset.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1459", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nWait 10 seconds.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1460", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nVerify that an identify controller issued to the drive returns successfully.\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1461", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart running I/O + Admin command to the device. \nadmin command like identify or get log page could be run in a loop along side IO\n\n\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-1462", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue a device discovery command using attached binary \"sedlib\". \nFor example \n./sedlib -a q -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "The command completes successfully and device returns discovery data."}], "source": ""}
{"case_id": "case-1463", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\ncheck feature: 0x2  specific fields along with Feature 0x 203\n\nInput Data", "expected": "The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then \r\nLocking Enabled: 0 other wise 1 if already SP is activated. \r\nAlso Feature 0x203 should advertise Opal 2 support"}], "source": ""}
{"case_id": "case-1464", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue Get Endpoint ID (EID) MCTP command to each drive (preferably via the automation script 'MCTPControl.py).\r\n\r\npython3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'", "expected": "The command is successful and all the devices have a valid non-zero Endpoint ID (EID)."}], "source": ""}
{"case_id": "case-1465", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Repeat step 2 after performing hotplug on all PCIe SSDs.", "expected": "The command is successful and all the devices have a valid non-zero Endpoint ID (EID)."}], "source": ""}
{"case_id": "case-1466", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\nFor example \npython3 NVMeIOCTCLI.py -gl bdf \n\n NSID = 0xffffffff\nLID= 0x0d\nsubpage =0x0\nnum of dwords = 0x7f\n\n\n\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-1467", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "root", "description": "Description\nIssue delete name space  command to the drive . \nFor example\n\npython3 NVMeIOCTCLI.py -dlns bdf \n\n\n\n\nInput Data", "expected": "The name space got deleted without any issue."}], "source": ""}
{"case_id": "case-1468", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nhIssue Controller reset, then Go to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for Change namespace correctly logged earlier in the Persistent Event Log data\r\nMake sure the fields are programmed correctly."}], "source": ""}
{"case_id": "case-1469", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nRestore the original namespace by using create name space and attach namespace.\nThe PEL event log could be used to know the size of the namespace deleted.\n\nFor example\npython3 NVMeIOCTCLI.py -crns bdf\n\npython3 NVMeIOCTCLI.py -atns bdf\n\n\nInput Data", "expected": "Namespace was created and attached."}], "source": ""}
{"case_id": "case-1470", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nStart running heavy IO on all the devices for 12 hrs and capture SMART logs from all devices\n\nInput Data", "expected": "No issue is found starting the IO and SMART logs are captured from all devices."}], "source": ""}
{"case_id": "case-1471", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nStart running NVMe Subsystem Health Status poll MI command similar to iDRAC. \nUse automation framework to start the traffic. \n\n\nInput Data", "expected": "Side band MI traffic started and commands start completing successfully"}], "source": ""}
{"case_id": "case-1472", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nRun both IO and side band command stress for 12 hrs. \nDump smart logs from all devices and compare from previous one collected at the beginning. \nAlso, check OS logs for the timeout or any errors.\n\n\nInput Data", "expected": "Test completes successfully and no errors are logged in SMART log."}], "source": ""}
{"case_id": "case-1473", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSSH into the iDRAC having test firmware for TCG Support into rootshell\r\n\r\nIf performing tests first time after iDRAC reboot run following 2 commands\r\nsetenforce 0\r\ntestlibsednvme\r\n\r\n\r\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1474", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nStart running I/O + Admin command to the device.\nadmin command like identify or get log page could be run in a loop along side some IO\nAlso, if this is the first test after iDRAC reboot make sure you set MTU size. to 120 as recomended \ntestlibsednvme setMTUsize <eid> 120\n\nIssue following command to get the MSID of the device which is the default key \ntestlibsednvme getmsid < eid > <controller ID>\n\ncontroller id should be determined from identify controller response\nand eid from previous step.\nFor example:\ntestlibsednvme getmsid 4 0\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\nInput Data", "expected": "The device should return the MSID. \r\nFor example \r\n msid = MSID_password\r\n\r\nThe msid varies from device to device and vendor to vendor."}], "source": ""}
{"case_id": "case-1475", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nRemove the drive from the system\r\n\r\nInput Data", "expected": "The drive is no longer enumerated in the OS"}], "source": ""}
{"case_id": "case-1476", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\n   1. Assign all signals to a source group.\nAssign all refclk signals to a separate source group\n\n   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source\n          o signal:ref_clk_0_mn:source 1 <1>\n          o add the other 3 similarly using a 100ms delay\n   2. \n\n\n\nInput Data", "expected": "Signals are added successfully."}], "source": ""}
{"case_id": "case-1477", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInsert the drive so that all signals except the refclk are inserted\r\n\r\nInput Data", "expected": "The drive will likely not get detected but that's fine"}], "source": ""}
{"case_id": "case-1478", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove the drive normally\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-1479", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert the drive back in normally\r\n\r\nInput Data", "expected": "The OS is able to detect the drive"}], "source": ""}
{"case_id": "case-1480", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRun I/O for a minute to the drive to verify functionality\r\n\r\nInput Data", "expected": "The drive successfully processes I/O"}], "source": ""}
{"case_id": "case-1481", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCapture the values of the following PCIe registers: \n\nUncorrectale Error Mask Register (UEMsk)\nCorrectale Error Mask Register  (CEMsk)\nUncorrectable Error Severity Register  (UESvrt)\n\n\nInput Data", "expected": "Implict"}], "source": ""}
{"case_id": "case-1482", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSurprise remove the drive from the system\r\n\r\nInput Data", "expected": "The system is functional. No error/ fatal error is reported."}], "source": ""}
{"case_id": "case-1483", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot Insert the drive that was removed in step 4 back into the system\r\n\r\nInput Data", "expected": "The device is recognized by the OS and functional"}], "source": ""}
{"case_id": "case-1484", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nCapture the values of the following PCIe registers: \n\nUncorrectale Error Mask Register (UEMsk)\nCorrectale Error Mask Register  (CEMsk)\nUncorrectable Error Severity Register  (UESvrt)\n\n\n\n\nInput Data", "expected": "The values of the registers are the same as when they were captured in step 2"}], "source": ""}
{"case_id": "case-1485", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCheck if device is enabled for locking by doing query. \nEx- ./sedlib -a q -d /dev/nvme0n1 -x nvme\nIf not enabled then activate SP \n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\n\n\n\nInput Data", "expected": "The device is activated for locking"}], "source": ""}
{"case_id": "case-1486", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nRead some data from the device \nEx- nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\n\n\n\nInput Data", "expected": "The data is read without any issue"}], "source": ""}
{"case_id": "case-1487", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nLock the device for the global range (whole device) using Band 0 (global ) \nEx-\n./sedlib -a l -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme\n\n\n\nInput Data", "expected": "The device is locked and command completes successfully. \r\nRun query command to confirm."}], "source": ""}
{"case_id": "case-1488", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nTry to read data previously written . \nEx- \nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\n\n\nInput Data", "expected": "Access is denied showing device is locked"}], "source": ""}
{"case_id": "case-1489", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nUnlock the device using following command and read data again \nEx-\n ./sedlib -a u -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme\n\n\n\n\nInput Data", "expected": "The data is accessible."}], "source": ""}
{"case_id": "case-1490", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO\r\n\r\n\r\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-1491", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue print MSID command to get MSID for the device. \nEx. \n./sedlib -a pm -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "The command get's completed successfully and MSID is printed, note down for future purpose. \r\nEx. \r\nAttempting to perform action: PRINT MSID\r\nMSID is 13 bytes long:\r\nMSID_password"}], "source": ""}
{"case_id": "case-1492", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nAdd the target devices reference clock pins to a quarch source.\n\n   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source\n          o signal:ref_clk_0_mn:source 1 <1>\n          o add the other 3 similarly\n   2. All other signals would be another source number with a delay of 10ms after the clock source group\n\n\n\n\nInput Data", "expected": "Signals are added successfully."}], "source": ""}
{"case_id": "case-1493", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBegin I/O to the target device.  \r\n    Example:\r\n        Linux:  testio -t50 -f/dev/nvme0n1\r\n        Windows:  testio.exe -f50 -f\\\\.\\PHYSICALDRIVEX\r\n        Framework:   \r\n            import ServerStorageSDK.Helpers.IO as IO\r\n            io = IO.IO()\r\n            io.Validate('testio', False)\r\n            io.Threads = 50\r\n            io.Start(['/dev/nvme0n1'])\r\n\r\n\r\nInput Data", "expected": "I/O starts without error."}], "source": ""}
{"case_id": "case-1494", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\n\r\nRemove the reference clock by turning the source off\r\n\r\n    * source:1:state off <1>\r\n\r\n\r\n\r\nInput Data", "expected": "I/O will likely fail"}], "source": ""}
{"case_id": "case-1495", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nImmediately remove all other signals from the Quarch\r\n\r\nInput Data", "expected": "The drive is removed from the OS"}], "source": ""}
{"case_id": "case-1496", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert the drive back in normally\r\n\r\nInput Data", "expected": "The OS is able to detect the drive"}], "source": ""}
{"case_id": "case-1497", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRun I/O for a minute to the drive to verify functionality\r\n\r\nInput Data", "expected": "The drive successfully processes I/O"}], "source": ""}
{"case_id": "case-1498", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck Expansion ROM Base Address Register at offset 30h in the Config space. \r\n\r\n\r\n\r\nInput Data", "expected": "The value of the register should be zero."}], "source": ""}
{"case_id": "case-1499", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall a Linux VM and attach nvme device as passthrough along with data store nvme devices\r\n\r\nInput Data", "expected": "The VM boots and drive is attached without any errors."}], "source": ""}
{"case_id": "case-1500", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInstall \"nvme-cli \" package and dump smart-log for each pass through device using following command. \r\n\"nvme smart-log /dev/nvmexn1\" . Save the output to  file. \r\n\r\n\r\nInput Data", "expected": "The package get's install and the drive logs are collected in a file."}], "source": ""}
{"case_id": "case-1501", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart running IO to all devices (pass through as well as data store) and in the background run shell script to poll for smart log on all pass through devices.\r\n\"nvme smart-log /dev/nvmexn1\". \r\n\r\n\r\nInput Data", "expected": "IO runs fine and smart data is polled without any issues."}], "source": ""}
{"case_id": "case-1502", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue controller reset to all pass through devices after every 20 min interval. please find the attached script for reference. \r\n\r\nInput Data", "expected": "The drive goes through a reset and temporarily IO is paused."}], "source": ""}
{"case_id": "case-1503", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nLet the test run for at least 2 hrs and collect smart  log for all the devices mentioned in step 3. Also, check SEL and OS logs to make sure no errors are reported. \r\n\r\nInput Data", "expected": "There are no errors reported as part of SMART log and OS logs."}], "source": ""}
{"case_id": "case-1504", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFrom the OS, run the DUP as below -\r\n\r\n1) In Windows Server, double click on the DUP (.exe) and follow the prompts\r\n\r\n2) In Linux, open a terminal from where the DUP is located and execute it, and follow the prompts\r\n\r\n\r\nInput Data", "expected": "DUPs launch and the FW update process starts"}], "source": ""}
{"case_id": "case-1505", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nOnce the FW update is completed, make sure to check from the OS if the device shows up with the correct FW\r\n\r\nIf you are using a Gen3 device, you will be prompted to reboot\r\nIf you are using a Gen4 device, reboot will not be required\r\n\r\nWindows Servers have different behavior, please check with the project lead for exact behvior on reboot prompts\r\n\r\n\r\nInput Data", "expected": "FW update applied in Step #2 is visible and device is at correct Firmware"}], "source": ""}
{"case_id": "case-1506", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nFollow the steps #2 and #3 for Firmware Downgrade\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1507", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\nFor example \npython3 NVMeIOCTCLI.py -gl bdf \n\nNSID = 0x0\nLID= 0x0d\nsubpage = 0x0\nnum of dwords = 0x0\nevent notification = 0x0\n\n\n\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-1508", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nInject UR error on the device \n\nsetpci -s bdf 0x10.w=0xffff\n\n\n\n\n\n\nInput Data", "expected": "The device goes through DPC recovery"}], "source": ""}
{"case_id": "case-1509", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for NVM subsystem Hardware Error Event  correctly logged in the Persistent Event Log with event code as 0x05"}], "source": ""}
{"case_id": "case-1510", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the MCTP Support Bit is set to 1 in NVMe PCIe MultiRecord Area.\r\n\r\nInput Data", "expected": "MCTP Support Bit is set to 1 confirms that PCIe VDM is supported on the device."}], "source": ""}
{"case_id": "case-1511", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\n NSID = 0xffffffff\r\nLID= 0x0d\r\nsubpage =0x0\r\nnum of dwords = 0x7f\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-1512", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue Sanitize command to the drive . \r\nFor example\r\n\r\npython3 NVMeIOCTCLI.py -sn bdf \r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Sanitize operation successfully completed without any errors."}], "source": ""}
{"case_id": "case-1513", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue Controller reset, then Go to step 2 and dump the log. \r\nMake sure to save the log in different files. \r\nCompare the two logs\r\n\r\n\r\nInput Data", "expected": "The new event for Sanitize correctly logged earlier in the Persistent Event Log data"}], "source": ""}
{"case_id": "case-1514", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue an Identify Controller command to the drive(s)\r\n\r\nInput Data", "expected": "The \"Optional Admin Command Support\" field (offset 257:256) shows that bit 4 is set"}], "source": ""}
{"case_id": "case-1515", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue a Device Self-Test command with the \"Self-test Code\" set to 0x01 in order to initiate a short DST\r\n\r\nInput Data", "expected": "The command completes successfully"}], "source": ""}
{"case_id": "case-1516", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nIssue an Identify Controller command and read the \"Extended Device Self-test Time\" field (offset 317:316)\n\nInput Data", "expected": "The value read is non-zero"}], "source": ""}
{"case_id": "case-1517", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue a Device Self-test command with the \"Self-test Code\" set to 0x02 in order to initiate an extended DST\r\n\r\nInput Data", "expected": "The command completes successfully and takes no longer than 20% of the value specified from step 4. For example, if the value from step 4 says 5 minutes, then the test should take no longer than 6 minutes."}], "source": ""}
{"case_id": "case-1518", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nMake sure that PCIe SSD is connected to Qurach module and system is connected to APC outlet.\r\n\r\nInput Data", "expected": "The device is discovered is functional in the OS."}], "source": ""}
{"case_id": "case-1519", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nWrite a script to:\n\n1.     Issue Controller Reset to the PCIe SSD\n\nUsing nvmecli: nvme reset /dev/nvme0n1\n\nUsing framework: python3 NVMeIOCTL.py -rc B:D.F\n\n2.     Wait 10s\n\n3.     Issue a Secondary Bus Reset the PCIe SSD:\n\na.     Cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1\n\nb.     Wait 3s\n\nc.     Make sure the link is x0, Gen-1\n\nd.     Take the device out of reset by writing a 0\n\ne.     Wait 10s\n\nf.      Make sure the link width and speed is the maximum capable for the PCIe SSD\n\ne.   The link width and speed is the maximum capable for the PCIe SSD \n\n1.                4.  Wait 10s. \n\n1.                 5. Issue PERST to the PCIe SSD:\n\na.     Unload the NVMe Driver to prevent a UR\n\nb.     Assert PERST to the drive using Quarch\n\nc.     Wait 10s\n\nd.     Make sure the link was fully disabled\n\ne.     De-assert PERST to the drive using Quarch\n\nf.      Verify that drive is available, and no smart warning is issued and drive is Gen 3, x4\n\ng.     Load NVMe driver\n\n2.                  6. Wait 10s\n\nfor 15 loops. After each loop. make sure that device is trained to maximum link width and speed. After 15 loops, perform A/C cycle to the system. Repeat this for 12 hours. \n\n\n\nInput Data", "expected": "The script runs successfully with no errors."}], "source": ""}
{"case_id": "case-1520", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nIssue Identify controller to the device and get the response.\nnvme-cli (linux only) or NVMeIOCTL (Automation Framework) can be used. \n\n\nInput Data", "expected": "The drive responds with Identify Controller data structure."}], "source": ""}
{"case_id": "case-1521", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck for the \"Firmware Updates\" field that is byte 260. \r\n\r\nInput Data", "expected": "The drive reports firmware slot 1 to be read only."}], "source": ""}
{"case_id": "case-1522", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1523", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the system and dump PCIe config space for the PCIe SSD. Verify ASPM is disabled.\r\n\r\nInput Data", "expected": "Link Control Register bits 0 and 1 are set to 0 (disabled)"}], "source": ""}
{"case_id": "case-1524", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDelete all the partitions on the drives to be tested\r\n\r\nInput Data", "expected": "The partitions are deleted and raw volume is available."}], "source": ""}
{"case_id": "case-1525", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart heavy IO on the drives\r\n\r\nInput Data", "expected": "IO runs without any issue"}], "source": ""}
{"case_id": "case-1526", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue a Hot reset to the drives (Secondary Bus Reset can be used) \r\n\r\nInput Data", "expected": "The drives goes through reset and Namespace is still available"}], "source": ""}
{"case_id": "case-1527", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStart MI traffic to the drives along with IO running \r\n\r\nInput Data", "expected": "No issue running MI commands and drive responds without any errors"}], "source": ""}
{"case_id": "case-1528", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIssue a DC cycle for the Sudden Power Loss scenario for the drives \r\n\r\nInput Data", "expected": "The system goes through a power cycle and OS boots back without any issue"}], "source": ""}
{"case_id": "case-1529", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCheck if all devices are discovered and available \r\n\r\nInput Data", "expected": "All devices shows up"}], "source": ""}
{"case_id": "case-1530", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nrepeat steps 3-8 50 times \r\n\r\nInput Data", "expected": "No errors reported"}], "source": ""}
{"case_id": "case-1531", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue identify controller to the device. \r\nFor example \r\npython3 NVMeIOCTLCLI.py -ic bdf\r\n\r\n\r\nInput Data", "expected": "Check byte 261 bit 4 of LPA or else look at the decoded response of IC. \r\nThe bit should be set advertising PEL support"}], "source": ""}
{"case_id": "case-1532", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue get log page command with log page id 0xd for persistent event log \r\n\r\nFor example:\r\npython3 NVMeIOCTLCLI.py -gl bdf\r\n\r\nNSID=0\r\nLID=0xd\r\nsubpageid=0\r\nnumofdwords=0x7f\r\nRAE=0\r\n\r\n\r\nInput Data", "expected": "The  device responds with required Persistent Event log. \r\nMake sure the header fields are correct like Log identifier,model number,POH and supported event. \r\nMake sure device advertise all event as per requirement document. \r\nContact device lead for the information."}], "source": ""}
{"case_id": "case-1533", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf testing with iDRAC version is 5.0.0.0, cold boot the system.\r\nIf testing with version is 5.10.00.0 or greater, omit this step. \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1534", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nGet the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.\n\n\n\nInput Data", "expected": "Device BDF's are listed in iDRAC log."}], "source": ""}
{"case_id": "case-1535", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nLaunch the iDRAC GUI, go to Maintenance / System Update and Upload n-1 FW DUP for the PCIe SSD. Once you get success for the download, go ahead and select the \"Install\" button.\n\nNOTE: If you see Install and Reboot, Install Next Reboot buttons, it is an issue.\n\nPop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.\n\nInput Data", "expected": "Verified that the DUP package uploads successfully and both the job passed with no issues."}], "source": ""}
{"case_id": "case-1536", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.\r\n   1. SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version n-1).\r\n   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n-1>).\r\n   3. PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version: <version n>, Current version: <version n-1>).\r\n\r\n\r\nInput Data", "expected": "User verified LC logs reported the correct entry for each PCIe SSD."}], "source": ""}
{"case_id": "case-1537", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nGo to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.\n\nGo to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.\n\nGo to OS and verify that new FW version is reported on all drives you updated.\n\nInput Data", "expected": "User verified storage inventory reported the correct FW version for all drives.\r\n\r\nUser verified FW inventory reported the correct FW version for all drives.\r\n\r\nUser verified that OS reported the correct FW version for all drives."}], "source": ""}
{"case_id": "case-1538", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-7 after performing hotplug operation to PCIe SSDs.\r\n\r\nInput Data", "expected": "Firmware is updated successfully after hotplug."}], "source": ""}
{"case_id": "case-1539", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\n\n Write a script to: \n\n1.     Issue FW download to the PCIe SSD. You can get the binary or tar file of the FW by extracting its DUP.\n\nUsing nvmecli: nvme fw-download /dev/nvme0n1 -f FW.bin\n\nUsing framework: python3 NVMeIOCTL.py -fd B:D.F <path to FW file>\n\n2.     Issue Controller Reset to the PCIe SSD. \n\nUsing nvmecli: nvme reset /dev/nvme0n1\n\nUsing framework: python3 NVMeIOCTL.py -rc B:D.F\n\n3.     Unload NVMe Driver. In linux, it can be done by issuing modprobe -r nvme. In windows, use framework.\n\n4.     Load NVMe Driver. In Linux, it can be done by issuing modprobe nvme. In windows, use framework.\n\nfor 12 hours. After each loop, make sure device is discovered. If it doesn't, exit the script with a a failure.\n\n\n\n\nInput Data", "expected": "The script runs for 12 hours successfully."}], "source": ""}
{"case_id": "case-1540", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue Persistent event log command to the respective device and store the log in a file for later issue.\r\nFor example \r\npython3 NVMeIOCTCLI.py -gl bdf \r\n\r\n NSID = 0xffffffff\r\nLID= 0x0d\r\nsubpage =0x0\r\nnum of dwords = 0x7f\r\n\r\n\r\n\r\nInput Data", "expected": "The command get's executed successfully without any errors."}], "source": ""}
{"case_id": "case-1541", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck if the Thermal event is supported by reading the NVMe header section of the PEL log.\r\n\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The device supports the event and if the device doesn't support the event then this test case is N/A.\r\nCheck with the device lead for the same."}], "source": ""}
{"case_id": "case-1542", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nThe device composite temperature is allowed to cross WCTEMP.\r\nUse any applicable method to achieve this.\r\n\r\n\r\nInput Data", "expected": "The thermal excursion get's logged and all the fields correctly displayed."}], "source": ""}
{"case_id": "case-1543", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nStart running I/O + Admin command to the device. \r\nadmin command like identify or get log page could be run in a loop along side IO \r\n\r\n\r\nInput Data", "expected": "The traffic to the device is started without any issue"}], "source": ""}
{"case_id": "case-1544", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nIssue a discovery command and make sure the locking is not enabled.\nEX- \n./sedlib -a q -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "The Feature 0x2 shows the drive locking is not enabled"}], "source": ""}
{"case_id": "case-1545", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue an activate SP command to enable locking of the device for Admin1 authority\r\nEx- where (MSID_password is the key to enable locking)\r\n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The command completes successfully without any errors."}], "source": ""}
{"case_id": "case-1546", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue a level 0 discovery command again to check if locking is enabled. \r\nEx-\r\n./sedlib -a q -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The discovery data now shows locking is enabled. \r\nLocking Enabled: 1"}], "source": ""}
{"case_id": "case-1547", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nChange the PIN of the admin to a new PIN and upon successful completion change back to the original \n\nEx for reference only :\n\n./sedlib -a cp -w admin1 -o S6X053AJH9T6GLEHJEVD0QCYS8C0N7R9 -P S6X053AJH9T6GLEHJEVD0QCYS8C0N7R8 -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "The PIN was changed successfully and then restored back to original key"}], "source": ""}
{"case_id": "case-1548", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size.\r\n\r\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The command completes successfully and the value is saved"}], "source": ""}
{"case_id": "case-1549", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Detach the current single namespace.\r\nEx- python3 NVMeIOCTLCLI.py -dtns <bdf>\r\n\r\nReset the controller (do this since not all drives support dynamic namespace change reporting)\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "Both commands are successful"}], "source": ""}
{"case_id": "case-1550", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Delete the current single namespace \r\npython3 NVMeIOCTLCLI.py -dlns <bdf>", "expected": "The command is successful and the block device is gone.\r\n\r\nEx - lsblk no longer shows the drive"}], "source": ""}
{"case_id": "case-1551", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Create a new namespace of the same size as noted in Step 2\r\nEx- python3 NVMeIOCTLCLI.py -crns <bdf>\r\n\r\nAttach the newly created namespace\r\nEx- python3 NVMeIOCTLCLI.py -atns <bdf>\r\n\r\nReset to controller (do this since not all drives support dynamic namespace change reporting)\r\npython3 NVMeIOCTLCLI.py -rc <bdf>", "expected": "All commands were successful and the drive block device is now enumerated\r\n\r\n\r\nEx - lsblk now shows a new drive"}], "source": ""}
{"case_id": "case-1552", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Issue an Identify Namespace command to the drive and take a note of the: Namespace Size\r\n\r\npython3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value", "expected": "The Namespace Size has the same value as in step 2"}], "source": ""}
{"case_id": "case-1553", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one NVMe PCIe SSD in the system.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1554", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSetup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD D3hot transition.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1555", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart capturing the PCIe trace. Power on the system and put the PCIe SSD in D3hot. Stop PCIe trace capture.\r\n\r\nInput Data", "expected": "PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation\r\n\r\nPCIe trace shows CC.SHST = 10b to indicate shutdown is complete"}], "source": ""}
{"case_id": "case-1556", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nStart capturing the PCIe trace. Transition the PCIe SSD out of D3hot. Stop the PCIe trace capture.\r\n\r\nInput Data", "expected": "Verify the PCIe SSD does not reset when transitioning out of D3hot (PMCSR No_Soft_Reset = 1)"}], "source": ""}
{"case_id": "case-1557", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSet SID credentials which can be used to revert the device state . \r\nTry to put same MSID as new key to avoid losing key\r\nEX-\r\n./sedlib -a cp -w sid -o MSID_password -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\nInput Data", "expected": "The SID key is set without any issues"}], "source": ""}
{"case_id": "case-1558", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nDo a device discovery and make sure device is locked, if not already locked.  Also write some data to the device.\nnvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1\n\nIssue a revert SP command using admin as SP and sid as user (admin or psid can also be used)\n./sedlib -a rev -S admin -u sid -P MSID_password -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "The command get's completed successfully"}], "source": ""}
{"case_id": "case-1559", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nIssue a discovery command and make sure the device state goes to initial state without SP enabled and unlocked. \n./sedlib -a q -d /dev/nvme0n1 -x nvme\nAlso check the data written to the device earlier. \n\n\nInput Data", "expected": "The device is restored to it's initial state and all data erased as well.\r\nDo a read of the data written\r\nnvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1\r\n\r\nAll data returned should be 0."}], "source": ""}
{"case_id": "case-1560", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCheck if device is enabled for locking by doing query. \nEx- ./sedlib -a q -d /dev/nvme0n1 -x nvme\nIf not enabled then activate SP \n./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme\n\nThe default password is set as MSID and can be retrieved via below command\n./sedlib -a pm -d /dev/nvme0n1 -x nvme\n\n\n\nInput Data", "expected": "The device is activated for locking"}], "source": ""}
{"case_id": "case-1561", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nStart running I/O to the device \nEx- ./diskio -f /dev/nvme0n1 -b 128k -t 10\n\n\n\nInput Data", "expected": "The I/O starts running on the device"}], "source": ""}
{"case_id": "case-1562", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nChange the key of the device \nEx-\n./sedlib -a cp -w admin1 -o MSID_password -P MSID_passwordnew -d /dev/nvme0n1 -x nvme\n\n\n\n\n\nInput Data", "expected": "The pass key get's changed without any issue."}], "source": ""}
{"case_id": "case-1563", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck the status of I/O running from step 3\r\n\r\nInput Data", "expected": "The I/O continues to run uninterrupted."}], "source": ""}
{"case_id": "case-1564", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nChange the key of the device to default passkey\r\nEx-\r\n./sedlib -a cp -w admin1 -o MSID_passwordnew -P MSID_password -d /dev/nvme0n1 -x nvme\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The key is changed back to default key i.e MSID"}], "source": ""}
{"case_id": "case-1565", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIssue identify controller command to the device and check if firmware activation without reset is supported and also note down current firmware version. nvme-cli(linux only) or NVMeIOCTL (Automation Framework) can be used. \r\n\r\nInput Data", "expected": "The drive reports that firmware activation without reset is supported"}], "source": ""}
{"case_id": "case-1566", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue firmware download command with right payload/binary path. \r\nSame tool as above can be used. \r\n\r\n\r\nInput Data", "expected": "The command completes successfully without any failure."}], "source": ""}
{"case_id": "case-1567", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue firmware activation command with slot to be activated and firmware commit action to be 3. \r\n\r\nInput Data", "expected": "Command completes successfully without any errors"}], "source": ""}
{"case_id": "case-1568", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIssue identify controller and check firmware revision \r\n\r\nInput Data", "expected": "The firmware provided for the flash was activated."}], "source": ""}
{"case_id": "case-1569", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPerform the following steps:\r\n\r\n- Dump the PCI registers of the endpoint device\r\n\r\n- Check the range of completion time out value under Device Control 2 register (bit location 0-3)\r\n\r\n- Surprise remove the device\r\n\r\nInput Data", "expected": "Check if the value is programmed as per the spec, which states a value of 0x6 (65ms - 210ms)"}], "source": ""}
{"case_id": "case-1570", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert the device and dump the PCI register and check the time out value again.\r\n\r\nInput Data", "expected": "The value is reprogrammed on hot insertion as per the spec, 0x6 (65ms - 210ms)"}], "source": ""}
{"case_id": "case-1571", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nCheck CAP.TO value available part of MMIO space. Any tool can be used.\n\nFor example:\npython3 NVMeIOCLTCLI.py -mr bdf\n\nInput Data", "expected": "Note down the CAP.TO value before enabling security."}], "source": ""}
{"case_id": "case-1572", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nSSH into the iDRAC supporting side band tool for TCG Support into rootshell\n\nIf performing tests first time after iDRAC reboot run following 2 commands\nsetenforce 0\ntestlibsednvme\n\n\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1573", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nActivate and Lock the device for the global range (whole device) using user as admin via side band\n\ncontroller id should be determined from identify controller response\nThe user is Admin and the value passed should be 1\ntestlibsednvme Dellenablesecurity <eid> <controller id> <new key> <key length> 1\n\n testlibsednvme lock <eid> <controllerid> <key> <keylength> <user>\n\nFor example :\ntestlibsednvme lock 6 0 Dell123456 10 1\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "The device is locked and command completes successfully. \r\nRun query command to confirm. \r\n\r\nFor example \r\ntestlibsednvme query 6 0\r\n\r\nOutput:\r\nlocked = 1\r\nlocking supported = 1\r\nlocking enabled = 1"}], "source": ""}
{"case_id": "case-1574", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove the drive and hot insert it back. \r\nCheck OS log \r\n\r\n\r\nInput Data", "expected": "Note down the time at which hot plug interrupt was generated and when the controller becomes ready (OS starts polling for queues and block layer)\r\nIf this couldn't be determined via OS logs please collect PCIe trace to verify CSTS.RDY turning 1 after ~60 sec from the time CC.EN =1"}], "source": ""}
{"case_id": "case-1575", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nCheck CAP.TO value available part of MMIO space. Any tool can be used. \n\nFor example:\npython3 NVMeIOCLTCLI.py -mr bdf\n\n\nInput Data", "expected": "The CAP.TO value is set to 60 sec or greater \r\n\r\nNote :\r\nCAP.TO field have value in units of 500ms. So, make appropriate conversion."}], "source": ""}
{"case_id": "case-1576", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\nIssue a revert operation to bring the device to default state. \n\ntestlibsednvme revert <eid> <controllerid> <key> <key_length> 0\n\n\nInput Data", "expected": "Issue query to make sure security is disabled."}], "source": ""}
{"case_id": "case-1577", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\nActivate and lock device in band . \n\nFor example \n./sedlib -a asp -P <MSID> -d /dev/nvme0n1 -x nvme\n\n./sedlib -a l -B 0 -P MSID -d /dev/nvme0n1 -x nvme\n\n\nInput Data", "expected": "Issue query to determine if device is locked. \r\n./sedlib -a q -d /dev/nvme0n1 -x nvme"}], "source": ""}
{"case_id": "case-1578", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nHot remove the drive and re insert.\r\nCheck the OS logs or verify via other methods if device has been gone ready i.e CSTS.RDY bit set to 1 in less than 60 sec. \r\n\r\n\r\nInput Data", "expected": "The CSTS.RDY got set to 1 in less than or equal to 56 sec"}], "source": ""}
{"case_id": "case-1579", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nCheck CAP.TO value available part of MMIO space. Any tool can be used.\r\n\r\nFor example:\r\npython3 NVMeIOCLTCLI.py -mr bdf\r\n\r\nInput Data", "expected": "The CAP.TO value is less than or equal to 56 sec.\r\n\r\nNote :\r\nCAP.TO field have value in units of 500ms. So, make appropriate conversion."}], "source": ""}
{"case_id": "case-1580", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCreate a partition on a drive and write at least 30 GB data to it \r\n\r\nInput Data", "expected": "Partition is created and data is successfully written"}], "source": ""}
{"case_id": "case-1581", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nStart running Crypto Erase in the back ground \r\n\r\nInput Data", "expected": "Crypto Erases are successfully completing"}], "source": ""}
{"case_id": "case-1582", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPerform Sudden Power Loss for drive (DC cycle through IDRAC does) \r\n\r\nInput Data", "expected": "drive goes through power cycle"}], "source": ""}
{"case_id": "case-1583", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck FPI (Format Progress Indicator) by issuing Identify Namespace Command\r\n\r\nInput Data", "expected": "The value of FPI is zero if the field is supported by the device."}], "source": ""}
{"case_id": "case-1584", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nSSH into the iDRAC having test firmware for TCG Support into rootshell\n\nIf performing tests first time after iDRAC reboot run following 2 commands\nsetenforce 0\ntestlibsednvme\n\n\nInput Data", "expected": "The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section"}], "source": ""}
{"case_id": "case-1585", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nStart running I/O + Admin command to the device. \nadmin command like identify or get log page could be run in a loop along side IO\nIssue following command to query the drive of it's state\n\n\ncontroller id should be determined from identify controller response in OS\ntestlibsednvme query\n\n\nFor example:\n\ntestlibsedclient query 6 0\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "Locking enabled is turned off \r\nFor example:\r\nlocking enabled = [0]\r\n\r\nIf the locking is enabled make sure to run revert test case prior to running this."}], "source": ""}
{"case_id": "case-1586", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nEnable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. \nProvide user as Admin and it should be 1\n\ntestlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>\nAlso make sure function return code is 0\n\nFor example \ntestlibsednvme DellEnableSecurity 6 0 Dell123456 10 1\n\n\nNote : This is just an example change according to your device\nSending command to wrong eid can result in hang and racreset is required\n\n\nInput Data", "expected": "The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. \r\n\r\nFor example \r\nlocking supported = [@1]\r\nlocking enabled = [@1]\r\ndatastore size = [10485760]\r\ndatastore flag = [@2]\r\nold_keyId = [MSID KEY]\r\ncurrent_keyId = [Dell123456]"}], "source": ""}
{"case_id": "case-1587", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nWait for 1 minute and Disable Security by issuing Revert \r\nUse the same key to issue revert which was used for enabling security \r\nGo to step 4 and repeat for at least 20 times\r\n\r\n\r\nInput Data", "expected": "Operations are successful in all steps."}], "source": ""}
{"case_id": "case-1588", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Start I/O stress to the NVMe drives which support power states.", "expected": "I/O is being processed successfully"}], "source": ""}
{"case_id": "case-1589", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Lower the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-1590", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-1591", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Repeat steps 3 and 4 until no power states are remaining.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 3 and 4"}], "source": ""}
{"case_id": "case-1592", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Raise the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-1593", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-1594", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Repeat steps 6 and 7 until the drive is back at the default power state 0.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 6 and 7"}], "source": ""}
{"case_id": "case-1595", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Stop the I/O stress to the NVMe drives", "expected": "The I/O stops successfully"}], "source": ""}
{"case_id": "case-1596", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Start I/O stress to the NVMe drives which support power states.", "expected": "I/O is being processed successfully"}], "source": ""}
{"case_id": "case-1597", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Lower the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-1598", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-1599", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Repeat steps 3 and 4 until no power states are remaining.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 3 and 4"}], "source": ""}
{"case_id": "case-1600", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Raise the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-sf\" option to indicate a Set Features command. Use the \"Power State\" feature ID.", "expected": "The Set Features command to change the power state was successful, and the I/O continues to be processed."}], "source": ""}
{"case_id": "case-1601", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the \"-gf\" option to indicate a Get Features command. Use the \"Power State\" feature ID.", "expected": "The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously."}], "source": ""}
{"case_id": "case-1602", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Repeat steps 6 and 7 until the drive is back at the default power state 0.\r\n\r\nNOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.", "expected": "Same results as in steps 6 and 7"}], "source": ""}
{"case_id": "case-1603", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Stop the I/O stress to the NVMe drives", "expected": "The I/O stops successfully"}], "source": ""}
{"case_id": "case-1604", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-1605", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1606", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInject error on up stream port . \r\nThis can be done in many ways. \r\nFor example \r\nChange MPS of up stream  port that is less than endpoint Max Payload Size\r\nRun some I/O to the device\r\n\r\n\r\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "case-1607", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nMake sure to install the latest DUP for the ePSA UEFI Diagnostics utility\n\nInput Data", "expected": "DUP installs successfully"}], "source": ""}
{"case_id": "case-1608", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBoot into the \"F11 (Boot Manager)->System Utilties->Launch Diagnostics\"\r\n\r\nInput Data", "expected": "The ePSA utility opens"}], "source": ""}
{"case_id": "case-1609", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nClick the \"Configuration\" tab In the \"[PCIe]\" section, make sure that you see the NVMe device, and the PCIe Bridge Card (if there are 2.5\" PCIe SSD devices in the system) In the \"[Storage]\" section, find the hard drive(s) that have type \"NVMe\"\r\n\r\nInput Data", "expected": "The tab is present\r\n\r\n\r\nThe PCIe Bridge Card (if present) and all NVMe PCIe SSDs are listed and have the correct, \"Slot Number\" \"Vendor\" \"Device\" \"SubVendor\" and \"SubDevice\" IDs.\r\n\r\n\r\nAll devices are displayed as unique hard drives with the correct information, \"OEM\" \"product\" \"revision\" \"S/N\" \"type\" \"size\" \"CTRL\""}], "source": ""}
{"case_id": "case-1610", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDouble-click each of the NVMe PCIe SSD hard drive numbers (identified in step 4)\r\n\r\nInput Data", "expected": "The tests run successfully and report the results to the \"Results\" tab\r\n\r\nIn the \"Results\" tab, if the device supports the NVMe Device Self-test command, then make sure that the results indicate that a DST Short or Long was ran in place of simply the SMART data"}], "source": ""}
{"case_id": "case-1611", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nGet all parent BDFs to the NVMe drives (regardless if the slots are populated).\r\n\r\nIf the system has a PCIe switch in it, then get then get the root port above the switch, switch upstream port, and all switch downstream ports.\r\n\r\n\r\nInput Data", "expected": "All parent BDFs are obtained"}], "source": ""}
{"case_id": "case-1612", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nDump PCIe config. space for each port that was found in the previous step\n\nInput Data", "expected": "If the OS and Hardware Supports DPC (EDR), then the \"DPC Control Register's\" DPC Trigger Enable should be set to 0x2.\n\nIf the OS or Hardware do not Support DPC (EDR), then the DPC capability will not be found or, the \"DPC Control Register's\" DPC Trigger Enable should be set to 0x0."}], "source": ""}
{"case_id": "case-1613", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nsetpci -s bdf 0x10.w=0xffff \n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/message or syslog  \n\n\nInput Data", "expected": "check if \n1) ACPI event 0xf received\n2) containment event, status:0x1f03 source:0xe300\n3) device recovery successful\n\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-1614", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1615", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove the drive \r\n\r\nInput Data", "expected": "The device is removed and not visible both at PCI and NVMe level"}], "source": ""}
{"case_id": "case-1616", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert the drive back in the same slot\r\n\r\nInput Data", "expected": "device is enumerated properly"}], "source": ""}
{"case_id": "case-1617", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-1618", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1619", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat the steps 2-3 on a different end point\r\n\r\n\r\nInput Data", "expected": "The devices are properly enumerated"}], "source": ""}
{"case_id": "case-1620", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove both the drives on which error was injected & recovered\r\n\r\n\r\nInput Data", "expected": "The devices are removed and not visible both at PCIe and NVMe level"}], "source": ""}
{"case_id": "case-1621", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nHot insert the drives back in the same slots\r\n\r\n\r\nInput Data", "expected": "The devices are enumerated properly both at PCIe level and NVMe block level"}], "source": ""}
{"case_id": "case-1622", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCompare the Physical Slot Number (bits 31:19) in the Slot Capabilities register:\r\n\r\n31:27 - Zeroes\r\n\r\n26 - Unique Bit Always Set to 1\r\n\r\n25:24 - Bay ID\r\n\r\n23:19 - Slot ID\r\n\r\n\r\nto the expected value for each NVMe-capable SFF slot.\r\n\r\n\r\nInput Data", "expected": "The Physical Slot Number info matches the expectation for each NVMe capable SFF slot in the system. See the attached file 'example_decode.txt' for an in-depth decode of the Slot Capabilities register in the raw hex config space data.\n\nThe Bay / Slot ID may be found from the Storage::Physical Disks menu in the iDRAC GUI; this info should match the decode from the Slot Capabilities register."}], "source": ""}
{"case_id": "case-1623", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Telemetry Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).\r\n\r\nInput Data", "expected": "1. Save Debug Log page will show the following options/fields:\r\n\r\nSelect File System target (header)\r\n\r\nSelect File System (link)\r\n\r\n\r\nSelect Directory (header)\r\n\r\nDirectory list selection\r\n\r\n\r\nExport Log File path (header)\r\n\r\nFile path\r\n\r\n\r\nExport Log (link)\r\n\r\n\r\n\r\n\r\n2. All options/fields display corresponding help text at the bottom of the screen."}], "source": ""}
{"case_id": "case-1624", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSelect a file system target (ie. if there is more than one USB key inserted)\r\n\r\nInput Data", "expected": "1. All attached file systems are listed under \"Select File System Target\". The default (root) directory should be selected by default.\r\n\r\n2. \"Select File System Target\" (link) can be used to change currently selected File System."}], "source": ""}
{"case_id": "case-1625", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect a directory.\r\n\r\nInput Data", "expected": "1. All attached directories are listed under \"Select Directory\". The default (root) directory should be selected by default.\r\n\r\n2. User can choose appropriate directory to save the file to under \"Select Directory\".\r\n\r\n3. \"Select Directory\" (link) can be used to change currently selected Directory."}], "source": ""}
{"case_id": "case-1626", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect Telemetry Log.\r\n\r\nInput Data", "expected": "Message displayed is \"Log saved successfully. PCIeSSD_(date time string).log\".\r\n\r\n\r\nFor NVMe PCIe SSD log, User can choose the any filename with extension .log"}], "source": ""}
{"case_id": "case-1627", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRetrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly.\r\n\r\nInput Data", "expected": "The file size is non-zero"}], "source": ""}
{"case_id": "case-1628", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1629", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nNavigate to the directory where UpdateTest.efi is saved, and run \"UpdateTest.efi\" to get a list of controller handles. (UpdateTest.efi: download from Agile ENG0011622)\n\nInput Data", "expected": "PCIe SSD is listed as a controller that supports UEFI update. The display name is \"Dell [NVMe] PCIe SSD Controller\"."}], "source": ""}
{"case_id": "case-1630", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nExecute getImageInfo(). \"UpdateTest.efi CtrlHdl\" where CtrlHdl is the controller handle for a PCIe SSD. Example: Step 2 reported Controller Handle CD for PCIeSSD. You would type \"UpdateTest.efi CD\"\n\nInput Data", "expected": "Package Version (int): \"0xFFFFFFFE\"\r\n\r\nPackage Version (str): firmware package version running on the PCIeSSD\r\n\r\n\r\nRemaining fields shall report values per Dell IHV and UEFI specs."}], "source": ""}
{"case_id": "case-1631", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nExecute SetImage() to upgrade the firmware. Run \"UpdateTest.efi CtrlHdl -f firmware_img\".\n\nInput Data", "expected": "Firmware starts flashing on the device. Activity LED is blinking on PCIeSSD. Return success."}], "source": ""}
{"case_id": "case-1632", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nReboot the system and verify firmware update flashed successfully. Perform some I/O to the device to ensure functionality.\r\n\r\nInput Data", "expected": "Firmware flashed successfully. Device fully functional."}], "source": ""}
{"case_id": "case-1633", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nOptional: Repeat step 6 and 7 but flashing to an older version of the firmware.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1634", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nGetImage() and SetPackageInfo() are not required by Dell so vendor may have selectively chosen to not support these.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1635", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSurprise remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-1636", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nImmediately re-insert the PCIe SSD back into the system\r\n\r\nInput Data", "expected": "The PCIe SSD shows up in the OS and is functional"}], "source": ""}
{"case_id": "case-1637", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1638", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBegin running I/O stress on all hot-pluggable NVMe drives\r\n\r\nInput Data", "expected": "The I/O is successful"}], "source": ""}
{"case_id": "case-1639", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWhile the I/O is in progress, disable the link to the NVMe drives by writing a '1' to bit 4 of the parent BDF's Link Control Register\r\n\r\nInput Data", "expected": "I/O stops\r\nThe NVMe drive is removed from the system\r\nThe system does not crash"}], "source": ""}
{"case_id": "case-1640", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRe-enable the link by writing a '0' to bit 4 of all parent BDF's Link Control Register\r\n\r\nInput Data", "expected": "The NVMe drives are re-enumerated by the OS"}], "source": ""}
{"case_id": "case-1641", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-1642", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1643", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nHot remove  the drive on which error was injected & recovered\r\n\r\n\r\nInput Data", "expected": "The device is removed and not visible both at PCIe and NVMe level"}], "source": ""}
{"case_id": "case-1644", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert the drive back in the same slots\r\n\r\n\r\nInput Data", "expected": "The device is enumerated properly both at PCIe level and NVMe block level"}], "source": ""}
{"case_id": "case-1645", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nUsing ipmitool (or GetPCIeSSDFRU.py automation script), read the contents of the FRU for each NVMe device using the following commands:\n\nU.2 devices (NOTE for Windows that, \"-I wmi\" will have to be added before the -U):\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x00 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x20 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x40 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x60 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x80 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xA0 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xC0 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xE0 0x00 0x20\n\nAIC devices (NOTE for Windows that, \"-I wmi\" will have to be added before the -U):\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x00 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x20 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x40 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x60 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x80 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xA0 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xC0 0x00 0x20\nipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xE0 0x00 0x20\n\n\nInput Data", "expected": "All ipmi commands successfully pass and the FRU contents are saved for each device"}], "source": ""}
{"case_id": "case-1646", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nUsing libi2ctest (or GetPCIeSSDFRU.py automation script), read the FRU for each NVMe device in the system using the following commands:\n\nlibi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256\n\nNOTE if you're not using automation, then the I2C_bus_num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file from the iDRAC filesystem\n\n\nInput Data", "expected": "All libi2ctest commands successfully pass and the FRU data is saved"}], "source": ""}
{"case_id": "case-1647", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCompare the FRU data read from I2C in step 3 with the FRU data read from IPMI for each device\r\n\r\nInput Data", "expected": "There should be no difference"}], "source": ""}
{"case_id": "case-1648", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the NVME_PRES and PERST# signals to an oscilloscope\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1649", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1650", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of NVME_PRES\r\n\r\nInput Data", "expected": "Trigger enabled"}], "source": ""}
{"case_id": "case-1651", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nConfigure the horizontal divisions to be 500ms\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1652", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nConfigure the vertical divisions for both signals to be 1V\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1653", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The trigger occurs\r\n\r\nPrior to the falling edge of NVME_PRES, PERST# was low\r\n500ms after the falling edge of NVME_PRES, PERST# went high"}], "source": ""}
{"case_id": "case-1654", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with a hotpluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1655", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-1656", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-1657", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nBegin recording on the PCIe analyzer\n\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-1658", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nSurprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests\r\n\r\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is removed from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-1659", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-1660", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1661", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-1662", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-1663", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, a Completer Abort is generated with a Completer ID equal to the endpoint PCIe SSD that was removed\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1664", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1665", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nFrom the PCIe trace, an ERR_FATAL message is generated by the parent of the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1666", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "14", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer Changed bit is set"}], "source": ""}
{"case_id": "case-1667", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCompare the 'Slot Power Limit Scale' and 'Slot Power Limit Value' data (bits 16:7) to either of the following values:\r\n\r\n14:7 = 0xFA\r\n\r\n16:15 = 0b01\r\n\r\n\r\nOR:\r\n\r\n\r\n14:7 = 0x19\r\n\r\n16:15 = 0b00\r\n\r\n\r\nfor each slot.\r\n\r\n\r\nBoth of these encoding corresponds to a limit of 25 W. In the first case, we have 0d250 * .1 = 25 W. In the second case, we have 0d25 * 1 = 25 W.\r\n\r\n\r\nInput Data", "expected": "The 'Slot Power Limit Scale' and 'Slot Power Limit Value' are programmed as specified, indicating a slot power limit of 25 W."}], "source": ""}
{"case_id": "case-1668", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nType \"DlpDump.efi\"\r\n\r\nInput Data", "expected": "All PCIe SSDs in the system are discovered and they have FQDDs as follows:\r\n\r\n\r\nIf 2.5\":\r\n\r\nDisk.Bay.XX:Enclosure.Internal.0-1:PCIeExtender.Slot.Y\" where XX is the backplane slot number and Y is the PCIe slot that the PCIe SSD Extender card is in\r\n\r\n\r\nIf Adapter Card:\r\n\r\nPCIeSSD.Slot.X where X is the PCIe slot that the PCIe SSD is in"}], "source": ""}
{"case_id": "case-1669", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with a hotpluggable PCIe SSD in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1670", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-1671", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIf possible, disable or unload the PCIe SSD driver. The reason is to reduce the chances that any traffic will be outstanding to the PCIe SSD once it's removed.\r\n\r\nInput Data", "expected": "The driver is disabled or unloaded"}], "source": ""}
{"case_id": "case-1672", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-1673", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nSurprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests\n\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is removed from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-1674", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-1675", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1676", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-1677", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.\r\n\r\nInput Data", "expected": "The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set"}], "source": ""}
{"case_id": "case-1678", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1679", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set"}], "source": ""}
{"case_id": "case-1680", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "13", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.\r\n\r\nInput Data", "expected": "The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set"}], "source": ""}
{"case_id": "case-1681", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nRun stress to all PCIe SSD devices using MLTT, iogen, or diskio overnight.\r\n\r\nInput Data", "expected": "implicit."}], "source": ""}
{"case_id": "case-1682", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReview logs from all management applications, the test tool, and OS logs.\r\n\r\nInput Data", "expected": "No errors in logs."}], "source": ""}
{"case_id": "case-1683", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the SEL for any correctable errors\r\n\r\nInput Data", "expected": "No correctable errors are found"}], "source": ""}
{"case_id": "case-1684", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nSet the threshold value to 10 using below command\r\n\r\nesxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 10\r\nand verify\r\nesxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit\r\n\r\n\r\nInput Data", "expected": "The OS error threshold is set to 10"}], "source": ""}
{"case_id": "case-1685", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\r\n\r\nHere 196 = bus (in decimal) for the endpoint bdf\r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nRun some activity like\r\nesxcli nvme device get -A vmhba3\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/vmkernel.log\r\n\r\n\r\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-1686", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1687", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat step 3-4  at least 11 times \r\n\r\nInput Data", "expected": "The driver for the corresponding device is unloaded and device is not visible anymore in the OS inventory. \n\nCheck the device list\nesxcli nvme device list"}], "source": ""}
{"case_id": "case-1688", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInstall at least one PCIe SSD in a SAS/SATA slot and power on the system.\r\n\r\nInput Data", "expected": "PCIe SSD is not detected in the system.\r\n\r\nStatus LED blinks identify pattern (Green on/off).\r\n\r\nLifecycle log reports incorrect drive type on slot detected \"Invalid Device Type Installed\""}], "source": ""}
{"case_id": "case-1689", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 until all PERC slots have been tested with a PCIe SSD.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1690", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInstall at least one SAS or SATA drive and at least one PCIe SSD in the SAS/SATA slots (ie. the SAS or SATA drive on slot 0 and the PCIe SSD on slot 1). ** this step is N/A on blade systems.\r\n\r\nInput Data", "expected": "PCIe SSD is not detected in the system.\r\n\r\nStatus LED blinks identify pattern (Green on/off).\r\n\r\nLifecycle Log reports incorrect drive type on slot detected \"Invalid Device Type Installed\"\r\n\r\nSAS/SATA drive Status LED is solid Green"}], "source": ""}
{"case_id": "case-1691", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInstall a SAS/SATA drive in one of the PCIe SSD slots\r\n\r\nInput Data", "expected": "The Status LED blink identify (Green on/off) and is not detected in the system\r\nSEL reports incorrect drive type on slot detected \"Invalid Device Type Installed\""}], "source": ""}
{"case_id": "case-1692", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat step 5 until all PCIe SSD slots have been tested\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-1693", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nRemove any drives and examine the Presence Detect bit in the Slot Status Register\n\nInput Data", "expected": "The PD bit should be off (zero)."}], "source": ""}
{"case_id": "case-1694", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nInsert a SAS drive into the slot and examine the Presence Detect bit in the Slot Status Register\n\nInput Data", "expected": "The PD bit should still be off"}], "source": ""}
{"case_id": "case-1695", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRemove the SAS drive and insert and NVMe device into the slot.  Examine the Presence Detect bit in the Slot Status Register\r\n\r\nInput Data", "expected": "The PD bit should now be on (one)"}], "source": ""}
{"case_id": "case-1696", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nOpen the OS logging mechanism (e.g. Event Viewer in Windows or tail -f /var/log/messages in Linux)\r\n\r\nInput Data", "expected": "The OS logs are being recorded"}], "source": ""}
{"case_id": "case-1697", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWindows - \r\nGo to the bottom right-corner taskbar and click the \"^\" symbol.\r\nSelect the USB icon\r\n\r\nLinux -\r\nGo to /sys/bus/pci/slots/<SLOT> # The correct SLOT can be determined by looking at the contents of the address file or using grep command\r\nFor example\r\ngrep -ir 0000:e4:00\r\n\r\n\r\nInput Data", "expected": "Windows - \r\nThe NVMe drives are enumerated\r\n\r\nLinux - \r\nThe correct SLOT folder is found and a file exists named, \"power\""}], "source": ""}
{"case_id": "case-1698", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nWindows - \r\nSelect the NVMe device to cause the safe removal process\r\n\r\nLinux - \r\necho 0 > /sys/pci/slots/SLOT/power # where SLOT is the value you determined in the previous step\r\n\r\n\r\nInput Data", "expected": "The NVMe drive is removed from the system.\r\n\r\nOn Windows, the OS logs the removal.\r\n\r\nOn Linux, the OS is not required to log the removal."}], "source": ""}
{"case_id": "case-1699", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRemove the drive from the slot, either manually, or using a quarch.\r\n\r\n\r\nInput Data", "expected": "No crashes or aberrant behavior is observed."}], "source": ""}
{"case_id": "case-1700", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRe-insert the drive back into the same slot\r\n\r\nInput Data", "expected": "The NVMe drive is fully discovered"}], "source": ""}
{"case_id": "case-1701", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 2-4\r\n\r\nInput Data", "expected": "Same results as above"}], "source": ""}
{"case_id": "case-1702", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRepeat steps 2-6 on another other drive slots (all drive slots if reasonable)\r\n\r\nInput Data", "expected": "Same results as above"}], "source": ""}
{"case_id": "case-1703", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nHot insert a PCIe SSD into the system\r\n\r\nInput Data", "expected": "N/A"}], "source": ""}
{"case_id": "case-1704", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nImmediately remove the PCIe SSD from the system\r\n\r\nInput Data", "expected": "The PCIe SSD does not show up in the OS (PCI bus, NVMe driver loaded, or disk mgmt utilities)"}], "source": ""}
{"case_id": "case-1705", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 an additional 5 more times\r\n\r\nInput Data", "expected": "Same expected outcomes as in steps 2 and 3"}], "source": ""}
{"case_id": "case-1706", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\n\nConnect a PCIe analyzer to the system such that the traffic to the NVMe devices can be captured.\n\n(Note: it is possible to run this test without using an analyzer by examining the contents of the drive's Sanitize log page after each step and noting how the status bits change.)\n\nInput Data", "expected": "implicit"}], "source": ""}
{"case_id": "case-1707", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server and boot to the HII\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1708", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nGo to the Physical Device Operations section for the device that supports Sanitize and issue the operation\r\n\r\nInput Data", "expected": "The operation completes successfully and the PCIe trace shows that an NVMe Sanitize was used instead of a Format NVM"}], "source": ""}
{"case_id": "case-1709", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nGo to the Physical Device Operations for the device that only supports Format NVM and issue the operation\r\n\r\nInput Data", "expected": "The operation completes successfully and the PCIe trace shows that a Format NVM was sent to the drive instead of a Sanitize"}], "source": ""}
{"case_id": "case-1710", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf you have a device that does not support Sanitize or Format NVM, the operation to perform Cryptographic Erase should either be greyed out or not available\r\n\r\nInput Data", "expected": "Cryptographic Erase should either be greyed out or not available"}], "source": ""}
{"case_id": "case-1711", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1712", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\r\n\r\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-1713", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-1714", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-1715", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\n\r\nHave the PCIe SSD stop responding to the Configuration Reads (do not stop the tool/script that's issuing the config. reads). \r\n\r\n\r\nFor example, in the case of PM1725a, a drive with special Error Injection firmware is used.  The drive is cabled as a USB COM port.  Setting up the com port is per instruction found at NVMe\\NVME_PCIeSSD\\Tools\\UART_Capture\\Setup.  The command used for this step are:  urdev =1 to stop drive from responding.  urdev=0 to put drive back to normal state\r\n\r\n\r\n\r\nInput Data", "expected": "The operating system crashes"}], "source": ""}
{"case_id": "case-1716", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-1717", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, find the Non-Posted request that was ignored by the endpoint (it will have a completion type of Completer Abort)\r\n\r\nInput Data", "expected": "The Completer Abort is found"}], "source": ""}
{"case_id": "case-1718", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, zero the timestamp of the Non-Posted Request that received the Completer Abort\r\n\r\nInput Data", "expected": "The amount of time between the command being issued and the Completer Abort completion is 60ms"}], "source": ""}
{"case_id": "case-1719", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system with no hotpluggable PCIe SSDs in the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1720", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nNote down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD\n\nInput Data", "expected": "The MSI Address register is captured and should start with \"0xFEExxxxx\""}], "source": ""}
{"case_id": "case-1721", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBegin recording on the PCIe analyzer\r\n\r\nInput Data", "expected": "The analyzer starts recording successfully"}], "source": ""}
{"case_id": "case-1722", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInsert the PCIe SSD\r\n\r\nInput Data", "expected": "The operating system does not crash and the PCIe SSD is enumerated from the OS\r\n    * Windows - The PCIe SSD immediately (within 5s) shows up from the Windows Device Manager, \"Storage Controllers\" section\r\n    * Linux - The PCIe SSD immediately (within 5s) shows up after running the command, \"lspci\"\r\n    * ESXi - The PCIe SSD immediately (within 5s)shows up after running the command, \"lspci\""}], "source": ""}
{"case_id": "case-1723", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nTrigger the PCIe analyzer to stop recording\r\n\r\nInput Data", "expected": "The trace is captured and uploaded to the test case"}], "source": ""}
{"case_id": "case-1724", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nFrom the PCIe trace, find the first hotplug interrupt where the PCIe SSD was inserted\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1725", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 1\r\n\r\nData Link Layer State Changed (DLLSC) = 0"}], "source": ""}
{"case_id": "case-1726", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 1\r\n\r\nData Link Layer State Changed (DLLSC) = 0"}], "source": ""}
{"case_id": "case-1727", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "10", "description": "Description\r\nFrom the PCIe trace, find the second hotplug interrupt where the PCIe SSD was inserted\r\n    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case\r\n\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1728", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "11", "description": "Description\r\nFrom the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 0\r\n\r\nData Link Layer State Changed (DLLSC) = 1"}], "source": ""}
{"case_id": "case-1729", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "12", "description": "Description\r\nFrom the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted\r\n\r\nInput Data", "expected": "The Presence Detect State (PDS) =1\r\n\r\nPresence Detect State Changed (PDSC) = 0\r\n\r\nData Link Layer State Changed (DLLSC) = 1"}], "source": ""}
{"case_id": "case-1730", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to the \"Configuration->Storage Configuration\" section of the iDRAC GUI\r\n\r\nInput Data", "expected": "There are no NVMe PCIe SSDs listed"}], "source": ""}
{"case_id": "case-1731", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The PCIe SSD get's enumerated in the \"Configuration->Storage Configuration\" view\r\n\r\nNOTE that a \"refresh\" may be needed"}], "source": ""}
{"case_id": "case-1732", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect the drop-down \"Action\" menu\r\n\r\nInput Data", "expected": "The option to \"Prepare to remove\" is available"}], "source": ""}
{"case_id": "case-1733", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf there are 2.5\" NVMe drives already in the system, remove them from the system\r\n\r\nInput Data", "expected": "The SEL log shows an entry for each drive that was removed and it's location.  For tests run on systems with DPC, you will see 5 entries (1 Critical Error listing the drive removal, 2 warnings, one PCIe correctable error for the drive and one for the parent port, one warning about a low severity error, listing the Bay and Slot of the drive you removed, and an informational event noting that an OEM diagnostic event occurred."}], "source": ""}
{"case_id": "case-1734", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInsert NVMe drives back into the system\r\n\r\nInput Data", "expected": "The SEL log shows an entry for each drive that was inserted and it's location"}], "source": ""}
{"case_id": "case-1735", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nvsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1\n\nHere 196 = bus (in decimal) for the endpoint bdf\n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/vmkernel.log\n\n\nInput Data", "expected": "check if \r\n1) \"ACPI event 0xf\" is received\r\n2) Port experienced DPC\r\n3) Error recovery done\r\n\r\nare logged in /var/log/vmkernel.log"}], "source": ""}
{"case_id": "case-1736", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nUse following commands to determine the handle and issue identify\r\n\r\nesxcli device driver list\r\nesxcli nvme device get -A vmhba5\r\n\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1737", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat step 2-3 at least four times \r\n\r\nInput Data", "expected": "The device get's enumerated successfully after each recovery. \r\nThe device is visible in \r\n\"esxcli nvme device list\""}], "source": ""}
{"case_id": "case-1738", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nrepeat step 2-4 instead inject error on upstream port by using Malformed TLP mechanism. \r\n\r\nInput Data", "expected": "The devices are visible in OS"}], "source": ""}
{"case_id": "case-1739", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf Windows -\r\nComputer Management->Device Manager->Storage Controllers\r\nRight-click one of the PCIe SSDs and select \"Properties\"\r\nClick the \"Details\" tab\r\nClick the Property drop-down and select the \"PCI label string\"\r\nElse if Linux -\r\nRun the attached dslot.sh shell script\r\nElse if ESXi -\r\nThere is a tool called \"smbiosDump\" that will display the SMBIOS/DSM information\r\n\r\n\r\nInput Data", "expected": "PCIe SSD in Slot X in Bay Y (where X is the slot number, and Y is the backplane ID)"}], "source": ""}
{"case_id": "case-1740", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIf Windows - Repeat step 2 for the other form factor PCIe SSD (the Linux shell script will show all devices)\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-1741", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [], "source": ""}
{"case_id": "case-1742", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nDiscover the PCIe topology for all NVMe slots. \nFor CPU direct-attach slots, it will just be a single CPU root port BDF. \nFor PCIe switch-connected slots, it will be something like: CPU Root Port -> Switch Upstream Port -> Switch Downstream Port.\n\nNOTE that the easiest way of doing this is imply to look-up the information on the PCIeSSD Confluence page. Look for the \"Slot BDF Mapping\" page.\n\n\nInput Data", "expected": "The PCIe BDF topology is dsicovered for all NVMe slots"}], "source": ""}
{"case_id": "case-1743", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nRead the Device Control register from PCIe config. space for the CPU root port at the top of the tree for each slot.\n\nThe UEFI command to read PCIe config space is \"pci BUS DEVICE FUNCTION -i\", ie \"pci 65 00 00 -i\" for a BDF of 65:00.0.  This command takes BDFs in hex.\n\nTo specifically read the Max_Payload_Size, you can take advantage of DellGrep (only in the Dell UEFI shell) and run this for example: \"pci 65 00 00 -i | DellGrep Max_Payload_Size\"\n\n\nInput Data", "expected": "The configured Max_Payload_Size is set to 256B for each root port"}], "source": ""}
{"case_id": "case-1744", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRead the Max_Payload_Size field from the Device Control Register from the CPU root port all the way down to the switch downstream port (if applicable)\r\n\r\nInput Data", "expected": "The Max_Payload_Size is set to 256B for all BDFs"}], "source": ""}
{"case_id": "case-1745", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nShutdown the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1746", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert NVMe devices into the slots that were checked previously and boot into the Dell UEFI shell\r\n\r\nInput Data", "expected": "The system boots successfully and all NVMe devices are discovered"}], "source": ""}
{"case_id": "case-1747", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3 and 4\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-1748", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRead the Max_Payload_Size field from the Device Control Register of the NVMe devices\r\n\r\nInput Data", "expected": "Each device has the Max_Payload_Size set to 256B"}], "source": ""}
{"case_id": "case-1749", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the NVME_PRES, PERST#, and P4 signals to an oscilloscope\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1750", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower on the server\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1751", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of NVME_PRES\r\n\r\nInput Data", "expected": "Trigger enabled"}], "source": ""}
{"case_id": "case-1752", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nConfigure the horizontal divisions to be 500ms\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1753", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nConfigure the vertical divisions for both signals to be 1V\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1754", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nHot insert an NVMe drive\r\n\r\nInput Data", "expected": "The trigger occurs\r\n\r\n==============================\r\nBefore the trigger occurs, P4 and NVME_PRES are both high (~3.3V).  PERST# is low (~0V).\r\n\r\nUpon insertion of the device, P4 immediately transitions to 0V.\r\n\r\nOne second after insertion, PERST transitions to high, and NVME_PRES transitions to low."}], "source": ""}
{"case_id": "case-1755", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the Status LED of the NVMe device\r\n\r\nInput Data", "expected": "The Status LED is solid green"}], "source": ""}
{"case_id": "case-1756", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPut the device into a failed state:\r\n    * NVM Subsystem Reliability Degraded\r\n    * Volatile Memory Backup Failed\r\n    * Read Only\r\n    * (special case) Available spare below threshold\r\n    * (special case) Temperature above threshold\r\n\r\n\r\nInput Data", "expected": "The device successfully goes into the failed state (can be verified by an in-band Get Log Page -SMART/Health command)\r\n\r\nWithin 1 minute, the Status LED is now in the following state:\r\n    * Read only, Back fail, or reliability degraded:  blinking amber/off\r\n    * Spare below threshold:  blinking amber/green/off\r\n    * Temperature:  solid green (normal operation, no physical indicator)"}], "source": ""}
{"case_id": "case-1757", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nD/C cycle the server and repeat the above steps, but choosing a different failure reason than before\r\n\r\nInput Data", "expected": "Same results as earlier"}], "source": ""}
{"case_id": "case-1758", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nD/C cycle the server and repeat the above steps, but this time choose for the device to go into Approaching Read-Only mode instead of one of the failure scenarios\r\n\r\nInput Data", "expected": "The status LED should now blink Green/Amber"}], "source": ""}
{"case_id": "case-1759", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into an operating system or UEFI shell\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1760", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nGet the PCIe BDFs of each of the U.2 NVMe devices in the system (lspci, Device Manager->Storage Contollers, etc.)\r\n\r\nInput Data", "expected": "BDFs are obtained for all U.2 NVMe PCIe SSDs"}], "source": ""}
{"case_id": "case-1761", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDump the SMBIOS table\r\n\r\nWindows:\r\nRWEverything -> SMBIOS\r\n\r\nLinux:\r\ndmidecode\r\n\r\nUEFI shell (Note you need to be using the Dell UEFI shell):\r\nsmbios\r\n\r\n\r\nInput Data", "expected": "Windows:\n   1. Go to the Type 9 section\n   2. Find the entry that has one of the U.2 NVMe bus numbers you saved\n   3. Check the \"Slot Location\" and confirm it's the correct location for the given device\nLinux:\n   1. Go to the Type 9 section (grep for DMI type 9)\n   2. Find the entry tat has a bus address equal to one of the U.2 NVMe bus numbers you saved\n   3. Check the \"Designation\" and confirm it's the correct location for the given device"}], "source": ""}
{"case_id": "case-1762", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 4 for all slots\r\n\r\nInput Data", "expected": "Same results as in step 4"}], "source": ""}
{"case_id": "case-1763", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nIf the operating system does not support the PLX SDK (ESXi or the UEFI shell), then connect an Aardvark to the debug I2C port on the switch.\r\n\r\nElse install the PLX SDK onto the SUT\r\n\r\n\r\nInput Data", "expected": "Aardvark is connected or PLX SDK is installed directly onto the SUT"}], "source": ""}
{"case_id": "case-1764", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLaunch the PLX PEX Device Editor software and select the Serdes Eye Width operation\r\n\r\nInput Data", "expected": "A SerDes Eye tab opens"}], "source": ""}
{"case_id": "case-1765", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nUse the Select a Port drop-down menu to choose a port (only choose a port that actually has an NVMe drive plugged into it)\r\n\r\nClick the Click to Draw Eye button\r\n\r\n\r\nInput Data", "expected": "The test completes and you see the eye \"open\"\r\n\r\nThe data may need to be analyzed by a hardware engineer to determine pass/fail"}], "source": ""}
{"case_id": "case-1766", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat the test for all possible NVMe slots\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-1767", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBoot into a supported operating system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1768", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetermine the parent PCIe BDF to the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1769", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD\r\n\r\nInput Data", "expected": "The PCIe Configuration Reads are being responded to"}], "source": ""}
{"case_id": "case-1770", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHave the PCIe SSD suddenly stop responding to the Non-Posted Requests\r\n\r\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.\r\n\r\n\r\nInput Data", "expected": "If the OS and platform do not support Downstream Port Containment, the system crashes.\r\n\r\nIf DPC is supported, then the OS should log a Completion Timeout and attempt to recover."}], "source": ""}
{"case_id": "case-1771", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDump the system SEL (e.g. racadm getsel -E)\r\n\r\nInput Data", "expected": "If no DPC support, there's an entry for a Completion Timeout logged by the root port above the endpoint that stopped responding.\n\nWith DPC support, there will be a DPC event logged with a reason of Completion Timeout."}], "source": ""}
{"case_id": "case-1772", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nConnect the oscilloscope probes to the P4, P10, and NVMe_PRES wires.\r\n\r\nInput Data", "expected": "The probes are added and channels are enabled."}], "source": ""}
{"case_id": "case-1773", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nConfigure the oscilloscope to trigger on the falling edge of the P4 signal.\r\n\r\nSet the horizontal divisions to 200ms divisions.\r\n\r\nSet the vertical divisions for P4, P10, and NVME_PRES to 1V.\r\n\r\n\r\nInput Data", "expected": "The oscilloscope is configured"}], "source": ""}
{"case_id": "case-1774", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nPower on the server with no drive plugged into the slot that's been wired for the measurement\r\n\r\nInput Data", "expected": "The server powers on and boots into an operating system or UEFI environment"}], "source": ""}
{"case_id": "case-1775", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot insert an NVMe drive into the slot\r\n\r\nInput Data", "expected": "The oscilloscope triggers"}], "source": ""}
{"case_id": "case-1776", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAnalyze the oscilloscope capture\r\n\r\nInput Data", "expected": "1. The time before the trigger, all three signals were high (3.3V)\r\n   2. At the trigger, the P4 signal went low (0V) while the other two signals remained high\r\n   3. *500ms later, the P10 signal remains high, but the NVME_PRES went low\r\n*The parts are allowed to have some small deviation from 500ms. E.g. 490ms, 510ms, etc. but should not vary much more than that"}], "source": ""}
{"case_id": "case-1777", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Physical Device Operations menu option.\r\n\r\nInput Data", "expected": "Blink/Ublink operations are displayed and active (they are not grayed out)."}], "source": ""}
{"case_id": "case-1778", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nInitiate identify on a PCIe SSD. (Blink)\r\n\r\nInput Data", "expected": "1. Blink operation starts successfully\r\n\r\n2. The PCIe SSD is blinking its status LED"}], "source": ""}
{"case_id": "case-1779", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect Unblink.\r\n\r\nInput Data", "expected": "1. Unblink operations starts successfully\r\n\r\n2. The PCIe SSD stops blinking its activity LED"}], "source": ""}
{"case_id": "case-1780", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 3 and 4 but select to blink more than one device. For Unblink, unblink one drive first, wait 10 seconds, unblink the second device.\r\n\r\nInput Data", "expected": "For blink: user is able to blink more than one device at the same time.\r\n\r\n\r\nFor unblink: unblink of one device does not disrupt the LED pattern of the other drive(s), ie. other device continues to blink until user selects unblink."}], "source": ""}
{"case_id": "case-1781", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nDisable correctable error reporting for all NVMe drives, and parents BDFs above them (write to PCIe Cfg Space - Device Control Register)\r\n\r\nClear the Correctable Error Mask register\r\n\r\n\r\nInput Data", "expected": "Correctable Error Reporting is disabled and all errors have been masked"}], "source": ""}
{"case_id": "case-1782", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nBegin running I/O to all of the devices and allow it to run for 70 minutes\r\nWhile I/O is in progress, poll the Correctable Error Status registers of the NVMe drives and parents of the drives\r\n\r\n\r\nInput Data", "expected": "I/O runs successfully\r\nNo correctable errors are detected"}], "source": ""}
{"case_id": "case-1783", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDump the system event log (e.g. racadm getsel -E)\r\n\r\nInput Data", "expected": "There are no Correctable or Uncorrectable errors being reported by the NVMe devices or parent of the NVMe devices in the log"}], "source": ""}
{"case_id": "case-1784", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nReboot the system and repeat steps 2-4 an additional 9 times\r\n\r\nInput Data", "expected": "Same results"}], "source": ""}
{"case_id": "case-1785", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNote down the BDF of the endpoint and try to inject a FATAL/Non-Fatal error . \r\nEx- A malformed TLP can be generated by changing MPS of endpoint causing mismatch with the root port.  \r\n\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1786", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nThe device Max Payload Size has been changed and reflected in config space \r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1787", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRun heavy IO to device to make sure error is generated in short time\r\n\r\nInput Data", "expected": "/var/log/message logs when the error is generated and can be seen there"}], "source": ""}
{"case_id": "case-1788", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCheck /var/log/message and make sure DPC event triggered information is logged along with successful device recovery \r\n\r\nInput Data", "expected": "The expected functionality was logged correctly"}], "source": ""}
{"case_id": "case-1789", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBoot into a supported config which has Dpsudo C support both from BIOS as well as OS\n\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1790", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDetermine the parent PCIe BDF to the PCIe SSD\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1791", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nStart generating continuous I/O to the device\r\n\r\nInput Data", "expected": "The I/O starts without any issue"}], "source": ""}
{"case_id": "case-1792", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nHave the PCIe SSD suddenly stop responding to the Non-Posted Requests\n\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.\n\n\nInput Data", "expected": "The system doesn't crash"}], "source": ""}
{"case_id": "case-1793", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nDump the PCIe CFG space of parent port and check DPC Trigger Status \r\n\r\nInput Data", "expected": "For Linux:\r\n\r\nThe DPC Trigger Status should be set\r\n\r\nFor ESXi:\r\n\r\nThe DPC Trigger Status should be clear, and the device driver is not loaded for the endpoint (drive). NOTE: ESXi does not leave the port in containment, and instead takes it out to unload the driver)"}], "source": ""}
{"case_id": "case-1794", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nCheck the OS message for recovery failure and EDR event triggered \r\n\r\nInput Data", "expected": "The message indicates EDR event and also recovery failure"}], "source": ""}
{"case_id": "case-1795", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nCheck the SEL log for DPC event \r\n\r\nInput Data", "expected": "The SEL log has DPC event captured"}], "source": ""}
{"case_id": "case-1796", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nsetpci -s bdf 0x10.w=0xffff \n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/message or syslog  \n\n\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-1797", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1798", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat steps 2-3 14 times\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1799", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nInsert 15th error to the same end point \r\nand get the SEL logs\r\n\r\n\r\nInput Data", "expected": "The end point devices is not visible and DPC Status is set to triggered mode. \r\nGet the SEL logs and make sure there are 14 DPC error event and 1 Fatal error event. \r\nAlso, check if the SEL decoding is correct and logging right event and errors along with right bdf"}], "source": ""}
{"case_id": "case-1800", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPlace your system on the network such that you're able to remotely access it via iDRAC.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1801", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nLog into the iDRAC GUI and go into the \"Maintenance -> Support Assist\" section\r\n\r\nClick on the Start a Collection button\r\n\r\nIn the Data to Collect section, select all options\r\n\r\nIn the Collection Preferences section, select Save Locally\r\n\r\nClick Collect\r\n\r\n\r\nInput Data", "expected": "The collection completes successfully"}], "source": ""}
{"case_id": "case-1802", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nExtract the zip file that gets generated\r\n\r\nExtract the zip file inside of that zip file as well\r\n\r\nNavigate into the tsr -> storagelog directory\r\n\r\n\r\nInput Data", "expected": "There should be files for each NVMe drive present"}], "source": ""}
{"case_id": "case-1803", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nOpen each file\r\n\r\nInput Data", "expected": "The SMART/Health and Error Information is present and accurate (this can be confirmed via Get Log Page from an in-band tool)"}], "source": ""}
{"case_id": "case-1804", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nCheck the status LED of the device as soon as you boot the system\r\n\r\nInput Data", "expected": "The status LED of the device should turn on green as soon as the Backplane is powered on.\r\n\r\n\r\n\r\nNote: Usually the staus LED is set to solid green within 1-3 second after the system is booted."}], "source": ""}
{"case_id": "case-1805", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nWait till the system boots to OS and check the LED of the drives\r\n\r\nInput Data", "expected": "The LED of the drive stays solid green"}], "source": ""}
{"case_id": "case-1806", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReboot the system and check the status LED of the drives\r\n\r\nInput Data", "expected": "The status LED of the drive should stay Green all the time."}], "source": ""}
{"case_id": "case-1807", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nFind out the parent BDF to the NVMe devices\r\n\r\nWindows:\r\nDevice Manager -> View by Connection\r\n\r\nLinux:\r\nlspci -t\r\n\r\n\r\nInput Data", "expected": "The parent BDFs for each NVMe drive are captured"}], "source": ""}
{"case_id": "case-1808", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nDump PCIe config. space for each parent BDF determined in the previous step\r\n\r\nInput Data", "expected": "PCIe config. space is successfully captured"}], "source": ""}
{"case_id": "case-1809", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nCheck the Device Control 2 Register, bits 0-3\r\n\r\nInput Data", "expected": "The value decodes to 0x6"}], "source": ""}
{"case_id": "case-1810", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link speed.\r\n\r\nInput Data", "expected": "BIOS halts due to link down train error, reporting the actual versus expected speed. \r\n\r\nThe error is reported to screen with the BDF of the parent of the NVMe device. \r\n\r\nThere is an entry for this error in the Lifecycle Log.\r\n\r\nIf the system is 15G or newer, then the bay and slot of the link degradation is reported as well."}], "source": ""}
{"case_id": "case-1811", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same results as above except the BIOS does not pause during POST"}], "source": ""}
{"case_id": "case-1812", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to the \"View Physical Device Properties\" menu option.\r\n\r\nInput Data", "expected": "1. Under Physical Disk Properties, following fields listed:\r\n    * Physical Device ID\r\n    * Form Factor\r\n    * State\r\n    * Capacity\r\n    * Bus Protocol (PCIe)\r\n    * Bus Protocol Version\r\n    * Device Protocol, \r\n    * Device Life Remaining (AHCI)/Remaining Rated Write Endurance (NVMe)\r\n    * Failure Predicted\r\n    * Firmware revision\r\n    * Serial number\r\n    * Model number\r\n    * Capable Transfer Speed (AHCI)/PCIe Maximum Link Speed(NVMe)\r\n    * PCIe Maximum Link Width\r\n    * PCIe Negotiated Link Width \r\n 2. Physical Device ID is in the form of:\r\n    * AHCI X:Y:Z (Port:Bay:Slot)\r\n    * NVMe \"PCIe SSD in Slot (Slot#) in Bay (Bay#)\r\n    * NVMe HHHL Adapter: \"PCIe SSD in Slot (Slot#)\" \r\n 3. All fields are non-editable strings. \r\n\r\n 4. All options/fields will display corresponding help text at the bottom of the screen or in the help screen."}], "source": ""}
{"case_id": "case-1813", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\n\nIssue an NVMe-MI command to each backplane slot (and wherever the AIC PCI slot is). For example, the command could be the NVM Subsystem Health Status Poll:\n\nlibi2ctest -pec -d -c I2C_Bus_Num 100 100 0 -v 0x20 -a 0xD4 -r 27 0xf 0x19 0x21 0x1 0x0 0x0 0xc8 0x84 0x8 0x0 0x0 0x1 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xd2 0xd4 0x77 0x36 30\n\nNOTE that the I2C_Bus_Num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file in the iDRAC filesystem\n\nOr the NVMeMICLI.py tool can be used in place\n\nExample of a Passing test output using NVMeMICLI.py\n\npython3 NVMeMICLI.py -c ns -b 1 -s 1\n\nClear Status (0 or 1) = 0\nWARNING:root:Backplane - No type match found for BP type 389 in I2Ctopology, guessing...\n0x00000: 20 0F 19 3B 01 00 00 C0 84 88 00 00 00 00 00 00 ..;............\n0x00010: 38 FF 24 01 00 00 00 00 AF B1 49 94 59 8.$.......I.Y\nReserved - 0x0\nNVM Subsystem Status - 0x38\nSmart Warnings - 0xff\nComposite Temperature - 36\nPercentage Drive Life Used - 1\nComposite Controller Status - 0x0\n\nInput Data", "expected": "The I2C command is successful (no NAK, Unknown error, or Timeout) for all NVMe backplane slots as well as the AIC"}], "source": ""}
{"case_id": "case-1814", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nssh or serial into the iDRAC and go to the iDRAC console (rootshell or gilchrist or racadm debug invoke rootshellash)\n\nInput Data", "expected": "root access to the iDRAC is obtained"}], "source": ""}
{"case_id": "case-1815", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRun the \"bptest\" command\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1816", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect the SEP number of where you're planning on inserting drives\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1817", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect the \"Drive Area\" sub-menu and verify that the presence information is correct\r\n\r\nInput Data", "expected": ""}], "source": ""}
{"case_id": "case-1818", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nInsert NVMe drives into all available NVMe drive slots\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1819", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRe-read the \"Drive Area\" section (may require to exit bptest and re-start it)\r\n\r\nInput Data", "expected": "The newly inserted drives correctly show that there are NVMe drives present in the correct slots"}], "source": ""}
{"case_id": "case-1820", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nRemoval all of the NVMe drives from the system\r\n\r\nInput Data", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1821", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "9", "description": "Description\r\nRe-read the \"Drive Area\" section (may require to exit bptest and re-start it)\r\n\r\nInput Data", "expected": "The removed drives correctly show as the slots no longer have any NVMe drives present"}], "source": ""}
{"case_id": "case-1822", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nAttach the maximum number of PCIe SSDs permitted by the system configuration.\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1823", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nClear the system's SEL log.\r\n\r\nInput Data", "expected": "SEL log cleared."}], "source": ""}
{"case_id": "case-1824", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nBoot into the OS and ensure system logs in automatically\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1825", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nUse a controllable PDU to remove AC power from the system after the system boots and the attempt has been made to discover all PCIe SSD devices. This will require some tweaking of parameters depending on how long the device discovery takes.\r\nSequence should look like: boot --> OS login --> Device Detection --> AC power off --> repeat\r\n\r\nInput Data", "expected": "Test is set up to run unattended."}], "source": ""}
{"case_id": "case-1826", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAllow the system to repeat the A/C cycle for at least 12 hours.\r\n\r\nInput Data", "expected": "No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible."}], "source": ""}
{"case_id": "case-1827", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nIf applicable, check the device debug log for any errors.\r\n\r\nInput Data", "expected": "No errors found."}], "source": ""}
{"case_id": "case-1828", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject error on a NVMe device using any of error injection methods. \r\nFor example following command can be used along with some transaction. \r\nsetpci -s bdf 0x10.w=0xffff \r\n\r\nor Malformed TLP can be injected using mismatched MPS settings.\r\n\r\nMake sure you have another terminal with running OS log, \r\ntail -f /var/log/message or syslog  \r\n\r\n\r\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-1829", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1830", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nRepeat the steps 2-3 on a different end point\r\n\r\nInput Data", "expected": "The devices are properly enumerated"}], "source": ""}
{"case_id": "case-1831", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nHot remove  both the drives on which error  was injected & recovered\r\n\r\nInput Data", "expected": "The devices are removed and not visible both at PCI and NVMe level"}], "source": ""}
{"case_id": "case-1832", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nHot insert the drives back in the same slots\r\n\r\nInput Data", "expected": "devices are enumerated properly"}], "source": ""}
{"case_id": "case-1833", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link width.\r\n\r\nInput Data", "expected": "BIOS halts due to link down train error\r\n\r\nThe error is reported to screen with correct BDF\r\n\r\nThere is an entry for this error in the Lifecycle Log\r\n\r\nIf the system is 15G or newer, then the bay and slot location of the failure will be reported as well"}], "source": ""}
{"case_id": "case-1834", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPress F1 to continue.\r\n\r\nInput Data", "expected": "System continues to boot without issues. PCIe SSD device is accessible through the OS without any issues."}], "source": ""}
{"case_id": "case-1835", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nReboot the system.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1836", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nDC power cycle the system (press power button to turn off/on, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1837", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nAC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1838", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same as above except the BIOS should not pause during POST"}], "source": ""}
{"case_id": "case-1839", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nPower on the system and let it boot through POST.\r\n\r\nInput Data", "expected": "BIOS pauses at an F1/F2 prompt displaying that a link training error has occurred.\r\n\r\nThe error is reported to screen with correct BDF. \r\n\r\nUser can proceed system boot with F1 or F2.\r\n\r\nIf the system is a 15G or newer, then the bay and slot of where the training failure occurred should be shown."}], "source": ""}
{"case_id": "case-1840", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReboot the system.\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1841", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nDC power cycle the system (press power button to turn off/on, wait 10 seconds in between).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1842", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\nAC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).\n\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1843", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nRepeat steps 1 and 2 but with \"F1/F2 Prompt On Error\" BIOS option disabled.\r\n\r\nInput Data", "expected": "Same results except the BIOS won't pause in POST, although the messaging should still be the same."}], "source": ""}
{"case_id": "case-1844", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nNavigate to Export Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).\r\n\r\nInput Data", "expected": "1. Save Debug Log page will show the following options/fields:\r\n\r\nSelect File System target (header)\r\n\r\nSelect File System (link)\r\n\r\n\r\nSelect Directory (header)\r\n\r\nDirectory list selection\r\n\r\n\r\nExport Log File path (header)\r\n\r\nFile path\r\n\r\n\r\nExport Log (link)\r\n\r\n\r\n\r\n\r\n2. All options/fields display corresponding help text at the bottom of the screen."}], "source": ""}
{"case_id": "case-1845", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nSelect a file system target (ie. if there is more than one USB key inserted)\r\n\r\nInput Data", "expected": "1. All attached file systems are listed under \"Select File System Target\". The default (root) directory should be selected by default.\r\n\r\n2. \"Select File System Target\" (link) can be used to change currently selected File System."}], "source": ""}
{"case_id": "case-1846", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nSelect a directory.\r\n\r\nInput Data", "expected": "1. All attached directories are listed under \"Select Directory\". The default (root) directory should be selected by default.\r\n\r\n2. User can choose appropriate directory to save the file to under \"Select Directory\".\r\n\r\n3. \"Select Directory\" (link) can be used to change currently selected Directory."}], "source": ""}
{"case_id": "case-1847", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nSelect Export Log.\r\n\r\nInput Data", "expected": "Message displayed is \"Log saved successfully. PCIeSSD_(date time string).log\".\r\n\r\n\r\nFor NVMe PCIe SSD log, User can choose the any filename with extension .log"}], "source": ""}
{"case_id": "case-1848", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nBoot into your OS and retrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly. Logs saved on the USB key will be visible as normal. Logs saved to file systems will be in the EFI partition of the OS. This will be mounted as normal in Linux. In windows, get an Administrator powershell prompt, and type \"mountvol P: /S\" (P can be any available mount point). Logs can then be viewed under P:\\ as normal.\r\n\r\nInput Data", "expected": "Data and values are returned correctly for all drives."}], "source": ""}
{"case_id": "case-1849", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\nRepeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).\r\n\r\nInput Data", "expected": "Same results."}], "source": ""}
{"case_id": "case-1850", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nUsing the same drive(s) that was used in step 1, put those into the new SUT and again read the FRU as in step 1\r\n\r\nNOTE that the virtual/I2C bus number are likely different and need to be updated\r\n\r\n\r\nInput Data", "expected": "The FRU data is successfully read"}], "source": ""}
{"case_id": "case-1851", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCompare the FRU contents from step 1 and step 2\r\n\r\nInput Data", "expected": "There are no differences"}], "source": ""}
{"case_id": "case-1852", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Determine the parent PCIe BDF to the PCIe SSD under test.(the DUT here is NVMe device with special firmware that can go unresponsive)", "expected": "Implicit"}], "source": ""}
{"case_id": "case-1853", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Start generating continuous I/O to the device", "expected": "The I/O starts without any issue"}], "source": ""}
{"case_id": "case-1854", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Have the PCIe SSD suddenly stop responding to the Non-Posted Requests\n\n\nNOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.", "expected": "The system doesn't crash and EDR event is logged in the OS log"}], "source": ""}
{"case_id": "case-1855", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Check the OS log and look for recovery failure message", "expected": "There will be recovery failure message post EDR event logging as the device won't come back up"}], "source": ""}
{"case_id": "case-1856", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Dump the PCIe CFG space of parent port and check DPC Trigger Status", "expected": "The DPC Trigger Status should be cleared.\n\n\nNote: BIOS puts the port in Software Triggered DPC but ESXi brings the port back from containment."}], "source": ""}
{"case_id": "case-1857", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Check the SEL log for DPC event", "expected": "The SEL log has DPC event captured"}], "source": ""}
{"case_id": "case-1858", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject PCIe errors  upto the threshold (16 errors) on NVMe devices and check OS logs. Upon crossing the threshold the error severity is marked as non-recoverable. \r\nEx- UR or Malformed TLP \r\n\r\n\r\nInput Data", "expected": "The correct error severity is set upon crossing the threshold."}], "source": ""}
{"case_id": "case-1859", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL logs\r\n\r\nInput Data", "expected": "The SEL logs have all the errors logged with correct BDF and error type information"}], "source": ""}
{"case_id": "case-1860", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nInject errors such as UR or Malformed TLP is generated by the nvme device. \r\n\r\nInput Data", "expected": "The system crashes . (BSOD,PSOD etc)"}], "source": ""}
{"case_id": "case-1861", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL Logs and decode \r\n\r\nInput Data", "expected": "Make sure the correct errors are logged."}], "source": ""}
{"case_id": "case-1862", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\n\r\nClear the SEL logs and clear the OS logs if possible (ex- dmesg --clear)\r\n\r\nInject a Fatal or Non Fatal errors on one of the  NVMe device. You can either generate Malformed TLP, UR or any other PCIe errors.\r\n\r\n\r\nInput Data", "expected": "It's OS discretion to attempt recovery but most OS does. \r\nThe error reported back by BIOS is marked as \"Recoverable\" . Check OS logs (/var/log/message) to see relevant messages."}], "source": ""}
{"case_id": "case-1863", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nCheck the SEL logs and make sure the error was logged. \r\n \r\n\r\n\r\nInput Data", "expected": "The errors are logged in the SEL and if recovery was successful device will be available for use."}], "source": ""}
{"case_id": "case-1864", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nsetpci -s bdf 0x10.w=0xffff \n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/message or syslog  \n\n\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-1865", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1866", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nInject error on up stream port . \nThis can be done in many ways. \nFor example \nChange MPS of up stream  port that is less than endpoint Max Payload Size\nRun some I/O to the device\n\n\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "case-1867", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nRepeat steps 1-4 at least 2 times\r\n\r\nInput Data", "expected": "Endpoint device is enumerated properly"}], "source": ""}
{"case_id": "case-1868", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nInject error on a NVMe device using any of error injection methods. \nFor example following command can be used along with some transaction. \nsetpci -s bdf 0x10.w=0xffff \n\nor Malformed TLP can be injected using mismatched MPS settings.\n\nMake sure you have another terminal with running OS log, \ntail -f /var/log/message or syslog  \n\n\nInput Data", "expected": "check if \r\n1) ACPI event 0xf received\r\n2) containment event, status:0x1f03 source:0xe300\r\n3) device recovery successful\r\n\r\nare logged in /var/log/message"}], "source": ""}
{"case_id": "case-1869", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIssue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.\r\n\r\nInput Data", "expected": "The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded."}], "source": ""}
{"case_id": "case-1870", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInject error on up stream port . \r\nThis can be done in many ways. \r\nFor example \r\nChange MPS of up stream  port that is less than endpoint Max Payload Size\r\nRun some I/O to the device\r\n\r\n\r\nInput Data", "expected": "EDR notification sent to same events are noticed as in step 2\r\nMake sure the device below the port is accessible and enumerated."}], "source": ""}
{"case_id": "case-1871", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.\n\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than what an OMSA-issues Crypto Erase sanitize will present. It is recommended to do this in Linux.\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 \n\nCollect the sanitize log once the operation has completed. \n\nLinux:\n\nnvme sanitize-log /dev/nvme7n1\n\nWindows:\n\npython NVMeMICLI.py -c gl -b 0 -s 1\nController ID = 0x0000\nNamespace ID = 0xffffffff\nLog Page ID = 0x81\nLog Page Sub ID = 0x00\nNumber of DWORDS = 0x08\nRetain Asynchronous Event = 1\n\n\nInput Data", "expected": "The erase operation succeeds. \r\n\r\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xa\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0"}], "source": ""}
{"case_id": "case-1872", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nNow, issue a Crypto Erase via OMSA while using the OS intended for this testcase, whether that be Linux, Windows or ESXi.\r\n\r\nDump the sanitize get-log page to determine the type of erase issued, e.g.:\r\n\r\nLinux: \r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nWindows:\r\n\r\npython NVMeMICLI.py -c gl -b 0 -s 1\r\nController ID = 0x0000\r\nNamespace ID = 0xffffffff\r\nLog Page ID = 0x81\r\nLog Page Sub ID = 0x00\r\nNumber of DWORDS = 0x08\r\nRetain Asynchronous Event = 1\r\n\r\n\r\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nSee the Sanitize Status Log section of the NVMe spec for a full decode of the log.\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.\r\n\r\nNote: Until OMSA implements JIT-154745, SCDW10 will be '0x4,' indicating Crypto Erase sanitize in restricted mode."}], "source": ""}
{"case_id": "case-1873", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nConfirm the sanitize operation is in progress via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nHot remove the device prior to the completion of the sanitize operation.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation is successfully launched; the NVMe device is removed prior to completion of the sanitize operation."}], "source": ""}
{"case_id": "case-1874", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nPower down the machine. Once the machine is off, insert the NVMe device and power on the machine.\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The sanitize operation should resume immediately following application of power to the NVMe device slot. The drive should not exit POST prior to the completion of the sanitize operation. A message may be printed to the screen indicating a sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1875", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.\n\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than that created by a management software-issued Crypto Erase.\n\nTo issue the Block Erase sanitize:\n\nnvme sanitize /dev/nvme7n1 -a 2 -u\n\nCollect the sanitize log once the operation has completed. \n\nLinux:\n\nnvme sanitize-log /dev/nvme7n1\n\n\nInput Data", "expected": "The erase operation succeeds. \r\n\r\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xa\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0"}], "source": ""}
{"case_id": "case-1876", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nIn the iDRAC GUI, navigate to Configuration -> Storage Configuration. Select the 'Cryptographic Erase' action and the 'Apply at Next Reboot' option; click 'Apply.' Reboot the machine.\r\n\r\nFollowing the execution of the Cryptographic Erase operation via LC (and once the machine has booted to the OS), read the Sanitize log:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "case-1877", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nNext, repeat step 2 in order to update the Sanitize log with data to reflect a Block Erase operation.\n\nOnce that is finished and verified, boot to HII. Navigate the NVMe device page and issue a Cryptographic Erase. Then, boot to the OS and read the Sanitize log:\n\nnvme sanitize-log /dev/nvme7n1\n\n \n\n\nInput Data", "expected": "The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "case-1878", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\n(Optional)\r\n\r\nRepeat steps 2 and 3, this time selecting the 'Apply at Scheduled Time' operation mode in the iDRAC GUI.\r\n\r\n\r\nInput Data", "expected": "The erase is performed at the expected time and subsequently succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 65535\r\nSanitize Status (SSTAT) : 0x101\r\nSanitize Command Dword 10 Information (SCDW10): 0xc\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nIf SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above."}], "source": ""}
{"case_id": "TC-25086", "name": "Verify Sanitize Operation Execution Time and Status Updates", "status": "Active", "type": "Manual", "description": "Confirm sanitize operation execution time is consistent with the 'estimated time' fields in the Sanitize Status log. Additionally, verify the 'SPROG' and 'SSTAT' fields are updated as expected while a sanitize operation is in progress.", "precondition": "", "steps": [{"step": "1", "description": "Description\r\nBoot to the OS with an NVMe device that supports Block Erase and Crypto Erase sanitize. Sanitize erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:\r\n\r\nnvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5\r\n\r\n\r\nIt is recommended to use Linux for its passthru command capabilities.\r\n\r\n\r\nInput Data", "expected": "Implicit."}], "source": ""}
{"case_id": "case-1880", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 \r\n\r\nBegin timing the operation immediately upon issuing the command. Monitor the Sanitize Status log while the operation is in progress by repeatedly issuing\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\nuntil the operation completes. Stop the timer once the operation completes.  (The operation is complete once 'SSTAT' is 0b101). \r\n\r\n\r\nInput Data", "expected": "While the operation is in progress, the 'SPROG' and 'SSTAT' fields are updated, For example:\r\n\r\nSanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize in Unrestricted Completion Mode was initiated. 'SPROG' contains a value less than 65536, indicating the fraction of the operation that has been completed at the time of the log read. Finally, 'SSTAT' is 0b010, indicating a sanitize operation is in progress. For example:\r\n\r\nlinux-g03y:~ # nvme sanitize-log /dev/nvme7n1\r\nSanitize Progress (SPROG) : 32335\r\nSanitize Status (SSTAT) : 0x002\r\nSanitize Command Dword 10 Information (SCDW10): 0xa\r\nEstimated Time For Overwrite : 0\r\nEstimated Time For Block Erase : 93\r\nEstimated Time For Crypto Erase : 0\r\n\r\nAdditionally, the timed value of the operation execution duration is withink 10% of the value reported in the 'Estimated Time for Block Erase' field. In the example above, the log indicates the operation is estimated to take 93 s on this particular device."}], "source": ""}
{"case_id": "case-1881", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nRepeat step 2 for a Crypto Erase sanitize:\r\nnvme sanitize /dev/nvme7n1 -a 4 -u 1 \r\n\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectation for step 2. Note that a Crypto Erase sanitize may complete virtually instantly (in less than 1 s). Hence, it may not be feasible to time this operation manually nor to observe SPROG and SSTAT at 'in progress' values. However, SCDW10 should be set to '0xc' to indicate a Crypto Erase in Unrestricted Mode was performed."}], "source": ""}
{"case_id": "case-1882", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\n(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).\r\n\r\nRepeat step 2 using the Overwrite sanitize operation (if the device supports this method):\r\n\r\nnvme sanitize /dev/nvme7n1 -a 3 -u 1\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 2. In particular, pay attention to the time it takes to execute the operation and compare this value to the estimated time listed in the Sanitize Status log."}], "source": ""}
{"case_id": "case-1883", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf the device is NVMe rev 1.4 compliant, repeat step 2 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1 -d\r\n\r\n\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 2. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "case-1884", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\r\nIf the device is NVMe rev 1.4 compliant, repeat step 3 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 4 -u 1 -d\r\n\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 3. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "case-1885", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\r\n(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).\r\n\r\nIf the device is NVMe rev 1.4 compliant (and support Overwrite sanitize), repeat step 4 using the 'no deallocate' option during the sanitize erase:\r\n\r\nnvme sanitize /dev/nvme7n1 -a 3 -u 1 -d\r\n\r\n\r\nInput Data", "expected": "Analogous to the expectations for step 4. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4)."}], "source": ""}
{"case_id": "case-1886", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\r\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\r\n\r\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nConfirm the sanitize operation is in progress via:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\nHot remove the device prior to the completion of the sanitize operation.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation is successfully launched and interrupted via a hot removal of the device prior to completion."}], "source": ""}
{"case_id": "case-1887", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\r\nReinsert the NVMe device. Check the progress of the sanitize operation:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n\r\nIn Windows, check the progress of the operation via:\r\n\r\nWindows:\r\n\r\npython NVMeMICLI.py -c gl -b 0 -s 1\r\nController ID = 0x0000\r\nNamespace ID = 0xffffffff\r\nLog Page ID = 0x81\r\nLog Page Sub ID = 0x00\r\nNumber of DWORDS = 0x08\r\nRetain Asynchronous Event = 1\r\n\r\nContinue monitoring the progress of the operation until it completes. Furthermore, check to ensure the device is enumerated in the system device tree; check OS errors logs, etc.\r\n\r\n\r\nInput Data", "expected": "The sanitize operation should resume on the device; eventually, the sanitize operation completes successfully.\r\n\r\nThe OS enumerates the NVMe device.\r\n\r\nNo abnormal or critical errors are logged."}], "source": ""}
{"case_id": "case-1888", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\r\nInstall OMSA.\r\n\r\nIf debug FW is available (or an NVMe device in sanitize failure mode is available), while the OS is up hot insert a drive in sanitize failure mode into the system.\r\n\r\nInput Data", "expected": "The NVMe device is enumerated by the OS. \n\nOMSA lists the device and initially presents a warning or alert status indicating a recovery action is needed on the device. OMSA presents an option to perform a Cryptographic Erase on the device.\n\nNo abnormal or critical errors are logged."}], "source": ""}
{"case_id": "case-1889", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nIf debug FW is available (or an NVMe device in sanitize failure mode is available), attempt to perform a FW update via DUP on the device. \r\n\r\nInput Data", "expected": "The DUP update should fail with an error message indicating the failure was due to the device being in sanitize failure mode and should suggest corrective action of sanitizing the device."}], "source": ""}
{"case_id": "case-1890", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "2", "description": "Description\nBefore beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.\n\nIssue a sanitize Block Erase to the NVMe device in unrestricted mode.\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\n\nConfirm the sanitize operation is in progress via:\n\nnvme sanitize-log /dev/nvme7n1 \n\n\nInput Data", "expected": "The sanitize operation is sucessfully launched."}], "source": ""}
{"case_id": "case-1891", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "3", "description": "Description\nWhile the sanitize operation remains in progress, issue the following permitted commands:\n\nnvme smart-log /dev/nvme8n1\nnvme error-log /dev/nvme8n1\nnvme id-ctrl /dev/nvme8n1\nnvme id-ns /dev/nvme8n1\nnvme get-feature /dev/nvme8n1 -f 7\necho \"abcdef\" | nvme set-feature /dev/nvme7n1 -f 0x81 -l 8\nnvme get-feature /dev/nvme7n1 -f 0x81\n\nIt is crucial that the sanitize operation be in progress while these commands are submitted. Monitor the Sanitize Status log frequently to confirm the operation is in progress:\n\nnvme sanitize-log /dev/nvme7n1 \n\n\nInput Data", "expected": "All of the commands complete successfully while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1892", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "4", "description": "Description\nUpon completion of the first sanitize operation, Issue another sanitize Block Erase to the NVMe device in unrestricted mode.\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\n\nWhile the sanitize operation remains in progress, issue the following MI command:\n\npython3 NVMeMICLI.py -c gl -b X -s Y\n\nwhere the NVMe device is in Bay X and Slot Y. Enter the following parameters when prompted:\n\nController Id - 0x0000\nNamespace Id - 0xffffffff\nLogpage Id - 0x02\nLog page Sub Id - 0x00\nNumber of DWords - 0xxff\nRetain Async Event - 0\n\n\nConfirm the sanitize operation is in progress before and after issuing the above MI command via:\n\nnvme sanitize-log /dev/nvme7n1 \n\n\nInput Data", "expected": "The MI command completes successfully while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1893", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "5", "description": "Description\r\nCreate a small file with some text data. For example,\r\n\r\nvi /root/Documents/mydata.txt\r\n\r\nEnter some text, \"This is my data in my file!\" and save.\r\n\r\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, attempt to write data to the device:\r\n\r\nhexdump mydata.txt > /dev/nvme7n1\r\n\r\nAgain, confirm the sanitize operation is in progress before and after attempting the write to the device:\r\n\r\nnvme sanitize-log /dev/nvme7n1 \r\n\r\n\r\nInput Data", "expected": "The write to the NVMe device undergoing the sanitize operation should fail. (Hence, the 'hexdump' command should fail)."}], "source": ""}
{"case_id": "case-1894", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "6", "description": "Description\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\n\nWhile the sanitize operation is in progress, issue the following commands to the device:\n\nnvme fw-log /dev/nvme7n1\nnvme device-self-test /dev/nvme7n1 -s 1\n\nVerify the targeted device supports device self test before issuing the command. And once again, verify the sanitize is in progress before and after the above commands:\n\nnvme sanitize-log /dev/nvme7n1\n \n\n\nInput Data", "expected": "The 'fw-log' and 'device-self-test' commands fail while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1895", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "7", "description": "Description\nIf the device supports telemetry logs and persistent event logging, issue another sanitize Block Erase to the NVMe device in unrestricted mode:\n\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\n\nWhile the sanitize operation is in progress, issue the following commands to the device:\n\nnvme telemetry-log /dev/nvme7n1 -o output.bin\nnvme get-log /dev/nvme7n1 -i 0x0d -l 0x20\n\n\nOnce again, verify the sanitize is in progress before and after the above commands:\n\nnvme sanitize-log /dev/nvme7n1\n\n\nNote: The persistent event log command above needs to be verified on a device that supports PEL.\n\n\nInput Data", "expected": "The telemetry and persistent event log commands fail while the sanitize operation is in progress."}], "source": ""}
{"case_id": "case-1896", "name": "", "status": "", "type": "", "description": "", "precondition": "", "steps": [{"step": "8", "description": "Description\r\nIssue another sanitize Block Erase to the NVMe device in unrestricted mode.\r\n\r\nnvme sanitize /dev/nvme7n1 -a 2 -u 1\r\n\r\nWhile the sanitize operation is in progress, attempt a DUP update of FW on the device.\r\n\r\nVerify the sanitize is in progress before and after launching the DUP:\r\n\r\nnvme sanitize-log /dev/nvme7n1\r\n \r\n\r\n\r\nInput Data", "expected": "The DUP update should fail and provide an error message that specifies the reason for the failure (a sanitize was in progress on the device) and suggest corrective action (reattempt the update after the sanitize operation has finished). It should also indicate that if repeated attempts to execute the DUP receive the same error message, it is recommended that the drive be sanitized via HII."}], "source": ""}
