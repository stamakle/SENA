Name,Id,Status,Type,Description,Precondition,Test Step #,Test Step Description,Test Step Expected Result,Test Case Entity Key (qMetry),FW Version,Owner,Micron Scripts,Results
PCIe SSD: Hotplug in UEFI/HII (negative test),TC-1198,Active,Manual,Verify system stability when user hotplugs a device while in HII.,,1,"Description
Note: This test is applicable to 15G and earlier only.
Install at least one PCIe SSD in the system and boot to HII.


Input Data
",Dell PCIe SSD Configuration Utility is displayed.,ESG-TC-176,,,,
,,,,,,2,"Description
For AHCI PCIe SSDs: navigate to the PD properties and ensure the device is listed under the PD selection list. Otherwise (for NVMe PCIe SSDs), skip to step 4.

Input Data
",PCIe SSD is displayed and accessible.,,,,,
,,,,,,3,"Description
Navigate out to the main configuration menu.

Input Data
",Implicit.,,,,,
,,,,,,4,"Description
Hot remove the PCIe SSD.

Input Data
","PCIe SSD main configuration page (for NVMe) may still be displayed, or the PCIe SSD may still be listed under PD properties (for AHCI) with ""invalid"" or stale data; however:


1. Verify system is still stable and functional.

2. Verify user can navigate within HII Configuration Utility.",,,,,
,,,,,,5,"Description
Power off the system. Insert one PCIe SSD and boot into HII.

Input Data
",Dell PCIe SSD Configuration Utility is displayed.,,,,,
,,,,,,6,"Description
While in the main configuration page, hot insert a new PCIe SSD in the system.

Input Data
","PCIe SSD may not get displayed (record exact behavior seen in the test results)


1. Verify system is still stable and functional.

2. Verify user can navigate within HII Configuration Utility.",,,,,
,,,,,,7,"Description
Reboot the system and boot into HII.

Input Data
",Hot inserted PCIe SSD from step 6 is now displayed properly and is accessible.,,,,,
PCIe SSD - Operating Systems - fdisk,TC-1676,Active,Manual,The purpose of this test case is to ensure that the Linux fdisk utility works with the PCIe SSDs.,-,1,"Description
Boot into a supported Linux operationg system with at least one PCIe SSD in it.

Input Data
",The OS sees the device and loads the driver for it.,ESG-TC-97338,,,,
,,,,,,2,"Description
From a terminal, run the command, ""fdisk -l""

Input Data
",The PCIe SSD device node is listed,,,,,
,,,,,,3,"Description
From a terminal, run the command, ""fdisk /dev/DEVICE"" where DEVICE is the PCIe SSD in the system If there are any partitions on the device already, delete them with the ""d"" command and then create a new partition, otherwise just create a new partition as follows: n p 1 w

Input Data
","""cat /proc/partitions"" now shows that the PCIe SSD has a partition on it now",,,,,
Lifecycle Controller(Negative Test Case):  Verify that the System remains stable when user hotinsert / Hot removes the drives in LifeCycle Controller,TC-3565,Active,Manual,Lifecycle Controller(Negative Test Case): Verify that the System remains stable when user hotinsert / Hot removes the drives in LifeCycle Controller,,1,"Description
Install at least one PCIe SSD; boot the system and Launch lifecycle controller.

Input Data
",Implicit,ESG-TC-308,,,,
,,,,,,2,"Description
In the left pane, click Hardware configuration

Input Data
",Option displayed,,,,,
,,,,,,3,"Description
In the right pane, click hardware Inventory

Input Data
",Option displayed,,,,,
,,,,,,4,"Description
Click view Current Inventory and from the listed device inventory look for PCIe SSD.

Input Data
",Lifecycle controller displays the Hardware inventory of the selected PCIe SSD.,,,,,
,,,,,,5,"Description
Follow below step: 1. Hotremove the installed PCie SSD and hot inset the pcie SSD in the same slot 2. Hot remove the SSD again and hot insert in a different slot

Input Data
",No kernel panic or Blue screen. system is functional,,,,,
,,,,,,6,"Description
Reboot the system and boot to OS. Run some IO to the drives

Input Data
",Implict. No I/O errors. Drive is fully functional.,,,,,
PCIe SSD - Long term: IO and wear leveling stress during power interruption,TC-3576,Active,Manual,Verify device stability and wear leveling runs regardless of power interruption.,,1,"Description
Install maximum supported PCIe SSDs in the system. Preferably have a mix of device capacities and form factor.

Input Data
",Implicit.,ESG-TC-310,,,,
,,,,,,2,"Description
Export the PCIe SSD logs via a supported utility such as OMSS or HII.

Input Data
",Logs exported for all devices in the system. Make record of the %life used and spare blocks.,,,,,
,,,,,,3,"Description
Setup an IO utility to run heavy IO to the PCIe SSD with a high thread count for 1min. 

Input Data
",IO runs without issues.,,,,,
,,,,,,4,"Description
After IO is stopped from step 3, SRSI the PCIe SSD (surprise remove the PCIe SSD followed by a surprise insertion).  

Repeat steps 3 and 4 10 times if doing manual, or 1000 times if automated (preferred). Wait 1 second in between SR, SI and restarting IO.


Input Data
",No issues during SRSI cycles.,,,,,
,,,,,,5,"Description
Export the PCIe SSD logs via a supported utility such as OMSS or HII.

Input Data
",Logs exported for all devices in the system. %life used and spare blocks have not changed significantly.,,,,,
,,,,,,6,"Description
Review the SEL, OS logs, and other applicable management logs for any issues or oddities.

Input Data
",No issues.,,,,,
PCIe SSD: Hot remove a drive while running I/O,TC-3759,Active,Manual,Verify the system remains operational when a PCIe SSD device disappears (ie. removed) while running I/O.,,1,"Description
Install the device under test. If Write Through (WT) mode is applicable to the device, complete steps 1-4 for drives that are in WT mode (write caching disabled).

Input Data
","Implicit.

",ESG-TC-78,,,,
,,,,,,2,"Description
Boot to the OS and load the driver for the device. Perform some simple I/O operations on the drive.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Pull the device out.

Input Data
I/O halted and reported unknown error upon pulling device out
but system continues to function  without any fatal system error","I/O halts. The OS should report I/O errors saying that it could not complete certain I/O’s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional.",,,,,
,,,,,,4,"Description
Re-insert the drive. If supported by the I/O utility, verify data integrity (no data loss) when write caching is disabled.

Input Data
",Drive is visible and accessible. Data processed prior to the removal is intact. No data loss.,,,,,
,,,,,,5,"Description
If applicable to the device, complete steps 1-4 for drives that have write caching enabled (might experience data loss).

Input Data
no differences  noted with & without windows OS Cache enabled/disabled
system continues to function irrespective","I/O halts. The OS should report I/O errors saying that it could not complete certain I/O’s. Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional.",,,,,
,,,,,,6,"Description
Repeat steps 2-5 10 times.

Input Data
results duplicated every repitition",Same results.,,,,,
PCIe SSD: Pre-OS hot add [negative test],TC-4928,Active,Manual,Verify that a hot inserted drive during boot is present and accessible after the OS loads.,,1,"Description
Boot the system and hot insert the device under test before the OS starts to load

Input Data
",Device is inserted. System continues to be funcional.,ESG-TC-181,,,,
,,,,,,2,"Description
Boot to the OS

Input Data
","OS loads successfully.

No fatal system side effects occur.",,,,,
,,,,,,3,"Description
Verify that the hot inserted device functions properly (ie. perform some I/O)

Input Data
","The PCIe SSD device functions correctly (correct link width and speed). No errors are reported.

No fatal system side effects occur.",,,,,
PCIe SSD: mdadm - Add a Hot-Inserted Drive to an Existing Array,TC-4997,Active,Manual,The purpose of this test case is to make sure that a newly hot inserted device can be added to an existing RAID array.,,1,"Description
Create a RAID1

Input Data
",The RAID1 array is successfully created,ESG-TC-121405,,,,
,,,,,,2,"Description
Hot insert a new NVMe drive into the system

Input Data
",It is successfully discovered by the device driver,,,,,
,,,,,,3,"Description
Add the hot inserted drive to be a part of the RAID0

Input Data
",The hot added drive is now successfully a part of the RAID0,,,,,
,,,,,,4,"Description
Create a RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,5,"Description
Hot insert a new NVMe drive into the system

Input Data
",It is successfully discovered by the device driver,,,,,
,,,,,,6,"Description
Add the hot inserted drive to be a part of the RAID5

Input Data
",The hot added drive is now successfully a part of the RAID5 and resyncs,,,,,
PCIeSSD: BIOS Memory Reservation on Empty Ports,TC-11027,Active,Manual,This test is to ensure that the BIOS always allocates memory for empty root ports/PCIe switch ports to support hot insertion.,,1,"Description
Boot into the OS of the system with no NVMe devices installed

Input Data
",Implicit,ESG-TC-135462,,,,
,,,,,,2,"Description
Dump the PCIe configuration space of the root ports or PCIe switch ports above where the NVMe drives would be

Input Data
","The ""Memory Base"" and ""Memory Limit"" registers are both non-zero, and equal to each other.",,,,,
PCIeSSD: 4k Sector Size Capacity Check in HII,TC-18261,Active,Manual,The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.,,1,"Description
While the drive is configured in the default 512B sector size, boot into the HII page for the drive

Input Data
","In the ""View Physical Properties"" menu, the device capacity is displayed. NOTE it down",ESG-TC-134674,,,,
,,,,,,2,"Description
Change the format of the drive to 4kB (do not enable PI, use the format with no MS).

Here's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).


Input Data
",The format completes successfully,,,,,
,,,,,,3,"Description
Go back into the HII page for the newly formatted drive

Input Data
","In the ""View Physical Properties"" menu, the device capacity is displayed and matches the value originally recorded",,,,,
,,,,,,4,"Description
Don't forget to put the drive back to 512B format.

Input Data
",The format completes successfully,,,,,
PCIe SSD - Factory WinPE - NVMe inventory (factory util),TC-19270,Active,Manual,To validate compatibility of NVMe PCIe SSD in WinPE environment. Confirm user is able to retrieve NVMe PCIe SSD properties via the utility used by the factory.,,1,"Description
Install at least one NVMe PCIe SSD in the system of each device type and/or form factor.

Input Data
",Implicit,ESG-TC-109,,,,
,,,,,,2,"Description
Pull the latest FICore image and boot to it.

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Using the factory utility, retrieve the NVMe PCIe SSD properties. This step will need to be repeated for every different type of NVMe PCIe SSD in the system.

Input Data
",Device properties are retrieved successfully. All expected properties are returned and these contain the correct value (also formatted correctly).,,,,,
PCIe SSD ESXi - Hot-Plug of Assigned Datastore (VM Off),TC-21294,Active,Manual,The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is off,,1,"Description
Create a datastore on an NVMe drive (use more than 1 if possible)

Input Data
",Datastore is successfully created,ESG-TC-115809,,,,
,,,,,,2,"Description
Assign a virtual disk from the newly created datastore to a virtual machine

Input Data
",The virtual disk is successfully assigned to the VM,,,,,
,,,,,,3,"Description
With the VM powered OFF, remove the NVMe drive that has the datastore on it

Input Data
","The OS does not crash
The drive is removed from lspci
The drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI",,,,,
,,,,,,4,"Description
Re-insert the NVMe drive that was removed

Input Data
","The device is re-enumerated in lspci
The device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)",,,,,
,,,,,,5,"Description
Power on the VM

Input Data
",The virtual disks carved from the NVMe datastore is detected within the VM and can successfully complete I/O (run for a minute),,,,,
PCIeSSD: NVMe MI - Hotplug a device and check the device discovery time,TC-21854,Active,Manual,The device should respond in 1 sec to idrac when idrac talks to its channel after it is hot plugged.,,1,"Description
Connect an I2C Analyzer to the system


Input Data
",Implicit,ESG-TC-93584,,,,
,,,,,,2,"Description
Boot the SUT without any NVMe drive into the OS

NOTE if you must have another NVMe drive installed as the OS, then you will see traffic going to that drive if it's in the same bay as the drive you will be inserting. If this is the case, then consult the I2CTopology.bin file in the iDRAC's root filesystem to view the MUX information to understand when the iDRAC is communicating to the OS drive versus the hotplugged drive.


Input Data
",Implicit,,,,,
,,,,,,3,"Description
Start the I2C trace capture/recording

Input Data
",You should not see any communication with I2C address 0xD4 or 0x3A,,,,,
,,,,,,4,"Description
Hot insert an NVMe drive

Input Data
","Within 10s, in the I2C trace:
1. The FRU of the device will be read from 0xA6 address
2. NVMe-MI traffic to I2C address 0x3A (or 0xD4 if an old device) starts (likely a Read NVme-MI Data Structure command)

The order of items #1 and #2 does not matter.",,,,,
,,,,,,5,"Description
Remove that same drive that was just inserted

Input Data
","Within 10s, no more I2C communication with I2C addresses 0xD4 or 0x3A is seen",,,,,
PCIe SSD - UEFI Driver - HII Forms and xUEFI,TC-24794,Active,Manual,Will make sure that HII forms can be processed and that the x-UEFI language is supported,,1,"Description
Insert at least one PCIe SSD in the system and boot to an EFI-bootable USB key

Input Data
",Implicit,ESG-TC-393,,,,
,,,,,,2,"Description
Type ""DlpDump.efi""

Input Data
",The FQDD for the PCIe SSD is displayed,,,,,
,,,,,,3,"Description
Type ""HiiDump.efi -f -d FQDD > tempFile.txt"" where FQDD is the FQDD from step 2

Input Data
","In the ""Form Set #1"" section, ""x-UEFI"" is listed as a supported language",,,,,
PCIe SSD: mdadm - Configure Hot Added Drive as a Local Hot Spare,TC-25059,Active,Manual,This test case is used to make sure that a hot inserted NVMe drive can be configured to be configures as a global hot spare for a redundant mdadm RAID array.,,1,"Description
Create a redundant mdadm RAID array (like a RAID1)

Input Data
",The array is created successfully and the background sync completes,ESG-TC-121394,,,,
,,,,,,2,"Description
Hot insert an NVMe drive into the system

Input Data
",The NVMe drive is discovered and enumerated by the device driver,,,,,
,,,,,,3,"Description
Configure the hot inserted NVMe drive to be a local hot-spare for the RAID1 array

Input Data
",The drive is successfully configured as a local hot-spare for the RAID1 array,,,,,
PCIe SSD: device power measurements,TC-26314,Active,Manual,Verify PCIe SSD power requirements meet Dell specifications.,,1,"Description
Pull the latest PCIe SSD device spec and ensure the power requirements meet the Dell requirements. Refer to the Dell RFQ or related document to confirm. Check for the following: - Max/Idle power - Main voltage - Main current - Voltage/Current aux

Input Data
",Device specs meet Dell specs.,ESG-TC-121,,,,
PCIe SSD: LVM - Configure Hot Added Drive as a Global Hot Spare,TC-26936,Active,Manual,This test case is used to make sure that a hot inserted NVMe drive can be configured to be configures as a global hot spare for a redundant LVM RAID array.,,1,"Description
Create a redundant LVM RAID array (like a RAID1)

Input Data
",The array is created successfully and the background sync completes,ESG-TC-121418,,,,
,,,,,,2,"Description
Hot insert an NVMe drive into the system

Input Data
",The NVMe drive is discovered and enumerated by the device driver,,,,,
,,,,,,3,"Description
Configure the hot inserted NVMe drive to be a global hot-spare

For example:

vgextend testvg /dev/nvme8n1


Input Data
",The drive is successfully configured as a global hot-spare,,,,,
"PCIeSSD - Hot Insertion : Using Quarch when surprised inserted, the device is available and  unavailable on surprise removal",TC-27143,Active,Manual,Verify MPS is correctly programmed with system booted with device vs. newly added device during runtime using a Quarch,,1,"Description
Boot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.

Input Data
",Implict,ESG-TC-381,,,,
,,,,,,2,"Description
Hot remove the device using Quarch.

Input Data
",Host system continues to run without freeze or hang after the device hot removed and the device is removed from the system.,,,,,
,,,,,,3,"Description
Hot insert the device using Quarch and run some I/O

Input Data
",The device is detected by the system and I/O runs fine.,,,,,
,,,,,,4,"Description
Repeat step 2 and 3 for 30 minutes

Input Data
",Result same as step 2 and 3.,,,,,
PCIe SSD ESXi - Hot-Plug of Assigned Datastore (VM On),TC-32106,Active,Manual,The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is on,,1,"Description
Create a datastore on an NVMe drive (use more than 1 if possible)

Input Data
",Datastore is successfully created,ESG-TC-115810,,,,
,,,,,,2,"Description
Assign a virtual disk from the newly created datastore to a virtual machine (1 to Windows and 1 to Linux)

Input Data
",The virtual disk is successfully assigned to the VM,,,,,
,,,,,,3,"Description
Power on the VM

Input Data
",The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive,,,,,
,,,,,,4,"Description
With the VM powered ON, remove the NVMe drive that has the datastore on it

Input Data
","The hypervisor does not crash
The VM OS does not crash
The drive is removed from lspci from the hypervisor
The drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI
The virtual disk is removed from the VM OS (you can check ""cat /proc/partitions | grep sd"" in Linux or the Disk Manager in Windows)",,,,,
PCIe SSD: in-rush protection,TC-37377,Active,Manual,Verify that a PCIe SSD device can be hot inserted into a running system and remain operational.,,1,"Description
Boot to the OS.

Input Data
",Implicit.,ESG-TC-196,,,,
,,,,,,2,"Description
Install the device under test while the OS is running.

Input Data
",Verify that the new hardware is added to the system and will configure it if the driver is available. Pull the SMART/Error log from the device.,,,,,
,,,,,,3,"Description
Verify that the hot inserted device functions properly (ie. perform some I/O)

Input Data
","The PCIe SSD device functions correctly after the hot insertion operation. The PCIe SSD default settings are unchanged. Device config space is unchanged.

SMART/Error log reports 0 errors or abnormalities.",,,,,
,,,,,,4,"Description
Repeat steps 2 and 3 at least 10 times.

Input Data
",Same results.,,,,,
,,,,,,5,"Description
Using Quarch equipment (or other automation method) to perform at least 50 cycles of a PCIe SSD hot insertion with a running system.

Input Data
",Same results.,,,,,
PCIe SSD: LVM - Rebuild Array after Surprise Removal with Local Hot Spare,TC-38886,Active,Manual,"The purpose of this test case is to make sure that after a drive is surprise removed from a redundant RAID array, that a rebuild will start with the assigned hot-spare.",,1,"Description
Create a redundant LVM RAID array (like a RAID1)

Input Data
",The array is created successfully and the background sync completes,ESG-TC-121419,,,,
,,,,,,2,"Description
Configure another NVMe drive that's not a part of the array to be a local hot-spare

Input Data
",The drive is successfully configured as a hot-spare,,,,,
,,,,,,3,"Description
Start I/O to the virtual disk

Input Data
",I/O is being handled successfully,,,,,
,,,,,,4,"Description
Surprise remove one of the NVMe drives that's a part of the redundant LVM RAID array

Input Data
","The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy.

I/O continues to be processed.",,,,,
,,,,,,5,"Description
Stop the I/O stress to allow the resync to finish quicker

Input Data
",Implicit,,,,,
PCIe SSD: Power loss during firmware update,TC-38896,Active,Manual,Verify that firmware is not corrupted upon subsequent boot when the PCIe SSD device loses power during firmware flash update.,,1,"Description
Boot to an environment supported by the firmware flash utility. With a N-1 firmware installed on device, launch firmware update. Keep updating/downgrading firmware in loop. 

Input Data
",Firmware process upgrade/downgrade starts.,ESG-TC-173,,,,
,,,,,,2,"Description
During execution, pull the AC cable out from the system.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Restore power to the system and boot the system into the OS.

Input Data
",Device is present and functional. ,,,,,
,,,,,,4,"Description
Make sure the devices are available and repeat the steps 2,3,4 10 times. 

Input Data
",Make sure that device contains the N-1 firmware as power was pulled during DUP execution.,,,,,
,,,,,,5,"Description
Make sure device is available at block layer and is accessible. 

Input Data
",Test completes successfully ,,,,,
PCIeSSD: NVMe MI - Device Discovery in idrac GUI,TC-41116,Active,Manual,NVMe MI - Device Discovery in  idrac GUI,,1,"Description
Hookup the I2C Analyzer to the System Back plane to capture the I2C traffic  
Note: D4 is the device I2C address 
As per system get the Channel  I2C mapping to slot

(This step is not mandatory - But preferred)


Input Data
",NA,ESG-TC-93537,,,,
,,,,,,2,"Description
Boot the SUT with atleast 1 NVMe SSD

Input Data
",NA,,,,,
,,,,,,3,"Description
Check the drive is inventoried in idrac.

Input Data
",Drive should be detected under storage - physical drives,,,,,
PCIe SSD: mdadm - Arrays Fail at the Right Time when Drives are Removed,TC-44160,Active,Manual,"The purpose of this test case is to make sure that RAID arrays will transition to the failed state at the right time when drives are removed.

RAID0 - Fails after 1 drive being removed.
RAID5 - Fails after 2 drives being removed.
RAID6 - Fails after 3 drives being removed.
RAID10 - Fails after 2 drives being removed.",,1,"Description
Create a 2-drive RAID0

Input Data
",The RAID0 array is created successfully,ESG-TC-121404,,,,
,,,,,,2,"Description
Surprise remove one of the drives in the RAID0 array

Input Data
",The status of the array is now failed,,,,,
,,,,,,3,"Description
Create a 3-drive RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,4,"Description
Surprise remove two of the drives in the RAID5 array

Input Data
",The status of the array is now failed,,,,,
,,,,,,5,"Description
Create a 4-drive RAID6

Input Data
","The RAID6 is created successfully, and the background resync completes",,,,,
,,,,,,6,"Description
Surprise remove three of the drives in the RAID6 array

Input Data
",The status of the array is now failed,,,,,
,,,,,,7,"Description
Create a 4-drive RAID10

Input Data
","The RAID10 is created successfully, and the background resync completes",,,,,
,,,,,,8,"Description
Surprise remove two of the drives in the RAID10 array

Input Data
",The status of the array is now failed,,,,,
PCIe SSD ESXi - Hot-Plug of Assigned Physical RDM (VM Off),TC-46577,Active,Manual,The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is off,,1,"Description
Create a physical RDM on an NVMe drive (use more than 1 if possible)

Input Data
",Physical RDM is successfully created,ESG-TC-115813,,,,
,,,,,,2,"Description
Assign a virtual disk from the newly created Physical RDM to a virtual machine

Input Data
",The virtual disk is successfully assigned to the VM,,,,,
,,,,,,3,"Description
With the VM powered OFF, remove the NVMe drive that has the Physical RDM on it

Input Data
","The OS does not crash
The drive is removed from lspci
The drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI",,,,,
,,,,,,4,"Description
Re-insert the NVMe drive that was removed

Input Data
","The device is re-enumerated in lspci
The device is listed in the Storage -> Datastores tab within the ESXi web GUI (NOTE a page refresh may be needed)",,,,,
,,,,,,5,"Description
Power on the VM

Input Data
",The virtual disks carved from the NVMe Physical RDM is detected within the VM and can successfully complete I/O (run for a minute),,,,,
PCIeSSD: 4k Sector Size Capacity Check in iDRAC,TC-49509,Active,Manual,The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.,,1,"Description
While the drive is configured in the default 512B sector size, check the iDRAC page for the drive

Input Data
","n the ""View Physical Properties"" menu, the device capacity is displayed. NOTE it down",ESG-TC-134686,,,,
,,,,,,2,"Description
Change the format of the drive to 4kB (do not enable PI, use the format with no MS).

Here's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).

Input Data
",The format completes successfully,,,,,
,,,,,,3,"Description
Go back into the iDRAC page for the newly formatted drive

Input Data
","In the ""View Physical Properties"" menu, the device capacity is displayed and matches the value originally recorded",,,,,
,,,,,,4,"Description
Don't forget to put the drive back to 512B format.

Input Data
",The format completes successfully,,,,,
PCIe SSD: mdadm - Redundant Arrays Degrade at the Right Time when Drives are Removed,TC-51958,Active,Manual,"The purpose of this test case is to make sure that redundant RAID arrays will transition to the degraded state at the right time when drives are removed.

RAID1 - Degrades after 1 drive being removed.
RAID5 - Degrades after 1 drive being removed.
RAID6 - Degrades after 2 drives being removed.
RAID10 - Degrades after 1 drive being removed.",,1,"Description
Create a 2-drive RAID1

Input Data
","The RAID1 is created successfully, and the background resync completes",ESG-TC-121396,,,,
,,,,,,2,"Description
Surprise remove one of the drives in the RAID1 array

Input Data
",The status of the array is now degraded,,,,,
,,,,,,3,"Description
Create a 3-drive RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,4,"Description
Surprise remove one of the drives in the RAID5 array

Input Data
",The status of the array is now degraded,,,,,
,,,,,,5,"Description
Create a 4-drive RAID6

Input Data
","The RAID6 is created successfully, and the background resync completes",,,,,
,,,,,,6,"Description
Surprise remove two of the drives in the RAID6 array

Input Data
",The status of the array is now degraded,,,,,
,,,,,,7,"Description
Create a 4-drive RAID10

Input Data
","The RAID10 is created successfully, and the background resync completes",,,,,
,,,,,,8,"Description
Surprise remove one of the drives in the RAID10 array

Input Data
",The status of the array is now degraded,,,,,
PCIe SSD: Generic Full Sweep Performance on Raw Drive,TC-53188,Active,Manual,TestDrive TestCase Objective was not specified.,,1,"Description
Boot to a supported Windows or Linux OS with 1 PCIe SSD installed in the system.

Input Data
",The system boots and recognizes the PCIe SSD.,ESG-TC-304,,,,
,,,,,,2,"Description
If using Windows, copy the IOMeter.exe and dynamo.exe files to the system. Else if using Linux, copy the source files to the system and run: 1. touch /usr/include/stropts.h 2. make -f Makefile-Linux.x86_64 dynamo

Input Data
",IOMeter is successfully installed on the test system.,,,,,
,,,,,,3,"Description
Ensure that the PCIe SSD to be tested is not partitioned and does not have a filesystem on it.

Input Data
",The drive is raw.,,,,,
,,,,,,4,"Description
If using Windows, double-click the IOMeter.exe file. Else if using Linux, you'll need another computer to run a Windows version of IOMeter on it. Then, you'll have to make sure that both the Linux test machine and the Windows computer are on the same network and can ping each other. The firewall on both machines will also have to be disabled ( service iptbales stop for the Linux machine). Once, this is setup, edit the /etc/hosts file on the Linux machine and add an entry for the new IP address of your Linux machine. Last, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i ""IP-Address of Windows computer"" -m ""my current IP-Address"" Then, go to the Windows computer and double-click the IOMeter.exe file.

Input Data
","IOMeter shows the system that you plan on testing underneath ""All Managers."" If Windows, it will look something like, ""WIN-...,"" else if using Linux, it will be the hostname of the machine.",,,,,
,,,,,,5,"Description
Download the .icf files that are attached to this test case and save them somewhere on the test system if using Windows, or somewhere on the Windows computer if using Linux.

Input Data
",The .icf files are copied onto the appropriate machine.,,,,,
,,,,,,6,"Description
From the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the PreCondition.icf file .

Input Data
",You see only 4 workers listed now underneath the manager of the test system.,,,,,
,,,,,,7,"Description
After expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its ""Disk Target""

Input Data
",Implicit,,,,,
,,,,,,8,"Description
For each worker, remove the ""4kRandWrite4kAlign"" access specification from the ""Access Specifications"" tab.

Input Data
","Each worker only has the ""64kSeq.."" test to run.",,,,,
,,,,,,9,"Description
Click the ""Start Tests"" green flag button and the results do not need to be saved so you can click ""Cancel"" on the pop-up screen.

Input Data
",IO starts on the PCIe SSD.,,,,,
,,,,,,10,"Description
You need to calculate the amount of time to let the test run. Select the ""Results Display"" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = (2 * C) / B

Input Data
",Number of seconds to allow the PCIe SSD to be written to twice over is calculated.,,,,,
,,,,,,11,"Description
Stop the I/O after the amount of time calulated in the step above.

Input Data
",I/O stops.,,,,,
,,,,,,12,"Description
Now remove the ""64kSeq..."" test from each workers ""Access Specifications"" tab and add the ""4kSeqWrite.."" test in its place.

Input Data
","Each worker only has the ""4kSeq.."" test to run.",,,,,
,,,,,,13,"Description
Click the ""Start Tests"" green flag button and the results do not need to be saved so you can click ""Cancel"" on the pop-up screen.

Input Data
",IO starts on the PCIe SSD.,,,,,
,,,,,,14,"Description
You need to calculate the amount of time to let the test run. Select the ""Results Display"" tab and monitor the bandwith (Total MBs per Second) metric, call it B. Then get the capacity (in MB) of the PCIe SSD that you're measuring, call it C. Then, Number of seconds to run test = C / B

Input Data
",Number of seconds to allow the PCIe SSD to be written to once is calculated.,,,,,
,,,,,,15,"Description
Stop the I/O after the amount of time calulated in the step above.

Input Data
",I/O stops.,,,,,
,,,,,,16,"Description
Close the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)

Input Data
",Implicit,,,,,
,,,,,,17,"Description
If using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i ""IP-Address of Windows computer"" -m ""my current IP-Address"" Then, go to the Windows computer and double-click the IOMeter.exe file.

Input Data
","IOMeter shows the system that you plan on testing underneath ""All Managers."" If Windows, it will look something like, ""WIN-...,"" else if using Linux, it will be the hostname of the machine.",,,,,
,,,,,,18,"Description
From the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Latency.icf file.

Input Data
",You see only 1 worker listed now underneath the manager of the test system.,,,,,
,,,,,,19,"Description
After expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its ""Disk Target""

Input Data
",Implicit,,,,,
,,,,,,20,"Description
Click the ""Start Tests"" green flag and make sure to save the results this time.

Input Data
",I/O starts and the output is saved to a .csv file.,,,,,
,,,,,,21,"Description
Once the ""Latency"" test is done, close the IOMeter window (this needs to be done due to a bug with opening multiple .icf files)

Input Data
",Implicit,,,,,
,,,,,,22,"Description
If using Windows, double-click the IOMeter.exe file. Else if using Linux, go into the directory with the IOMeter source files on the Linux machine and run: ./dynamo -i ""IP-Address of Windows computer"" -m ""my current IP-Address"" Then, go to the Windows computer and double-click the IOMeter.exe file.

Input Data
","IOMeter shows the system that you plan on testing underneath ""All Managers."" If Windows, it will look something like, ""WIN-...,"" else if using Linux, it will be the hostname of the machine.",,,,,
,,,,,,23,"Description
From the IOMeter window, click the Open button and navigate to the location of where the .icf files are. Select and open the Run4kA.icf file.

Input Data
",You see only 4 workers listed now underneath the manager of the test system.,,,,,
,,,,,,24,"Description
After expanding the manager of the test system, select each worker and assign the PCIe SSD drive as its ""Disk Target""

Input Data
",Implicit,,,,,
,,,,,,25,"Description
Click the ""Start Tests"" green flag and make sure to save the results this time.

Input Data
",I/O starts and the output is saved to a .csv file.,,,,,
,,,,,,26,"Description
Both of the results files should be analyzed.

Input Data
",,,,,,
PCIe SSD: LVM - Arrays Fail at the Right Time when Drives are Removed,TC-53686,Active,Manual,"The purpose of this test case is to make sure that RAID arrays will transition to the failed state at the right time when drives are removed.

RAID0 - Fails after 1 drive being removed.
RAID5 - Fails after 2 drives being removed.
RAID6 - Fails after 3 drives being removed.
RAID10 - Fails after 2 drives being removed.",,1,"Description
Make sure that the ""raid_fault_policy"" setting in /etc/lvm.conf is set to ""warn""

Input Data
",Implicit,ESG-TC-121421,,,,
,,,,,,2,"Description
Create a 2-drive RAID0

Input Data
",The RAID0 array is created successfully,,,,,
,,,,,,3,"Description
Surprise remove one of the drives in the RAID0 array

Input Data
",The status of the array may not fail until I/O has started,,,,,
,,,,,,4,"Description
Start I/O

Input Data
",The I/O fails and the status of the array is now failed,,,,,
,,,,,,5,"Description
Create a 3-drive RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,6,"Description
Surprise remove two of the drives in the RAID5 array

Input Data
",The status of the array may not fail until I/O has started,,,,,
,,,,,,7,"Description
Start I/O

Input Data
",The I/O fails and the status of the array is now failed,,,,,
,,,,,,8,"Description
Create a 4-drive RAID6

Input Data
","The RAID6 is created successfully, and the background resync completes",,,,,
,,,,,,9,"Description
Surprise remove three of the drives in the RAID6 array

Input Data
",The status of the array may not fail until I/O has started,,,,,
,,,,,,10,"Description
Start I/O

Input Data
",The I/O fails and the status of the array is now failed,,,,,
,,,,,,11,"Description
Create a 4-drive RAID10

Input Data
","The RAID10 is created successfully, and the background resync completes",,,,,
,,,,,,12,"Description
Surprise remove two of the drives in the RAID10 array

Input Data
",The status of the array may not fail until I/O has started,,,,,
,,,,,,13,"Description
Start I/O

Input Data
",The I/O fails and the status of the array is now failed,,,,,
PCIe SSD: NVMe shutdown notification,TC-53701,Active,Manual,Verify NVMe PCIe SSD goes through the expected shutdown sequence during a graceful or ungraceful shutdown.,,1,"Description
Verify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-356,,,,
,,,,,,2,"Description
Install at least one NVMe PCIe SSD in the system.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Setup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD shutdown sequence.

Input Data
",Implicit.,,,,,
,,,,,,4,"Description
Boot to the OS and once drive handle is created start capturing the trace. Press power button gently once and allow system to reboot. 

Input Data
",The system starts rebooting and trace capture is in progress. ,,,,,
,,,,,,5,"Description
Once the boot starts again stop the trace capture. 

Input Data
",PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete,,,,,
,,,,,,6,"Description
Repeat step 4-5 but instead of using power button , issue Shutdown of the system from OS it self. 

Input Data
",Same as above steps,,,,,
,,,,,,7,"Description
Once in the OS start capturing the trace again.
AC power off the system (pull AC power cable).


Input Data
",The trace capture is in progress and system starts rebooting. ,,,,,
,,,,,,8,"Description
Once the boot process starts stop the trace capture. 

Input Data
",PCIe trace shows CC.SHN = 10b to indicate abrupt shutdown operation PCIe trace shows CC.SHST = 10b to indicate shutdown is complete,,,,,
PCIe SSD - OMSS Report Multiple Surprise Insertions,TC-54468,Active,Manual,Validate that OMSS successfully handles reporting multiple surprise insertions,,1,"Description
Boot into the OS

Input Data
",Implicit,ESG-TC-124,,,,
,,,,,,2,"Description
Install OMSS version known to support PCIe SSD reporting and discover

Input Data
",OMSS installed,,,,,
,,,,,,3,"Description
Launch OMSS and navigate to PCIe SSD storage subsystem

Input Data
","-User is able to navigate OMSS Menu

-PCIe SSD Subsystem is clearly called out and selectable as a target link",,,,,
,,,,,,4,"Description
Keep expanding the PCIe SSD subsystem tree until the physical disk menu is displayed

Input Data
","-Tree expands

-No physical disks listed as none should be installed at this point",,,,,
,,,,,,5,"Description
Surprise insert 2 drive2 into the two lowest enumerated slots on the chassis face known to support PCIeSSD drives

Input Data
","-Both drives detected

-Surprise insertion events detected by the OS and driver loaded

-LED illuminted and indicates ready (steady Green)

-Slot number is accurate to where the drive is installed

-Physical Drive Properties page updated by OMSS and accurately reflects the following:

--Physical Disk with slot number

--State of the drive

--Drop Down task menu

--Protocol Type

--Firmware Revision

--Predictive Failure status",,,,,
,,,,,,6,"Description
Run some I/O to the drives to verify it is functional. Stop I/O after 30 seconds.

Input Data
",-Drives responds to I/O requests without issue,,,,,
,,,,,,7,"Description
Do a ""Prepare for Removal"" on the drive on the drive in the lowest slot

Input Data
","-Drive removed, OS still functional, OMSS still functional and responsive",,,,,
,,,,,,8,"Description
Do a ""Prepare for Removal"" on the second drive

Input Data
",Same result as steps 6,,,,,
,,,,,,9,"Description
Perform steps 5 through 7 on any slots not used in the previous steps, i.e. if drives were surprised inserted into slots 0 and 1 in step 5, surprise insert the two drives into slots 2 and 3 (if the platform supports that quantity of slots)

Input Data
","-Same result as steps 5 and 7

-Slot accurately reflects where the drive was inserted",,,,,
PCIe SSD - Factory WinPE - NVMe driver,TC-55211,Active,Manual,To validate compatibility of NVMe PCIe SSD in WinPE environment. To confirm correct NVMe driver is installed and loaded as part of the FICore image.,,1,"Description
Install at least one NVMe PCIe SSD in the system

Input Data
",Implicit,ESG-TC-53,,,,
,,,,,,2,"Description
Pull the latest FICore image and boot to it.

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Verify the correct NVMe driver is installed and loaded (please note that this may not necessarily be an Arev driver, depending on when the FICore image was created and/or pulled down). Ensure to pull the latest FICore image available. To do this, you may need to (1) navigate to the Windows\System32\drivers directory, (2) confirm nvme.sys driver file is present, (3) copy this file to check its properties

Input Data
","NVMe driver is installed and loaded.


If testing with FICore image after NVMe drivers have been Arev, the NVMe driver that is installed must be the Arev driver.",,,,,
,,,,,,4,"Description
Run some I/O to the NVMe PCIe SSD.

Input Data
",I/O runs successfully.,,,,,
PCIe SSD: Hot insert: AER mask register is configured/restored on hot insertion using Quarch,TC-55616,Active,Manual,Verify that AER mask register for a PCIe SSD device is configured/restored on hot insertion per system BIOS defaults,,1,"Description
Boot to the OS with a drive installed in the system.

Input Data
",Implicit.,ESG-TC-115,,,,
,,,,,,2,"Description
Capture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register

Input Data
",Implict,,,,,
,,,,,,3,"Description
Surprise remove the drive from the system using Quarch

Input Data
",The system is functional. No error/ fatal error is reported.,,,,,
,,,,,,4,"Description
Using Quarch Hot Insert the drive that was removed in step 4 back into the system

Input Data
",The device is recognized by the OS and functional,,,,,
,,,,,,5,"Description
Capture the following PCIe registers values: Uncorrectale Error Mask Register Correctale Error Mask Register uncorrectable Error severity register

Input Data
",The values of the registers are the same as when they were captured in step 2,,,,,
PCIe SSD: Linux Filesystem Integrity after Sync Followed by Hot-Plug,TC-57395,Active,Manual,"The purpose of this test case is to make sure that the data on the various Linux filesystems remains in-tact after being sync-ed, surprise removed (while still mounted), then re-inserted.",,1,"Description
Create a single partition on each NVMe drive in the system

Input Data
",The partitions are successfully created,ESG-TC-121424,,,,
,,,,,,2,"Description
Format each of the partitions on the NVMe drives to have one of the following filesystems:
ext3
ext4
xfs
btrfs <- ONLY for SLES


Input Data
",The filesystems are successfully created,,,,,
,,,,,,3,"Description
Mount the filesystems

Input Data
",Mounts are successful,,,,,
,,,,,,4,"Description
Put some data files on each of the filesystems and create a checksum

Input Data
",Data is successfully written and checksums are calculated,,,,,
,,,,,,5,"Description
Call ""sync -f"" on each filesystem

Input Data
",The sync completes successfully,,,,,
,,,,,,6,"Description
With the filesystem still mounted surprise remove each NVMe drive

Input Data
","The device driver no longer enumerates the removed NVMe drives
NOTE that stale mount points will likely still exist",,,,,
,,,,,,7,"Description
Re-Insert each NVMe drive back into the system

Input Data
",The device driver enumerates all drives,,,,,
,,,,,,8,"Description
Mount each of the filesystems

Input Data
",Filesystems successfully mount,,,,,
,,,,,,9,"Description
Check the filesystems with fsck

Input Data
",The filesystem check doesn't report any errors,,,,,
,,,,,,10,"Description
Re-calculate the checksums for each filesystem

Input Data
",The checksums match that of the original values calculated before the previous unmount,,,,,
PCIeSSD: NVMe MI - Hotplug and check the MTU size set by the idrac,TC-63095,Active,Manual,PCIeSSD: NVMe MI - Check the MTU size set by the idrac,,1,"Description
Optional: Not Necessary
Hookup the I2C Analyzer to the System Back plane to capture the I2C traffic  
Note: D4 is the device I2C address 
As per system get the Channel  I2C mapping to slot


Input Data
",NA,ESG-TC-93570,,,,
,,,,,,2,"Description
After the system is booted without any PCIe SSD.  Hot plug a drive using quarch . 

Input Data
",Device is recognized normally,,,,,
,,,,,,3,"Description
Check the Configuration get command for the MCTP Transmission Unit Size.

Input Data
", MTU should be at least 0x78 (120d),,,,,
PCIe SSD BOOT: LC OS Install using LVM or OS RAID with mix of FF and types,TC-63576,Active,Manual,"Verify that the LifecyleController OS Deployment process will correctly install an OS to a PCIe SSD and the customer uses a fault tolerant configuration such as LVM or native raid OS.Also verify that the device boots normally and after a cold-swap of the devices, that it and any additional devices operate correctly, and that the system will survive a failure of one of the fault tolerant devices while running.",,1,"Description
Install various PCIe SSDs in the system of different form factors and flash types (ie. 2.5"", HHHL).

Input Data
",System is correctly configured.,ESG-TC-372,,,,
,,,,,,2,"Description
Install the latest LC OS Driver Pack using the DUP with either LC Firmware Upgrade, remote iDrac firmware upgrade, or from an already installed OS.

Input Data
",DUP installs successfully.,,,,,
,,,,,,3,"Description
Install at least two PCIe SSDs in the system

Input Data
",Status LED goes to solid on to indicate PCIe SSD is online and ready.,,,,,
,,,,,,4,"Description
Configure the BIOS Setup boot mode to UEFI (default mode). (no legacy mode)

Input Data
",Setting saved successfully.,,,,,
,,,,,,5,"Description
If necessary, attach a DVD drive to the system.

Input Data
",Implicit,,,,,
,,,,,,6,"Description
Insert OS installation media into the DVD drive.

Input Data
",Installation media is detected.,,,,,
,,,,,,7,"Description
Launch LC ""OS Deployment"", click ""Deploy OS"", select ""Go Directly to OS Deployment"", click ""Next"" and proceed to install the OS to the PCIe SSD. Ensure that the PCIe SSDs (mix of FF or types) are configured in a fault tolerant configuration such as LVM or native OS raid. This may need to be delayed until step 7. Record the configuration used in the test results Overall Notes.

Input Data
","Installation process is successful.

Fault tolerant configuration successful (if done at this step).

Configuration used recorded.",,,,,
,,,,,,8,"Description
Boot to the OS and perform simple IO to all devices. Check logs for errors. If not possible in step 6, configure the devices into a fault tolerant configuration, for example, but using the native OS raid function to mirror the 2 PCIe-SSD's to turn the single boot PCIe-SSD into a mirroed bootable set of drives.

Input Data
","No errors reported in logs.

Fault tolerant configuration successful (if done at this step).",,,,,
,,,,,,9,"Description
Reboot and ensure the OS is still bootable. check logs for errors.

Input Data
",No errors reported in logs.,,,,,
,,,,,,10,"Description
Power down system. Power back up and ensure OS boots. check logs.

Input Data
",No errors reported in logs.,,,,,
,,,,,,11,"Description
Power down system. With power off, swap the devices. Power back up and ensure OS boots. check logs.

Input Data
",No errors reported in logs.,,,,,
,,,,,,12,"Description
Surprise remove one of the devices (will need to select a 2.5"" FF to be SR).

Input Data
",OS continues to run. Expected information is logged in the system logs.,,,,,
,,,,,,13,"Description
reboot. Check logs for errors.

Input Data
","Degraded condition of the boot device is reported as expected, but no other errors are reported in logs.",,,,,
PCIe SSD ESXi - Hot-Plug of Assigned Physical RDM (VM On),TC-65708,Active,Manual,The purpose of this test case is to validate the hot-plug functionality when the NVMe drive is assigned to a VM that is on,,1,"Description
Create a Physical RDM on an NVMe drive (use more than 1 if possible)

Input Data
",Physical RDM is successfully created,ESG-TC-115814,,,,
,,,,,,2,"Description
Assign a virtual disk from the newly created physical RDM to a virtual machine (1 to Windows and 1 to Linux)

Input Data
",The virtual disk is successfully assigned to the VM,,,,,
,,,,,,3,"Description
Power on the VM

Input Data
",The VM successfully detects the virtual disk and can run 1 minute of I/O to the drive,,,,,
,,,,,,4,"Description
With the VM powered ON, remove the NVMe drive that has the physical RDM on it

Input Data
","The hypervisor does not crash
The VM OS does not crash
The drive is removed from lspci from the hypervisor
The drive is removed (or is greyed communicating something intelligent about the drive no longer being present) from Storage -> Datastores tab within the ESXI web GUI
The virtual disk is removed from the VM OS (you can check ""cat /proc/partitions | grep sd"" in Linux or the Disk Manager in Windows)",,,,,
PCIeSSD Virtualization - device in fault state,TC-66176,Active,Manual,Verify PCIe SSD VMware driver handles and manages devices in fault state.,,1,"Description
Install at least one PCIe SSD in the system and boot to the OS. Ensure the device driver is installed for PCIe SSD.

Input Data
",Implicit.,ESG-TC-110315,,,,
,,,,,,2,"Description
If needed, cause the PCIeSSD to enter in a fault state (test all possible fault conditions if enabled, otherwise at least cover Read-Only and Security Locked State modes).

Talk to the program lead for getting a device in Read-Only mode.

Input Data
",PCIe SSD enters in fault mode.,,,,,
,,,,,,3,"Description
Verify the driver detects the PCIe SSD in fault state. ie. an entry is added to the OS system log during PCIeSSD discovery indicating the device is in some fault state.

Input Data
",System continues to function without issues. The system log shows device in a fault state (and there is no flooding of messages).,,,,,
,,,,,,4,"Description
Attempt to create a datastore on the fault device.

Input Data
",Operation fails gracefully. Entries may be added in the OS system log indicating such.,,,,,
,,,,,,5,"Description
Attempt to configure PCIe SSD as passthrough, add it to a VM and boot to it. If not already done so, install the device driver.

Input Data
","Device can be configured as a passthrough device with no issues. Device driver installs and/or loads successfully. Any host I/Os to the device fail gracefully. System continues to function correctly.




If the device is in read-only, only writes fail to the device.",,,,,
,,,,,,6,"Description
If possible, save some data onto the PCIe SSD and get the PCIe SSD to transition to read only mode during runtime.

Input Data
",PCIe SSD goes from Ready to Read Only. Data is still accessible in the device. System continues to function without issues. Unable to write further data to the device.,,,,,
PCIe SSD: LVM - Add a Hot-Inserted Drive to an Existing Array,TC-72252,Active,Manual,The purpose of this test case is to make sure that a newly hot inserted device can be added to an existing RAID array.,,1,"Description
Create a RAID1

Input Data
",The RAID1 array is successfully created,ESG-TC-121422,,,,
,,,,,,2,"Description
Hot insert a new NVMe drive into the system

Input Data
",It is successfully discovered by the device driver,,,,,
,,,,,,3,"Description

Add the hot inserted drive to be a part of the RAID1


For example:
vgextend vgname /dev/nvmeXnX

lvconvert -m 2 vgname/lvname /dev/nvmeXnX



Input Data
","The hot added drive is now successfully a part of the RAID1

You can use:
lvs -a -o name,raid_sync_action,copy_percent,devices vgname",,,,,
,,,,,,4,"Description
Create a RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,5,"Description
Hot insert a new NVMe drive into the system

Input Data
",It is successfully discovered by the device driver,,,,,
,,,,,,6,"Description
Add the hot inserted drive to be a part of the RAID5

Input Data
",The hot added drive is now successfully a part of the RAID5 and resyncs,,,,,
PCIe SSD: Pre-OS hot remove [negative test],TC-78048,Active,Manual,Verify that a drive removed during boot does not cause system errors and OS is able to load successfully.,,1,"Description
Install the device under test.

Input Data
",Implicit.,ESG-TC-202,,,,
,,,,,,2,"Description
Boot the system and hot remove the device before the OS starts to load.

Input Data
",Device is removed. No errors are reported. System continues to boot.,,,,,
,,,,,,3,"Description
Boot to the OS.

Input Data
","System boots successfully.

No fatal system side effects occur.",,,,,
,,,,,,4,"Description
Verify the OS loads properly and there are no errors in the event log.

Input Data
","There are no errors in the windows event log or the SEL. The OS is fully functional.

No fatal system side effects occur.",,,,,
,,,,,,5,"Description
Re-insert the previously hot removed device and verify it is still functional.

Input Data
",Device is fully functional.,,,,,
PCIeSSD - PLX Capella 2 Switch ACS P2P Redirection Caution 1.13 Safety Bit Workaround,TC-80474,Active,Manual,This test case is used to confirm that bit 21 of offset 0x760 (station ports) is set to avoid Caution 1.13.,,1,"Description
Boot into a system with one or more Capella 2 PCIe switches

Input Data
",All switches are detected,ESG-TC-110043,,,,
,,,,,,2,"Description
Identify each PCIe switch's upstream BAR0 register by reading PCIe Cfg Space (offset 0x13-0x10)

Input Data
",All Memory addresses are captured and saved,,,,,
,,,,,,3,"Description
Identify all of the downstream station ports for each switch (*typically a multiple of 4: e.g. 0, 4, 8, etc.)

Input Data
",All Downstream Switch ports identified for each Capella 2 switch,,,,,
,,,,,,4,"Description
Read 32 bits of memory using the following formula:
BAR0 + (StationPortDeviceNumber * 0x1000) + 0x760

Do this for each port identified in the step above


Input Data
",Bit 21 should be set,,,,,
PCIe SSD ESXi - Hot-Plug of Unassigned Physical RDM,TC-82475,Active,Manual,"This test is intended to check if NVMe hot-plug works when there's a Physical RDM on the drive being hot-plugged, yet the drive is not assigned to any VM.",,1,"Description
Create a physical RDM on an NVMe drive

Input Data
",The physical RDM is successfully created,ESG-TC-115811,,,,
,,,,,,2,"Description
Without assigning the RDM to any VM, surprise remove the NVMe drive

Input Data
","The removed drive is no longer enumerated on the PCIe bus
The drive no longer shows up in the ESXi web GUI Storage->Datastores view",,,,,
,,,,,,3,"Description
Re-insert the same NVMe drive back into the system

Input Data
","The drive shows up on the PCIe bus
The drive shows back up in the ESXi web GUI Storage -> Datastores view",,,,,
PCIeSSD: 4k Sector Size Capacity Check in OMSA,TC-83980,Active,Manual,The purpose of this test case is to ensure that the drive capacity shows correctly no matter how the drive is formatted.,,1,"Description
While the drive is configured in the default 512B sector size, launch OMSS

Input Data
","In the ""View Physical Properties"" menu, the device capacity is displayed. NOTE it down",ESG-TC-134685,,,,
,,,,,,2,"Description
Change the format of the drive to 4kB (do not enable PI, use the format with no MS).

Here's a (possibly incomplete) list of tools which can re-format the drive: nvme-cli and NVMeIOCTLCLI (both in Linux).

Input Data
",The format completes successfully,,,,,
,,,,,,3,"Description
Go back into the OMSA page for the newly formatted drive

Input Data
","In the ""View Physical Properties"" menu, the device capacity is displayed and matches the value originally recorded",,,,,
,,,,,,4,"Description
Don't forget to put the drive back to 512B format.

Input Data
",The format completes successfully,,,,,
PCIe SSD: Surprise Hot removal / Insertion of a device doesn't alter ongoing activity of other devices  sharing the same device driver,TC-85996,Active,Manual,Verify that Hot removal of a device doesn't alter ongoing activity of other devices sharing the same device driver.,,1,"Description
Install at least two devices under test.

Input Data
",Implicit,ESG-TC-201,,,,
,,,,,,2,"Description
Boot to the OS and load the driver for the device.

Input Data
",The OS load successfully.,,,,,
,,,,,,3,"Description
Perform some simple I/O operations on one of the drive.

Input Data
",Drive is fully functional and no errors are reported from I/O activity.,,,,,
,,,,,,4,"Description
Pull the other device out in which I/O is not running. Check if I/O on the other drive is still running

Input Data
","Events are generated as a result of a Surprise Removal (ie. windows event log, linux dmesg, etc). The hardware disappeared from the system, there are no fatal system errors (eg. blue screen, kernel panic), the system continues to be functional.


Hot removal of a device doesn't alter ongoing activity of other devices",,,,,
,,,,,,5,"Description
Re-insert device and allow FTL rebuild to complete. check if I/O is running on the other drive is still running

Input Data
","Events are generated as a result of a insertion and device is properly detected. Once FTL table rebuild completes, volume is available for use in operating system.

I/O starts and runs successfully.


No fatal system errors (eg. blue screen, kernel panic) are encountered and the system continues to be functional.",,,,,
,,,,,,6,"Description
Repeat steps 3-5 again.

Input Data
",Results are the same for the 2nd attempt.,,,,,
PCIeSSD (exploratory performance): Validation of PCIe SSD Theoretical WriteBandwidth Limits,TC-86097,Active,Manual,"Validate that the PCIe SSD devices are capable of capping at theoretical PCIe limits. This is an experimentation based test to explore the capabilities of the drive and that the drive is capable of performing accross multiple block transfer sizes, and queue depths.",,1,"Description
Install a single PCIe SSD drive and boot to Windows

Input Data
",implicit,ESG-TC-305,,,,
,,,,,,2,"Description
Configure performance monitor to display the PCIe SSD under test MB/s

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Use IOMeter to generate I/O for maximum write MB/s. Start I/O with 64k block transfers and queue depth of 256. Increase the queue depth as needed to reach peak throughput. If performance already seems to be near theoretical max, reduce queue depth until lane the x4 port no longer saturates. Allow I/O to run for 5 minutes before checking MB/s.

Input Data
","Compare against PCIe theoretical limits.


For example, Gen 2 theoretical max throughput for a x4 PCIe SSD is approximately 2 GB/s minus overhead for protocol and 8b/10b encoding which is generally around 20%.",,,,,
,,,,,,4,"Description
Reduce the block transfer size from step 2 by half. Attempt to saturate link with queue depth 256. Raise or lower queue depth as needed to saturate the link. -Keep reducing block transfer size by half and adjusting queue depth as needed to achieve max performance and iterate until block transfer size is 512 bytes -Allow each for 5 minutes of run time prior to noting MB/s

Input Data
","-Eventually, protocol overhead will prohibit the device from saturating the PCIe link. Record this block transfer size in the test results. Validate with vendor that this is the expected result for saturation cutoff.",,,,,
,,,,,,5,"Description
PRECONDITION (precondition.icf) the PCIe SSD(s): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput – runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set – just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.

Input Data
",PCIe SSD(s) preconditioned.,,,,,
,,,,,,6,"Description
Repeat step 3

Input Data
","Observe and record the throughput value observed. This value gives the steady state performance of the device when having to manage the reclamation of erase blocks. Micron reports this to be approximately 600 MB/s. Write defect if less than this value.


For reference on expected performance, use Dell's RFQ or similar document.",,,,,
PCIe SSD ESXi - Hot-Plug of Unassigned Datastore,TC-87292,Active,Manual,"This test is intended to check if NVMe hot-plug works when there's a VMFS datastore on the drive being hot-plugged, yet the drive is not assigned to any VM.",,1,"Description
Create a datastore on an NVMe drive

Input Data
",The datastore is successfully created,ESG-TC-115744,,,,
,,,,,,2,"Description
Without assigning the datastore to any VM, surprise remove the NVMe drive

Input Data
","The removed drive is no longer enumerated on the PCIe bus
The drive no longer shows up in the ESXi web GUI Storage->Datastores view",,,,,
,,,,,,3,"Description
Re-insert the same NVMe drive back into the system

Input Data
","The drive shows up on the PCIe bus
The drive shows back up in the ESXi web GUI Storage -> Datastores view",,,,,
PCIe SSD: LVM - Redundant Arrays Degrade at the Right Time when Drives are Removed,TC-88770,Active,Manual,"The purpose of this test case is to make sure that redundant RAID arrays will transition to the degraded state at the right time when drives are removed.

RAID1 - Degrades after 1 drive being removed.
RAID5 - Degrades after 1 drive being removed.
RAID6 - Degrades after 2 drives being removed.
RAID10 - Degrades after 1 drive being removed.",,1,"Description
Make sure that the ""raid_fault_policy"" setting in /etc/lvm.conf is set to ""warn""

Input Data
",Implicit,ESG-TC-121420,,,,
,,,,,,2,"Description
Create a 2-drive RAID1

Input Data
","The RAID1 is created successfully, and the background resync completes",,,,,
,,,,,,3,"Description
Surprise remove one of the drives in the RAID1 array

Input Data
",The status of the array may not degraded until I/O is started,,,,,
,,,,,,4,"Description
Start I/O

Input Data
","The I/O is successful, but the status of the array is now degraded",,,,,
,,,,,,5,"Description
Stop I/O

Input Data
",Implicit,,,,,
,,,,,,6,"Description
Create a 3-drive RAID5

Input Data
","The RAID5 is created successfully, and the background resync completes",,,,,
,,,,,,7,"Description
Surprise remove one of the drives in the RAID5 array

Input Data
",The status of the array may not degraded until I/O is started,,,,,
,,,,,,8,"Description
Start I/O

Input Data
","The I/O is successful, but the status of the array is now degraded",,,,,
,,,,,,9,"Description
Stop I/O

Input Data
",Implicit,,,,,
,,,,,,10,"Description
Create a 5-drive RAID6.  LVM requires at least 5 drives for RAID 6


Input Data
","The RAID6 is created successfully, and the background resync completes",,,,,
,,,,,,11,"Description
Surprise remove two of the drives in the RAID6 array

Input Data
",The status of the array may not degraded until I/O is started,,,,,
,,,,,,12,"Description
Start I/O

Input Data
","The I/O is successful, but the status of the array is now degraded",,,,,
,,,,,,13,"Description
Stop I/O

Input Data
",Implicit,,,,,
,,,,,,14,"Description
Create a 4-drive RAID10

Input Data
","The RAID10 is created successfully, and the background resync completes",,,,,
,,,,,,15,"Description
Surprise remove one of the drives in the RAID10 array

Input Data
",The status of the array may not degraded until I/O is started,,,,,
,,,,,,16,"Description
Start I/O

Input Data
","The I/O is successful, but the status of the array is now degraded",,,,,
,,,,,,17,"Description
Stop I/O

Input Data
",Implicit,,,,,
PCIeSSD (exploratory performance) - OS RAID Performance Analysis,TC-88996,Active,Manual,Validate that PCIe SSD drives can be used for OS RAIDs without crippling the subsystems performance.,,1,"Description
Install 4 PCIe SSD drives and boot to the OS

Input Data
",implicit,ESG-TC-275,,,,
,,,,,,2,"Description
Secure Erase the drives

Input Data
",-Data erased from the drives,,,,,
,,,,,,3,"Description
PRECONDITION (precondition.icf): The preconditioning .icf calls out for two workloads - 64KSeqWrite (4K aligned) and 4KRandWrite (4K aligned). Four workers with 4 outstanding IOs for each. All you need to do is set the runtime length under the test setup tab to run each workload for the amount of time it takes to fill the drive twice. For the precondition, runtime will need to be set manually based on throughput – runtime duration should be based on 2x fill of capacity for each profile. Single QD duration, and workload already set – just assign worker to non-partitioned volume and start. Multi-QD.icfs will automatically increase QD, but will need to assign each worker (4 total) to non-partitioned volume of test device before start.

Input Data
",-drives preconditioned,,,,,
,,,,,,4,"Description
Configure the drives into a 4 drive RAID 0

Input Data
",RAID configured,,,,,
,,,,,,5,"Description
Run the comprehensive performance IOMeter test against the RAID 0. Save IOMeter output and label as 4 drive RAID 0 data

Input Data
",I/O executes without error,,,,,
,,,,,,6,"Description
Delete the RAID 0 and configure a single worker/thread to run the conprehensive performance IOMeter suite against the 4 raw PCIe SSD devices. Save IOMeter output and label as 4 drive non-RAID data

Input Data
","-RAID deleted

-Data saved",,,,,
,,,,,,7,"Description
Compare results from both runs

Input Data
","-OS RAID data set is within at least 10% of the non-raid data

-no major ""sore spots"" in either data sets where performance does not scale with workload",,,,,
PCIe SSD - Operating Systems - Full Filesystem (Negative),TC-89055,Active,Manual,"The purpose of this test case is to make sure that files can be read on a full filesystem, but not written.",,1,"Description
Boot into a supported OS with at least one PCIe SSD in the system

Input Data
",The OS detects and loads the driver for the device,ESG-TC-376,,,,
,,,,,,2,"Description
Partition and format the PCIe SSD

Input Data
",The partition and filesystem is successfully applied,,,,,
,,,,,,3,"Description
Fill the entire filesystem with file(s) One way to do this in Windows is to use the ""Make-A-File"" aplpication, or using a combination of ""touch"" and ""dd"" in Linux

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Attempt to create a new file on the full filesystem

Input Data
",The file is not allowed to be created,,,,,
,,,,,,5,"Description
Attempt to copy a file from another location to the full filesystem

Input Data
",The file is not allowed to be copied,,,,,
,,,,,,6,"Description
Copy a file from the full filesystem to another location

Input Data
",The file is successsfully copied,,,,,
PCIe SSD: mdadm - Rebuild Array after Surprise Removal with Local Hot Spare,TC-89814,Active,Manual,"The purpose of this test case is to make sure that after a drive is surprise removed from a redundant RAID array, that a rebuild will start with the assigned hot-spare.",,1,"Description
Create a redundant mdadm RAID array (like a RAID1)

Input Data
",The array is created successfully and the background sync completes,ESG-TC-121395,,,,
,,,,,,2,"Description
Configure another NVMe drive that's not a part of the array to be a local hot-spare

Input Data
",The drive is successfully configured as a hot-spare,,,,,
,,,,,,3,"Description
Surprise remove one of the NVMe drives that's a part of the redundant mdadm RAID array

Input Data
",The status of the array now displays as it's currently resyncing with the local spare. Eventually the resync completes and the status shows as healthy.,,,,,
PCIe SSD - Operating Systems - Transition to Temperature Threshold Exceeded,TC-91348,Active,Manual,The purpose of this test case is to ensure that the PCIe SSD will throttle I/O performance to allow for cooling of the device.,,1,"Description
Boot into a supported OS with at least one PCIe SSD

Input Data
",The OS detects the device and loads the driver,ESG-TC-340,,,,
,,,,,,2,"Description
Begin running I/O to the device where you can monitor performance (e.g. IOMeter, fio, or use a normal I/O tool with Perfmon)

Input Data
",I/O continues to run successfully. There are no I/O errors or data miscompares,,,,,
,,,,,,3,"Description
While I/O is running, cause the device to enter the temperature exceeded threshold state

Input Data
",The performance of the I/O drops off to allow for cooling. There are no I/O errors or data miscompares,,,,,
PCIe SSD: Linux Filesystem Integrity after Unmount Followed by Hot-Plug,TC-91646,Active,Manual,"The purpose of this test case is to make sure that the data on the various Linux filesystems remains in-tact after being unmounted, surprise removed, then re-inserted.",,1,"Description
Create a single partition on each NVMe drive in the system

Input Data
",The partitions are successfully created,ESG-TC-121423,,,,
,,,,,,2,"Description
Format each of the partitions on the NVMe drives to have one of the following filesystems:
ext3
ext4
xfs
btrfs <- ONLY for SLES


Input Data
",The filesystems are successfully created,,,,,
,,,,,,3,"Description
Mount the filesystems

Input Data
",Mounts are successful,,,,,
,,,,,,4,"Description
Put some data files on each of the filesystems and create a checksum

Input Data
",Data is successfully written and checksums are calculated,,,,,
,,,,,,5,"Description
Unmount each filesystem

Input Data
",Unmounts are successful,,,,,
,,,,,,6,"Description
Surprise remove each NVMe drive

Input Data
",The device driver no longer enumerates the removed NVMe drives,,,,,
,,,,,,7,"Description
Re-Insert each NVMe drive back into the system

Input Data
",The device driver enumerates all drives,,,,,
,,,,,,8,"Description
Mount each of the filesystems

Input Data
",Filesystems successfully mount,,,,,
,,,,,,9,"Description
Check the filesystems with fsck

Input Data
",The filesystem check doesn't report any errors,,,,,
,,,,,,10,"Description
Re-calculate the checksums for each filesystem

Input Data
",The checksums match that of the original values calculated before the previous unmount,,,,,
Validate hot removal functionality on Vmware running with datastore devices mapped to a VM.,TC-93321,Active,Manual,Validate hot removal functionality on Vmware running with datastore devices mapped to a VM.,,1,"Description
Install one or more PCIe SSDs in the host system and load appropriate ESXi host
driver.&nbsp; 


Input Data
","
Implicit",ESG-TC-74963,,,,
,,,,,,2,"Description
Create a datastore on the PCIeSSD and add it to a Windows VM. Install a supported guest OS on the VM. 


Input Data
","
PCIe SSD
datastore added to guest VM.",,,,,
,,,,,,3,"Description
Launch the VM and run I/O to the PCIe SSD datastore.&nbsp; 


Input Data
","
I/O runs without
any issues. ",,,,,
,,,,,,4,"Description
Stop I/O, and wait (idle) for about 10 seconds. Hot remove the PCIe SSD. 


Input Data
","
Guest OS
continues to run without issues. I/O can be run to other devices in the
system through the guest OS. If any access attempt is done to the dev node
associated to the removed PCIe SSD (including fdisk), the command times out
and the kernel prints out a stack dump after some predetermined time. The
host kernel log (vmkernel.log) shows a series of timeout and error messages
related to the removed PCIe SSD but continues to run ok. The guest OS may not
be able to be rebooted if the PCIe SSD remains removed from the system. A
host reboot may be required for the system to become functional/responsive
again.",,,,,
,,,,,,5,"Description
If running, shutdown the VM. 


Input Data
","
Implicit.",,,,,
,,,,,,6,"Description
Re-insert the removed PCIe SSD into the host system. 


Input Data
","
Host system
continues to run without freeze or hang. The guest OS may not be able to be
restarted until the PCIe SSD datastore is recognized by the host. (A host
reboot may be required for the system accept the datastore and become
functional/responsive to the guest OS.)",,,,,
,,,,,,7,"Description
Launch the VM, and run some I/O to the PCIe SSD datastore. 


Input Data
","
I/O runs
successfully.",,,,,
,,,,,,8,"Description
Repeat steps 1-7 but with a Linux VM. 


Input Data
",,,,,,
,,,,,,9,"Description
Implicit


Input Data
",,,,,,
Automated FRU validation - Dell P/N TJ9T4,TC-94974,New,Manual,,,1,"Description
Use FRU_FRUDummyDataValidation.py to validate FRU on the drive

Input Data
",Other than serial number and date of amnufacture all other comparison points should match with the reference FRU ,ESG-TC-121583,,,,
PCIeSSD: Hotplug - Long-Term Manual Hotplugs,TC-6428,Active,Manual,The point of this test is to analyze the subsystem behavior after doing a significant amount of hotplug operations in a row.,,1,"Description
Boot into the OS with no PCIe SSDs in the system

Input Data
",Implicit,ESG-TC-78853,,,,
,,,,,,2,"Description
Insert a PCIe SSD into the system

Input Data
","The PCIe SSD shows up everywhere (PCI bus, NVMe driver is loaded, disk. mgmt tools, etc.) and is functional",,,,,
,,,,,,3,"Description
Surprise remove the PCIe SSD from the system after you notice the OS has completed enumerated the previous insertion

Input Data
","The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)",,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 124 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
,,,,,,5,"Description
Repeat steps 2-4 for each slot in the given controller.

For example, let's say there's 3 PCIe extender cards in the system, and each one connects to 4 drives. Then in this case, you would run to each of the four slots of one of the extender cards.

Another example would be CPU direct-attach, if the CPU port controls, 2 drives, then 125 hotplugs will be performed for both slots.


Input Data
",Same results as in steps 2-4,,,,,
PCIeSSD: PCIe - Continuous Link Retrains,TC-26817,Active,Manual,The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.,,1,"Description
Boot to a supported operating system with at least two PCIe SSDs.

Input Data
",Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space.,ESG-TC-79698,,,,
,,,,,,2,"Description
Start a script to cause a Link Retrain (bit 5 - Link Control Register) for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.

Input Data
",The script completes all 100 loops successfully.,,,,,
PCIeSSD: Hotplug - Hot Insertion/Surprise Removal of Multiple Drives,TC-30914,Active,Manual,"The point of this test is to make sure that hot inserting multiple drives at the same time results in all devices getting fully configured.
The point of this test is to make sure that surprise removing multiple drives at the same time results in all devices getting fully removed.
",-,1,"Description
Boot into the OS with no PCIe SSDs in the system

Input Data
",Implicit,ESG-TC-97341,,,,
,,,,,,2,"Description
Hot insert 2 or more (preferably the maximum amount) hotpluggable PCIe SSDs at the same time

Input Data
","All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)",,,,,
,,,,,,3,"Description
Surprise remove all of the drives that were just inserted at the same time

Input Data
","None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)",,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIeSSD: Hotplug - Surprise Removal after Partially Handled Insertion,TC-50141,Active,Manual,"The point of this test is to analyze the subsystem behavior when a device is immediately removed after just have been inserted, but before the OS has finished undoing the actions from the initial insertion.",,1,"Description
Boot into the OS with no PCIe SSDs in the system

Input Data
","Implicit
only have boot disk
[root@rhel91 neuron]# nvme list
Node Generic SN Model Namespace Usage Format FW Rev
--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0
[root@rhel91 neuron]#

",ESG-TC-78851,,,,
,,,,,,2,"Description
Insert a PCIe SSD into the system

Input Data
",N/A,,,,,
,,,,,,3,"Description
Surprise remove the PCIe SSD from the system after you notice the OS starting to handle the previous insertion (adding drive to the OS however storage is not ready), but before it actually completes

Input Data
","The PCIe SSD does not show up anywhere in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.)",,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIe SSD: discovery after DC power cycle (long term),TC-51058,Active,Manual,Verify PCIe SSDs are reliably discovered after D/C power cycle.,,1,"Description
Verify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-131,,,,
,,,,,,2,"Description
Attach the maximum number of PCIe SSDs permitted by the system configuration.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Clear the system's SEL log.

Input Data
",SEL log cleared.,,,,,
,,,,,,4,"Description
Boot into the OS and ensure system logs in automatically

Input Data
",Implicit.,,,,,
,,,,,,5,"Description
Using a utility such as racadm (may use any other utilities that are available), DC power cycle the system after the system boots and the attempt has been made to discover all PCIe SSD devices. Sequence should look like: boot --> OS login --> Device Detection --> DC power cycle (if no errors) Using racadm, the command should look like: racadm serveraction powercycle

Input Data
",Test is set up to run unattended.,,,,,
,,,,,,6,"Description
Allow the system to repeat the D/C cycle for at least 12 hours.

Input Data
","No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible.",,,,,
,,,,,,7,"Description
If applicable, check the device debug log for any errors.

Input Data
",No errors found.,,,,,
,,,,,,8,"Description
Check the system's SEL log for any errors.

Input Data
",No errors related to PCIe SSD are found.,,,,,
PCIeSSD: PCIe - Continuous Link Disables/Enables,TC-55980,Active,Manual,The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.,,1,"Description
Boot to a supported operating system with at least two PCIe SSDs.

Input Data
",Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space.,ESG-TC-79700,,,,
,,,,,,2,"Description
Start a script to:
   1. cause a Link Disable (bit 4 - Link Control Register) by writing a 1
   2. wait 3s
   3. make sure the link is x0, Gen-1
   4. re-enable the link by writing a 0
   5. wait 3s
   6. make sure the link width and speed is the maximum capable for the PCIe SSD
for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.


Input Data
",The script completes all 100 loops successfully.,,,,,
PCIe SSD: discovery after OS reboots (long term),TC-57691,Active,Manual,Verify PCIe SSDs are reliably discovered after OS reboots and no errors are found.,,1,"Description
Verify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-197,,,,
,,,,,,2,"Description
Attach the maximum number of PCIe SSDs permitted by the system configuration.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Clear the system's SEL log.

Input Data
",SEL log cleared.,,,,,
,,,,,,4,"Description
Boot into the OS and ensure system logs in automatically

Input Data
",Implicit.,,,,,
,,,,,,5,"Description
Setup a script to do the following upon power on: boot --> OS login --> Device Detection --> OS reboot --> repeat

Input Data
",Test is set up to run unattended.,,,,,
,,,,,,6,"Description
Allow the system to repeat the reboots for at least 12 hours.

Input Data
","No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible.",,,,,
,,,,,,7,"Description
If applicable, check the device debug log for any errors.

Input Data
",No errors found.,,,,,
,,,,,,8,"Description
Check the system's SEL log for any errors.

Input Data
",No errors related to PCIe SSD are found.,,,,,
PCIeSSD: Hotplug - Hot Insertion after Fully Handled Removal,TC-70705,Active,Manual,The point of this test is to make sure a drive that was hot inserted is fully configured after it was previously successfully removed from the system.,,1,"Description
Boot into the OS with at least one hot-pluggable PCIe SSD in the system

Input Data
",The PCIe SSD is discovered once in the OS,ESG-TC-78852,,,,
,,,,,,2,"Description
Surprise remove the PCIe SSD from the system

Input Data
","The PCIe SSD is completely removed from the system (PCI bus, NVMe driver unloaded, disk mgmt tools, etc.)",,,,,
,,,,,,3,"Description
Re-insert the PCIe SSD back into the system after the OS has completely handled the previous removal

Input Data
",The PCIe SSD shows up in the OS and is functional,,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIeSSD: PCIe - Continuous Secondary Bus Resets,TC-75213,Active,Manual,The purpose of this test case is to make sure that the link going to the endpoint PCIe SSD always trains to the maximum supported width and speed.,,1,"Description
Boot to a supported operating system with at least two PCIe SSDs.

Input Data
",Both PCIe SSDs are discovered and the link is fully trained to the maximum width and speed. Verify this from the parent above the PCIe SSD's config. space.,ESG-TC-79701,,,,
,,,,,,2,"Description
Start a script to:
   1. cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1
   2. wait 3s
   3. make sure the link is x0, Gen-1
   4. take the device out of reset by writing a 0
   5. wait 3s
   6. make sure the link width and speed is the maximum capable for the PCIe SSD
for 100 loops. After each loop, make sure that the link fully trains to the maximum width and speed. If it doesn't, exit the script with a failure.


Input Data
",The script completes all 100 loops successfully.,,,,,
,,,,,,,,,,,,,
PCIeSSD: Hotplug - Hot Insertion after Partially Handled Removal,TC-86299,Active,Manual,"The point of this test is to analyze the subsystem behavior when a device is immediately inserted after just have been removed, but before the OS has finished cleaning up the from the removal.",,1,"Description
Boot into the OS with at least one hot-pluggable PCIe SSD in the system

Input Data
",The PCIe SSD is discovered once in the OS,ESG-TC-78850,,,,
,,,,,,2,"Description
Surprise remove the PCIe SSD from the system

Input Data
",N/A,,,,,
,,,,,,3,"Description
Re-insert the PCIe SSD back into the system after you notice the OS starting to handle the previous surprise removal (removing drive from OS), but before it actually completes

Input Data
",The PCIe SSD shows up in the OS and is functional,,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIeSSD - Hot insertion : Max Payload Size is correctly programmed upon hot insertion of a device,TC-56778,Active,Manual,Verify MPS is correctly programmed with system booted with device vs. newly added device during runtime,,1,"Description
Boot the system to OS without a PCIe SSD device installed.

Input Data
",Implicit.,ESG-TC-325,,,,
,,,,,,2,"Description
Hot insert a PCIe SSD

Input Data
",Host system continues to run without freeze or hang after the device hot insertion.,,,,,
,,,,,,3,"Description
Check the current and max payload of the inserted PCIe SSD and run some I/O to the drive

Input Data
","Current and max payload values match system root complex.

No OS hang or any fatal error seen in the system",,,,,
,,,,,,4,"Description
Repeat steps 2 and 3, but this time hot insert the drive in a different slot

Input Data
",Same as in steps 2 and 3,,,,,
PCIe SSD: HII Telemetry Log Contents Validation,TC-12663,Active,Manual,The purpose of this test case is to make sure that the Telemetry log captured from the HII is valid by having the drive vendor verify the contents.,,1,"Description
Boot into the HII of the system with a drive that supports the NVMe telemetry log page.

Input Data
",The option to capture the Telemetry log page is available.,ESG-TC-117671,,,,
,,,,,,2,"Description
Capture the Telemetry log

Input Data
",The log page data is successfully obtained,,,,,
,,,,,,3,"Description
Send the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification

Input Data
",The drive vendor approves the correct format of the Telemetry data,,,,,
PCIe SSD: OMSS Telemetry Log Contents Validation,TC-35747,Active,Manual,The purpose of this test case is to make sure that the Telemetry log captured from OMSS is valid by having the drive vendor verify the contents.,,1,"Description
Boot into the OS of the system with a drive that supports the NVMe telemetry log page.

Input Data
",Implicit,ESG-TC-117673,,,,
,,,,,,2,"Description
Capture the Telemetry log using OMSS

Input Data
",The log page data is successfully obtained,,,,,
,,,,,,3,"Description
Send the Telemetry file, along with the FW version, and drive model number to the appropriate drive vendor, asking them for content verification

Input Data
",The drive vendor approves the correct format of the Telemetry data,,,,,
NVMe TCG Opal: iLKM single drive hot removal/insertion and partition enumeration check,TC-2993,Active,Manual,"The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security ","For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>

TCG Opal tests should be run in a specific order. Please refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order>",1,"Description
Boot into system with iLKM enabled along with the devices to test. 
Make sure device doesn't have security enabled from the factory or coming out of revert operation. 


Input Data
",The system boots up without any issue. ,ESG-TC-135150,,,,
,,,,,,2,"Description
Check the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. 

racadm raid get pdisks -o -p SecurityStatus

For example 

Disk.Bay.13:Enclosure.Internal.0-1
SecurityStatus = Secured


Input Data
",All the devices came as secured and no other status is displayed,,,,,
,,,,,,3,"Description
Create partitions on a single drive under test

Input Data
",The OS enumerates partitions on the device under test. ,,,,,
,,,,,,4,"Description
Hot remove the drive and hot insert the drive in the same slot.
Check the partitions after 60sec


Input Data
",All the partitions are enumerated correctly by the OS,,,,,
NVMe TCG Opal: iLKM runtime secure of NVMe drives,TC-22694,Active,Manual,"The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security ","For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>

TCG Opal tests should be run in a specific order. Please refer to the following:

https://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order",1,"Description
Boot into system with iLKM enabled and auto secure disabled(Go to services->iDRAC Key Management)
Make sure device doesn't have security enabled from the factory or coming out of revert operation. 


Input Data
",The system boots up without any issue. ,ESG-TC-135463,,,,
,,,,,,2,"Description
Hot insert an unsecured NVMe SED into the system and check the status of the disk after sometime 
racadm raid get pdisks -o -p SecurityStatus

The hot inserted disk should show as Encryption Capable
For example 

Disk.Bay.13:Enclosure.Internal.0-1
SecurityStatus = Encryption Capable 


Input Data
",The hot inserted device is not secured and can also be verified via iDRAC GUI,,,,,
,,,,,,3,"Description
Go to Storage->physical disk and selection action to secure the drive 
Secure drive option shall be available in the drop down Action menu


Input Data
",Secure drive Job is created and completes successfully ,,,,,
,,,,,,4,"Description
Check the security state of the drive via Racadm command in step 2 or via GUI security section. 



Input Data
","The status should be ""secured"" ",,,,,
NVMe TCG Opal: iLKM Rekey operation for NVMe SEDs,TC-96088,Active,Manual,"The test cases goes through the configuration of security over side band on NVMe devices via various configuration process i.e discovery, reading/writing datastore, changing PIN, Activating security ","For instructions on configuring iLKM, refer to the following:<https://confluence.gtie.dell.com/display/ESGSTOR/iLKM+Setup+Guide>

TCG Opal tests should be run in a specific order. Please refer to the following:

https://confluence.gtie.dell.com/display/ESGSTOR/TCG+Opal+Test+Execution+Order",1,"Description
Boot into system with iLKM enabled along with the devices to test. 
Make sure device doesn't have security enabled from the factory or coming out of revert operation. 


Input Data
",The system boots up without any issue. ,ESG-TC-135149,,,,
,,,,,,2,"Description
Check the status of the NVMe SEDs via iDRAC GUI disk properties section or using racadm command as stated below. 

racadm raid get pdisks -o -p SecurityStatus

For example 

Disk.Bay.13:Enclosure.Internal.0-1
SecurityStatus = Secured


Input Data
",All the devices came as secured and no other status is displayed,,,,,
,,,,,,3,"Description
Go to services->iDRAC Key Management->Rekey
Perform rekey operation  


Input Data
",The rekey operation is successful and job completed successfully without any issue. ,,,,,
PCIe SSD: Hot Remove:  Transition to and from a low link power state,TC-814,Active,Manual,"Verify that transition to a low power state, if supported,hot removing the device will de-assert presence detect and will be removed from the system (PCI List)


This test case may fail on platforms earlier than 15G due to the behavior described in JIT-138589.
 <https://jira.gtie.dell.com/browse/JIT-138589>",,1,"Description
Boot to the OS with a drive installed in the system. 

Input Data
",Implicit.,ESG-TC-322,,,,
,,,,,,2,"Description
Once in OS, Check the power state of the device (Config space or trace capture) and check the presence detect bit by dumping the pci register

Input Data
",The drive is in D0 and Link in L0 state and the presence detect bit is set to 1,,,,,
,,,,,,3,"Description
From OS disable or unload the driver


Input Data
","The driver is unloaded and no transactions going to the device
",,,,,
,,,,,,4,"Description
Check the power state of the device by checking config space or trace


Input Data
","Depending on OS the device should go to D3 state and if not write to the register to bring device to D3 state
",,,,,
,,,,,,5,"Description
Hot remove the drive from the system and dump the pci register and check the presence detect bit

Input Data
",The values of the presence detect bit is 0 for the port above the drive. (downstream switch port or root port),,,,,
PCIe SSD: Command Effects Log Page,TC-2844,Active,Manual,,,1,"Description
Boot to a supported operating system with at least one NVMe device in the system

Input Data
",All NVme devices are detected,ESG-TC-74000,,,,
,,,,,,2,"Description
Make a list of all NVMe devices which are compliant to the NVMe 1.2 spec or greater.

This can be done by issuing an Identify Controller command and reading the VER offset, or by reading the MMIO location where the version is stored


Input Data
",There is at least one NVMe device which is compliant to 1.2 or greater,,,,,
,,,,,,3,"Description
Issue the Get Log Page - Command Effects Log (Log Page ID = 5) to each of the drives discovered in step 2

Input Data
",The command is successful,,,,,
PCIe SSD: PCIe VDM Interoperability Test for NVMe MI Commands,TC-6686,Active,Manual,"Description: This test will validate if the NVMe device can successfully respond to the NVMe-MI commands through PCIe VDM.
    * Configuration Get
    * Configuration Set
    * Controller Health Status Poll
    * NVM Subsystem Health Status Poll
    * Read-NVMe-MI Data Structure
    * Get Log Page
    * Identify
    * Set Features
    * Get Features",,1,"Description
Boot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).

To check for VDM support:
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1

Note: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. 


Input Data
",System boots without any issue and device have VDM support.,ESG-TC-130662,,,,
,,,,,,2,"Description
Issue below NVMe MI Commands to the each drive (preferably via the automation script 'NVMeMICLI.py).

python3 NVMeMICLI.py -i 'iDRAC IP' -a PCIe BDF'
   1. Send Configuration Get
   2. Send Configuration Set
   3. Send Controller Health Status Poll
   4. Send NVM Subsystem Health Status Poll
   5. Send Get Log Page - Firmware Information
   6. Send Get Log Page - SMART/Health Information
   7. Send Get Log Page - Telemetry/PEL log
   8. Send Identify - Controller
   9. Send Identify - Namespace
  10. Send Get Features
  11. Send Set Features



Input Data
","All the commands are successful, no NACKS or timeouts.",,,,,
,,,,,,3,"Description
Repeat step 2 after performing hotplug on all PCIe SSDs.

Input Data
","All commands are successful after hotplug, no NACKs or timeouts.",,,,,
PCIe SSD: TCG Opal NVMe MI - Revert to factory default using SID/PSID key,TC-7682,Active,Manual,"The test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.
Also check if device supports Opal 2+",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Note: This test case needs to be run once locking has been enabled on the device. 


Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-122672,,,,
,,,,,,2,"Description
SSH into the iDRAC having test firmware for TCG Support into rootshell

If performing tests first time after iDRAC reboot run following 2 commands
setenforce 0
testlibsednvme


Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,3,"Description
Issue following command to query the drive of it's state


controller id should be determined from identify controller response in OS
testlibsednvme query  <eid> <controllerid>


For example:

 testlibsedclient query 6 65


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","Check if the locking enabled is turned on 
For example:
locking enabled = 1

If not security needs to be enabled first.",,,,,
,,,,,,4,"Description
Write some data to the device in band /OS
Ex-
nvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1

Issue a revert command using SID as user 

testlibsednvme revert  <eid> <controllerID>  <key> <keylength> <user>


Also make sure function return code is 0
The user shall be SID which is 0.
Also, use the key that was used to enable security and if security is not enabled use default MSID key
For example 
testlibsednvme revert 6 65 Dell1234 8 0


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required




Input Data
",The revert operation get's completed and return code is 0,,,,,
,,,,,,5,"Description
Issue following command to query the drive of it's state

testlibsednvme query <eid> <controllerID>

For example:

testlibsednvme query 6 65

Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","Locking is enabled is turned off 

For example:
locking enabled = [0]

Also, Check the data written in step 4 is erased.
Ex-
nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1
",,,,,
,,,,,,6,"Description
Enable Security again on drive and 
go to step 3 and repeat all steps except use PSID printed on device label and user as PSID which is 1. 

testlibsednvme DellEnableSecurity <eid> <controllerid> <key> <keylength> 1 


Input Data
",The same state of device is reached even after doing PSID revert. ,,,,,
,,,,,,7,"Description
Enable Security and go to step 3. 
Repeat the sequence for for at least 20 times. 


Input Data
",All operations succeed fully,,,,,
PCIe SSD: PCIe VDM Device Discovery after Hotplug,TC-8154,Active,Manual,Verify that the device responds to Discovery Commands after Hotplug,,1,"Description
Boot into the system with at least 2 PCIe SSD which supports PCIe VDM in the system. 

To check for VDM support: 
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1 

Note: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. 


Input Data
",System boots without any issue and device supports PCIe VDM.,ESG-TC-130638,,,,
,,,,,,2,"Description
Issue Prepare for Endpoint Discovery and Endpoint Discovery command on the PCIe SSD (preferably via automation script .MCTPControl.py).

python3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'


Input Data
",Device responds to discovery commands.,,,,,
,,,,,,3,"Description
Surprise Remove PCIe SSDs under test in the system. 

Input Data
","None of the PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.).",,,,,
,,,,,,4,"Description
Hot Insert PCIe SSDs in the system which was removed.

Input Data
","All PCIe SSDs show up in the OS (PCI bus, NVMe driver, disk mgmt. tools, etc.).",,,,,
,,,,,,5,"Description
Issue Prepare for Endpoint Discovery and Endpoint Discovery command on hot inserted PCIe SSD (preferably via automation script .MCTPControl.py).

python3 MCTPControl.py -i 'iDRAC IP' -a 'PCIe BDF'

Input Data
",Device responds to discovery commands after hotplug.,,,,,
"PCIeSSD - Hot Insertion : No data is lost, when surprise removed the drive, while IO is running",TC-13242,Active,Manual,"Verify that No data is lost, when surprise removed the drive using Quarch, while IO is runing",,1,"Description
Boot the system to OS with a PCIe SSD device installed. Note: Make sure Quarch is installed in the system before you run the test.

Input Data
",Implict,ESG-TC-104,,,,
,,,,,,2,"Description
Make sure the drive has some data and Run some I/O to the device.

Input Data
",Implict,,,,,
,,,,,,3,"Description
Hot remove the device using Quarch while I/O is running

Input Data
",You might see I/O errror,,,,,
,,,,,,4,"Description
Hot insert the drive and check for the data loss

Input Data
",Data is intact. No data loss is found.,,,,,
,,,,,,5,"Description
Repeat step 2, 3 and 4

Input Data
","Result same as step 2,3 and 4.",,,,,
PCIe SSD: PCIe VDM Interoperability Test for MCTP Commands,TC-18231,Active,Manual,"Description: This test will validate if the NVMe device can successfully respond to the MCTP commands through PCIe VDM.
    * Set Endpoint ID
    * Get Endpoint ID
    * Get Endpoint UUID
    * Get MCTP Version Support
    * Get Message Type Support
    * Prepare for Endpoint Discovery
    * Endpoint Discovery",,1,"Description
Boot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).

To check for VDM support:
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1

Note: System should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. 

Input Data
",System boots without any issue and device have VDM support.,ESG-TC-130663,,,,
,,,,,,2,"Description
Issue below MCTP commands to the each drive (preferably via the automation script 'MCTPControl.py).

python3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'
   1. Send Set Endpoint ID
   2. Send Get Endpoint ID
   3. Get Endpoint UUID
   4. Get MCTP Version Support
   5. Get Message Type Support
   6. Prepare for Endpoint Discovery
   7. Endpoint Discovery


Input Data
","All the commands are successful, no NACKS or timeouts.",,,,,
,,,,,,3,"Description
Repeat step 2 after performing hotplug on all PCIe SSDs.

Input Data
","All commands are successful after hotplug, no NACKs or timeouts.",,,,,
PCIe SSD: TCG Opal NVMe MI - Enable Security on NVMe SEDs,TC-18957,Active,Manual,"The test case enables security on the device. It encompases several operations in the process like read MSID, activate SP, write data store, rekey ",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Note: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation


Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-122673,,,,
,,,,,,2,"Description
SSH into the iDRAC having test firmware for TCG Support into rootshell

If performing tests first time after iDRAC reboot run following 2 commands
setenforce 0
testlibsednvme


Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,3,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side IO
Issue following command to query the drive of it's state


controller id should be determined from identify controller response in OS
testlibsednvme query


For example:

testlibsedclient query 6 0


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","Locking enabled is turned off 
For example:
locking enabled = [0]

If the locking is enabled make sure to run revert test case prior to running this. ",,,,,
,,,,,,4,"Description
Enable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. 
Provide user as Admin and it should be 1

testlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>
Also make sure function return code is 0

For example 
testlibsednvme DellEnableSecurity 6 0 Dell123456 10 1


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. 

For example 
locking supported = [1]
locking enabled = [1]
datastore size = [10485760]
datastore flag = [2]
old_keyId = [MSID KEY]
current_keyId = [Dell123456]
",,,,,
PCIe SSD: D3hot,TC-19864,Active,Manual,Verify that PCIe SSDs and bridge can be brought into and out of the D3 power state continuously.,,1,"Description
Install at least one PCIe extender card in the system and attach the maximum number of PCIe SSDs supported. Make sure the system has the latest BIOS, CPLD, iDRAC FW, etc.

Input Data
",Implicit.,ESG-TC-80,,,,
,,,,,,2,"Description
Boot to a DOS/DRMK bootable media with the D3hot and PCI utilities provided in this test case.

Input Data
",Run pciall.exe to determine what the position is for the PCIe extender card and drives. Use these values and make sure that the script is updated correctly.,,,,,
,,,,,,3,"Description
Run the script overnight.

Input Data
",No PCIe fatal errors should be reported. Check the SEL logs for any errors.,,,,,
PCIe SSD: Flush commands interleaved with IO submission queue deletions (Linux only),TC-21314,Active,Manual,"This test case is to repeatedly issue a large number of NVME flush commands simultaneously with IO queue creations and deletions, in an attempt to trigger a situation where a flush command is still active when the corresponding IO submission queue is deleted.",,1,"Description
Boot system to a supported Linux operating system with an NVMe drive installed.

Input Data
",System boots normally and drive is available.,ESG-TC-110712,,,,
,,,,,,2,"Description
Install the NVMe CLI tools from the operating system distribution.

For example:
Ubuntu: apt-get install nvme-cli
Red Hat: yum install nvme-cli


Input Data
",Implicit,,,,,
,,,,,,3,"Description
Run the attached shell script

Input Data
","Script runs without any errors for 10 minutes and exits.

System does not crash.",,,,,
,,,,,,4,"Description
Verify that the drive is still accessible by performing some IO to it.



Input Data
",Drive responds normally and IO completes without error,,,,,
PCIeSSD: Create and delete maximum number of namespace supported by Dell,TC-24071,Active,Manual,,,1,"Boot to the supported OS with device that supports Namespace management. 
(check identify controller OACS field)","Device is discovered and full capacity of device is listed in block layer. 
EX- nvme list  or lsblk can be used in linux",ESG-TC-115178,,,,
,,,,,,2,"Issue identify namespace command and note down original name space size.
",Original namespace size is noted ,,,,,
,,,,,,3,"Detach and delete the original namespace by using nvme-cli or the automation framework. 
Ex-
python3 NVMeIOCTLCLI.py -dtns <bdf>
python3 NVMeIOCTLCLI.py -rc <bdf>
python3 NVMeIOCTLCLI.py -dlns <bdf>",The original NS is detached and deleted. ,,,,,
,,,,,,4,"Determine the maximum number of namespaces supported by the drive by sending an Identify Controller command to the drive, looking at the ""Number of Namespaces"" field.

Divide the entire drive capacity by the ""Number of Namespaces"" field from above to obtain the new namespace size.

Create ""Number of Namepaces"" amount of namespaces using the calculated size from above.

Ex- 4 Namespaces
python3 NVMeIOCTLCLI.py <bdf> -crns
python3 NVMeIOCTLCLI.py <bdf> -crns
python3 NVMeIOCTLCLI.py <bdf> -crns
python3 NVMeIOCTLCLI.py <bdf> -crns
python3 NVMeIOCTLCLI.py <bdf> -atns
python3 NVMeIOCTLCLI.py <bdf> -atns
python3 NVMeIOCTLCLI.py <bdf> -atns
------------------------------------------------------------------------
python3 NVMeIOCTLCLI.py <bdf> -atns
python3 NVMeIOCTLCLI.py <bdf> -rc
","All commands are successful and the max. number of NS created is visible at block layer. 
Ex- lsblk or nvme list ",,,,,
,,,,,,5,"Issue and Identify Namesapce to each of the newly created namespaces, taking note of the ""Namespace Globally Unique Identifier"" and ""IEEE Extended Unique Identifier"" fields","The NGUID is unique for all namespaces OR, it is 0 for all namespaces and the EUI64 is unique for all namespaces.

The EUI64 is unique for all namespaces OR, it is 0 for all namespaces and the NGUID is unique for all namespaces.",,,,,
,,,,,,6,"Detach and delete all the NS created. 
Ex- python3 ns_create_delete_max.py <bdf> -dlns <number of NS supported>","All the NS is deleted and verified using appropriate command 
Ex- lsblk or nvme list in linux ",,,,,
,,,,,,7,"create and attach the original NS of size noted in step2. 
python3 NVMeIOCTLCLI.py -crns <bdf>  
python3 NVMeIOCTLCLI.py -atns <bdf>
python3 NVMeIOCTLCLI.py -rc <bdf>","The original NS is created and visible to OS
Ex- lsblk or nvme list
Also check SMART log for any errors. ",,,,,
PCIe SSD : Persistent Event Log-  Firmware Commit Event logging check,TC-30397,Active,Manual,,,1,"Description
Boot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). 

Input Data
",The device boots without any errors. ,ESG-TC-124780,,,,
,,,,,,2,"Description
Issue Persistent event log command to the respective device and store the log in a file for later issue.
For example 
python3 NVMeIOCTCLI.py -gl bdf 

NSID = 0x0
LID= 0x0d
subpage = 0x0
num of dwords = 0x0
event notification = 0x0



Input Data
",The command get's executed successfully without any errors.  ,,,,,
,,,,,,3,"Description
Note down the current active firmware version running on the device. 
Update the firmware on the device, up rev or down rev both could be used for this test case with live firmware activate
Any  utility could be used for updating firmware but DUP is a preferred method. 

Note down the version of the newly activated firmware. 





Input Data
",The firmware update was a successful operation and both old as well as new version was noted. ,,,,,
,,,,,,4,"Description
Go to step 2 and dump the log. 
Make sure to save the log in different files. 
Compare the two logs


Input Data
",The new event for Firmware Commit  correctly logged earlier in the Persistent Event Log data with all the respective fields correctly populated as per spec. ,,,,,
PCIe SSD: TCG Opal NVMe MI - Device Query for Opal support,TC-31502,Active,Manual,"iDrac 5.10+ and Linux are required for this testcase. 

The test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.
The location of the test firmware is here . 
\\S3bnsx01nas05.amer.dell.com\RAIDSERVER\NVMe\NVME_PCIeSSD\NVMe_SEKM\iDRACTCGOpaltestfirmware

",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-122666,,,,
,,,,,,2,"Description
SSH into the iDRAC having test firmware for TCG Support into rootshell  

If performing tests first time after iDRAC reboot run following 2 commands 
setenforce 0
testlibsednvme




Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,3,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side some IO

Issue following command to get the discovery for determining if drive supports Locking 
 testlibsednvme query < eid > <controller id in decimal>

 
controller id should be determined from identify controller response
and eid from previous step. 
For example:
testlibsednvme query 4 65



Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then 
Locking Enabled: 0 other wise 1 if already security is enabled

",,,,,
PCIeSSD: Concurrent IO to four namespaces on a multi-NS capable device,TC-35453,Active,Manual,Verify that it is possible to create four namespaces on a multi-NS device and run IO to all four simultaneously without error,,1,"Description
Boot to the supported OS with device that supports Namespace management. 
(check identify controller OACS field)


Input Data
","Device is discovered and full capacity of device is listed in block layer. 
EX- nvme list  or lsblk can be used in linux",ESG-TC-115888,,,,
,,,,,,2,"Description
Issue identify namespace command and note down original name space size.

Input Data
",Original namespace size is noted ,,,,,
,,,,,,3,"Description
Detach and delete the original NS by using nvme-cli or automation framework. 
Ex- python3 NVMeIOCTLCLI.py -dtns <bdf>
python3 NVMeIOCTLCLI.py -rc <bdf>
python3 NVMeIOCTLCLI.py -dlns <bdf>


Input Data
",The original NS is detached and deleted. ,,,,,
,,,,,,4,"Description
Create and attach four namespaces
 
python3 ns_create_delete_max.py <bdf> -crns 4

TODO: Verify that this tool actually works this way


Input Data
","Wait sufficient time for all of the namespaces to be created.  There should be 4 namespaces visible at the block layer
 
Ex- lsblk or nvme list ",,,,,
,,,,,,5,"Description
Use a tool such as testio or diskio to write to all four namespaces simultaneously for at least 30 minutes, with multiple threads per namespace and data verification enabled.  This will entail running four instances of the tool, one per block device visible in the operating system

Input Data
",IO test tools should all run to completion without errors noted,,,,,
,,,,,,6,"Description
Detach and delete all the NS created . 
Ex- python3 ns_create_delete_max.py <bdf> -dlns 4


Input Data
","All the NS is deleted and verified using appropriate command 
Ex- lsblk or nvme list in linux ",,,,,
,,,,,,7,"Description
create and attach the original NS of size noted in step2. 
python3 NVMeIOCTLCLI.py -crns <bdf>  
python3 NVMeIOCTLCLI.py -atns <bdf>
python3 NVMeIOCTLCLI.py -rc <bdf>


Input Data
","The original NS is created and visible to OS
Ex- lsblk or nvme list
Also check SMART log for any errors. ",,,,,
PCIe SSD: Error injection verification,TC-36170,Active,Manual,The objective is  to verify the drive functionality when the error is injected and drive smart health response,,1,"Description
boot the SUT with atleast one PCIe SSD

Input Data
",The device is detected in idarc and OS/,ESG-TC-73994,,,,
,,,,,,2,"Description
Get the smart logs from the device 
please use attachment in this test case to verify the test case 


Input Data
",The critical bits are not set and device status LED is solid green,,,,,
,,,,,,3,"Description
create the file SMARTErrorInjection.txt in the same directory where NVMEIOCTLCLI.py exists

Input Data
","
",,,,,
,,,,,,4,"Description
Enter the values 1,2,4,8,10 in the SMARTErrorInjection.txt one at a time.

These values can be found in NVMe SPEC under SMART/Health information section



Input Data
",,,,,,
,,,,,,5,"Description

run the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 



Input Data
",get the smart logs and check the bit is set for the critcal bits,,,,,
,,,,,,6,"Description
Wait for 20 mins and Check idrac, OMSS, HII for status/state and Failure predicted.


Input Data
",The message across all the management application is same`,,,,,
,,,,,,7,"Description
1. Clear the bit , by entering 0 into SMARTErrorInjection.tx

2.run the command python NVMeIOCTLCLI.py -sf bdf 1 0xDE 3 1 



Input Data
",get the smart logs and check the bit is cleared ,,,,,
,,,,,,8,"Description
Repeat the steps from step 2 - 6 for next critical bits

Input Data
",,,,,,
PCIe SSD : Telemetry Log,TC-36313,Active,Manual,The test case checks the device telemetry log feature and make sure the device vendor can decode the log. ,,1,"Description
Boot to supported operating system with at least one NVMe device. 

Input Data
",The nvme device get's detected and enumerated by OS. ,ESG-TC-114580,,,,
,,,,,,2,"Description
Issue an Identify Controller to the device  

Input Data
","Check LPA (Log Page Attribute ) Field at offset 261 bit 3 to be set. 
If set the device supports telemetry",,,,,
,,,,,,3,"Description
Issue a host initiated telemetry command for the all the data area to be returned as response.  
If using automation framework
follow below example NSID=0xFFFFFFFF

[root@localhost PCIeSSD]# python3 NVMeIOCTLCLI.py -gl 24:00.0
        

        Log Page ID (0x00 - 0xFF) = 0x07
        Log Page Sub ID (0x00 - 0xFF) = 0x0
        Number of DWORDS (0x00 - 0xFF) = 0x7f
        Retain Asynchronous Event (0 or 1) = 0



Input Data
",The device responds with the required telemetry log. ,,,,,
,,,,,,4,"Description
The telemetry log returned is to be stored in a .bin file and should be saved. 

Input Data
",The log saved should be sent to the vendor for analysis and to be confirmed if data returned is good. ,,,,,
PCIe SSD : Complete FRU validation,TC-36856,Active,Manual,"FRU validation :
==========
14G system recommended.

libI2C read vs shipped image
IPMI command read vs shipped image


",,1,"Description
Install PCIe SSD, boot to the OS 

Input Data
",OS should detect the drive,ESG-TC-114,,,,
,,,,,,2,"Description
read the FRU of the device using libi2c command from the slot where the PCIeSSD or Extender card is present

PCIeSSD
libi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256'

Adapteres
libi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256


Input Data
","FRU data is read from the device from the particular slot
note down the serial number and manufacturing date and time values",,,,,
,,,,,,3,"Description
Input the serial number and manufacturing date and time and calculate the checksum value for board information area format version.
Compare the data from the shipped FRU image vs FRU read from the  device .


Input Data
",The shipped FRU images and FRU from the device should match,,,,,
,,,,,,4,"Description
read the FRU using IPMI command for the device and match against shipped image with the modified serial number, manufacturing date and time and checksum for the section which is already done in step 3.

IPMI commands
PCIESSD U.2
ipmitool -U root -P calvin raw 0x30 0x36 0x00 0x0  bay  slot 0x01 0x00 0x00 0x20

AIC
'ipmitool -U root -P calvin raw 0x30 0x36 0x01 slotnumer  0x01 0x01 0x00 0x00 0x20

For Extender card : IPMI commands donot support - 14G


Input Data
",The values read using IPMI commands and idrac should match.,,,,,
PCIe SSD Crypto Erase with Shutdown notification (Linux Only),TC-37090,Active,Manual,This test case covers drive behavior for getting a shutdown notification immediately after Crypto Erase is issued and then it compares if false data is reported for unsafe shutdown. ,,1,"Description
Boot to the supported Linux OS with at least 2 PCIe SSD. 

Input Data
",Systems boots successfully and all NVMe devices are discovered. ,ESG-TC-89435,,,,
,,,,,,2,"Description
Select a NVMe device and dump SMART log(OMSA Can be used). Take a note of Unsafe Shutdown Count. 

Input Data
",SMART data is successfully pulled. ,,,,,
,,,,,,3,"Description
Issue a Crypto Erase to the drive (OMSA Can be used)

Input Data
",The Command goes to the drive. ,,,,,
,,,,,,4,"Description
Issue a shutdown notification to the drive immediately after CE . (Driver unload and load will do ) 

Input Data
",Device is available.,,,,,
,,,,,,5,"Description
Dump the SMART Log for the drive and look for Unsafe Shutdown Count

Input Data
",The Unsafe shutdown count remains same. ,,,,,
,,,,,,6,"Description
Repeat steps 2-5 for at least 5 times. 

Input Data
",,,,,,
PCIeSSD SSD DUP: FW Update via iDRAC GUI w/ multiple devices,TC-38867,Active,Manual,Verify successful DUP execution against multiple devices via iDRAC.,,1,"Description
Install at least two PCIe SSDs with PCIe VDM support (preferably of same model with down-rev firmware version i.e. n-1.

To check for VDM support:
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1

Note: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. 


Input Data
",Drive is installed without any issue.,ESG-TC-130630,,,,
,,,,,,2,"Description
If testing with iDRAC version is 5.0.0.0, cold boot the system.
If testing with version is 5.10.00.0 or greater, omit this step. 


Input Data
",,,,,,
,,,,,,3,"Description
Get the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.




Input Data
",Device BDF's are listed in iDRAC log.,,,,,
,,,,,,4,"Description
Launch the iDRAC GUI, go to Maintenance / System Update and Upload DUP for the PCIe SSD. Once you get success for the download, go ahead and select the ""Install"" button.

NOTE: If you see Install and Reboot, Install Next Reboot buttons, it is a issue.

Pop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.


Input Data
",Verified that the DUP package uploads successfully and both the job passed with no issues.,,,,,
,,,,,,5,"Description
Go to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.
   1.  SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version <version n>.)
   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n>).
   3.  PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version :<version n-1>, Current version: <version n>).



Input Data
","User verified LC logs reported the correct entry for each PCIe SSD.
",,,,,
,,,,,,6,"Description
Go to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.

Go to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.

Go to OS and verify that new FW version is reported on all drives you updated.

Input Data
","User verified storage inventory reported the correct FW version for all drives.

User verified FW inventory reported the correct FW version for all drives.

User verified that OS reported the correct FW version for all drives.",,,,,
,,,,,,7,"Description
Repeat steps 3-7 after performing hotplug operation to PCIe SSDs.

Input Data
",Firmware is updated successfully after hotplug.,,,,,
PCIe SSD: Firmware activate and reset during I/O (Linux Only),TC-39349,Active,Manual,Perform firmware activation and device reset during I/O stress.,,1,"Description
Begin I/O to the target device.  
    Example:
        Linux:  testio -t50 -f/dev/nvme0n1
        Windows:  testio.exe -f50 -f\\.\PHYSICALDRIVE0
        Framework:   
            import ServerStorageSDK.Helpers.IO as IO
            io = IO.IO()
            io.Validate('testio', False)
            io.Threads = 50
            io.Start(['/dev/nvme0n1'])



Input Data
",I/O starts.,ESG-TC-110633,,,,
,,,,,,2,"Description
Download device firmware:
Linux:
    nvme fw-download /dev/nvme0n1 -f your_fw_file.tar

Use the raw binary file or tar file for the FW (not the DUP)


Input Data
",Firmware download completes successfully.,,,,,
,,,,,,3,"Description
Activate FW w/o reset:
Linux:
    nvme fw-commit /dev/nvme0n1 -a 3-s 0


Input Data
","Firmware activation succeeds.
IO haults while FW download and commit take place and then re-starts",,,,,
PCIeSSD - NVMe Sanitize,TC-41756,Active,Manual,This test case is intended to validate that the NVMe Sanitize operations are supported and implemented correctly by the NVMe device.,,1,"Description
Boot to a supported operating system with at least one NVMe device in the system

Input Data
",The NVMe device is detected by the driver and displayed in the OS,ESG-TC-93511,,,,
,,,,,,2,"Description
Using a tool that can send IOCTLs to the NVMe driver (like nvme-cli in Linux/ESXi or the Dell NVMeIOCTLCLI tool), issue an Identify Controller command to the drive(s)

Input Data
","Read the ""Sanitize Capabilities"" field (offset 331:328) and confirm that at the very least, bits 0 and 1 are set",,,,,
,,,,,,3,"Description
Partition, format, and put some data onto the drive(s)

Input Data
",Data is successfully copied onto the drive(s),,,,,
,,,,,,4,"Description
Using a tool for sending an IOCTL, issue a Sanitize command with the ""Sanitize Action"" set to 0x04 to the drive(s) in order to initiate a Sanitize - Cryptographic Erase operation

Input Data
",The command completes successfully and the data on the drive(s) is no longer accessible,,,,,
,,,,,,5,"Description
Partition, format, and put some data onto the drive(s)

Input Data
",Data is successfully copied onto the drive(s),,,,,
,,,,,,6,"Description
Using a tool for sending an IOCTL, issue a Sanitize command with the ""Sanitize Action"" set to 0x02 to the drive(s) in order to initiate a Sanitize - Block Erase operation

Input Data
",The command completes successfully and the data on the drive(s) is no longer accessible,,,,,
PCIe SSD: Issue PERST during initialization,TC-42864,Active,Manual,Issue a PEReset during device initialization.,,1,"Description
Use the automation framework, or:

Input Data
",,ESG-TC-110762,,,,
,,,,,,2,"Description
Attach a target drive to a Quarch and insert it into the system.

Input Data
",,,,,,
,,,,,,3,"Description
Using the Quarch, remove the drive from the system.  Verify that the drive is not present in the system.

Input Data
",,,,,,
,,,,,,4,"Description
Using the Quarch, reinsert the drive in the system.

Input Data
",,,,,,
,,,,,,5,"Description
Wait 45 seconds.

Input Data
",,,,,,
,,,,,,6,"Description
Using the Quarch, issue a P/E reset to the drive.

Input Data
",,,,,,
,,,,,,7,"Description
Using the Quarch, remove the drive from reset.

Input Data
",,,,,,
,,,,,,8,"Description
Wait 10 seconds.

Input Data
",,,,,,
,,,,,,9,"Description
Verify that an identify controller issued to the drive returns successfully.

Input Data
",,,,,,
PCIe SSD: TCG Opal - Device Query for Opal support (Linux Only),TC-44021,Active,Manual,"The test case does level 0 discovery for various feature and also checks if locking is supported , enabled or locked.
Also check if device supports Opal 2+",,1,"Description
Boot to a Linux OS with TCG Opal enabled device

Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-116234,,,,
,,,,,,2,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side IO


Input Data
",The traffic to the device is started without any issue,,,,,
,,,,,,3,"Description
Issue a device discovery command using attached binary ""sedlib"". 
For example 
./sedlib -a q -d /dev/nvme0n1 -x nvme


Input Data
",The command completes successfully and device returns discovery data. ,,,,,
,,,,,,4,"Description
check feature: 0x2  specific fields along with Feature 0x 203

Input Data
","The device should be in unlocked state with Locked: 0 and if it is  fresh out of box device then 
Locking Enabled: 0 other wise 1 if already SP is activated. 
Also Feature 0x203 should advertise Opal 2 support",,,,,
PCIe SSD: PCIe VDM EID Check after Hotplug,TC-46357,Active,Automation,"Description: This test will validate if the NVMe device has a valid EID assigned through PCIe VDM before and after hotplug.
* Set Endpoint ID

",,1,"Boot to the system with PCIe SSD which has PCIe VDM Support (preferably one of each model).

To check for VDM support:
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1

Note: The system should be 15G Intel or 15G AMD with Milan CPU and also support iDRAC 5.0.0.0 or greater. 
","System boots without any issue and devices have VDM support.
",ESG-TC-130637,,,,
,,,,,,2,"Issue Get Endpoint ID (EID) MCTP command to each drive (preferably via the automation script 'MCTPControl.py).

python3 MCTPControl.py -i 'iDRAC IP' -a PCIe BDF'",The command is successful and all the devices have a valid non-zero Endpoint ID (EID).,,,,,
,,,,,,3,"Repeat step 2 after performing hotplug on all PCIe SSDs.
","The command is successful and all the devices have a valid non-zero Endpoint ID (EID).
",,,,,
PCIe SSD : Persistent Event Log-  Namespace Management logging check,TC-46466,Active,Manual,,,1,"Description
Boot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). 

Input Data
",The device boots without any errors. ,ESG-TC-125194,,,,
,,,,,,2,"Description
Issue Persistent event log command to the respective device and store the log in a file for later issue.
For example 
python3 NVMeIOCTCLI.py -gl bdf 

 NSID = 0xffffffff
LID= 0x0d
subpage =0x0
num of dwords = 0x7f



Input Data
",The command get's executed successfully without any errors.  ,,,,,
,,,,,,3,"Description
Issue delete name space  command to the drive . 
For example

python3 NVMeIOCTCLI.py -dlns bdf 




Input Data
","The name space got deleted without any issue.
",,,,,
,,,,,,4,"Description
hIssue Controller reset, then Go to step 2 and dump the log. 
Make sure to save the log in different files. 
Compare the two logs


Input Data
","The new event for Change namespace correctly logged earlier in the Persistent Event Log data
Make sure the fields are programmed correctly.
",,,,,
,,,,,,5,"Description
Restore the original namespace by using create name space and attach namespace.
The PEL event log could be used to know the size of the namespace deleted.

For example
python3 NVMeIOCTCLI.py -crns bdf

python3 NVMeIOCTCLI.py -atns bdf


Input Data
","Namespace was created and attached.
",,,,,
PCIe SSD: Long term mixed side band MI  and in band stress,TC-46688,Active,Manual,,,1,"Description
Boot to the OS with maximum supported NVMe devices

Input Data
",System boots up without any errors and all devices discovered,ESG-TC-114668,,,,
,,,,,,2,"Description
Start running heavy IO on all the devices for 12 hrs and capture SMART logs from all devices

Input Data
",No issue is found starting the IO and SMART logs are captured from all devices.,,,,,
,,,,,,3,"Description
Start running NVMe Subsystem Health Status poll MI command similar to iDRAC. 
Use automation framework to start the traffic. 


Input Data
",Side band MI traffic started and commands start completing successfully ,,,,,
,,,,,,4,"Description
Run both IO and side band command stress for 12 hrs. 
Dump smart logs from all devices and compare from previous one collected at the beginning. 
Also, check OS logs for the timeout or any errors.


Input Data
",Test completes successfully and no errors are logged in SMART log. ,,,,,
PCIe SSD: TCG Opal NVMe MI - Get MSID of the device,TC-48635,Active,Manual,"iDrac 5.10+ and Linux are required for this testcase.

The test case prints MSID of the device. 
The location of the test firmware is here .
\\S3bnsx01nas05.amer.dell.com\RAIDSERVER\NVMe\NVME_PCIeSSD\NVMe_SEKM\iDRACTCGOpaltestfirmware
",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-122670,,,,
,,,,,,2,"Description
SSH into the iDRAC having test firmware for TCG Support into rootshell

If performing tests first time after iDRAC reboot run following 2 commands
setenforce 0
testlibsednvme


Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,3,"Description
Start running I/O + Admin command to the device.
admin command like identify or get log page could be run in a loop along side some IO
Also, if this is the first test after iDRAC reboot make sure you set MTU size. to 120 as recomended 
testlibsednvme setMTUsize <eid> 120


Issue following command to get the MSID of the device which is the default key 
testlibsednvme getmsid < eid > <controller ID>


controller id should be determined from identify controller response
and eid from previous step.
For example:
testlibsednvme getmsid 4 0



Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","The device should return the MSID. 
For example 
 msid = MSID_password

The msid varies from device to device and vendor to vendor. ",,,,,
PCIe SSD: Connect refclk After 12V is Stable and PERST# De-Assertion,TC-49774,Active,Manual,"The purpose of this test case is to start the reference clock to the NVMe drive after the 12V power good, and PERST# de-asserting. Even though this is a PCIe spec. violation, it's expected that the drive remain functional after removing and re-inserting the drive.",,1,"Description
Connect the target device to a quarch.

Input Data
","Quarch is powered on and available, device is available to the OS.",ESG-TC-122049,,,,
,,,,,,2,"Description
Remove the drive from the system

Input Data
",The drive is no longer enumerated in the OS,,,,,
,,,,,,3,"Description
   1. Assign all signals to a source group.
Assign all refclk signals to a separate source group

   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source
          o signal:ref_clk_0_mn:source 1 <1>
          o add the other 3 similarly using a 100ms delay
   2. 



Input Data
",Signals are added successfully.,,,,,
,,,,,,4,"Description
Insert the drive so that all signals except the refclk are inserted

Input Data
",The drive will likely not get detected but that's fine,,,,,
,,,,,,5,"Description
Remove the drive normally

Input Data
",N/A,,,,,
,,,,,,6,"Description
Insert the drive back in normally

Input Data
",The OS is able to detect the drive,,,,,
,,,,,,7,"Description
Run I/O for a minute to the drive to verify functionality

Input Data
",The drive successfully processes I/O,,,,,
PCIe SSD: Hot insert: AER registers are configured/restored on hot insertion,TC-50334,Active,Manual,Verify that the AER registers for a PCIe SSD device are configured/restored on hot insertion per system BIOS defaults,,1,"Description
Boot to the OS with a drive installed in the system.

Input Data
",Implicit.,ESG-TC-122,,,,
,,,,,,2,"Description
Capture the values of the following PCIe registers: 

Uncorrectale Error Mask Register (UEMsk)
Correctale Error Mask Register  (CEMsk)
Uncorrectable Error Severity Register  (UESvrt)


Input Data
",Implict,,,,,
,,,,,,3,"Description
Surprise remove the drive from the system

Input Data
",The system is functional. No error/ fatal error is reported.,,,,,
,,,,,,4,"Description
Hot Insert the drive that was removed in step 4 back into the system

Input Data
",The device is recognized by the OS and functional,,,,,
,,,,,,5,"Description
Capture the values of the following PCIe registers: 

Uncorrectale Error Mask Register (UEMsk)
Correctale Error Mask Register  (CEMsk)
Uncorrectable Error Severity Register  (UESvrt)




Input Data
",The values of the registers are the same as when they were captured in step 2,,,,,
PCIe SSD: TCG Opal - Lock/Unlock global range (Linux Only),TC-50480,Active,Manual,This test case checks locking and unlocking of global range to be used by EKMS solution ,,1,"Description
Boot to the Linux OS with TCG Opal enabled device

Input Data
",The OS boots without any issue and device is accessible.,ESG-TC-116255,,,,
,,,,,,2,"Description
Check if device is enabled for locking by doing query. 
Ex- ./sedlib -a q -d /dev/nvme0n1 -x nvme
If not enabled then activate SP 
./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme



Input Data
",The device is activated for locking ,,,,,
,,,,,,3,"Description
Read some data from the device 
Ex- nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1



Input Data
",The data is read without any issue ,,,,,
,,,,,,4,"Description
Lock the device for the global range (whole device) using Band 0 (global ) 
Ex-
./sedlib -a l -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme



Input Data
","The device is locked and command completes successfully. 
Run query command to confirm. ",,,,,
,,,,,,5,"Description
Try to read data previously written . 
Ex- 
nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1


Input Data
",Access is denied showing device is locked,,,,,
,,,,,,6,"Description
Unlock the device using following command and read data again 
Ex-
 ./sedlib -a u -B 0 -P MSID_password -d /dev/nvme0n1 -x nvme




Input Data
",The data is accessible. ,,,,,
PCIe SSD: TCG Opal - Get MSID for the device  (Linux Only),TC-52088,Active,Manual,"The test case is used to get MSID for the device , the MSID is used as default PIN for activating and configuring the device first time. ",,1,"Description
Boot to a linux OS with a supported TCG Opal device 

Input Data
","The device get's discovered by OS without any issues. 
Also, perform some IO to make sure drive is functional. ",ESG-TC-116235,,,,
,,,,,,2,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side IO


Input Data
",The traffic to the device is started without any issue,,,,,
,,,,,,3,"Description
Issue print MSID command to get MSID for the device. 
Ex. 
./sedlib -a pm -d /dev/nvme0n1 -x nvme


Input Data
","The command get's completed successfully and MSID is printed, note down for future purpose. 
Ex. 
Attempting to perform action: PRINT MSID
MSID is 13 bytes long:
MSID_password
",,,,,
PCIe SSD: Remove refclk Prior to 12V Loss and PERST# Assertion,TC-53753,Active,Manual,"The purpose of this test case is to remove the reference clock to the NVMe drive prior to the 12V power good going away, and PERST# asserting. Even though this is a PCIe spec. violation, it's expected that the drive remain functional after ""re-inserting"" the drive.",,1,"Description
Connect the target device to a quarch.

Input Data
","Quarch is powered on and available, device is available to the OS.",ESG-TC-110637,,,,
,,,,,,2,"Description
Add the target devices reference clock pins to a quarch source.

   1. Add 'ref_clk_0_mn', 'ref_clk_1_mn', 'ref_clk_0_pl', and 'ref_clk_1_pl' to a source
          o signal:ref_clk_0_mn:source 1 <1>
          o add the other 3 similarly
   2. All other signals would be another source number with a delay of 10ms after the clock source group




Input Data
",Signals are added successfully.,,,,,
,,,,,,3,"Description
Begin I/O to the target device.  
    Example:
        Linux:  testio -t50 -f/dev/nvme0n1
        Windows:  testio.exe -f50 -f\\.\PHYSICALDRIVEX
        Framework:   
            import ServerStorageSDK.Helpers.IO as IO
            io = IO.IO()
            io.Validate('testio', False)
            io.Threads = 50
            io.Start(['/dev/nvme0n1'])


Input Data
",I/O starts without error.,,,,,
,,,,,,4,"Description

Remove the reference clock by turning the source off

    * source:1:state off <1>



Input Data
",I/O will likely fail,,,,,
,,,,,,5,"Description
Immediately remove all other signals from the Quarch

Input Data
",The drive is removed from the OS,,,,,
,,,,,,6,"Description
Insert the drive back in normally

Input Data
",The OS is able to detect the drive,,,,,
,,,,,,7,"Description
Run I/O for a minute to the drive to verify functionality

Input Data
",The drive successfully processes I/O,,,,,
PCIe SSD: Expansion ROM Base Address Register Check,TC-58391,Active,Manual,"This Test Case is to check if the Expansion ROM is present/enabled in any form for the device, as currently not supported by Dell. ",,1,"Description
Boot to the EFI Shell with at least one NVMe device installed 

Input Data
",The system boots without any errors ,ESG-TC-97312,,,,
,,,,,,2,"Description
Check Expansion ROM Base Address Register at offset 30h in the Config space. 



Input Data
",The value of the register should be zero. ,,,,,
PCIe SSD Virtualization - IO with admin command along with occasional controller reset (pass through),TC-59418,Active,Manual,The intent of the test case is to verify drive behavior in a pass through configuration under reset and admin command in flight,,1,"Description
Boot with combination of drives in pass through and data store

Input Data
",Implicit,ESG-TC-110929,,,,
,,,,,,2,"Description
Install a Linux VM and attach nvme device as passthrough along with data store nvme devices

Input Data
",The VM boots and drive is attached without any errors. ,,,,,
,,,,,,3,"Description
Install ""nvme-cli "" package and dump smart-log for each pass through device using following command. 
""nvme smart-log /dev/nvmexn1"" . Save the output to  file. 


Input Data
",The package get's install and the drive logs are collected in a file. ,,,,,
,,,,,,4,"Description
Start running IO to all devices (pass through as well as data store) and in the background run shell script to poll for smart log on all pass through devices.
""nvme smart-log /dev/nvmexn1"". 


Input Data
",IO runs fine and smart data is polled without any issues. ,,,,,
,,,,,,5,"Description
Issue controller reset to all pass through devices after every 20 min interval. please find the attached script for reference. 

Input Data
",The drive goes through a reset and temporarily IO is paused. ,,,,,
,,,,,,6,"Description
Let the test run for at least 2 hrs and collect smart  log for all the devices mentioned in step 3. Also, check SEL and OS logs to make sure no errors are reported. 

Input Data
",There are no errors reported as part of SMART log and OS logs. ,,,,,
PCIe SSD: FW DUP Upgrade-Downgrade from OS (Manual),TC-61268,Active,Manual,Confirm operation of the FW DUPs within the OS (Windows/Linux),,1,"Description
Make sure all the devices are discovered in the OS

Input Data
","All devices installed, are visible in the OS",ESG-TC-129863,,,,
,,,,,,2,"Description
From the OS, run the DUP as below -

1) In Windows Server, double click on the DUP (.exe) and follow the prompts

2) In Linux, open a terminal from where the DUP is located and execute it, and follow the prompts


Input Data
",DUPs launch and the FW update process starts,,,,,
,,,,,,3,"Description
Once the FW update is completed, make sure to check from the OS if the device shows up with the correct FW

If you are using a Gen3 device, you will be prompted to reboot
If you are using a Gen4 device, reboot will not be required

Windows Servers have different behavior, please check with the project lead for exact behvior on reboot prompts


Input Data
",FW update applied in Step #2 is visible and device is at correct Firmware,,,,,
,,,,,,4,"Description
Follow the steps #2 and #3 for Firmware Downgrade

Input Data
",,,,,,
PCIe SSD : Persistent Event Log-  NVM Subsystem Hardware Error logging check,TC-62832,Active,Manual,,,1,"Description
Boot to an OS that supports DPC with at least one NVMe device supporting PEL(Check Identify response). 

Input Data
",The device boots without any errors. ,ESG-TC-124777,,,,
,,,,,,2,"Description
Issue Persistent event log command to the respective device and store the log in a file for later issue.
For example 
python3 NVMeIOCTCLI.py -gl bdf 

NSID = 0x0
LID= 0x0d
subpage = 0x0
num of dwords = 0x0
event notification = 0x0



Input Data
",The command get's executed successfully without any errors.  ,,,,,
,,,,,,3,"Description
Inject UR error on the device 

setpci -s bdf 0x10.w=0xffff






Input Data
",The device goes through DPC recovery,,,,,
,,,,,,4,"Description
Go to step 2 and dump the log. 
Make sure to save the log in different files. 
Compare the two logs


Input Data
",The new event for NVM subsystem Hardware Error Event  correctly logged in the Persistent Event Log with event code as 0x05,,,,,
PCIe SSD: PCIe VDM Enablement Check,TC-62905,Active,Manual,To verify if the NVMe device has PCIe VDM Support.,,1,"Description
Dump the FRU of the PCIe SSD (preferably via automation script 'GetPCIeSSDFRU.py'). Eg:

python3 GetPCIeSSDFRU.py

Then, save the output to a file.


Input Data
",FRU Data is collected.,ESG-TC-130635,,,,
,,,,,,2,"Description
Check the MCTP Support Bit is set to 1 in NVMe PCIe MultiRecord Area.

Input Data
",MCTP Support Bit is set to 1 confirms that PCIe VDM is supported on the device.,,,,,
PCIe SSD : Persistent Event Log-  Sanitize operation logging check,TC-64013,Active,Manual,,,1,"Description
Boot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). 

Input Data
",The device boots without any errors. ,ESG-TC-121549,,,,
,,,,,,2,"Description
Issue Persistent event log command to the respective device and store the log in a file for later issue.
For example 
python3 NVMeIOCTCLI.py -gl bdf 

 NSID = 0xffffffff
LID= 0x0d
subpage =0x0
num of dwords = 0x7f



Input Data
",The command get's executed successfully without any errors.  ,,,,,
,,,,,,3,"Description
Issue Sanitize command to the drive . 
For example

python3 NVMeIOCTCLI.py -sn bdf 




Input Data
",Sanitize operation successfully completed without any errors. ,,,,,
,,,,,,4,"Description
Issue Controller reset, then Go to step 2 and dump the log. 
Make sure to save the log in different files. 
Compare the two logs


Input Data
",The new event for Sanitize correctly logged earlier in the Persistent Event Log data,,,,,
PCIeSSD - NVMe Device Self-Test,TC-64172,Active,Manual,The purpose of this test case is to ensure the NVMe device supports and can successfully complete a Device Self-Test,,1,"Description
Boot to a supported operating system with at least  one NVMe device in the system

Input Data
",The NVMe drive detects the device and it's seen within the OS,ESG-TC-93512,,,,
,,,,,,2,"Description
Issue an Identify Controller command to the drive(s)

Input Data
","The ""Optional Admin Command Support"" field (offset 257:256) shows that bit 4 is set",,,,,
,,,,,,3,"Description
Issue a Device Self-Test command with the ""Self-test Code"" set to 0x01 in order to initiate a short DST

Input Data
",The command completes successfully,,,,,
,,,,,,4,"Description
Issue an Identify Controller command and read the ""Extended Device Self-test Time"" field (offset 317:316)

Input Data
",The value read is non-zero,,,,,
,,,,,,5,"Description
Issue a Device Self-test command with the ""Self-test Code"" set to 0x02 in order to initiate an extended DST

Input Data
","The command completes successfully and takes no longer than 20% of the value specified from step 4. For example, if the value from step 4 says 5 minutes, then the test should take no longer than 6 minutes.",,,,,
"PCIe SSD: A/C Cycle with Controller Reset, SBR, PERST (Linux Only)",TC-65342,Active,Manual,,,1,"Description
Boot into a supported operating system with at least one 2.5"" PCIe SSD.

Input Data
",Implicit.,ESG-TC-110710,,,,
,,,,,,2,"Description
Make sure that PCIe SSD is connected to Qurach module and system is connected to APC outlet.

Input Data
",The device is discovered is functional in the OS.,,,,,
,,,,,,3,"Description
Write a script to:

1.     Issue Controller Reset to the PCIe SSD

Using nvmecli: nvme reset /dev/nvme0n1

Using framework: python3 NVMeIOCTL.py -rc B:D.F

2.     Wait 10s

3.     Issue a Secondary Bus Reset the PCIe SSD:

a.     Cause a Secondary Bus Reset (bit 6 - Bridge Control Register) by writing a 1

b.     Wait 3s

c.     Make sure the link is x0, Gen-1

d.     Take the device out of reset by writing a 0

e.     Wait 10s

f.      Make sure the link width and speed is the maximum capable for the PCIe SSD

e.   The link width and speed is the maximum capable for the PCIe SSD 

1.                4.  Wait 10s. 

1.                 5. Issue PERST to the PCIe SSD:

a.     Unload the NVMe Driver to prevent a UR

b.     Assert PERST to the drive using Quarch

c.     Wait 10s

d.     Make sure the link was fully disabled

e.     De-assert PERST to the drive using Quarch

f.      Verify that drive is available, and no smart warning is issued and drive is Gen 3, x4

g.     Load NVMe driver

2.                  6. Wait 10s

for 15 loops. After each loop. make sure that device is trained to maximum link width and speed. After 15 loops, perform A/C cycle to the system. Repeat this for 12 hours. 



Input Data
",The script runs successfully with no errors.,,,,,
PCIe SSD: Read only Firmware slot (Slot1),TC-65940,Active,Automation,Read only Firmware slot (Slot1),,1,"Description
Install NVMe devices and boot to the OS

Input Data
",The system is booted and no relevant errors are reported in the OS logs. ,ESG-TC-73832,,,,
,,,,,,2,"Description
Issue Identify controller to the device and get the response.
nvme-cli (linux only) or NVMeIOCTL (Automation Framework) can be used. 


Input Data
",The drive responds with Identify Controller data structure. ,,,,,
,,,,,,3,"Description
Check for the ""Firmware Updates"" field that is byte 260. 

Input Data
",The drive reports firmware slot 1 to be read only. ,,,,,
PCIe SSD: ASPM control,TC-71793,Active,Manual,"Dell systems disable Active State Power Management (ASPM) - No L0 or L1 support, regardless if the PCIe SSD supports it",,1,"Description
Verify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-296,,,,
,,,,,,2,"Description
Install at least one NVMe PCIe SSD in the system.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Power on the system and dump PCIe config space for the PCIe SSD. Verify ASPM is disabled.

Input Data
",Link Control Register bits 0 and 1 are set to 0 (disabled),,,,,
Namespace check after IO and Hot Reset & MI with Sudden Power Loss,TC-73119,Active,Manual,"This test case checks for the namespace availability after performing IO and Hot Reset, followed by running MI traffic with Sudden Power Loss. ",,1,"Description
Boot to the OS with at least 2 NVMe SSD installed

Input Data
",System boots up without any errors and all devices are discovered ,ESG-TC-89858,,,,
,,,,,,2,"Description
Delete all the partitions on the drives to be tested

Input Data
",The partitions are deleted and raw volume is available. ,,,,,
,,,,,,3,"Description
Start heavy IO on the drives

Input Data
",IO runs without any issue ,,,,,
,,,,,,4,"Description
Issue a Hot reset to the drives (Secondary Bus Reset can be used) 

Input Data
",The drives goes through reset and Namespace is still available,,,,,
,,,,,,5,"Description
Start MI traffic to the drives along with IO running 

Input Data
",No issue running MI commands and drive responds without any errors ,,,,,
,,,,,,6,"Description
Issue a DC cycle for the Sudden Power Loss scenario for the drives 

Input Data
",The system goes through a power cycle and OS boots back without any issue,,,,,
,,,,,,7,"Description
Check if all devices are discovered and available 

Input Data
",All devices shows up ,,,,,
,,,,,,8,"Description
repeat steps 3-8 50 times 

Input Data
",No errors reported ,,,,,
PCIe SSD: Mixed Read/Write/DSM workload (Linux Only),TC-73472,Active,Manual,"Run read, write and trim commands to a device in equal quantities.",,1,"Description
Start Reads, Writes, and Trim operations to the drive at the same time, running for 1 minute.

note - Due to lack of dsm support on Windows, this test can only be run under Linux.


Input Data
","All reads, writes, and Trim operations complete successfully",ESG-TC-110638,,,,
PCIe SSD: Persistent Event Log Collection  (Linux Only),TC-74677,Active,Manual,The test case checks the command response of the Persistent Event Log from the drive and also checks if the data is valid. ,,1,"Description
Boot to supported operating system with at least one NVMe device. 

Input Data
",The nvme device get's detected and enumerated by OS,ESG-TC-120769,,,,
,,,,,,2,"Description
Issue identify controller to the device. 
For example 
python3 NVMeIOCTLCLI.py -ic bdf


Input Data
","Check byte 261 bit 4 of LPA or else look at the decoded response of IC. 
The bit should be set advertising PEL support",,,,,
,,,,,,3,"Description
Issue get log page command with log page id 0xd for persistent event log 

For example:
python3 NVMeIOCTLCLI.py -gl bdf

NSID=0
LID=0xd
subpageid=0
numofdwords=0x7f
RAE=0


Input Data
","The  device responds with required Persistent Event log. 
Make sure the header fields are correct like Log identifier,model number,POH and supported event. 
Make sure device advertise all event as per requirement document. 
Contact device lead for the information. ",,,,,
PCIeSSD SSD DUP: FW Downgrade via iDRAC GUI w/ multiple devices,TC-78641,Active,Manual,,,1,"Description
Install at least two PCIe SSDs with PCIe VDM support (preferably of same model with latest firmware versions).

To check for VDM support:
python3 GetPCIeSSDFRU.py and check MCTP Support Bit is set to 1

Note: System must be 15G Intel or 15G AMD with Milan CPU and must support iDRAC version 5.0.0.0 or greater and has root shell access. 


Input Data
",Drive is installed without any issue.,ESG-TC-130631,,,,
,,,,,,2,"Description
If testing with iDRAC version is 5.0.0.0, cold boot the system.
If testing with version is 5.10.00.0 or greater, omit this step. 


Input Data
",,,,,,
,,,,,,3,"Description
Get the BDF of the PCIe SSD from OS. SSH into iDRAC as rootshell and check that these BDF's are listed in BDF Discovery List of /var/log/bop.log.



Input Data
",Device BDF's are listed in iDRAC log.,,,,,
,,,,,,4,"Description
Launch the iDRAC GUI, go to Maintenance / System Update and Upload n-1 FW DUP for the PCIe SSD. Once you get success for the download, go ahead and select the ""Install"" button.

NOTE: If you see Install and Reboot, Install Next Reboot buttons, it is an issue.

Pop up will be displayed, go ahead and select Job Queue button. On the Job Queue page, verify the job is marked completed for all the PCIe SSD to which DUP applies.

Input Data
",Verified that the DUP package uploads successfully and both the job passed with no issues.,,,,,
,,,,,,5,"Description
Go to Maintenance / Lifecycle Logs and verify that you see below entries for each PCIe SSD.
   1. SUP0516 (Updating Firmware for PCIe SSD in Slot X in Bay Y to version n-1).
   2. SUP0518 (Successfully Updated the PCIe SSD in Slot X in Bay Y firmware to version ,version n-1>).
   3. PR36 (Version change detected for PCIe SSD in Slot X in Bay Y firmware. Previous version: <version n>, Current version: <version n-1>).


Input Data
",User verified LC logs reported the correct entry for each PCIe SSD.,,,,,
,,,,,,6,"Description
Go to Storage / Overview / Physical Disks and expand the drives you just updated and check for Revision property, verify it reports the correct FW version that was just updated to. Make sure to verify this for all drives you updated.

Go to System / Inventory / Firmware Inventory and for each drive you updated, verify it reports the new FW version you just updated to. Make sure to verify this for all drives you updated.

Go to OS and verify that new FW version is reported on all drives you updated.

Input Data
","User verified storage inventory reported the correct FW version for all drives.

User verified FW inventory reported the correct FW version for all drives.

User verified that OS reported the correct FW version for all drives.",,,,,
,,,,,,7,"Description
Repeat steps 3-7 after performing hotplug operation to PCIe SSDs.

Input Data
",Firmware is updated successfully after hotplug.,,,,,
PCIe SSD: Firmware Download with Controller Reset (Linux Only),TC-81104,Active,Manual,,,1,"Description
Boot to a supported operating systems with at least one PCIe SSD. 

Input Data
",PCIe SSD is discovered and link is fully trained to maximum width and speed.,ESG-TC-110707,,,,
,,,,,,2,"Description

 Write a script to: 

1.     Issue FW download to the PCIe SSD. You can get the binary or tar file of the FW by extracting its DUP.

Using nvmecli: nvme fw-download /dev/nvme0n1 -f FW.bin

Using framework: python3 NVMeIOCTL.py -fd B:D.F <path to FW file>

2.     Issue Controller Reset to the PCIe SSD. 

Using nvmecli: nvme reset /dev/nvme0n1

Using framework: python3 NVMeIOCTL.py -rc B:D.F

3.     Unload NVMe Driver. In linux, it can be done by issuing modprobe -r nvme. In windows, use framework.

4.     Load NVMe Driver. In Linux, it can be done by issuing modprobe nvme. In windows, use framework.

for 12 hours. After each loop, make sure device is discovered. If it doesn't, exit the script with a a failure.




Input Data
",The script runs for 12 hours successfully.,,,,,
PCIe SSD : Persistent Event Log-  Thermal Excursion event logging check,TC-82712,Active,Manual,,,1,"Description
Boot to a supported OS with at least one NVMe device supporting PEL(Check Identify response). 

Input Data
",The device boots without any errors. ,ESG-TC-125195,,,,
,,,,,,2,"Description
Issue Persistent event log command to the respective device and store the log in a file for later issue.
For example 
python3 NVMeIOCTCLI.py -gl bdf 

 NSID = 0xffffffff
LID= 0x0d
subpage =0x0
num of dwords = 0x7f



Input Data
",The command get's executed successfully without any errors.  ,,,,,
,,,,,,3,"Description
Check if the Thermal event is supported by reading the NVMe header section of the PEL log.





Input Data
","The device supports the event and if the device doesn't support the event then this test case is N/A.
Check with the device lead for the same.
",,,,,
,,,,,,4,"Description
The device composite temperature is allowed to cross WCTEMP.
Use any applicable method to achieve this.


Input Data
","The thermal excursion get's logged and all the fields correctly displayed.
",,,,,
PCIe SSD: TCG Opal - Activate Locking SP and changing admin PIN  (Linux Only),TC-85464,Active,Manual,"/*must do this on new drive or after revert:  enables OPAL Admin1 authority with MSID credentials */
/* note that both SID and Admin1 authorities have MSID credentials after activate.",,1,"Description
Boot to a linux system with supported TCG Opal drive 

Input Data
",The system boots and drive is visible to the OS without any errors,ESG-TC-116242,,,,
,,,,,,2,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side IO 


Input Data
",The traffic to the device is started without any issue,,,,,
,,,,,,3,"Description
Issue a discovery command and make sure the locking is not enabled.
EX- 
./sedlib -a q -d /dev/nvme0n1 -x nvme


Input Data
",The Feature 0x2 shows the drive locking is not enabled,,,,,
,,,,,,4,"Description
Issue an activate SP command to enable locking of the device for Admin1 authority
Ex- where (MSID_password is the key to enable locking)
./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme


Input Data
",The command completes successfully without any errors. ,,,,,
,,,,,,5,"Description
Issue a level 0 discovery command again to check if locking is enabled. 
Ex-
./sedlib -a q -d /dev/nvme0n1 -x nvme


Input Data
","The discovery data now shows locking is enabled. 
Locking Enabled: 1
",,,,,
,,,,,,6,"Description
Change the PIN of the admin to a new PIN and upon successful completion change back to the original 

Ex for reference only :

./sedlib -a cp -w admin1 -o S6X053AJH9T6GLEHJEVD0QCYS8C0N7R9 -P S6X053AJH9T6GLEHJEVD0QCYS8C0N7R8 -d /dev/nvme0n1 -x nvme


Input Data
",The PIN was changed successfully and then restored back to original key,,,,,
PCIe SSD: Delete original NameSpace and recreate an identical NameSpace,TC-85634,Active,Manual,The test case checks the device for Namespace management support ,,1,"Boot to the supported OS with device supporting Namespace management
",The devices shows up in OS and no errors  were reported in SMART and OS logs,ESG-TC-115105,,,,
,,,,,,2,"Issue an Identify Namespace command to the drive and take a note of the: Namespace Size.

python3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value",The command completes successfully and the value is saved,,,,,
,,,,,,3,"Detach the current single namespace.
Ex- python3 NVMeIOCTLCLI.py -dtns <bdf>

Reset the controller (do this since not all drives support dynamic namespace change reporting)
python3 NVMeIOCTLCLI.py -rc <bdf>",Both commands are successful,,,,,
,,,,,,4,"Delete the current single namespace 
python3 NVMeIOCTLCLI.py -dlns <bdf>","The command is successful and the block device is gone.

Ex - lsblk no longer shows the drive",,,,,
,,,,,,5,"Create a new namespace of the same size as noted in Step 2
Ex- python3 NVMeIOCTLCLI.py -crns <bdf>

Attach the newly created namespace
Ex- python3 NVMeIOCTLCLI.py -atns <bdf>

Reset to controller (do this since not all drives support dynamic namespace change reporting)
python3 NVMeIOCTLCLI.py -rc <bdf>

","All commands were successful and the drive block device is now enumerated


Ex - lsblk now shows a new drive",,,,,
,,,,,,6,"Issue an Identify Namespace command to the drive and take a note of the: Namespace Size

python3 NVMeIOCTCLI.py -id <bdf> # then select 1 as the NSID value",The Namespace Size has the same value as in step 2,,,,,
PCIe SSD: NVMe shutdown notification across D3hot transition (Windows Only),TC-87469,Active,Manual,Verify PCIe SSD transitions out of D3hot correctly.,,1,"Description
Verify that the system is updated with the latest revisions for iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-245,,,,
,,,,,,2,"Description
Install at least one NVMe PCIe SSD in the system.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Setup a PCIe analyzer to capture the PCIe traffic for the PCIe SSD D3hot transition.

Input Data
",Implicit.,,,,,
,,,,,,4,"Description
Start capturing the PCIe trace. Power on the system and put the PCIe SSD in D3hot. Stop PCIe trace capture.

Input Data
","PCIe trace shows CC.SHN = 01b to indicate normal shutdown operation

PCIe trace shows CC.SHST = 10b to indicate shutdown is complete",,,,,
,,,,,,5,"Description
Start capturing the PCIe trace. Transition the PCIe SSD out of D3hot. Stop the PCIe trace capture.

Input Data
",Verify the PCIe SSD does not reset when transitioning out of D3hot (PMCSR No_Soft_Reset = 1),,,,,
PCIe SSD: TCG Opal - Revert SP to restore the drive state (Linux Only),TC-87655,Active,Manual,,,1,"Description
Boot to Linux OS with a TCG Opal enabled device 

Input Data
","The OS boots without any errors and device is visible to OS.
Make sure this test case is run after device is fully configured and locked ",ESG-TC-116254,,,,
,,,,,,2,"Description
Set SID credentials which can be used to revert the device state . 
Try to put same MSID as new key to avoid losing key
EX-
./sedlib -a cp -w sid -o MSID_password -P MSID_password -d /dev/nvme0n1 -x nvme


Input Data
",The SID key is set without any issues ,,,,,
,,,,,,3,"Description
Do a device discovery and make sure device is locked, if not already locked.  Also write some data to the device.
nvme write -s 0 -z 512 -d user_data.txt /dev/nvme0n1

Issue a revert SP command using admin as SP and sid as user (admin or psid can also be used)
./sedlib -a rev -S admin -u sid -P MSID_password -d /dev/nvme0n1 -x nvme


Input Data
",The command get's completed successfully ,,,,,
,,,,,,4,"Description
Issue a discovery command and make sure the device state goes to initial state without SP enabled and unlocked. 
./sedlib -a q -d /dev/nvme0n1 -x nvme
Also check the data written to the device earlier. 


Input Data
","The device is restored to it's initial state and all data erased as well.
Do a read of the data written
nvme read -s 0 -z 512 -d nvme0n1_read.bin /dev/nvme0n1

All data returned should be 0.
",,,,,
PCIe SSD: TCG Opal - Re key while running I/O to the device (Linux Only),TC-87961,Active,Manual,This test case checks locking and unlocking of global range to be used by EKMS solution ,,1,"Description
Boot to the Linux OS with TCG Opal enabled device

Input Data
",The OS boots without any issue and device is accessible.,ESG-TC-124343,,,,
,,,,,,2,"Description
Check if device is enabled for locking by doing query. 
Ex- ./sedlib -a q -d /dev/nvme0n1 -x nvme
If not enabled then activate SP 
./sedlib -a asp -P MSID_password -d /dev/nvme0n1 -x nvme

The default password is set as MSID and can be retrieved via below command
./sedlib -a pm -d /dev/nvme0n1 -x nvme



Input Data
",The device is activated for locking ,,,,,
,,,,,,3,"Description
Start running I/O to the device 
Ex- ./diskio -f /dev/nvme0n1 -b 128k -t 10



Input Data
",The I/O starts running on the device ,,,,,
,,,,,,4,"Description
Change the key of the device 
Ex-
./sedlib -a cp -w admin1 -o MSID_password -P MSID_passwordnew -d /dev/nvme0n1 -x nvme





Input Data
",The pass key get's changed without any issue.  ,,,,,
,,,,,,5,"Description
Check the status of I/O running from step 3

Input Data
",The I/O continues to run uninterrupted. ,,,,,
,,,,,,6,"Description
Change the key of the device to default passkey
Ex-
./sedlib -a cp -w admin1 -o MSID_passwordnew -P MSID_password -d /dev/nvme0n1 -x nvme




Input Data
",The key is changed back to default key i.e MSID,,,,,
PCIe SSD: Firmware activation without reset,TC-89513,Active,Manual,"NVMe devices must support Firmware Activation without Reset. Requiring a reset under any condition should be
avoided if possible
",,1,"Description
Install NVMe device in the system and boot to the supported OS 

Input Data
",The system boots up without any relevant error in OS logs,ESG-TC-73996,,,,
,,,,,,2,"Description
Issue identify controller command to the device and check if firmware activation without reset is supported and also note down current firmware version. nvme-cli(linux only) or NVMeIOCTL (Automation Framework) can be used. 

Input Data
",The drive reports that firmware activation without reset is supported ,,,,,
,,,,,,3,"Description
Issue firmware download command with right payload/binary path. 
Same tool as above can be used. 


Input Data
",The command completes successfully without any failure. ,,,,,
,,,,,,4,"Description
Issue firmware activation command with slot to be activated and firmware commit action to be 3. 

Input Data
",Command completes successfully without any errors,,,,,
,,,,,,5,"Description
Issue identify controller and check firmware revision 

Input Data
",The firmware provided for the flash was activated. ,,,,,
PCIe SSD: Hot insert: Completion Time out value from boot on hot insertion,TC-90540,Active,Manual,"Verify that the CTO value from boot, on hot insertion as per specification.",,1,"Description
Boot to the OS with a drive installed in the system.

Input Data
",Implicit.,ESG-TC-167,,,,
,,,,,,2,"Description
Perform the following steps:

- Dump the PCI registers of the endpoint device

- Check the range of completion time out value under Device Control 2 register (bit location 0-3)

- Surprise remove the device

Input Data
","Check if the value is programmed as per the spec, which states a value of 0x6 (65ms - 210ms)",,,,,
,,,,,,3,"Description
Hot insert the device and dump the PCI register and check the time out value again.

Input Data
","The value is reprogrammed on hot insertion as per the spec, 0x6 (65ms - 210ms)",,,,,
PCIe SSD: TCG Opal NVMe MI- CSTS.RDY check for 60sec delay when locked,TC-93915,Active,Manual,"This test case checks locking and unlocking of global range to be used by EKMS solution 
The test firmware is placed here. 
\\S3bnsx01nas05.amer.dell.com\RAIDSERVER\NVMe\NVME_PCIeSSD\NVMe_SEKM\iDRACTCGOpaltestfirmware

",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Note: This test case needs to be run on a drive where either security was never enabled or has gone through revert operation prior.

Input Data
",The OS boots without any issue and device is accessible.,ESG-TC-127297,,,,
,,,,,,2,"Description
Check CAP.TO value available part of MMIO space. Any tool can be used.

For example:
python3 NVMeIOCLTCLI.py -mr bdf

Input Data
sudo ",Note down the CAP.TO value before enabling security. ,,,,,
,,,,,,3,"Description
SSH into the iDRAC supporting side band tool for TCG Support into rootshell

If performing tests first time after iDRAC reboot run following 2 commands
setenforce 0
testlibsednvme


Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,4,"Description
Activate and Lock the device for the global range (whole device) using user as admin via side band

controller id should be determined from identify controller response
The user is Admin and the value passed should be 1
testlibsednvme Dellenablesecurity <eid> <controller id> <new key> <key length> 1

 testlibsednvme lock <eid> <controllerid> <key> <keylength> <user>

For example :
testlibsednvme lock 6 0 Dell123456 10 1

Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","The device is locked and command completes successfully. 
Run query command to confirm. 

For example 
testlibsednvme query 6 0

Output:
locked = 1
locking supported = 1
locking enabled = 1
",,,,,
,,,,,,5,"Description
Hot remove the drive and hot insert it back. 
Check OS log 


Input Data
","Note down the time at which hot plug interrupt was generated and when the controller becomes ready (OS starts polling for queues and block layer)
If this couldn't be determined via OS logs please collect PCIe trace to verify CSTS.RDY turning 1 after ~60 sec from the time CC.EN =1 ",,,,,
,,,,,,6,"Description
Check CAP.TO value available part of MMIO space. Any tool can be used. 

For example:
python3 NVMeIOCLTCLI.py -mr bdf


Input Data
","The CAP.TO value is set to 60 sec or greater 

Note :
CAP.TO field have value in units of 500ms. So, make appropriate conversion. 
",,,,,
,,,,,,7,"Description
Issue a revert operation to bring the device to default state. 

testlibsednvme revert <eid> <controllerid> <key> <key_length> 0


Input Data
",Issue query to make sure security is disabled. ,,,,,
,,,,,,8,"Description
Activate and lock device in band . 

For example 
./sedlib -a asp -P <MSID> -d /dev/nvme0n1 -x nvme

./sedlib -a l -B 0 -P MSID -d /dev/nvme0n1 -x nvme


Input Data
","Issue query to determine if device is locked. 
./sedlib -a q -d /dev/nvme0n1 -x nvme

",,,,,
,,,,,,9,"Description
Hot remove the drive and re insert.
Check the OS logs or verify via other methods if device has been gone ready i.e CSTS.RDY bit set to 1 in less than 60 sec. 


Input Data
",The CSTS.RDY got set to 1 in less than or equal to 56 sec,,,,,
,,,,,,10,"Description
Check CAP.TO value available part of MMIO space. Any tool can be used.

For example:
python3 NVMeIOCLTCLI.py -mr bdf

Input Data
","The CAP.TO value is less than or equal to 56 sec.

Note :
CAP.TO field have value in units of 500ms. So, make appropriate conversion. ",,,,,
Sudden Power Loss during Crypto Erase with FPI check,TC-94994,Active,Manual,"The test case checks the update of Format Progress Indicator when a SPO (Sudden Power Loss) event happen while crypto erase is in progress. 

",,1,"Description
Boot to the OS with at least 2 NVMe SSD installed 

Input Data
",System boots up without any errors and all devices are discovered. ,ESG-TC-89559,,,,
,,,,,,2,"Description
Create a partition on a drive and write at least 30 GB data to it 

Input Data
",Partition is created and data is successfully written ,,,,,
,,,,,,3,"Description
Start running Crypto Erase in the back ground 

Input Data
",Crypto Erases are successfully completing ,,,,,
,,,,,,4,"Description
Perform Sudden Power Loss for drive (DC cycle through IDRAC does) 

Input Data
",drive goes through power cycle,,,,,
,,,,,,5,"Description
Check FPI (Format Progress Indicator) by issuing Identify Namespace Command

Input Data
",The value of FPI is zero if the field is supported by the device. ,,,,,
PCIe SSD: TCG Opal NVMe MI - Enable/Disable Security on NVMe SEDs Stress testing,TC-96322,Active,Manual,"The test case enables security on the device. It encompases several operations in the process like read MSID, activate SP, write data store, rekey ",,1,"Description
Boot to an operating system and make sure all devices are visible in the OS

Note: This test case needs to be run once locking has not been enabled on the device or it has gone through revert operation


Input Data
","The system boot successfully and device discovered by OS. 
Perform some basic IO to make sure device is functional.",ESG-TC-132950,,,,
,,,,,,2,"Description
SSH into the iDRAC having test firmware for TCG Support into rootshell

If performing tests first time after iDRAC reboot run following 2 commands
setenforce 0
testlibsednvme


Input Data
",The eid for the corresponding slot is determined from the mapping printed at the bottom of the help section,,,,,
,,,,,,3,"Description
Start running I/O + Admin command to the device. 
admin command like identify or get log page could be run in a loop along side IO
Issue following command to query the drive of it's state


controller id should be determined from identify controller response in OS
testlibsednvme query


For example:

testlibsedclient query 6 0


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","Locking enabled is turned off 
For example:
locking enabled = [0]

If the locking is enabled make sure to run revert test case prior to running this. ",,,,,
,,,,,,4,"Description
Enable Security on the device by running following command. Provide a key and make sure you note it so that it doesn't get lost. 
Provide user as Admin and it should be 1

testlibsednvme DellEnableSecurity <eid> <controllerid>  <key> <keylength> <user>
Also make sure function return code is 0

For example 
testlibsednvme DellEnableSecurity 6 0 Dell123456 10 1


Note : This is just an example change according to your device
Sending command to wrong eid can result in hang and racreset is required


Input Data
","The enable security operation is completed , make sure locking enabled turned to 1 and also current keyid has same value as you entered in the key. 

For example 
locking supported = [@1]
locking enabled = [@1]
datastore size = [10485760]
datastore flag = [@2]
old_keyId = [MSID KEY]
current_keyId = [Dell123456]
",,,,,
,,,,,,5,"Description
Wait for 1 minute and Disable Security by issuing Revert 
Use the same key to issue revert which was used for enabling security 
Go to step 4 and repeat for at least 20 times


Input Data
",Operations are successful in all steps.,,,,,
PCIe SSD: Power State Control via NVMe-MI w/ I/O Stress,TC-101686,Active,Automated,The test case is used to validate that NVMe drives can successfully transition (via NVMe-MI) to and from all supported power states while continuing to service I/O.,,1,"Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the ""Number of Power States Supported"" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.",The drives are installed and recognized by the host OS.,,,,,
,,,,,,2,Start I/O stress to the NVMe drives which support power states.,I/O is being processed successfully,,,,,
,,,,,,3,"Lower the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the ""-sf"" option to indicate a Set Features command. Use the ""Power State"" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.","The Set Features command to change the power state was successful, and the I/O continues to be processed.",,,,,
,,,,,,4,"Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the ""-gf"" option to indicate a Get Features command. Use the ""Power State"" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.","The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously.",,,,,
,,,,,,5,"Repeat steps 3 and 4 until no power states are remaining.

NOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.",Same results as in steps 3 and 4,,,,,
,,,,,,6,"Raise the power state by 1 value on each drive. You can do this by using the NVMeMICLI tool with the ""-sf"" option to indicate a Set Features command. Use the ""Power State"" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.
","The Set Features command to change the power state was successful, and the I/O continues to be processed.
",,,,,
,,,,,,7,"Read the current power state on each drive. You can do this by using the NVMeMICLI tool with the ""-gf"" option to indicate a Get Features command. Use the ""Power State"" feature ID. Also, make sure to use the -b and -s options to ensure the command is sent via SMBus as opposed to PCIe VDM.
","The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously.
",,,,,
,,,,,,8,"Repeat steps 6 and 7 until the drive is back at the default power state 0.

NOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.",Same results as in steps 6 and 7,,,,,
,,,,,,9,Stop the I/O stress to the NVMe drives,The I/O stops successfully,,,,,
PCIe SSD: Power State Control via NVMe w/ I/O Stress,TC-103781,Active,Automated,The test case is used to validate that NVMe drives can successfully transition (via NVMe) to and from all supported power states while continuing to service I/O.,,1,"Install NVMe drives which support multiple (greater than 1) power states. This can be confirmed by reading the ""Number of Power States Supported"" (NPSS) field in the Identify Controller output. NOTE that the field is 0-based, so 0 means there is 1 power state available.
","The drives are installed and recognized by the host OS.
",,,,,
,,,,,,2,"Start I/O stress to the NVMe drives which support power states.
","I/O is being processed successfully
",,,,,
,,,,,,3,"Lower the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the ""-sf"" option to indicate a Set Features command. Use the ""Power State"" feature ID.
","The Set Features command to change the power state was successful, and the I/O continues to be processed.
",,,,,
,,,,,,4,"Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the ""-gf"" option to indicate a Get Features command. Use the ""Power State"" feature ID.
","The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously.
",,,,,
,,,,,,5,"Repeat steps 3 and 4 until no power states are remaining.

NOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.","Same results as in steps 3 and 4
",,,,,
,,,,,,6,"Raise the power state by 1 value on each drive. You can do this by using the NVMeIOCTLCLI tool with the ""-sf"" option to indicate a Set Features command. Use the ""Power State"" feature ID.
","The Set Features command to change the power state was successful, and the I/O continues to be processed.
",,,,,
,,,,,,7,"Read the current power state on each drive. You can do this by using the NVMeIOCTLCLI tool with the ""-gf"" option to indicate a Get Features command. Use the ""Power State"" feature ID.
","The Get Features command is successful, and the current power state reflects the power state you just transitioned the drive to previously.
",,,,,
,,,,,,8,"Repeat steps 6 and 7 until the drive is back at the default power state 0.

NOTE: It's possible that some drives will advertise Non-Operational power states. We do not want to test those. In order to check for those, send Identify Controller and look at the power state descriptor section. If the NOPS bit is set, then do not use that power state.","Same results as in steps 6 and 7
",,,,,
,,,,,,9,"Stop the I/O stress to the NVMe drives
","The I/O stops successfully
",,,,,
PCIe SSD ESXi DPC: Error Injection at endpoint & it's upstream port  with EDR notification/recovery check (ESXi Only),TC-304,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. 

Run below command to enable ACPI logging
esxcli system settings kernel set -s acpiDbgLevel -v 2

(Could be verified by checking DPC control register of parent port above endpoint)



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-125734,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
vsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1

Here 196 = bus (in decimal) for the endpoint bdf

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/vmkernel.log


Input Data
","check if 
1) ""ACPI event 0xf"" is received
2) Port experienced DPC
3) Error recovery done

are logged in /var/log/vmkernel.log
",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Use following commands to determine the handle and issue identify

esxcli device driver list
esxcli nvme device get -A vmhba5


Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Inject error on up stream port . 
This can be done in many ways. 
For example 
Change MPS of up stream  port that is less than endpoint Max Payload Size
Run some I/O to the device


Input Data
","EDR notification sent to same events are noticed as in step 2
Make sure the device below the port is accessible and enumerated.",,,,,
PCIe SSD - UEFI Driver - ePSA UEFI Diagnostics,TC-784,Active,Manual,To test that the NVM_EXPRESS_PASSTHRU_PROTOCOL has been implemented by the UEFI driver,,1,"Description
Install at least one NVMe PCIe SSD in the system

Input Data
",Implicit,ESG-TC-160,,,,
,,,,,,2,"Description
Make sure to install the latest DUP for the ePSA UEFI Diagnostics utility

Input Data
",DUP installs successfully,,,,,
,,,,,,3,"Description
Boot into the ""F11 (Boot Manager)->System Utilties->Launch Diagnostics""

Input Data
",The ePSA utility opens,,,,,
,,,,,,4,"Description
Click the ""Configuration"" tab In the ""[PCIe]"" section, make sure that you see the NVMe device, and the PCIe Bridge Card (if there are 2.5"" PCIe SSD devices in the system) In the ""[Storage]"" section, find the hard drive(s) that have type ""NVMe""

Input Data
","The tab is present


The PCIe Bridge Card (if present) and all NVMe PCIe SSDs are listed and have the correct, ""Slot Number"" ""Vendor"" ""Device"" ""SubVendor"" and ""SubDevice"" IDs.


All devices are displayed as unique hard drives with the correct information, ""OEM"" ""product"" ""revision"" ""S/N"" ""type"" ""size"" ""CTRL""",,,,,
,,,,,,5,"Description
Double-click each of the NVMe PCIe SSD hard drive numbers (identified in step 4)

Input Data
","The tests run successfully and report the results to the ""Results"" tab

In the ""Results"" tab, if the device supports the NVMe Device Self-test command, then make sure that the results indicate that a DST Short or Long was ran in place of simply the SMART data",,,,,
PCIe SSD DPC: DPC Enablement Check,TC-1076,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into the OS

Input Data
",Implicit,ESG-TC-121129,,,,
,,,,,,2,"Description
Get all parent BDFs to the NVMe drives (regardless if the slots are populated).

If the system has a PCIe switch in it, then get then get the root port above the switch, switch upstream port, and all switch downstream ports.


Input Data
",All parent BDFs are obtained,,,,,
,,,,,,3,"Description
Dump PCIe config. space for each port that was found in the previous step

Input Data
","If the OS and Hardware Supports DPC (EDR), then the ""DPC Control Register's"" DPC Trigger Enable should be set to 0x2.

If the OS or Hardware do not Support DPC (EDR), then the DPC capability will not be found or, the ""DPC Control Register's"" DPC Trigger Enable should be set to 0x0.",,,,,
PCIe SSD DPC: Hot removal/insertion after single error Injection on same endpoint  (Linux Only),TC-1610,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. 
Check test case notes



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-121128,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
setpci -s bdf 0x10.w=0xffff 

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/message or syslog  


Input Data
","check if 
1) ACPI event 0xf received
2) containment event, status:0x1f03 source:0xe300
3) device recovery successful

are logged in /var/log/message ",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Hot remove the drive 

Input Data
",The device is removed and not visible both at PCI and NVMe level,,,,,
,,,,,,5,"Description
Hot insert the drive back in the same slot

Input Data
",device is enumerated properly,,,,,
PCIe SSD ESXi DPC: Hot removal/insertion after  error Injection on different endpoints  (ESXi Only),TC-3128,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. 

Run below command to enable ACPI logging
esxcli system settings kernel set -s acpiDbgLevel -v 2

(Could be verified by checking DPC control register of parent port above endpoint)



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-125737,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
vsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1

Here 196 = bus (in decimal) for the endpoint bdf

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/vmkernel.log


Input Data
","check if 
1) ""ACPI event 0xf"" is received
2) Port experienced DPC
3) Error recovery done

are logged in /var/log/vmkernel.log
",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Use following commands to determine the handle and issue identify

esxcli device driver list
esxcli nvme device get -A vmhba5


Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Repeat the steps 2-3 on a different end point


Input Data
","The devices are properly enumerated
",,,,,
,,,,,,5,"Description
Hot remove both the drives on which error was injected & recovered


Input Data
","The devices are removed and not visible both at PCIe and NVMe level
",,,,,
,,,,,,6,"Description
Hot insert the drives back in the same slots


Input Data
","The devices are enumerated properly both at PCIe level and NVMe block level
",,,,,
PCIe_SSD - Physical Slot Number parameter in Slot Capabilities register of host,TC-3362,Active,Manual,"Verify the 'Physical Slot Number' parameter in the Slot Capabilities register of the root or downstream-facing switch port is correctly programmed for each NVMe capable slot in the platform:  

31:27 - Zeroes

26 - Unique Bit Always Set to 1

25:24 - Bay ID

23:19 - Slot ID

Note this applies to SFF slots only; AIC slots should be omitted for this TC.
",,1,"Description
For each NVMe-capable SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.

E.g. In Linux, as root issue:

lspci -xxx -s c0:03.3
or
lspci -vvv -s c0:03.3 (for decoded output. Slot number is listed as Slot # under the SltCap register)

where 'c0:03.3' is the bdf of the root port attached to an NVMe device.

In Windows, the 'RW Everything' tool can be used to dump config space data.


Input Data
",The config space read is successful.,ESG-TC-119276,,,,
,,,,,,2,"Description
Compare the Physical Slot Number (bits 31:19) in the Slot Capabilities register:

31:27 - Zeroes

26 - Unique Bit Always Set to 1

25:24 - Bay ID

23:19 - Slot ID


to the expected value for each NVMe-capable SFF slot.


Input Data
","The Physical Slot Number info matches the expectation for each NVMe capable SFF slot in the system. See the attached file 'example_decode.txt' for an in-depth decode of the Slot Capabilities register in the raw hex config space data.

The Bay / Slot ID may be found from the Storage::Physical Disks menu in the iDRAC GUI; this info should match the decode from the Slot Capabilities register.",,,,,
PCIe SSD: HII Telemetry Log,TC-3397,Active,Manual,Verify HII Debug Log page displays the correct properties. Verify user is able to save the NVMe Telemetry log for all drives in the system that support that log page.,,1,"Description
Install at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)

If possible, install a device that does not support the Telemetry log page.


Input Data
","System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe).

If there's a drive that does not support Telemetry, then the option to perform a Telemetry Log capture should not exist in the HII.",ESG-TC-117670,,,,
,,,,,,2,"Description
Navigate to Telemetry Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).

Input Data
","1. Save Debug Log page will show the following options/fields:

Select File System target (header)

Select File System (link)


Select Directory (header)

Directory list selection


Export Log File path (header)

File path


Export Log (link)




2. All options/fields display corresponding help text at the bottom of the screen.
",,,,,
,,,,,,3,"Description
Select a file system target (ie. if there is more than one USB key inserted)

Input Data
","1. All attached file systems are listed under ""Select File System Target"". The default (root) directory should be selected by default.

2. ""Select File System Target"" (link) can be used to change currently selected File System.",,,,,
,,,,,,4,"Description
Select a directory.

Input Data
","1. All attached directories are listed under ""Select Directory"". The default (root) directory should be selected by default.

2. User can choose appropriate directory to save the file to under ""Select Directory"".

3. ""Select Directory"" (link) can be used to change currently selected Directory.",,,,,
,,,,,,5,"Description
Select Telemetry Log.

Input Data
","Message displayed is ""Log saved successfully. PCIeSSD_(date time string).log"".


For NVMe PCIe SSD log, User can choose the any filename with extension .log",,,,,
,,,,,,6,"Description
Retrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly.

Input Data
",The file size is non-zero,,,,,
,,,,,,7,"Description
Repeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).

Input Data
",Same results.,,,,,
PCIe SSD: FMP protocol,TC-4695,Active,Manual,Verify user can update firmware on a PCIe SSD in UEFI.,,1,"Description
Install one PCIe SSD in the system and boot into UEFI shell.

Input Data
",Implicit.,ESG-TC-128,,,,
,,,,,,2,"Description
Navigate to the directory where UpdateTest.efi is saved, and run ""UpdateTest.efi"" to get a list of controller handles. (UpdateTest.efi: download from Agile ENG0011622)

Input Data
","PCIe SSD is listed as a controller that supports UEFI update. The display name is ""Dell [NVMe] PCIe SSD Controller"".",,,,,
,,,,,,3,"Description
Execute getImageInfo(). ""UpdateTest.efi CtrlHdl"" where CtrlHdl is the controller handle for a PCIe SSD. Example: Step 2 reported Controller Handle CD for PCIeSSD. You would type ""UpdateTest.efi CD""

Input Data
","Package Version (int): ""0xFFFFFFFE""

Package Version (str): firmware package version running on the PCIeSSD


Remaining fields shall report values per Dell IHV and UEFI specs.",,,,,
,,,,,,4,"Description
Execute SetImage() to upgrade the firmware. Run ""UpdateTest.efi CtrlHdl -f firmware_img"".

Input Data
",Firmware starts flashing on the device. Activity LED is blinking on PCIeSSD. Return success.,,,,,
,,,,,,5,"Description
Reboot the system and verify firmware update flashed successfully. Perform some I/O to the device to ensure functionality.

Input Data
",Firmware flashed successfully. Device fully functional.,,,,,
,,,,,,6,"Description
Optional: Repeat step 6 and 7 but flashing to an older version of the firmware.

Input Data
",Same results.,,,,,
,,,,,,7,"Description
GetImage() and SetPackageInfo() are not required by Dell so vendor may have selectively chosen to not support these.

Input Data
",Implicit.,,,,,
PCIeSSD: Hotplug - Hot Insertion after Unhandled Removal,TC-7389,Active,Manual,The point of this test is to analyze the subsystem behavior when a device is immediately inserted after just have been removed.,-,1,"Description
Boot into the OS with at least one hot-pluggable PCIe SSD in the system

Input Data
",The PCIe SSD is discovered once in the OS,ESG-TC-97339,,,,
,,,,,,2,"Description
Surprise remove the PCIe SSD from the system

Input Data
",N/A,,,,,
,,,,,,3,"Description
Immediately re-insert the PCIe SSD back into the system

Input Data
",The PCIe SSD shows up in the OS and is functional,,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIe SSD: Link Disable during I/O Stress,TC-8867,Active,Manual,The purpose of this test case is to make sure that the system does not crash when the link is disabled while I/O is in progress.,,1,"Description
Determine the parent BDFs of all hot-pluggable NVMe drives in the system

Input Data
",Implicit,ESG-TC-123273,,,,
,,,,,,2,"Description
Begin running I/O stress on all hot-pluggable NVMe drives

Input Data
",The I/O is successful,,,,,
,,,,,,3,"Description
While the I/O is in progress, disable the link to the NVMe drives by writing a '1' to bit 4 of the parent BDF's Link Control Register

Input Data
","I/O stops
The NVMe drive is removed from the system
The system does not crash",,,,,
,,,,,,4,"Description
Re-enable the link by writing a '0' to bit 4 of all parent BDF's Link Control Register

Input Data
",The NVMe drives are re-enumerated by the OS,,,,,
PCIe SSD ESXi DPC:  Hot removal/insertion after single error Injection on same endpoint  (ESXi Only),TC-9604,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. 

Run below command to enable ACPI logging
esxcli system settings kernel set -s acpiDbgLevel -v 2

(Could be verified by checking DPC control register of parent port above endpoint)



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-125738,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
vsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1

Here 196 = bus (in decimal) for the endpoint bdf

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/vmkernel.log


Input Data
","check if 
1) ""ACPI event 0xf"" is received
2) Port experienced DPC
3) Error recovery done

are logged in /var/log/vmkernel.log
",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Use following commands to determine the handle and issue identify

esxcli device driver list
esxcli nvme device get -A vmhba5


Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Hot remove  the drive on which error was injected & recovered


Input Data
","The device is removed and not visible both at PCIe and NVMe level
",,,,,
,,,,,,5,"Description
Hot insert the drive back in the same slots


Input Data
","The device is enumerated properly both at PCIe level and NVMe block level
",,,,,
PCIe SSD: Inband Drive FRU Validation,TC-9694,Active,Manual,Unit Testing of FRU Objects created for PCIeSSD Card FRU Data.,,1,"Description
Plug in a mixture of form factor and device model NVMe drives and boot to an operating system. Wait 5-10 minutes once in the OS just to make sure the iDRAC is fully initialized.

Input Data
",All devices are detected,ESG-TC-159,,,,
,,,,,,2,"Description
Using ipmitool (or GetPCIeSSDFRU.py automation script), read the contents of the FRU for each NVMe device using the following commands:

U.2 devices (NOTE for Windows that, ""-I wmi"" will have to be added before the -U):
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x00 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x20 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x40 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x60 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0x80 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xA0 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xC0 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x00 bay slot 0x01 0xE0 0x00 0x20

AIC devices (NOTE for Windows that, ""-I wmi"" will have to be added before the -U):
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x00 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x20 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x40 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x60 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0x80 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xA0 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xC0 0x00 0x20
ipmitool -U root -P calvin raw 0x30 0x36 0x01 pciSlot 0x01 0x01 0xE0 0x00 0x20


Input Data
",All ipmi commands successfully pass and the FRU contents are saved for each device,,,,,
,,,,,,3,"Description
Using libi2ctest (or GetPCIeSSDFRU.py automation script), read the FRU for each NVMe device in the system using the following commands:

libi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256

NOTE if you're not using automation, then the I2C_bus_num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file from the iDRAC filesystem


Input Data
",All libi2ctest commands successfully pass and the FRU data is saved,,,,,
,,,,,,4,"Description
Compare the FRU data read from I2C in step 3 with the FRU data read from IPMI for each device

Input Data
",There should be no difference,,,,,
PCIe SSD - 14G Hot Insertion PERST# Logic Validation,TC-11407,Active,Manual,This test case will be used to determine the PERST# logic that applies when hot inserting an NVMe device is correctly functioning.,,1,"Description
Confirm from the test notes that this test case is applicable to your SUT

Input Data
",Implicit,ESG-TC-103745,,,,
,,,,,,2,"Description
Connect the NVME_PRES and PERST# signals to an oscilloscope

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Power on the server

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Configure the oscilloscope to trigger on the falling edge of NVME_PRES

Input Data
",Trigger enabled,,,,,
,,,,,,5,"Description
Configure the horizontal divisions to be 500ms

Input Data
",Implicit,,,,,
,,,,,,6,"Description
Configure the vertical divisions for both signals to be 1V

Input Data
",Implicit,,,,,
,,,,,,7,"Description
Hot insert an NVMe drive

Input Data
","The trigger occurs

Prior to the falling edge of NVME_PRES, PERST# was low
500ms after the falling edge of NVME_PRES, PERST# went high",,,,,
PCIeSSD: PCIe - Read Tracking on Bridge with Surprise Removal,TC-12242,Active,Manual,"This test case is intended to test the Read Tracking feature of the Dell PCIe Extender Card. In the event of an endpoint device suddenly not being available while a Non-Posted request is still outstanding, then normally a Completion Timeout would be generated. However, with the Read Tracking feature, a response of all Fs should be synthesized by the bridge downstream port, along with a Completer Abort event.",,1,"Description
Connect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled

Input Data
",Implicit,ESG-TC-67804,,,,
,,,,,,2,"Description
Boot into a supported operating system with a hotpluggable PCIe SSD in the system

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Note down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD

Input Data
","The MSI Address register is captured and should start with ""0xFEExxxxx""",,,,,
,,,,,,4,"Description
Start generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD

Input Data
",The PCIe Configuration Reads are being responded to,,,,,
,,,,,,5,"Description
Begin recording on the PCIe analyzer

Input Data
",The analyzer starts recording successfully,,,,,
,,,,,,6,"Description
Surprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests

Input Data
","The operating system does not crash and the PCIe SSD is removed from the OS
    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, ""Storage Controllers"" section
    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, ""lspci""
    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, ""lspci""",,,,,
,,,,,,7,"Description
Trigger the PCIe analyzer to stop recording

Input Data
",The trace is captured and uploaded to the test case,,,,,
,,,,,,8,"Description
From the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,9,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed

Input Data
","The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set",,,,,
,,,,,,10,"Description
From the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed

Input Data
","The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set",,,,,
,,,,,,11,"Description
From the PCIe trace, a Completer Abort is generated with a Completer ID equal to the endpoint PCIe SSD that was removed

Input Data
",Implicit,,,,,
,,,,,,12,"Description
From the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,13,"Description
From the PCIe trace, an ERR_FATAL message is generated by the parent of the PCIe SSD

Input Data
",Implicit,,,,,
,,,,,,14,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed

Input Data
","The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer Changed bit is set",,,,,
PCIe_SSD - Slot Power Limit parameters in Slot Capabilities register of host,TC-12564,Active,Manual,"Verify the 'Slot Power Limit Scale' and 'Slot Power Limit Value' parameters in the Slot Capabilities register of the root or downstream-facing switch port is correctly programmed for each NVMe capable slot in the platform: 

14:7 = 0xFA

16:15 = 0b01

If the values are programmed thusly, the power limit of the slot is set to 25 W.
",,1,"Description
For each SFF slot in the platform, dump the Slot Capabilities register of the root or downstream-facing switch port (as appropriate). The slot capabilities register is located at 0x14 of the PCI Express Capabilities structure.

E.g. In Linux, as root issue:

lspci -xxx -s c0:03.3

where 'c0:03.3' is the bdf of the root port attached to an NVMe device.

In Windows, the 'RW Everything' tool can be used to dump config space data.


Input Data
",The config space read is successful.,ESG-TC-119277,,,,
,,,,,,2,"Description
Compare the 'Slot Power Limit Scale' and 'Slot Power Limit Value' data (bits 16:7) to either of the following values:

14:7 = 0xFA

16:15 = 0b01


OR:


14:7 = 0x19

16:15 = 0b00


for each slot.


Both of these encoding corresponds to a limit of 25 W. In the first case, we have 0d250 * .1 = 25 W. In the second case, we have 0d25 * 1 = 25 W.


Input Data
","The 'Slot Power Limit Scale' and 'Slot Power Limit Value' are programmed as specified, indicating a slot power limit of 25 W.",,,,,
PCIe SSD - UEFI Driver - FQDD,TC-13227,Active,Manual,Will check that the PCIe SSD FQDDs have been implemented correctly,,1,"Description
Insert at least one PCIe SSD in the system and boot to an EFI-bootable USB key, preferrably one of each type of form factor (2.5"" and an add-in adapter card)

Input Data
",Implicit,ESG-TC-347,,,,
,,,,,,2,"Description
Type ""DlpDump.efi""

Input Data
","All PCIe SSDs in the system are discovered and they have FQDDs as follows:


If 2.5"":

Disk.Bay.XX:Enclosure.Internal.0-1:PCIeExtender.Slot.Y"" where XX is the backplane slot number and Y is the PCIe slot that the PCIe SSD Extender card is in


If Adapter Card:

PCIeSSD.Slot.X where X is the PCIe slot that the PCIe SSD is in",,,,,
PCIeSSD: Hotplug - Detailed Surprise Removal Verification,TC-14716,Active,Manual,This test case is intended to test the full surprise removal behavior of the PCIe SSD subsystem as well as the operating system.,,1,"Description
Connect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled

Input Data
",Implicit,ESG-TC-77955,,,,
,,,,,,2,"Description
Boot into a supported operating system with a hotpluggable PCIe SSD in the system

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Note down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD

Input Data
","The MSI Address register is captured and should start with ""0xFEExxxxx""",,,,,
,,,,,,4,"Description
If possible, disable or unload the PCIe SSD driver. The reason is to reduce the chances that any traffic will be outstanding to the PCIe SSD once it's removed.

Input Data
",The driver is disabled or unloaded,,,,,
,,,,,,5,"Description
Begin recording on the PCIe analyzer

Input Data
",The analyzer starts recording successfully,,,,,
,,,,,,6,"Description
Surprise remove the PCIe SSD that's being targeted with all of the Non-Posted requests

Input Data
","The operating system does not crash and the PCIe SSD is removed from the OS
    * Windows - The PCIe SSD immediately (within 5s) gets removed from the Windows Device Manager, ""Storage Controllers"" section
    * Linux - The PCIe SSD immediately (within 5s) goes away after running the command, ""lspci""
    * ESXi - The PCIe SSD immediately (within 5s) goes away after running the command, ""lspci""",,,,,
,,,,,,7,"Description
Trigger the PCIe analyzer to stop recording

Input Data
",The trace is captured and uploaded to the test case,,,,,
,,,,,,8,"Description
From the PCIe trace, find the first hotplug interrupt where the PCIe SSD was removed
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,9,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed

Input Data
","The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set",,,,,
,,,,,,10,"Description
From the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.

Input Data
","The Presence Detect State and Data Link Layer State Changed bits are cleared, and the Presence Detect State Changed bit is set",,,,,
,,,,,,11,"Description
From the PCIe trace, find the second hotplug interrupt where the PCIe SSD was removed
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,12,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was removed

Input Data
","The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set",,,,,
,,,,,,13,"Description
From the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was removed.

Input Data
","The Presence Detect State and Presence Detect State Changed bits are cleared, and the Data Link Layer State Changed bit is set",,,,,
PCIe SSD: Overnight I/O Stress,TC-15174,Active,Manual,TestDrive TestCase Objective was not specified.,,1,"Description
Clear the SEL

Input Data
",Implicit,ESG-TC-261,,,,
,,,,,,2,"Description
Run stress to all PCIe SSD devices using MLTT, iogen, or diskio overnight.

Input Data
",implicit.,,,,,
,,,,,,3,"Description
Review logs from all management applications, the test tool, and OS logs.

Input Data
",No errors in logs.,,,,,
,,,,,,4,"Description
Check the SEL for any correctable errors

Input Data
",No correctable errors are found,,,,,
PCIe SSD ESXi DPC: Operating system error threshold  check (ESXi Only),TC-15555,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. 

Run below command to enable ACPI logging 
esxcli system settings kernel set -s acpiDbgLevel -v 2

(Could be verified by checking DPC control register of parent port above endpoint)



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-126698,,,,
,,,,,,2,"Description
Set the threshold value to 10 using below command

esxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 10
and verify
esxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit


Input Data
",The OS error threshold is set to 10,,,,,
,,,,,,3,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
vsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1

Here 196 = bus (in decimal) for the endpoint bdf

or Malformed TLP can be injected using mismatched MPS settings.

Run some activity like
esxcli nvme device get -A vmhba3

Make sure you have another terminal with running OS log, 
tail -f /var/log/vmkernel.log


Input Data
","check if 
1) ""ACPI event 0xf"" is received
2) Port experienced DPC
3) Error recovery done

are logged in /var/log/vmkernel.log
",,,,,
,,,,,,4,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Use following commands to determine the handle and issue identify

esxcli device driver list
esxcli nvme device get -A vmhba5


Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,5,"Description
Repeat step 3-4  at least 11 times 

Input Data
","The driver for the corresponding device is unloaded and device is not visible anymore in the OS inventory. 

Check the device list
esxcli nvme device list",,,,,
PCIe SSD: SAS/SATA combo backplane with PCIe SSD,TC-15837,Active,Manual,Verify system correctly detects and handles incorrect drive type in combo backplane when PCIe SSD is installed in PERC slot.,,1,"Description
Make sure the SUT has a backplane that supports both SAS/SATA as well as NVMe slots

Input Data
",Implicit,ESG-TC-180,,,,
,,,,,,2,"Description
Install at least one PCIe SSD in a SAS/SATA slot and power on the system.

Input Data
","PCIe SSD is not detected in the system.

Status LED blinks identify pattern (Green on/off).

Lifecycle log reports incorrect drive type on slot detected ""Invalid Device Type Installed""",,,,,
,,,,,,3,"Description
Repeat step 2 until all PERC slots have been tested with a PCIe SSD.

Input Data
",Same results.,,,,,
,,,,,,4,"Description
Install at least one SAS or SATA drive and at least one PCIe SSD in the SAS/SATA slots (ie. the SAS or SATA drive on slot 0 and the PCIe SSD on slot 1). ** this step is N/A on blade systems.

Input Data
","PCIe SSD is not detected in the system.

Status LED blinks identify pattern (Green on/off).

Lifecycle Log reports incorrect drive type on slot detected ""Invalid Device Type Installed""

SAS/SATA drive Status LED is solid Green",,,,,
,,,,,,5,"Description
Install a SAS/SATA drive in one of the PCIe SSD slots

Input Data
","The Status LED blink identify (Green on/off) and is not detected in the system
SEL reports incorrect drive type on slot detected ""Invalid Device Type Installed""
",,,,,
,,,,,,6,"Description
Repeat step 5 until all PCIe SSD slots have been tested

Input Data
",Same results,,,,,
Backplane Drive Type Evaluation for 15G,TC-16932,Active,Manual,This test is intended to validate the backplane's determination of the drive type.,,1,"Description
Select an NVMe-only U.2 slot and identify the slot's PCIe port BDF.  This will be the parent BDF of an NVMe endpoint device inserted in the slot.

Input Data
",implicit,ESG-TC-113064,,,,
,,,,,,2,"Description
Remove any drives and examine the Presence Detect bit in the Slot Status Register

Input Data
",The PD bit should be off (zero).,,,,,
,,,,,,3,"Description
Insert a SAS drive into the slot and examine the Presence Detect bit in the Slot Status Register

Input Data
",The PD bit should still be off,,,,,
,,,,,,4,"Description
Remove the SAS drive and insert and NVMe device into the slot.  Examine the Presence Detect bit in the Slot Status Register

Input Data
",The PD bit should now be on (one),,,,,
PCIeSSD - Orderly Removal,TC-18741,Active,Manual,This test is used to confirm that the low-level orderly removal process if functional.,,1,"Description
Boot to the OS with 2.5"" NVMe devices in the system

Input Data
",The devices are discovered in the OS,ESG-TC-111888,,,,
,,,,,,2,"Description
Open the OS logging mechanism (e.g. Event Viewer in Windows or tail -f /var/log/messages in Linux)

Input Data
",The OS logs are being recorded,,,,,
,,,,,,3,"Description
Windows - 
Go to the bottom right-corner taskbar and click the ""^"" symbol.
Select the USB icon

Linux -
Go to /sys/bus/pci/slots/<SLOT> # The correct SLOT can be determined by looking at the contents of the address file or using grep command
For example
grep -ir 0000:e4:00


Input Data
","Windows - 
The NVMe drives are enumerated

Linux - 
The correct SLOT folder is found and a file exists named, ""power""",,,,,
,,,,,,4,"Description
Windows - 
Select the NVMe device to cause the safe removal process

Linux - 
echo 0 > /sys/pci/slots/SLOT/power # where SLOT is the value you determined in the previous step


Input Data
","The NVMe drive is removed from the system.

On Windows, the OS logs the removal.

On Linux, the OS is not required to log the removal.",,,,,
,,,,,,5,"Description
Remove the drive from the slot, either manually, or using a quarch.


Input Data
",No crashes or aberrant behavior is observed.,,,,,
,,,,,,6,"Description
Re-insert the drive back into the same slot

Input Data
",The NVMe drive is fully discovered,,,,,
,,,,,,7,"Description
Repeat steps 2-4

Input Data
",Same results as above,,,,,
,,,,,,8,"Description
Repeat steps 2-6 on another other drive slots (all drive slots if reasonable)

Input Data
",Same results as above,,,,,
PCIeSSD: Hotplug - Surprise Removal after Unhandled Insertion,TC-18998,Active,Manual,The point of this test is to analyze the subsystem behavior when a device is immediately removed after just have been inserted.,-,1,"Description
Boot into the OS with no hot-pluggable PCIe SSDs in the system

Input Data
",Implicit,ESG-TC-97340,,,,
,,,,,,2,"Description
Hot insert a PCIe SSD into the system

Input Data
",N/A,,,,,
,,,,,,3,"Description
Immediately remove the PCIe SSD from the system

Input Data
","The PCIe SSD does not show up in the OS (PCI bus, NVMe driver loaded, or disk mgmt utilities)",,,,,
,,,,,,4,"Description
Repeat steps 2-3 an additional 5 more times

Input Data
",Same expected outcomes as in steps 2 and 3,,,,,
PCIe SSD - UEFI NVMe Crypto Erase - Format NVM vs. Sanitize,TC-22499,Active,Manual,"This test case is intended to make sure that the UEFI driver sends the correct kind of Cryptographic Erase. If the drive supports Sanitize, then it should be sent, else falling back to Format NVM is the expected behavior.",,1,"Description
Insert a drive that supports the NVMe Sanitize command and a drive that does not and only supports Format NVM

Optional: If possible, insert a device that doesn't support either Sanitize or Format NVM (there are probably no drives that support neither one)


Input Data
",Implicit,ESG-TC-103746,,,,
,,,,,,2,"Description

Connect a PCIe analyzer to the system such that the traffic to the NVMe devices can be captured.

(Note: it is possible to run this test without using an analyzer by examining the contents of the drive's Sanitize log page after each step and noting how the status bits change.)

Input Data",implicit,,,,,
,,,,,,3,"Description
Power on the server and boot to the HII

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Go to the Physical Device Operations section for the device that supports Sanitize and issue the operation

Input Data
",The operation completes successfully and the PCIe trace shows that an NVMe Sanitize was used instead of a Format NVM,,,,,
,,,,,,5,"Description
Go to the Physical Device Operations for the device that only supports Format NVM and issue the operation

Input Data
",The operation completes successfully and the PCIe trace shows that a Format NVM was sent to the drive instead of a Sanitize,,,,,
,,,,,,6,"Description
If you have a device that does not support Sanitize or Format NVM, the operation to perform Cryptographic Erase should either be greyed out or not available

Input Data
",Cryptographic Erase should either be greyed out or not available,,,,,
PCIeSSD: PCIe - Read Tracking on Bridge with Unresponsive Endpoint,TC-22931,Active,Manual,"This test case is intended to test the Read Tracking feature of the Dell PCIe Extender Card. In the event that an endpoint device suddenly stops responding, then normally a Completion Timeout would be generated. However, with the Read Tracking feature, a response of all Fs should be synthesized by the bridge downstream port, along with a Completer Abort event.",,1,"Description
Connect a PCIe analyzer between the Root Port and a PCIe Extender card that has the Read-Tracking capability enabled. The system should not have the option to mask CTO but if it does then make sure CTO masking is disabled

Input Data
",Implicit,ESG-TC-67805,,,,
,,,,,,2,"Description
Boot into a supported operating system

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Note down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD

Input Data
","The MSI Address register is captured and should start with ""0xFEExxxxx""",,,,,
,,,,,,4,"Description
Start generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD

Input Data
",The PCIe Configuration Reads are being responded to,,,,,
,,,,,,5,"Description
Begin recording on the PCIe analyzer

Input Data
",The analyzer starts recording successfully,,,,,
,,,,,,6,"Description

Have the PCIe SSD stop responding to the Configuration Reads (do not stop the tool/script that's issuing the config. reads). 


For example, in the case of PM1725a, a drive with special Error Injection firmware is used.  The drive is cabled as a USB COM port.  Setting up the com port is per instruction found at NVMe\NVME_PCIeSSD\Tools\UART_Capture\Setup.  The command used for this step are:  urdev =1 to stop drive from responding.  urdev=0 to put drive back to normal state



Input Data
",The operating system crashes,,,,,
,,,,,,7,"Description
Trigger the PCIe analyzer to stop recording

Input Data
",The trace is captured and uploaded to the test case,,,,,
,,,,,,8,"Description
From the PCIe trace, find the Non-Posted request that was ignored by the endpoint (it will have a completion type of Completer Abort)

Input Data
",The Completer Abort is found,,,,,
,,,,,,9,"Description
From the PCIe trace, zero the timestamp of the Non-Posted Request that received the Completer Abort

Input Data
",The amount of time between the command being issued and the Completer Abort completion is 60ms,,,,,
PCIeSSD: Hotplug - Detailed Hot Insertion Verification,TC-26558,Active,Manual,This test case is intended to test the full hot insertion behavior of the PCIe SSD subsystem as well as the operating system.,,1,"Description
Connect a PCIe analyzer between the root port and a PCIe bridge card that has the Read Tracking capability enabled. The system should not have the option to mask CTO but if it does make sure that CTO masking is disabled

Input Data
",Implicit,ESG-TC-77956,,,,
,,,,,,2,"Description
Boot into a supported operating system with no hotpluggable PCIe SSDs in the system

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Note down the value of the PCIe config. space MSI Address Register of the parent above the PCIe SSD

Input Data
","The MSI Address register is captured and should start with ""0xFEExxxxx""",,,,,
,,,,,,4,"Description
Begin recording on the PCIe analyzer

Input Data
",The analyzer starts recording successfully,,,,,
,,,,,,5,"Description
Insert the PCIe SSD

Input Data
","The operating system does not crash and the PCIe SSD is enumerated from the OS
    * Windows - The PCIe SSD immediately (within 5s) shows up from the Windows Device Manager, ""Storage Controllers"" section
    * Linux - The PCIe SSD immediately (within 5s) shows up after running the command, ""lspci""
    * ESXi - The PCIe SSD immediately (within 5s)shows up after running the command, ""lspci""",,,,,
,,,,,,6,"Description
Trigger the PCIe analyzer to stop recording

Input Data
",The trace is captured and uploaded to the test case,,,,,
,,,,,,7,"Description
From the PCIe trace, find the first hotplug interrupt where the PCIe SSD was inserted
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,8,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted

Input Data
","The Presence Detect State (PDS) =1

Presence Detect State Changed (PDSC) = 1

Data Link Layer State Changed (DLLSC) = 0",,,,,
,,,,,,9,"Description
From the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted

Input Data
","The Presence Detect State (PDS) =1

Presence Detect State Changed (PDSC) = 1

Data Link Layer State Changed (DLLSC) = 0",,,,,
,,,,,,10,"Description
From the PCIe trace, find the second hotplug interrupt where the PCIe SSD was inserted
    * The interrupt will be a MemWr to the MSI Address Register that was deduced earlier in the test case


Input Data
",Implicit,,,,,
,,,,,,11,"Description
From the PCIe trace, a config. read is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted

Input Data
","The Presence Detect State (PDS) =1

Presence Detect State Changed (PDSC) = 0

Data Link Layer State Changed (DLLSC) = 1",,,,,
,,,,,,12,"Description
From the PCIe trace, a config. write is issued to the Slot Status Register of the parent above the PCIe SSD that was inserted

Input Data
","The Presence Detect State (PDS) =1

Presence Detect State Changed (PDSC) = 0

Data Link Layer State Changed (DLLSC) = 1",,,,,
PCIe SSD - Orderly Removal Operation Dynamically Available,TC-31081,Active,Manual,This test case is used to test that a hot inserted device is allowed to be orderly removed from iDRAC.,,1,"Description
Boot into the OS with no NVMe drives, waiting a few minutes to allow iDRAC I2C discovery to occur

Input Data
",Implicit,ESG-TC-111889,,,,
,,,,,,2,"Description
Navigate to the ""Configuration->Storage Configuration"" section of the iDRAC GUI

Input Data
",There are no NVMe PCIe SSDs listed,,,,,
,,,,,,3,"Description
Hot insert an NVMe drive

Input Data
","The PCIe SSD get's enumerated in the ""Configuration->Storage Configuration"" view

NOTE that a ""refresh"" may be needed",,,,,
,,,,,,4,"Description
Select the drop-down ""Action"" menu

Input Data
","The option to ""Prepare to remove"" is available",,,,,
PCIe SSD - iDRAC - SEL Logging of Hotplug Events,TC-35143,Active,Manual,This test case is intended to test that NVMe hotplug operations are getting logged into the iDRAC SEL.,,1,"Description
Boot into the operating system and wait a few minutes for iDRAC to finish I2C discovery if starting from a cold boot

Input Data
",Implicit,ESG-TC-111690,,,,
,,,,,,2,"Description
If there are 2.5"" NVMe drives already in the system, remove them from the system

Input Data
","The SEL log shows an entry for each drive that was removed and it's location.  For tests run on systems with DPC, you will see 5 entries (1 Critical Error listing the drive removal, 2 warnings, one PCIe correctable error for the drive and one for the parent port, one warning about a low severity error, listing the Bay and Slot of the drive you removed, and an informational event noting that an OEM diagnostic event occurred.
",,,,,
,,,,,,3,"Description
Insert NVMe drives back into the system

Input Data
",The SEL log shows an entry for each drive that was inserted and it's location,,,,,
PCIe SSD ESXi DPC: Multiple Error Injection at endpoint & it's upstream port  with EDR notification/recovery check (ESXi Only),TC-35868,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported ESXi version that has EDR functionality enabled and also has acpi logging enabled. 

esxcli system settings kernel set -s acpiDbgLevel -v 2

(Could be verified by checking DPC control register of parent port above endpoint) 

Also increase the error threshold to higher value. 
esxcli system settings advanced set -o /Misc/PcieErrRecovErrLimit -i 15
and verify
esxcli system settings advanced list -o /Misc/PcieErrRecovErrLimit




Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-125805,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
vsish -e set /hardware/pci/seg/0/bus/196/slot/0/func/0/pciConfigReg/size/2/addr/0x10 0xffff 1

Here 196 = bus (in decimal) for the endpoint bdf

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/vmkernel.log


Input Data
","check if 
1) ""ACPI event 0xf"" is received
2) Port experienced DPC
3) Error recovery done

are logged in /var/log/vmkernel.log
",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Use following commands to determine the handle and issue identify

esxcli device driver list
esxcli nvme device get -A vmhba5


Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Repeat step 2-3 at least four times 

Input Data
","The device get's enumerated successfully after each recovery. 
The device is visible in 
""esxcli nvme device list""",,,,,
,,,,,,5,"Description
repeat step 2-4 instead inject error on upstream port by using Malformed TLP mechanism. 

Input Data
",The devices are visible in OS,,,,,
PCIe SSD - Operating Systems - DSM,TC-43325,Active,Manual,"The objective of this test case is to ensure that the DSM name is showing up for the PCIe SSDs of all form factors, and that it's correct.",,1,"Description
Boot into a supported OS with at least one 2.5"" PCIe SSD. 

Input Data
",The OS detects all PCIe SSDs in the system and loads the driver for them.,ESG-TC-63,,,,
,,,,,,2,"Description
If Windows -
Computer Management->Device Manager->Storage Controllers
Right-click one of the PCIe SSDs and select ""Properties""
Click the ""Details"" tab
Click the Property drop-down and select the ""PCI label string""
Else if Linux -
Run the attached dslot.sh shell script
Else if ESXi -
There is a tool called ""smbiosDump"" that will display the SMBIOS/DSM information


Input Data
","PCIe SSD in Slot X in Bay Y (where X is the slot number, and Y is the backplane ID)",,,,,
,,,,,,3,"Description
If Windows - Repeat step 2 for the other form factor PCIe SSD (the Linux shell script will show all devices)

Input Data
",Same results,,,,,
,,,,,,,,,,,,,
PCIe SSD - Max_Payload_Size Verification w/o Hotplug,TC-43995,Active,Manual,"This test case is used to verify that the Max_Payload_Size being used is always set to the same value, regardless of the presence of devices or not.",,1,"Description
Boot into the Dell UEFI shell with no NVMe devices in the system

Input Data
",System boots,ESG-TC-103683,,,,
,,,,,,2,"Description
Discover the PCIe topology for all NVMe slots. 
For CPU direct-attach slots, it will just be a single CPU root port BDF. 
For PCIe switch-connected slots, it will be something like: CPU Root Port -> Switch Upstream Port -> Switch Downstream Port.

NOTE that the easiest way of doing this is imply to look-up the information on the PCIeSSD Confluence page. Look for the ""Slot BDF Mapping"" page.


Input Data
",The PCIe BDF topology is dsicovered for all NVMe slots,,,,,
,,,,,,3,"Description
Read the Device Control register from PCIe config. space for the CPU root port at the top of the tree for each slot.

The UEFI command to read PCIe config space is ""pci BUS DEVICE FUNCTION -i"", ie ""pci 65 00 00 -i"" for a BDF of 65:00.0.  This command takes BDFs in hex.

To specifically read the Max_Payload_Size, you can take advantage of DellGrep (only in the Dell UEFI shell) and run this for example: ""pci 65 00 00 -i | DellGrep Max_Payload_Size""


Input Data
",The configured Max_Payload_Size is set to 256B for each root port,,,,,
,,,,,,4,"Description
Read the Max_Payload_Size field from the Device Control Register from the CPU root port all the way down to the switch downstream port (if applicable)

Input Data
",The Max_Payload_Size is set to 256B for all BDFs,,,,,
,,,,,,5,"Description
Shutdown the system

Input Data
",Implicit,,,,,
,,,,,,6,"Description
Insert NVMe devices into the slots that were checked previously and boot into the Dell UEFI shell

Input Data
",The system boots successfully and all NVMe devices are discovered,,,,,
,,,,,,7,"Description
Repeat steps 3 and 4

Input Data
",Same results,,,,,
,,,,,,8,"Description
Read the Max_Payload_Size field from the Device Control Register of the NVMe devices

Input Data
",Each device has the Max_Payload_Size set to 256B,,,,,
PCIe SSD - 15G Hot Insertion PERST# Logic Validation,TC-44299,Active,Manual,This test case will be used to determine the PERST# logic that applies when hot inserting an NVMe device is correctly functioning.,"For the documented steps, you will need an oscilloscope, but this test has an automation script, so it is not strictly required.",1,"Description
Confirm from the test notes that this test case is applicable to your SUT

Input Data
",Implicit,ESG-TC-113063,,,,
,,,,,,2,"Description
Connect the NVME_PRES, PERST#, and P4 signals to an oscilloscope

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Power on the server

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Configure the oscilloscope to trigger on the falling edge of NVME_PRES

Input Data
",Trigger enabled,,,,,
,,,,,,5,"Description
Configure the horizontal divisions to be 500ms

Input Data
",Implicit,,,,,
,,,,,,6,"Description
Configure the vertical divisions for both signals to be 1V

Input Data
",Implicit,,,,,
,,,,,,7,"Description
Hot insert an NVMe drive

Input Data
","The trigger occurs

==============================
Before the trigger occurs, P4 and NVME_PRES are both high (~3.3V).  PERST# is low (~0V).

Upon insertion of the device, P4 immediately transitions to 0V.

One second after insertion, PERST transitions to high, and NVME_PRES transitions to low.
",,,,,
PCIe SSD - iDRAC Health Poll Dynamic NVMe Health Change,TC-44399,Active,Manual,This test case is intended to make sure that the iDRAC can detect an NVMe device that goes into a failure state during runtime.,,1,"Description
Boot into the operating system with at least one U.2 NVMe PCIe SSD that supports Dell PowerEdge NVMe Error Injection (or any other vendor proprietary way of injecting NVMe critical warnings without the need of a reboot)

Wait between 5-10 minutes once in the OS to allow the iDRAC to fully initialize


Input Data
",The system boots and detects the NVMe device(s),ESG-TC-103714,,,,
,,,,,,2,"Description
Check the Status LED of the NVMe device

Input Data
",The Status LED is solid green,,,,,
,,,,,,3,"Description
Put the device into a failed state:
    * NVM Subsystem Reliability Degraded
    * Volatile Memory Backup Failed
    * Read Only
    * (special case) Available spare below threshold
    * (special case) Temperature above threshold


Input Data
","The device successfully goes into the failed state (can be verified by an in-band Get Log Page -SMART/Health command)

Within 1 minute, the Status LED is now in the following state:
    * Read only, Back fail, or reliability degraded:  blinking amber/off
    * Spare below threshold:  blinking amber/green/off
    * Temperature:  solid green (normal operation, no physical indicator)",,,,,
,,,,,,4,"Description
D/C cycle the server and repeat the above steps, but choosing a different failure reason than before

Input Data
",Same results as earlier,,,,,
,,,,,,5,"Description
D/C cycle the server and repeat the above steps, but this time choose for the device to go into Approaching Read-Only mode instead of one of the failure scenarios

Input Data
",The status LED should now blink Green/Amber,,,,,
PCIe SSD - SMBIOS Bay/Slot Information,TC-50677,Active,Manual,This test validates if the correct Bay/Slot information for U.2 NVMe devices is correctly populated into the SMBIOS Type 9 table.,,1,"Description
Insert NVMe devices into all applicable NVMe slots on the backplane.

*If not enough devices are available to populate all slots at one time, then test as many as possible, power off, then move the devices to the next slots and re-test. Perform this until all slots have been tested.


Input Data
",Implicit,ESG-TC-103657,,,,
,,,,,,2,"Description
Boot into an operating system or UEFI shell

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Get the PCIe BDFs of each of the U.2 NVMe devices in the system (lspci, Device Manager->Storage Contollers, etc.)

Input Data
",BDFs are obtained for all U.2 NVMe PCIe SSDs,,,,,
,,,,,,4,"Description
Dump the SMBIOS table

Windows:
RWEverything -> SMBIOS

Linux:
dmidecode

UEFI shell (Note you need to be using the Dell UEFI shell):
smbios


Input Data
","Windows:
   1. Go to the Type 9 section
   2. Find the entry that has one of the U.2 NVMe bus numbers you saved
   3. Check the ""Slot Location"" and confirm it's the correct location for the given device
Linux:
   1. Go to the Type 9 section (grep for DMI type 9)
   2. Find the entry tat has a bus address equal to one of the U.2 NVMe bus numbers you saved
   3. Check the ""Designation"" and confirm it's the correct location for the given device

",,,,,
,,,,,,5,"Description
Repeat steps 4 for all slots

Input Data
",Same results as in step 4,,,,,
PCIe SSD - PLX PCIe Switch Port Eye Diagram Capture,TC-51432,Active,Manual,The purpose of this test case is to check the signal integrity for all ports of the PCIe switch by capturing the eye diagrams.,,1,"Description
Install U.2 NVMe devices into each backplane slot that connects to a PLX PCIe switch

NOTE if you don't have enough drives to populate all slots at one time, then power cycle the server and move your drives to the next slots and repeat the test until all slots have been covered.


Input Data
",Implicit,ESG-TC-103742,,,,
,,,,,,2,"Description
If the operating system does not support the PLX SDK (ESXi or the UEFI shell), then connect an Aardvark to the debug I2C port on the switch.

Else install the PLX SDK onto the SUT


Input Data
",Aardvark is connected or PLX SDK is installed directly onto the SUT,,,,,
,,,,,,3,"Description
Launch the PLX PEX Device Editor software and select the Serdes Eye Width operation

Input Data
",A SerDes Eye tab opens,,,,,
,,,,,,4,"Description
Use the Select a Port drop-down menu to choose a port (only choose a port that actually has an NVMe drive plugged into it)

Click the Click to Draw Eye button


Input Data
","The test completes and you see the eye ""open""

The data may need to be analyzed by a hardware engineer to determine pass/fail",,,,,
,,,,,,5,"Description
Repeat the test for all possible NVMe slots

Input Data
",Same results,,,,,
PCIeSSD: PCIe - Completion Timeout Reporting with Unresponsive Endpoint,TC-52181,Active,Manual,"This test case is intended to test that in the event that an endpoint device suddenly stops responding, a Completion Timeout is generated and correctly logged.",,1,"Description
Make sure the SUT is a CPU direct-attach system, a switch configured system cannot be used.


Input Data
",Implicit,ESG-TC-109611,,,,
,,,,,,2,"Description
Boot into a supported operating system

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Determine the parent PCIe BDF to the PCIe SSD

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Start generating continuous Non-Posted requests (PCIe config. reads) to the PCIe SSD

Input Data
",The PCIe Configuration Reads are being responded to,,,,,
,,,,,,5,"Description
Have the PCIe SSD suddenly stop responding to the Non-Posted Requests

NOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.


Input Data
","If the OS and platform do not support Downstream Port Containment, the system crashes.

If DPC is supported, then the OS should log a Completion Timeout and attempt to recover.",,,,,
,,,,,,6,"Description
Dump the system SEL (e.g. racadm getsel -E)

Input Data
","If no DPC support, there's an entry for a Completion Timeout logged by the root port above the endpoint that stopped responding.

With DPC support, there will be a DPC event logged with a reason of Completion Timeout.",,,,,
Backplane Drive Type Evaluation for 14G,TC-57125,Active,Manual,This test is intended to validate the backplane's determination of the drive type.,,1,"Description
Re-work one of the NVMe drive slots on the backplane according to the test configuration notes.

Input Data
",The wires have been added,ESG-TC-103529,,,,
,,,,,,2,"Description
Connect the oscilloscope probes to the P4, P10, and NVMe_PRES wires.

Input Data
",The probes are added and channels are enabled.,,,,,
,,,,,,3,"Description
Configure the oscilloscope to trigger on the falling edge of the P4 signal.

Set the horizontal divisions to 200ms divisions.

Set the vertical divisions for P4, P10, and NVME_PRES to 1V.


Input Data
",The oscilloscope is configured,,,,,
,,,,,,4,"Description
Power on the server with no drive plugged into the slot that's been wired for the measurement

Input Data
",The server powers on and boots into an operating system or UEFI environment,,,,,
,,,,,,5,"Description
Hot insert an NVMe drive into the slot

Input Data
",The oscilloscope triggers,,,,,
,,,,,,6,"Description
Analyze the oscilloscope capture

Input Data
","   1. The time before the trigger, all three signals were high (3.3V)
   2. At the trigger, the P4 signal went low (0V) while the other two signals remained high
   3. *500ms later, the P10 signal remains high, but the NVME_PRES went low
*The parts are allowed to have some small deviation from 500ms. E.g. 490ms, 510ms, etc. but should not vary much more than that",,,,,
PCIe SSD: identify physical device in HII,TC-57740,Active,Manual,Verify user can locate/identify a PCIe SSD through HII.,,1,"Description
Install at least one PCIe SSD of each capacity in the system and boot to HII.

Input Data
",Implicit.,ESG-TC-177,,,,
,,,,,,2,"Description
Navigate to Physical Device Operations menu option.

Input Data
",Blink/Ublink operations are displayed and active (they are not grayed out).,,,,,
,,,,,,3,"Description
Initiate identify on a PCIe SSD. (Blink)

Input Data
","1. Blink operation starts successfully

2. The PCIe SSD is blinking its status LED",,,,,
,,,,,,4,"Description
Select Unblink.

Input Data
","1. Unblink operations starts successfully

2. The PCIe SSD stops blinking its activity LED",,,,,
,,,,,,5,"Description
Repeat steps 3 and 4 but select to blink more than one device. For Unblink, unblink one drive first, wait 10 seconds, unblink the second device.

Input Data
","For blink: user is able to blink more than one device at the same time.


For unblink: unblink of one device does not disrupt the LED pattern of the other drive(s), ie. other device continues to blink until user selects unblink.",,,,,
PCIe SSD - Correctable/Uncorrectable Error Check after I/O,TC-63651,Active,Manual,This test case is intended to check the signal integrity to the NVMe devices.,,1,"Description
Boot to the operating system with NVMe devices populated behind each cable routed to the backplane

Input Data
",The system boots and the devices are discovered,ESG-TC-103716,,,,
,,,,,,2,"Description
Disable correctable error reporting for all NVMe drives, and parents BDFs above them (write to PCIe Cfg Space - Device Control Register)

Clear the Correctable Error Mask register


Input Data
",Correctable Error Reporting is disabled and all errors have been masked,,,,,
,,,,,,3,"Description
Begin running I/O to all of the devices and allow it to run for 70 minutes
While I/O is in progress, poll the Correctable Error Status registers of the NVMe drives and parents of the drives


Input Data
","I/O runs successfully
No correctable errors are detected",,,,,
,,,,,,4,"Description
Dump the system event log (e.g. racadm getsel -E)

Input Data
",There are no Correctable or Uncorrectable errors being reported by the NVMe devices or parent of the NVMe devices in the log,,,,,
,,,,,,5,"Description
Reboot the system and repeat steps 2-4 an additional 9 times

Input Data
",Same results,,,,,
PCIe SSD - DPC - Error containment & recovery,TC-64460,Active,Manual,The test case is intended to check if the Error generated by end point is contained and a recovery is attempted ,,1,"Description
Boot to OS & BIOS that supports DPC and enabled with at least one PCIe SSD

Input Data
",System boots without error and device is visible to OS,ESG-TC-116566,,,,
,,,,,,2,"Description
Note down the BDF of the endpoint and try to inject a FATAL/Non-Fatal error . 
Ex- A malformed TLP can be generated by changing MPS of endpoint causing mismatch with the root port.  


Input Data
",,,,,,
,,,,,,3,"Description
The device Max Payload Size has been changed and reflected in config space 

Input Data
",,,,,,
,,,,,,4,"Description
Run heavy IO to device to make sure error is generated in short time

Input Data
",/var/log/message logs when the error is generated and can be seen there ,,,,,
,,,,,,5,"Description
Check /var/log/message and make sure DPC event triggered information is logged along with successful device recovery 

Input Data
",The expected functionality was logged correctly ,,,,,
PCIe SSD DPC: Port Containment with Unresponsive Endpoint,TC-67703,Active,Manual,"This test case is intended to test that in the event that an endpoint device suddenly stops responding, a Completion Timeout is generated and correctly logged.",,1,"Description
Make sure the SUT is a CPU direct-attach system, a switch configured system cannot be used

Input Data
",Implicit,ESG-TC-125157,,,,
,,,,,,2,"Description
Boot into a supported config which has DPC support both from BIOS as well as OS

Input Data
",Implicit,,,,,
,,,,,,3,"Description
Determine the parent PCIe BDF to the PCIe SSD

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Start generating continuous I/O to the device

Input Data
",The I/O starts without any issue ,,,,,
,,,,,,5,"Description
Have the PCIe SSD suddenly stop responding to the Non-Posted Requests

NOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.


Input Data
",The system doesn't crash,,,,,
,,,,,,6,"Description
Dump the PCIe CFG space of parent port and check DPC Trigger Status 

Input Data
","For Linux:

The DPC Trigger Status should be set

For ESXi:

The DPC Trigger Status should be clear, and the device driver is not loaded for the endpoint (drive). NOTE: ESXi does not leave the port in containment, and instead takes it out to unload the driver)",,,,,
,,,,,,7,"Description
Check the OS message for recovery failure and EDR event triggered 

Input Data
",The message indicates EDR event and also recovery failure,,,,,
,,,,,,8,"Description
Check the SEL log for DPC event 

Input Data
",The SEL log has DPC event captured,,,,,
PCIe SSD DPC: Error threshold check and SEL decoding check  (Linux Only),TC-69183,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. 
Check test case notes
Also clear SEL logs before starting the test


Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-121134,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
setpci -s bdf 0x10.w=0xffff 

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/message or syslog  


Input Data
","check if 
1) ACPI event 0xf received
2) containment event, status:0x1f03 source:0xe300
3) device recovery successful

are logged in /var/log/message ",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Repeat steps 2-3 14 times

Input Data
","The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. 
",,,,,
,,,,,,5,"Description
Insert 15th error to the same end point 
and get the SEL logs


Input Data
","The end point devices is not visible and DPC Status is set to triggered mode. 
Get the SEL logs and make sure there are 14 DPC error event and 1 Fatal error event. 
Also, check if the SEL decoding is correct and logging right event and errors along with right bdf",,,,,
PCIeSSD: Export Log via Support Assist,TC-69196,Active,Manual,Collect Support Assist bundle and verify inventory for each installed PCIeSSD (NVMe),,1,"Description
Install NVMe PCIe SSDs and boot to a supported OS.

Input Data
",Implicit.,ESG-TC-371,,,,
,,,,,,2,"Description
Place your system on the network such that you're able to remotely access it via iDRAC.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Log into the iDRAC GUI and go into the ""Maintenance -> Support Assist"" section

Click on the Start a Collection button

In the Data to Collect section, select all options

In the Collection Preferences section, select Save Locally

Click Collect


Input Data
",The collection completes successfully,,,,,
,,,,,,4,"Description
Extract the zip file that gets generated

Extract the zip file inside of that zip file as well

Navigate into the tsr -> storagelog directory


Input Data
",There should be files for each NVMe drive present,,,,,
,,,,,,5,"Description
Open each file

Input Data
",The SMART/Health and Error Information is present and accurate (this can be confirmed via Get Log Page from an in-band tool),,,,,
PCIe SSD - LED Management - The status LED must turn on to solid green within a few seconds of the backplane receiving power.,TC-69641,Active,Manual,Validate that the healthy device status LED turns on to solid green within a few seconds of the backplane receiving power.,,1,"Description
Install atleast one healthy PCIe SSDs and a backplne in the system Note: Make sure that the system is up to date.Specially the Backplane and the PCIe SSD

Input Data
",The status LED is solid Green.,ESG-TC-256,,,,
,,,,,,2,"Description
Check the status LED of the device as soon as you boot the system

Input Data
","The status LED of the device should turn on green as soon as the Backplane is powered on.



Note: Usually the staus LED is set to solid green within 1-3 second after the system is booted.",,,,,
,,,,,,3,"Description
Wait till the system boots to OS and check the LED of the drives

Input Data
",The LED of the drive stays solid green,,,,,
,,,,,,4,"Description
Reboot the system and check the status LED of the drives

Input Data
",The status LED of the drive should stay Green all the time.,,,,,
PCIe SSD - Completion Timeout Value Verification,TC-70512,Active,Manual,This test case is used to make sure that the completion timeout value being programmed from the CPU root port on down is correct,,1,"Description
Boot into an operating system or UEFI shell with NVMe devices in the system

Input Data
",The devices are discovered,ESG-TC-103658,,,,
,,,,,,2,"Description
Find out the parent BDF to the NVMe devices

Windows:
Device Manager -> View by Connection

Linux:
lspci -t


Input Data
",The parent BDFs for each NVMe drive are captured,,,,,
,,,,,,3,"Description
Dump PCIe config. space for each parent BDF determined in the previous step

Input Data
",PCIe config. space is successfully captured,,,,,
,,,,,,4,"Description
Check the Device Control 2 Register, bits 0-3

Input Data
",The value decodes to 0x6,,,,,
PCIe SSD: downgraded PCIe link speed,TC-73519,Active,Manual,TestDrive TestCase Objective was not specified.,,1,"Description
See Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card known to train at downgraded link speed (ie. if Gen3 PCIe SSD, the PCIe SSD trains at Gen1 or Gen2).

Input Data
",Implicit.,ESG-TC-108,,,,
,,,,,,2,"Description
Power on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link speed.

Input Data
","BIOS halts due to link down train error, reporting the actual versus expected speed. 

The error is reported to screen with the BDF of the parent of the NVMe device. 

There is an entry for this error in the Lifecycle Log.

If the system is 15G or newer, then the bay and slot of the link degradation is reported as well.",,,,,
,,,,,,3,"Description
Repeat steps 1 and 2 but with ""F1/F2 Prompt On Error"" BIOS option disabled.

Input Data
",Same results as above except the BIOS does not pause during POST,,,,,
PCIe SSD: HII Physical Disk Properties,TC-75007,Active,Manual,Verify:1. Physical Disks are displayed correctly2. Physical Disk Properties are displayed correctly3. Help content is displayed correctly,,1,"Description
Install a PCIe SSD in the system of each capacity and boot to HII.

Input Data
",Implicit.,ESG-TC-84,,,,
,,,,,,2,"Description
Navigate to the ""View Physical Device Properties"" menu option.

Input Data
","1. Under Physical Disk Properties, following fields listed:
    * Physical Device ID
    * Form Factor
    * State
    * Capacity
    * Bus Protocol (PCIe)
    * Bus Protocol Version
    * Device Protocol, 
    * Device Life Remaining (AHCI)/Remaining Rated Write Endurance (NVMe)
    * Failure Predicted
    * Firmware revision
    * Serial number
    * Model number
    * Capable Transfer Speed (AHCI)/PCIe Maximum Link Speed(NVMe)
    * PCIe Maximum Link Width
    * PCIe Negotiated Link Width 
 2. Physical Device ID is in the form of:
    * AHCI X:Y:Z (Port:Bay:Slot)
    * NVMe ""PCIe SSD in Slot (Slot#) in Bay (Bay#)
    * NVMe HHHL Adapter: ""PCIe SSD in Slot (Slot#)"" 
 3. All fields are non-editable strings. 

 4. All options/fields will display corresponding help text at the bottom of the screen or in the help screen.",,,,,
PCIe SSD - I2C Communication to all Available NVMe Slots,TC-82414,Active,Manual,This test case is intended to validate that I2C communication is allowed to propgate to all possible NVMe slots in the system.,,1,"Description
Boot into the operating system with all U.2 NVMe slots populated and at least one AIC

NOTE if you don't have enough drives to populate all backplane slots, then simply shutdown the server and move the current drives to the remaining slots until all have been tested.


Input Data
",The boot is successful and all devices are detected,ESG-TC-103715,,,,
,,,,,,2,"Description
Issue an NVMe-MI command to each backplane slot (and wherever the AIC PCI slot is). For example, the command could be the NVM Subsystem Health Status Poll:

libi2ctest -pec -d -c I2C_Bus_Num 100 100 0 -v 0x20 -a 0xD4 -r 27 0xf 0x19 0x21 0x1 0x0 0x0 0xc8 0x84 0x8 0x0 0x0 0x1 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xd2 0xd4 0x77 0x36 30

NOTE that the I2C_Bus_Num will have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file in the iDRAC filesystem

Or the NVMeMICLI.py tool can be used in place

Example of a Passing test output using NVMeMICLI.py

python3 NVMeMICLI.py -c ns -b 1 -s 1
Clear Status (0 or 1) = 0
WARNING:root:Backplane - No type match found for BP type 389 in I2Ctopology, guessing...


0x00000: 20 0F 19 3B 01 00 00 C0 84 88 00 00 00 00 00 00 ..;............
0x00010: 38 FF 24 01 00 00 00 00 AF B1 49 94 59 8.$.......I.Y


Reserved - 0x0
NVM Subsystem Status - 0x38
Smart Warnings - 0xff
Composite Temperature - 36
Percentage Drive Life Used - 1
Composite Controller Status - 0x0


Input Data
","The I2C command is successful (no NAK, Unknown error, or Timeout) for all NVMe backplane slots as well as the AIC",,,,,
PCIe SSD - SEP Memory Map Dynamic Drive Presence Detection,TC-85396,Active,Manual,This test case is used to ensure that the SEP memory map will dynamically store the correct state of whether an NVMe drive is present in the system or not.,,1,"Description
Boot the system

Input Data
","Implicit[root@rhel91 neuron]# nvme list
Node Generic SN Model Namespace Usage Format FW Rev
--------------------- --------------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
/dev/nvme4n1 /dev/ng4n1 1240A00YTX47 Dell NVMe CD7 E3.S 1.92TB 1 5.12 GB / 1.92 TB 512 B + 0 B 2.0.0
/dev/nvme3n1 /dev/ng3n1 1240A01FTX47 Dell NVMe CD7 E3.S 1.92TB 1 524.29 MB / 1.92 TB 512 B + 0 B 2.0.0
/dev/nvme2n1 /dev/ng2n1 12T0A01UTX57 Dell NVMe CD7 E3.S 3.84TB 1 6.83 GB / 3.84 TB 512 B + 0 B 2.0.0
/dev/nvme1n1 /dev/ng1n1 Z1H0A067TX57 Dell NVMe CD7 E3.S 3.84TB 1 11.27 GB / 3.84 TB 512 B + 0 B 2.0.0
/dev/nvme0n1 /dev/ng0n1 Y1J0A077TX47 Dell NVMe CD7 E3.S 1.92TB 1 319.97 GB / 1.92 TB 512 B + 0 B 2.0.1
[root@rhel91 neuron]#",ESG-TC-111890,,,,
,,,,,,2,"Description
ssh or serial into the iDRAC and go to the iDRAC console (rootshell or gilchrist or racadm debug invoke rootshellash)

Input Data
",root access to the iDRAC is obtained,,,,,
,,,,,,3,"Description
Run the ""bptest"" command

Input Data
",Implicit,,,,,
,,,,,,4,"Description
Select the SEP number of where you're planning on inserting drives

Input Data
",Implicit,,,,,
,,,,,,5,"Description
Select the ""Drive Area"" sub-menu and verify that the presence information is correct

Input Data
",,,,,,
,,,,,,6,"Description
Insert NVMe drives into all available NVMe drive slots

Input Data
",Implicit,,,,,
,,,,,,7,"Description
Re-read the ""Drive Area"" section (may require to exit bptest and re-start it)

Input Data
",The newly inserted drives correctly show that there are NVMe drives present in the correct slots,,,,,
,,,,,,8,"Description
Removal all of the NVMe drives from the system

Input Data
",Implicit,,,,,
,,,,,,9,"Description
Re-read the ""Drive Area"" section (may require to exit bptest and re-start it)

Input Data
",The removed drives correctly show as the slots no longer have any NVMe drives present,,,,,
PCIe SSD: discovery after A/C power cycle (long term),TC-85765,Active,Manual,Verify PCIe SSDs are reliably discovered after A/C power.,,1,"Description
Verify that the system is updated with the latest revisions for BMC/iDRAC, backplane, BIOS, CPLD, etc.

Input Data
",Implicit.,ESG-TC-208,,,,
,,,,,,2,"Description
Attach the maximum number of PCIe SSDs permitted by the system configuration.

Input Data
",Implicit.,,,,,
,,,,,,3,"Description
Clear the system's SEL log.

Input Data
",SEL log cleared.,,,,,
,,,,,,4,"Description
Boot into the OS and ensure system logs in automatically

Input Data
",Implicit.,,,,,
,,,,,,5,"Description
Use a controllable PDU to remove AC power from the system after the system boots and the attempt has been made to discover all PCIe SSD devices. This will require some tweaking of parameters depending on how long the device discovery takes.
Sequence should look like: boot --> OS login --> Device Detection --> AC power off --> repeat

Input Data
",Test is set up to run unattended.,,,,,
,,,,,,6,"Description
Allow the system to repeat the A/C cycle for at least 12 hours.

Input Data
","No memory or system initialization errors, or PCIe SSD errors are found. All PCIe SSDs are still accesible.",,,,,
,,,,,,7,"Description
If applicable, check the device debug log for any errors.

Input Data
",No errors found.,,,,,
PCIe SSD DPC: Hot removal/insertion after  error Injection on different endpoints  (Linux Only),TC-88986,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. 
Check test case notes



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-121127,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
setpci -s bdf 0x10.w=0xffff 

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/message or syslog  


Input Data
","check if 
1) ACPI event 0xf received
2) containment event, status:0x1f03 source:0xe300
3) device recovery successful

are logged in /var/log/message ",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Repeat the steps 2-3 on a different end point

Input Data
",The devices are properly enumerated,,,,,
,,,,,,5,"Description
Hot remove  both the drives on which error  was injected & recovered

Input Data
",The devices are removed and not visible both at PCI and NVMe level,,,,,
,,,,,,6,"Description
Hot insert the drives back in the same slots

Input Data
",devices are enumerated properly,,,,,
PCIe SSD: downgraded PCIe link width,TC-93173,Active,Manual,"Verify if a PCIe SSD SFF drive trains at a lower link width than advertised max capable, the BIOS reports an error but let's user continue booting without issues when prompted.

Note:There is no BIOS notification for HHHL/AIC cards that train at a lower link with. BIOS notification  only supported on SFF devices.
",,1,"Description
See Configuration Notes and Software requirements in Setup section. Install at least one PCIe SFF SSD device known to train at downgraded link width (or use the Quarch to disable lanes 2 and 3).

To configure a quarch to cause a link width downtrain:
1) log into your quarch
2) Issue the following to your target module:
    ""signal:lane#:source 0 <X>""
         - X is the number of the quarch module (ie quarch slot) you want to downtrain
         - # is the lane to downtrain, 0 through 3
         - ie:  ""signal:lane3:source 0 <1>""   will disable lane 3 on module 1
3) Repeat step 2 for all lanes you wish to disable
        - lanes 2 and 3 to cause a device to train to x2

To restore normal function, set your lanes to source 8.


Input Data
",Implicit.,ESG-TC-337,,,,
,,,,,,2,"Description
Power on the system and let it boot through POST. Verify through 2nd source (ie. iDRAC) the PCIe link width.

Input Data
","BIOS halts due to link down train error

The error is reported to screen with correct BDF

There is an entry for this error in the Lifecycle Log

If the system is 15G or newer, then the bay and slot location of the failure will be reported as well",,,,,
,,,,,,3,"Description
Press F1 to continue.

Input Data
",System continues to boot without issues. PCIe SSD device is accessible through the OS without any issues.,,,,,
,,,,,,4,"Description
Reboot the system.

Input Data
",Same results.,,,,,
,,,,,,5,"Description
DC power cycle the system (press power button to turn off/on, wait 10 seconds in between).

Input Data
",Same results.,,,,,
,,,,,,6,"Description
AC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).

Input Data
",Same results.,,,,,
,,,,,,7,"Description
Repeat steps 1 and 2 but with ""F1/F2 Prompt On Error"" BIOS option disabled.

Input Data
",Same as above except the BIOS should not pause during POST,,,,,
PCIe SSD: link training issues,TC-93174,Active,Manual,Verify correct error handling is in place when a PCIe link training error occurs.,,1,"Description
See Configuration Notes and Software requirements in Setup section. Install at least one PCIe SSD or PCIe extender card that fails to complete link training (or use the Quarch to turn off all lanes). Install at least one known good PCIe SSD.

Input Data
",Implicit.,ESG-TC-239,,,,
,,,,,,2,"Description
Power on the system and let it boot through POST.

Input Data
","BIOS pauses at an F1/F2 prompt displaying that a link training error has occurred.

The error is reported to screen with correct BDF. 

User can proceed system boot with F1 or F2.

If the system is a 15G or newer, then the bay and slot of where the training failure occurred should be shown.",,,,,
,,,,,,3,"Description
Reboot the system.

Input Data
",Same results.,,,,,
,,,,,,4,"Description
DC power cycle the system (press power button to turn off/on, wait 10 seconds in between).

Input Data
",Same results.,,,,,
,,,,,,5,"Description
AC power cycle the system (remove AC power cable and re-insert, wait 10 seconds in between).

Input Data
",Same results.,,,,,
,,,,,,6,"Description
Repeat steps 1 and 2 but with ""F1/F2 Prompt On Error"" BIOS option disabled.

Input Data
","Same results except the BIOS won't pause in POST, although the messaging should still be the same.",,,,,
PCIe SSD: HII Export Log,TC-94156,Active,Manual,Verify HII Debug Log page displays the correct properties. Verify user is able to save the debug log (smart data) for all drives in the system using Export Log.,,1,"Description
Install at least two different PCIe SSDs models or capacities in the system and boot to HII. (Include the PCIe SSD models and capacities used in the test's Overall Notes)

Input Data
",System boots to HII and PCIe SSD configuration utility is displayed and accessible (for each PCIe SSD if applicable: NVMe).,ESG-TC-170,,,,
,,,,,,2,"Description
Navigate to Export Log (note that this step will have to be re-run twice: one with a filesystem inserted into the system, and one without -- no need to power cycle, just exit the screen and re-enter).

Input Data
","1. Save Debug Log page will show the following options/fields:

Select File System target (header)

Select File System (link)


Select Directory (header)

Directory list selection


Export Log File path (header)

File path


Export Log (link)




2. All options/fields display corresponding help text at the bottom of the screen.
",,,,,
,,,,,,3,"Description
Select a file system target (ie. if there is more than one USB key inserted)

Input Data
","1. All attached file systems are listed under ""Select File System Target"". The default (root) directory should be selected by default.

2. ""Select File System Target"" (link) can be used to change currently selected File System.",,,,,
,,,,,,4,"Description
Select a directory.

Input Data
","1. All attached directories are listed under ""Select Directory"". The default (root) directory should be selected by default.

2. User can choose appropriate directory to save the file to under ""Select Directory"".

3. ""Select Directory"" (link) can be used to change currently selected Directory.",,,,,
,,,,,,5,"Description
Select Export Log.

Input Data
","Message displayed is ""Log saved successfully. PCIeSSD_(date time string).log"".


For NVMe PCIe SSD log, User can choose the any filename with extension .log",,,,,
,,,,,,6,"Description
Boot into your OS and retrieve the log saved in step 6 from your USB key and verify SMART/Health information, and NVMe error log (if applicable) is displayed for all drives correctly. Logs saved on the USB key will be visible as normal. Logs saved to file systems will be in the EFI partition of the OS. This will be mounted as normal in Linux. In windows, get an Administrator powershell prompt, and type ""mountvol P: /S"" (P can be any available mount point). Logs can then be viewed under P:\ as normal.

Input Data
",Data and values are returned correctly for all drives.,,,,,
,,,,,,7,"Description
Repeat steps 3-6 but ensure you have a file system target that contains no directories (step 4 will be skipped in this case).

Input Data
",Same results.,,,,,
PCIe SSD - I2C Drive FRU Validation,TC-94528,Active,Manual,"Verify FRU using CM538_A09_Modular_FRU_Specification.pdfTwo sections to verify, Board Information (p.15) and Thermal Information (p.111)Instructions on how to access and verify the FRU located in RAID Server > NVMe > FRU > FRU_Validation_Instructions.docx",,1,"Description
Read the device FRU from I2C of a shipping system using the following commands (alternatively, automation script GetPCIeSSDFRU.py can be used):
U.2 NVMe PCIe SSD
libi2ctest -c Virtual_BUS 100 100 0 -a 0xA6 -m 0 1 0 256

AIC NVMe PCIe SSD
libi2ctest -c I2C_bus_num 100 100 0 -a 0xA6 -m 0 1 0 256

# the Virtual_Bus and I2C_Bus_Num fields would have to be decoded from the /mnt/persistent_data/data0/BMC_Data/I2CTopology.bin file on the iDRAC filesystem



Input Data
",The FRU data is successfully read,ESG-TC-188,,,,
,,,,,,2,"Description
Using the same drive(s) that was used in step 1, put those into the new SUT and again read the FRU as in step 1

NOTE that the virtual/I2C bus number are likely different and need to be updated


Input Data
",The FRU data is successfully read,,,,,
,,,,,,3,"Description
Compare the FRU contents from step 1 and step 2

Input Data
",There are no differences,,,,,
PCIe SSD ESXi DPC: Port Containment with Unresponsive Endpoint (ESXi Only),TC-102266,Design,Manual,,"Make sure the SUT is a CPU direct-attach system, a switch configured system cannot be used for this test case",1,"Boot into a supported config which has DPC support both from BIOS as well as ESXi OS version
",Implicit,,,,,
,,,,,,2,"Determine the parent PCIe BDF to the PCIe SSD under test.(the DUT here is NVMe device with special firmware that can go unresponsive)

",Implicit,,,,,
,,,,,,3,"Start generating continuous I/O to the device
",The I/O starts without any issue,,,,,
,,,,,,4,"Have the PCIe SSD suddenly stop responding to the Non-Posted Requests


NOTE this will probably require special firmware to accomplish. For example, the Samsung devices can do this by using the urdev 1 command from the UART interface.","The system doesn't crash and EDR event is logged in the OS log
",,,,,
,,,,,,5,Check the OS log and look for recovery failure message,There will be recovery failure message post EDR event logging as the device won't come back up,,,,,
,,,,,,6,"Dump the PCIe CFG space of parent port and check DPC Trigger Status 
","The DPC Trigger Status should be cleared.


Note: BIOS puts the port in Software Triggered DPC but ESXi brings the port back from containment.",,,,,
,,,,,,7,"Check the SEL log for DPC event 
","The SEL log has DPC event captured
",,,,,
GHES Recovery: Error event severity marked as non-recoverable upon crossing threshold (deprecated),TC-23886,Active,Manual,"This test case checks upon crossing the error threshold, the error severity is marked as non-recoverable instead of recoverable. ",,1,"Description
Boot to the Non-DPC aware OS that supports error recovery. Clear SEL logs before starting the test case. 

Input Data
",The system boots and all devices are visible. ,ESG-TC-118837,,,,
,,,,,,2,"Description
Inject PCIe errors  upto the threshold (16 errors) on NVMe devices and check OS logs. Upon crossing the threshold the error severity is marked as non-recoverable. 
Ex- UR or Malformed TLP 


Input Data
","The correct error severity is set upon crossing the threshold. 

",,,,,
,,,,,,3,"Description
Check the SEL logs

Input Data
",The SEL logs have all the errors logged with correct BDF and error type information,,,,,
GHES Recovery: Crash with Non-Recoverable OS on PCIe error injection,TC-50046,Active,Manual,The test case is to make sure OS that doesn't support recover crash after receiving FATAL/Non-Fatal  error. ,,1,"Description
Boot to the OS that doesn't support recovery.
Clear SEL logs


Input Data
",The system boots without any issue and all nvme devices are visible,ESG-TC-118851,,,,
,,,,,,2,"Description
Inject errors such as UR or Malformed TLP is generated by the nvme device. 

Input Data
","The system crashes . (BSOD,PSOD etc) ",,,,,
,,,,,,3,"Description
Check the SEL Logs and decode 

Input Data
",Make sure the correct errors are logged. ,,,,,
GHES Recovery : Recovery attempted by fatal/non-fatal error injection,TC-97303,Active,Manual,The test case verify if the BIOS set's fatal/non-fatal error as recoverable if within threshold and system doesn't crash if recovery was attempted and successful ,,1,"Description

Boot into the system that supports GHES Recovery and OS that supports recovery . Make sure you have debug messages enabled . For example on Linux.

Add following kernel boot parameters

acpi.debug_layer=0xffffffff acpi.debug_level=0x2



Input Data
",The system boots without any errors. ,ESG-TC-117714,,,,
,,,,,,2,"Description

Clear the SEL logs and clear the OS logs if possible (ex- dmesg --clear)

Inject a Fatal or Non Fatal errors on one of the  NVMe device. You can either generate Malformed TLP, UR or any other PCIe errors.


Input Data
","It's OS discretion to attempt recovery but most OS does. 
The error reported back by BIOS is marked as ""Recoverable"" . Check OS logs (/var/log/message) to see relevant messages.  ",,,,,
,,,,,,3,"Description
Check the SEL logs and make sure the error was logged. 
 


Input Data
",The errors are logged in the SEL and if recovery was successful device will be available for use. ,,,,,
PCIe SSD DPC: Multiple error Injection on same endpoint & its upstream port with EDR notification/recovery check (Linux Only),TC-88957,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. 
Check test case notes



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-121078,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
setpci -s bdf 0x10.w=0xffff 

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/message or syslog  


Input Data
","check if 
1) ACPI event 0xf received
2) containment event, status:0x1f03 source:0xe300
3) device recovery successful

are logged in /var/log/message ",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Inject error on up stream port . 
This can be done in many ways. 
For example 
Change MPS of up stream  port that is less than endpoint Max Payload Size
Run some I/O to the device


Input Data
","EDR notification sent to same events are noticed as in step 2
Make sure the device below the port is accessible and enumerated.",,,,,
,,,,,,5,"Description
Repeat steps 1-4 at least 2 times

Input Data
",Endpoint device is enumerated properly,,,,,
PCIe SSD DPC: Error Injection at endpoint & its upstream port  with EDR notification/recovery check (Linux Only),TC-67861,Active,Manual,The test case checks PCIe UC fatal as well as non fatal error handling and recovery using EDR mechanism ,,1,"Description
Boot into a supported OS that has EDR functionality enabled and also has acpi logging enabled. 
Check test case notes



Input Data
",All NVMe devices are enumerated and no errors are logged in OS logs. ,ESG-TC-121077,,,,
,,,,,,2,"Description
Inject error on a NVMe device using any of error injection methods. 
For example following command can be used along with some transaction. 
setpci -s bdf 0x10.w=0xffff 

or Malformed TLP can be injected using mismatched MPS settings.

Make sure you have another terminal with running OS log, 
tail -f /var/log/message or syslog  


Input Data
","check if 
1) ACPI event 0xf received
2) containment event, status:0x1f03 source:0xe300
3) device recovery successful

are logged in /var/log/message ",,,,,
,,,,,,3,"Description
Issue identify controller to the device and make sure device is enumerated both at pci as well as nvme level if the recovery was successful.

Input Data
",The endpoint device is available and enumerated at both PCI as well as nvme driver is loaded. ,,,,,
,,,,,,4,"Description
Inject error on up stream port . 
This can be done in many ways. 
For example 
Change MPS of up stream  port that is less than endpoint Max Payload Size
Run some I/O to the device


Input Data
","EDR notification sent to same events are noticed as in step 2
Make sure the device below the port is accessible and enumerated.",,,,,
OMSA: Verify 'Crypto Erase Sanitize' is issued,TC-3422,Active,Manual,"Verify OMSA issues a Sanitize erase (vs. a Format NVM, etc).",,1,"Description
Insert (or boot with) an NVMe device that supports sanitize Crypto Erase. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5

Install the latest version of OMSA.


Input Data
",Implicit.,ESG-TC-119870,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than what an OMSA-issues Crypto Erase sanitize will present. It is recommended to do this in Linux.

nvme sanitize /dev/nvme7n1 -a 2 -u 1 

Collect the sanitize log once the operation has completed. 

Linux:

nvme sanitize-log /dev/nvme7n1

Windows:

python NVMeMICLI.py -c gl -b 0 -s 1
Controller ID = 0x0000
Namespace ID = 0xffffffff
Log Page ID = 0x81
Log Page Sub ID = 0x00
Number of DWORDS = 0x08
Retain Asynchronous Event = 1


Input Data
","
The erase operation succeeds. 

Sanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xa
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

",,,,,
,,,,,,3,"Description
Now, issue a Crypto Erase via OMSA while using the OS intended for this testcase, whether that be Linux, Windows or ESXi.

Dump the sanitize get-log page to determine the type of erase issued, e.g.:

Linux: 

nvme sanitize-log /dev/nvme7n1 

Windows:

python NVMeMICLI.py -c gl -b 0 -s 1
Controller ID = 0x0000
Namespace ID = 0xffffffff
Log Page ID = 0x81
Log Page Sub ID = 0x00
Number of DWORDS = 0x08
Retain Asynchronous Event = 1


Input Data
","The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xc
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

See the Sanitize Status Log section of the NVMe spec for a full decode of the log.

If SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.

Note: Until OMSA implements JIT-154745, SCDW10 will be '0x4,' indicating Crypto Erase sanitize in restricted mode. 

",,,,,
Sanitize: BIOS Handling in POST,TC-12291,Active,Manual,,,1,"Description
Boot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: 

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5

It is recommended to use a Linux OS to initiate the Block Erase sanitize operation.


Input Data
",Implicit.,ESG-TC-120984,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

Confirm the sanitize operation is in progress via:

nvme sanitize-log /dev/nvme7n1 

Hot remove the device prior to the completion of the sanitize operation.


Input Data
",The sanitize operation is successfully launched; the NVMe device is removed prior to completion of the sanitize operation.,,,,,
,,,,,,3,"Description
Power down the machine. Once the machine is off, insert the NVMe device and power on the machine.




Input Data
",The sanitize operation should resume immediately following application of power to the NVMe device slot. The drive should not exit POST prior to the completion of the sanitize operation. A message may be printed to the screen indicating a sanitize operation is in progress.,,,,,
Verify Crypto Erase Method in HII and iDRAC,TC-12934,Active,Manual,,,1,"Description
Boot to the OS with an NVMe device that support Cryptographic Erase sanitize. Sanitize Crypto Erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5

Install the latest version of OMSA.

It is recommended to use Linux for its passthru command capabilities.


Input Data
",Implicit.,ESG-TC-120980,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the Crypto Erase command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode. The  motivation is to create a Sanitize Status log entry that will have data different than that created by a management software-issued Crypto Erase.

To issue the Block Erase sanitize:

nvme sanitize /dev/nvme7n1 -a 2 -u

Collect the sanitize log once the operation has completed. 

Linux:

nvme sanitize-log /dev/nvme7n1


Input Data
","The erase operation succeeds. 

Sanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize was performed in unrestricted mode. Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xa
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0",,,,,
,,,,,,3,"Description
In the iDRAC GUI, navigate to Configuration -> Storage Configuration. Select the 'Cryptographic Erase' action and the 'Apply at Next Reboot' option; click 'Apply.' Reboot the machine.

Following the execution of the Cryptographic Erase operation via LC (and once the machine has booted to the OS), read the Sanitize log:

nvme sanitize-log /dev/nvme7n1




Input Data
","The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xc
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

If SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.
",,,,,
,,,,,,4,"Description
Next, repeat step 2 in order to update the Sanitize log with data to reflect a Block Erase operation.

Once that is finished and verified, boot to HII. Navigate the NVMe device page and issue a Cryptographic Erase. Then, boot to the OS and read the Sanitize log:

nvme sanitize-log /dev/nvme7n1

 


Input Data
","The erase succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xc
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

If SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.",,,,,
,,,,,,5,"Description
(Optional)

Repeat steps 2 and 3, this time selecting the 'Apply at Scheduled Time' operation mode in the iDRAC GUI.


Input Data
","The erase is performed at the expected time and subsequently succeeds; Sanitize Command Dword 10 should indicate '0xc,' which decodes to Crypto Erase Sanitize (in unrestricted mode). Additionally, SSTAT is '0x101,' indicating the operation completed successfully and the 'Global Data Erased' bit is set. Finally, 'SPROG' is 65536, indicating the operation is 100% complete. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 65535
Sanitize Status (SSTAT) : 0x101
Sanitize Command Dword 10 Information (SCDW10): 0xc
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

If SCDW10 is not '0xc,' the test case fails. Similarly, SSTAT and SPROG must have the values specified above.",,,,,
Verify Sanitize Operation Execution Time and Status Updates,TC-41116,Active,Manual,"Confirm sanitize operation execution time is consistent with the 'estimated time' fields in the Sanitize Status log. Additionally, verify the 'SPROG' and 'SSTAT' fields are updated as expected while a sanitize operation is in progress.",,1,"Description
Boot to the OS with an NVMe device that supports Block Erase and Crypto Erase sanitize. Sanitize erase support can be verified via the 'SANICAP' parameter in Identify Controller data structure. This can be verified via:

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5


It is recommended to use Linux for its passthru command capabilities.


Input Data
",Implicit.,ESG-TC-120981,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1 

Begin timing the operation immediately upon issuing the command. Monitor the Sanitize Status log while the operation is in progress by repeatedly issuing

nvme sanitize-log /dev/nvme7n1

until the operation completes. Stop the timer once the operation completes.  (The operation is complete once 'SSTAT' is 0b101). 


Input Data
","While the operation is in progress, the 'SPROG' and 'SSTAT' fields are updated, For example:

Sanitize Command Dword 10 in the Sanitize Status log should indicate '0xa,' which indicates a Block Erase Sanitize in Unrestricted Completion Mode was initiated. 'SPROG' contains a value less than 65536, indicating the fraction of the operation that has been completed at the time of the log read. Finally, 'SSTAT' is 0b010, indicating a sanitize operation is in progress. For example:

linux-g03y:~ # nvme sanitize-log /dev/nvme7n1
Sanitize Progress (SPROG) : 32335
Sanitize Status (SSTAT) : 0x002
Sanitize Command Dword 10 Information (SCDW10): 0xa
Estimated Time For Overwrite : 0
Estimated Time For Block Erase : 93
Estimated Time For Crypto Erase : 0

Additionally, the timed value of the operation execution duration is withink 10% of the value reported in the 'Estimated Time for Block Erase' field. In the example above, the log indicates the operation is estimated to take 93 s on this particular device.",,,,,
,,,,,,3,"Description
Repeat step 2 for a Crypto Erase sanitize:
nvme sanitize /dev/nvme7n1 -a 4 -u 1 



Input Data
","Analogous to the expectation for step 2. Note that a Crypto Erase sanitize may complete virtually instantly (in less than 1 s). Hence, it may not be feasible to time this operation manually nor to observe SPROG and SSTAT at 'in progress' values. However, SCDW10 should be set to '0xc' to indicate a Crypto Erase in Unrestricted Mode was performed. 


",,,,,
,,,,,,4,"Description
(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).

Repeat step 2 using the Overwrite sanitize operation (if the device supports this method):

nvme sanitize /dev/nvme7n1 -a 3 -u 1


Input Data
","Analogous to the expectations for step 2. In particular, pay attention to the time it takes to execute the operation and compare this value to the estimated time listed in the Sanitize Status log. ",,,,,
,,,,,,5,"Description
If the device is NVMe rev 1.4 compliant, repeat step 2 using the 'no deallocate' option during the sanitize erase:

nvme sanitize /dev/nvme7n1 -a 2 -u 1 -d




Input Data
","Analogous to the expectations for step 2. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4).",,,,,
,,,,,,6,"Description
If the device is NVMe rev 1.4 compliant, repeat step 3 using the 'no deallocate' option during the sanitize erase:

nvme sanitize /dev/nvme7n1 -a 4 -u 1 -d



Input Data
","Analogous to the expectations for step 3. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4).",,,,,
,,,,,,7,"Description
(Omit Overwrite, as it is unlikely we have any devices that support this operation. Furthermore, our PowerEdge sanitize b-spec intentionally omits handling for this method).

If the device is NVMe rev 1.4 compliant (and support Overwrite sanitize), repeat step 4 using the 'no deallocate' option during the sanitize erase:

nvme sanitize /dev/nvme7n1 -a 3 -u 1 -d


Input Data
","Analogous to the expectations for step 4. However, note that a different estimated timing parameter is in use when the operation is issued using the 'no deallocate' option. (This field for Estimated Time with No Deallocate is only present on devices compliant with NVMe rev 1.4).",,,,,
Sanitize hot remove / hot insert; OS Handling,TC-61166,Active,Manual,"Confirm sanitize operation behavior if interrupted by a hot remove (and following a reinsertion). Furthermore, confirm OS behavior following a hot insertion of a drive with a sanitize operation in progress.",,1,"Description
Boot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: 

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5

It is recommended to use a Linux OS to initiate the Block Erase sanitize operation. If this TC was intended to be run in Windows, initiate the operation via Linux and then hot insert the device to the DUT running Windows.


Input Data
",Implicit.,ESG-TC-120983,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

Confirm the sanitize operation is in progress via:

nvme sanitize-log /dev/nvme7n1 

Hot remove the device prior to the completion of the sanitize operation.


Input Data
",The sanitize operation is successfully launched and interrupted via a hot removal of the device prior to completion.,,,,,
,,,,,,3,"Description
Reinsert the NVMe device. Check the progress of the sanitize operation:

nvme sanitize-log /dev/nvme7n1

In Windows, check the progress of the operation via:

Windows:

python NVMeMICLI.py -c gl -b 0 -s 1
Controller ID = 0x0000
Namespace ID = 0xffffffff
Log Page ID = 0x81
Log Page Sub ID = 0x00
Number of DWORDS = 0x08
Retain Asynchronous Event = 1

Continue monitoring the progress of the operation until it completes. Furthermore, check to ensure the device is enumerated in the system device tree; check OS errors logs, etc.


Input Data
","The sanitize operation should resume on the device; eventually, the sanitize operation completes successfully.

The OS enumerates the NVMe device.

No abnormal or critical errors are logged.",,,,,
,,,,,,4,"Description
Install OMSA.

If debug FW is available (or an NVMe device in sanitize failure mode is available), while the OS is up hot insert a drive in sanitize failure mode into the system.

Input Data
","The NVMe device is enumerated by the OS. 

OMSA lists the device and initially presents a warning or alert status indicating a recovery action is needed on the device. OMSA presents an option to perform a Cryptographic Erase on the device.

No abnormal or critical errors are logged.",,,,,
,,,,,,5,"Description
If debug FW is available (or an NVMe device in sanitize failure mode is available), attempt to perform a FW update via DUP on the device. 

Input Data
",The DUP update should fail with an error message indicating the failure was due to the device being in sanitize failure mode and should suggest corrective action of sanitizing the device. ,,,,,
Sanitize: Permitted vs. Non-Permitted Commands,TC-96244,Active,Manual,"While a sanitize operation is in progress, confirm permitted commands execute successfully and that non-permitted commands are aborted.",,1,"Description
Boot to the OS with an NVMe device capable of Block Erase sanitize (higher capacities preferred). Sanitize erase support can be verified via the 'SANICAP' parameter in the Identify Controller data structure: 

nvme id-ctrl /dev/nvme7n1 -H |grep sanicap -a5


Input Data
",Implicit.,ESG-TC-120982,,,,
,,,,,,2,"Description
Before beginning, it is recommended to verify the target device is not that on which the OS is installed prior to issuing the sanitize command.

Issue a sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

Confirm the sanitize operation is in progress via:

nvme sanitize-log /dev/nvme7n1 


Input Data
",The sanitize operation is sucessfully launched.,,,,,
,,,,,,3,"Description
While the sanitize operation remains in progress, issue the following permitted commands:

nvme smart-log /dev/nvme8n1
nvme error-log /dev/nvme8n1
nvme id-ctrl /dev/nvme8n1
nvme id-ns /dev/nvme8n1
nvme get-feature /dev/nvme8n1 -f 7
echo ""abcdef"" | nvme set-feature /dev/nvme7n1 -f 0x81 -l 8
nvme get-feature /dev/nvme7n1 -f 0x81

It is crucial that the sanitize operation be in progress while these commands are submitted. Monitor the Sanitize Status log frequently to confirm the operation is in progress:

nvme sanitize-log /dev/nvme7n1 


Input Data
",All of the commands complete successfully while the sanitize operation is in progress.,,,,,
,,,,,,4,"Description
Upon completion of the first sanitize operation, Issue another sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

While the sanitize operation remains in progress, issue the following MI command:

python3 NVMeMICLI.py -c gl -b X -s Y

where the NVMe device is in Bay X and Slot Y. Enter the following parameters when prompted:

Controller Id - 0x0000
Namespace Id - 0xffffffff
Logpage Id - 0x02
Log page Sub Id - 0x00
Number of DWords - 0xxff
Retain Async Event - 0


Confirm the sanitize operation is in progress before and after issuing the above MI command via:

nvme sanitize-log /dev/nvme7n1 


Input Data
",The MI command completes successfully while the sanitize operation is in progress.,,,,,
,,,,,,5,"Description
Create a small file with some text data. For example,

vi /root/Documents/mydata.txt

Enter some text, ""This is my data in my file!"" and save.

Issue another sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

While the sanitize operation is in progress, attempt to write data to the device:

hexdump mydata.txt > /dev/nvme7n1

Again, confirm the sanitize operation is in progress before and after attempting the write to the device:

nvme sanitize-log /dev/nvme7n1 


Input Data
","The write to the NVMe device undergoing the sanitize operation should fail. (Hence, the 'hexdump' command should fail).",,,,,
,,,,,,6,"Description
Issue another sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

While the sanitize operation is in progress, issue the following commands to the device:

nvme fw-log /dev/nvme7n1
nvme device-self-test /dev/nvme7n1 -s 1

Verify the targeted device supports device self test before issuing the command. And once again, verify the sanitize is in progress before and after the above commands:

nvme sanitize-log /dev/nvme7n1
 


Input Data
",The 'fw-log' and 'device-self-test' commands fail while the sanitize operation is in progress.,,,,,
,,,,,,7,"Description
If the device supports telemetry logs and persistent event logging, issue another sanitize Block Erase to the NVMe device in unrestricted mode:

nvme sanitize /dev/nvme7n1 -a 2 -u 1

While the sanitize operation is in progress, issue the following commands to the device:

nvme telemetry-log /dev/nvme7n1 -o output.bin
nvme get-log /dev/nvme7n1 -i 0x0d -l 0x20


Once again, verify the sanitize is in progress before and after the above commands:

nvme sanitize-log /dev/nvme7n1


Note: The persistent event log command above needs to be verified on a device that supports PEL.


Input Data
",The telemetry and persistent event log commands fail while the sanitize operation is in progress.,,,,,
,,,,,,8,"Description
Issue another sanitize Block Erase to the NVMe device in unrestricted mode.

nvme sanitize /dev/nvme7n1 -a 2 -u 1

While the sanitize operation is in progress, attempt a DUP update of FW on the device.

Verify the sanitize is in progress before and after launching the DUP:

nvme sanitize-log /dev/nvme7n1
 


Input Data
","The DUP update should fail and provide an error message that specifies the reason for the failure (a sanitize was in progress on the device) and suggest corrective action (reattempt the update after the sanitize operation has finished). It should also indicate that if repeated attempts to execute the DUP receive the same error message, it is recommended that the drive be sanitized via HII.",,,,,
